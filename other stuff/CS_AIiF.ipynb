{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "############################################################\n",
    "# 0. Setup and Initial Checks + dtype fixes\n",
    "############################################################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import describe\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "\n",
    "df = pd.read_csv(\"data.csv\",low_memory=False)\n",
    "\n",
    "# 0.1 Datetime conversion\n",
    "if 'datadate' in df.columns:\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'], errors='coerce')\n",
    "\n",
    "# 0.2 Numeric conversion for price columns (prcc_c, prcc_f)\n",
    "for col in ['prcc_c', 'prcc_f']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# 0.3 Panel key types (safe even if some values are non-numeric)\n",
    "for col in ['gvkey', 'fyear', 'ismod']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "\n",
    "# 0.4 Categorical columns\n",
    "for col in ['indfmt', 'datafmt', 'consol']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "    len(df)\n",
    "print(df.dtypes)\n",
    "print(\"Numeric columns:\", len(df.select_dtypes(include=[np.number]).columns))\n",
    "print(\"Categorical columns:\", len(df.select_dtypes(include=['category']).columns))\n",
    "print(\"Datetime columns:\", len(df.select_dtypes(include=['datetime']).columns))"
   ],
   "id": "9508959a3cbb8558",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:04:59.843435Z",
     "start_time": "2025-12-18T15:04:59.370977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (df.isna().mean() * 100).sort_values(ascending=False)\n",
    "pd.DataFrame({\"missing_count\": missing_counts, \"missing_pct\": missing_pct})"
   ],
   "id": "7af54a0d886e6590",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75005 entries, 0 to 75004\n",
      "Data columns (total 89 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   gvkey     75005 non-null  Int64         \n",
      " 1   datadate  75005 non-null  datetime64[ns]\n",
      " 2   fyear     75005 non-null  Int64         \n",
      " 3   indfmt    75005 non-null  category      \n",
      " 4   datafmt   75005 non-null  category      \n",
      " 5   consol    75005 non-null  category      \n",
      " 6   ismod     75005 non-null  Int64         \n",
      " 7   conm      75005 non-null  object        \n",
      " 8   aco       68227 non-null  float64       \n",
      " 9   act       64284 non-null  float64       \n",
      " 10  ao        75000 non-null  float64       \n",
      " 11  aoloch    74543 non-null  float64       \n",
      " 12  ap        74917 non-null  float64       \n",
      " 13  apalch    44634 non-null  float64       \n",
      " 14  aqc       72193 non-null  float64       \n",
      " 15  at        75005 non-null  float64       \n",
      " 16  caps      71931 non-null  float64       \n",
      " 17  capx      74502 non-null  float64       \n",
      " 18  ceq       74856 non-null  float64       \n",
      " 19  che       74999 non-null  float64       \n",
      " 20  chech     74701 non-null  float64       \n",
      " 21  csho      74201 non-null  float64       \n",
      " 22  cstk      73080 non-null  float64       \n",
      " 23  cstke     75001 non-null  float64       \n",
      " 24  dlc       74974 non-null  float64       \n",
      " 25  dlcch     41862 non-null  float64       \n",
      " 26  dltis     73249 non-null  float64       \n",
      " 27  dltr      73617 non-null  float64       \n",
      " 28  dltt      74817 non-null  float64       \n",
      " 29  do        75004 non-null  float64       \n",
      " 30  dp        72283 non-null  float64       \n",
      " 31  dpc       73248 non-null  float64       \n",
      " 32  dv        73868 non-null  float64       \n",
      " 33  dvc       74302 non-null  float64       \n",
      " 34  dvp       74969 non-null  float64       \n",
      " 35  dvt       74299 non-null  float64       \n",
      " 36  esubc     68207 non-null  float64       \n",
      " 37  exre      74613 non-null  float64       \n",
      " 38  fiao      74671 non-null  float64       \n",
      " 39  fincf     74690 non-null  float64       \n",
      " 40  fopo      74574 non-null  float64       \n",
      " 41  ib        75005 non-null  float64       \n",
      " 42  ibadj     75005 non-null  float64       \n",
      " 43  ibc       74551 non-null  float64       \n",
      " 44  intan     74351 non-null  float64       \n",
      " 45  invch     69690 non-null  float64       \n",
      " 46  invt      74353 non-null  float64       \n",
      " 47  ivaco     74678 non-null  float64       \n",
      " 48  ivaeq     71457 non-null  float64       \n",
      " 49  ivao      72476 non-null  float64       \n",
      " 50  ivch      72465 non-null  float64       \n",
      " 51  ivncf     74689 non-null  float64       \n",
      " 52  ivstch    55811 non-null  float64       \n",
      " 53  lco       68226 non-null  float64       \n",
      " 54  lct       64310 non-null  float64       \n",
      " 55  lt        74904 non-null  float64       \n",
      " 56  mibt      74163 non-null  float64       \n",
      " 57  mkvalt    62655 non-null  float64       \n",
      " 58  niadj     75005 non-null  float64       \n",
      " 59  nopi      74993 non-null  float64       \n",
      " 60  oancf     74702 non-null  float64       \n",
      " 61  oibdp     72863 non-null  float64       \n",
      " 62  ppent     73282 non-null  float64       \n",
      " 63  prcc_c    69039 non-null  float64       \n",
      " 64  prcc_f    69029 non-null  float64       \n",
      " 65  prstkc    71595 non-null  float64       \n",
      " 66  pstk      74786 non-null  float64       \n",
      " 67  pstkn     74794 non-null  float64       \n",
      " 68  pstkr     74930 non-null  float64       \n",
      " 69  re        72409 non-null  float64       \n",
      " 70  recch     62416 non-null  float64       \n",
      " 71  rect      74125 non-null  float64       \n",
      " 72  seq       75002 non-null  float64       \n",
      " 73  siv       72706 non-null  float64       \n",
      " 74  spi       73879 non-null  float64       \n",
      " 75  sppe      62766 non-null  float64       \n",
      " 76  sppiv     71038 non-null  float64       \n",
      " 77  sstk      73569 non-null  float64       \n",
      " 78  tstk      74825 non-null  float64       \n",
      " 79  txach     52214 non-null  float64       \n",
      " 80  txbcof    74386 non-null  float64       \n",
      " 81  txdc      72533 non-null  float64       \n",
      " 82  txditc    65936 non-null  float64       \n",
      " 83  txp       67063 non-null  float64       \n",
      " 84  txt       74990 non-null  float64       \n",
      " 85  xi        75004 non-null  float64       \n",
      " 86  xido      75001 non-null  float64       \n",
      " 87  xidoc     74528 non-null  float64       \n",
      " 88  xint      64469 non-null  float64       \n",
      "dtypes: Int64(3), category(3), datetime64[ns](1), float64(81), object(1)\n",
      "memory usage: 49.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         missing_count  missing_pct\n",
       "dlcch            33143    44.187721\n",
       "apalch           30371    40.491967\n",
       "txach            22791    30.385974\n",
       "ivstch           19194    25.590294\n",
       "recch            12589    16.784214\n",
       "...                ...          ...\n",
       "fyear                0     0.000000\n",
       "datafmt              0     0.000000\n",
       "ibadj                0     0.000000\n",
       "ib                   0     0.000000\n",
       "niadj                0     0.000000\n",
       "\n",
       "[89 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dlcch</th>\n",
       "      <td>33143</td>\n",
       "      <td>44.187721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apalch</th>\n",
       "      <td>30371</td>\n",
       "      <td>40.491967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txach</th>\n",
       "      <td>22791</td>\n",
       "      <td>30.385974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ivstch</th>\n",
       "      <td>19194</td>\n",
       "      <td>25.590294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recch</th>\n",
       "      <td>12589</td>\n",
       "      <td>16.784214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fyear</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datafmt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ibadj</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ib</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niadj</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T15:09:22.025787Z",
     "start_time": "2025-12-18T15:09:21.908850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "############################################################\n",
    "# 1.a Data Cleaning Duplicates\n",
    "############################################################\n",
    "# Remove duplicates (panel-unique if possible)\n",
    "_before = len(df)\n",
    "if all(c in df.columns for c in ['gvkey', 'fyear']):\n",
    "    df = df.drop_duplicates(subset=['gvkey', 'fyear'], keep='last').reset_index(drop=True)\n",
    "else:\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "_after = len(df)\n",
    "print(f\"Duplicates dropped: {_before - _after}\")\n"
   ],
   "id": "20e244e93823c069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates dropped: 0\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "############################################################\n",
    "# 2. Data Cleaning Outlier Statistics\n",
    "#    - Only selected Compustat fields\n",
    "#    - Robust flags: IQR rule + MAD-based z-score\n",
    "############################################################\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# 2.1 Requested variables\n",
    "target_vars = [\n",
    "    \"sale\", \"ib\", \"ni\", \"xi\", \"xido\", \"dp\", \"xrd\", \"emp\",\n",
    "    \"ebit\", \"ebitda\", \"ob\", \"fca\", \"irent\"\n",
    "]\n",
    "\n",
    "# 2.1a Map ebit/ebitda if needed (Compustat mnemonics)\n",
    "if \"ebit\" not in df.columns and \"oiadp\" in df.columns:\n",
    "    df[\"ebit\"] = pd.to_numeric(df[\"oiadp\"], errors=\"coerce\")\n",
    "if \"ebitda\" not in df.columns and \"oibdp\" in df.columns:\n",
    "    df[\"ebitda\"] = pd.to_numeric(df[\"oibdp\"], errors=\"coerce\")\n",
    "\n",
    "# 2.2 Keep only those present (but keep ALL target_vars in diagnostics output)\n",
    "present_vars = [v for v in target_vars if v in df.columns]\n",
    "missing_vars = [v for v in target_vars if v not in df.columns]\n",
    "\n",
    "print(f\"[Outliers] Present vars: {present_vars}\")\n",
    "print(f\"[Outliers] Missing vars: {missing_vars}\")\n",
    "\n",
    "# 2.5 Compute per-variable stats + outlier counts (include missing target vars as diagnostic rows)\n",
    "summaries = []\n",
    "flag_cols = []\n",
    "\n",
    "# Add explicit rows for missing target vars so they are not \"dropped\" from diagnostics\n",
    "for v in missing_vars:\n",
    "    summaries.append({\n",
    "        \"var\": v,\n",
    "        \"n_nonmissing\": 0,\n",
    "        \"missing_pct\": 100.0,\n",
    "        \"note\": \"missing in df (not available for outlier flagging)\"\n",
    "    })\n",
    "\n",
    "if not present_vars:\n",
    "    summary_df = pd.DataFrame(summaries)\n",
    "\n",
    "    if not summary_df.empty and \"missing_pct\" in summary_df.columns:\n",
    "        summary_df = summary_df.sort_values([\"missing_pct\", \"var\"], ascending=[True, True])\n",
    "\n",
    "    print(\"\\n[Outliers] Per-variable statistics (requested vars only):\")\n",
    "    if summary_df.empty:\n",
    "        print(\"(no requested variables found and none listed)\")\n",
    "    else:\n",
    "        print(summary_df.to_string(index=False))\n",
    "else:\n",
    "    # 2.3 Coerce present vars to numeric + clean infinities\n",
    "    for v in present_vars:\n",
    "        df[v] = pd.to_numeric(df[v], errors=\"coerce\")\n",
    "    df[present_vars] = df[present_vars].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "    # 2.4 Robust flag functions\n",
    "    def iqr_outlier_flags(s: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "        s = s.dropna()\n",
    "        if len(s) < 30:\n",
    "            return pd.Series(False, index=s.index)\n",
    "        q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        if iqr == 0 or pd.isna(iqr):\n",
    "            return pd.Series(False, index=s.index)\n",
    "        lo, hi = q1 - k * iqr, q3 + k * iqr\n",
    "        return (s < lo) | (s > hi)\n",
    "\n",
    "\n",
    "    def mad_z_outlier_flags(s: pd.Series, z: float = 3.5) -> pd.Series:\n",
    "        s = s.dropna()\n",
    "        if len(s) < 30:\n",
    "            return pd.Series(False, index=s.index)\n",
    "        med = s.median()\n",
    "        mad = (s - med).abs().median()\n",
    "        if mad == 0 or pd.isna(mad):\n",
    "            return pd.Series(False, index=s.index)\n",
    "        mz = 0.6745 * (s - med) / mad\n",
    "        return mz.abs() > z\n",
    "\n",
    "\n",
    "    for v in present_vars:\n",
    "        s = df[v]\n",
    "        n = int(s.notna().sum())\n",
    "        miss_pct = float(s.isna().mean() * 100)\n",
    "\n",
    "        # skip truly unusable columns\n",
    "        if n < 30 or s.std(skipna=True) == 0:\n",
    "            summaries.append({\n",
    "                \"var\": v,\n",
    "                \"n_nonmissing\": n,\n",
    "                \"missing_pct\": miss_pct,\n",
    "                \"note\": \"skipped (too few obs or zero variance)\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # IQR and MAD flags\n",
    "        iqr_flags = pd.Series(False, index=df.index)\n",
    "        mad_flags = pd.Series(False, index=df.index)\n",
    "\n",
    "        _iqr = iqr_outlier_flags(s, k=1.5)\n",
    "        _mad = mad_z_outlier_flags(s, z=3.5)\n",
    "\n",
    "        iqr_flags.loc[_iqr.index] = _iqr.values\n",
    "        mad_flags.loc[_mad.index] = _mad.values\n",
    "\n",
    "        df[f\"out_iqr_{v}\"] = iqr_flags\n",
    "        df[f\"out_mad_{v}\"] = mad_flags\n",
    "        flag_cols.extend([f\"out_iqr_{v}\", f\"out_mad_{v}\"])\n",
    "\n",
    "        # core descriptive stats (robust + tails)\n",
    "        summaries.append({\n",
    "            \"var\": v,\n",
    "            \"n_nonmissing\": n,\n",
    "            \"missing_pct\": miss_pct,\n",
    "            \"mean\": float(s.mean(skipna=True)),\n",
    "            \"median\": float(s.median(skipna=True)),\n",
    "            \"std\": float(s.std(skipna=True)),\n",
    "            \"skew\": float(s.skew(skipna=True)),\n",
    "            \"kurt\": float(s.kurt(skipna=True)),\n",
    "            \"p1\": float(s.quantile(0.01)),\n",
    "            \"p5\": float(s.quantile(0.05)),\n",
    "            \"p25\": float(s.quantile(0.25)),\n",
    "            \"p75\": float(s.quantile(0.75)),\n",
    "            \"p95\": float(s.quantile(0.95)),\n",
    "            \"p99\": float(s.quantile(0.99)),\n",
    "            \"min\": float(s.min(skipna=True)),\n",
    "            \"max\": float(s.max(skipna=True)),\n",
    "            \"iqr_outliers\": int(iqr_flags.sum()),\n",
    "            \"mad_outliers\": int(mad_flags.sum())\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summaries)\n",
    "\n",
    "    # Sort: most complete first\n",
    "    if \"missing_pct\" in summary_df.columns:\n",
    "        summary_df = summary_df.sort_values([\"missing_pct\", \"var\"], ascending=[True, True])\n",
    "\n",
    "    print(\"\\n[Outliers] Per-variable statistics (requested vars only):\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # 2.6 Row-level “outlier burden” across present target vars only\n",
    "    if flag_cols:\n",
    "        df[\"outlier_flag_count_selvars\"] = df[flag_cols].sum(axis=1)\n",
    "        df[\"row_outlier_any_selvars\"] = df[\"outlier_flag_count_selvars\"] > 0\n",
    "        df[\"row_outlier_many_selvars\"] = df[\"outlier_flag_count_selvars\"] >= 3\n",
    "\n",
    "        print(f\"\\n[Outliers] Rows with ANY flag (selected vars): \"\n",
    "              f\"{df['row_outlier_any_selvars'].sum()} \"\n",
    "              f\"({df['row_outlier_any_selvars'].mean() * 100:.2f}%)\")\n",
    "        print(f\"[Outliers] Rows with >=3 flags (selected vars): \"\n",
    "              f\"{df['row_outlier_many_selvars'].sum()} \"\n",
    "              f\"({df['row_outlier_many_selvars'].mean() * 100:.2f}%)\")\n",
    "\n",
    "        # Optional: show the top 20 most-flagged rows for audit\n",
    "        audit_cols = [c for c in [\"gvkey\", \"fyear\", \"datadate\"] if c in df.columns] + present_vars\n",
    "        top = df.sort_values(\"outlier_flag_count_selvars\", ascending=False).head(20)\n",
    "        print(\"\\n[Outliers] Top 20 rows by outlier_flag_count_selvars (audit view):\")\n",
    "        print(top[audit_cols + [\"outlier_flag_count_selvars\"]].to_string(index=False))\n"
   ],
   "id": "af609ab6f8cd5eb9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
