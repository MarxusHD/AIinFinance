{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"# Next-Year Financial Distress Early-Warning (Transition) & Surveillance (Compustat Annual Panel) — Reproducible ML Pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Goal.** Predict the probability that a firm is in *financial distress* in fiscal year **t+1** using accounting (and permitted market) information available at fiscal year **t**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Important scope note.** The outcome is an **engineered distress proxy** (high leverage / balance-sheet stress), not a realized legal default or bankruptcy. The notebook is therefore a **predictive measurement and decision-support pipeline**, not a causal identification design.\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Notebook structure (Data Science Lifecycle — 10 phases)\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Problem Definition & Setup  \\n\",\n",
    "    \"2. Data Collection & Panel Integrity  \\n\",\n",
    "    \"3. Data Cleaning & Missingness Handling (leakage-aware)  \\n\",\n",
    "    \"4. Exploratory Data Analysis (EDA)  \\n\",\n",
    "    \"5. Feature Engineering & Target Construction  \\n\",\n",
    "    \"6. Preprocessing for Modeling (train-only fitting)  \\n\",\n",
    "    \"7. Model Selection & Training (7A Logit; 7B Trees)  \\n\",\n",
    "    \"8. Model Evaluation & Diagnostic Monitoring  \\n\",\n",
    "    \"9. Operational Risk Management Layer (Events + PDs)\\n\",\n",
    "    \"10. Results Summary, Guardrails, and Replication Artifacts\\n\",\n",
    "    \"\\n\",\n",
    "    \"> This organization mirrors the course lifecycle guidance and the project's technical review action items (see provided PDF and technical report).\\n\",\n",
    "    \"\\n\",\n",
    "    \"## How to run (replication package convention)\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Place `data.csv` in the project root (or update `CONFIG[\\\"DATA_PATH\\\"]` in Section 1).\\n\",\n",
    "    \"2. Keep `Variables.xlsx` (variable dictionary) alongside the notebook for automatic documentation.\\n\",\n",
    "    \"3. Run **Kernel → Restart & Run All**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The notebook creates an `outputs/` folder containing:\\n\",\n",
    "    \"- a predictions export (`predictions.csv`),\\n\",\n",
    "    \"- configuration and threshold tables,\\n\",\n",
    "    \"- model summary tables suitable for an appendix,\\n\",\n",
    "    \"- figures saved as PNG for paper workflow.\"\n",
    "   ],\n",
    "   \"id\": \"cdea472970c9294a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"## 1. Problem Definition & Setup\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 1.1 Prediction target, success metrics, and decision objective\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Target (supervised label):** `target_next_v1`, `target_next_v2`, or `target_next_v3` (separate distress proxies). Downstream modeling uses `target_next_v2` by default.\\n\",\n",
    "    \"- **Primary performance metrics (out-of-sample):**\\n\",\n",
    "    \"  - ROC-AUC (ranking quality),\\n\",\n",
    "    \"  - PR-AUC (class imbalance),\\n\",\n",
    "    \"  - Brier score (probability accuracy / calibration).\\n\",\n",
    "    \"- **Decision objective (screening):** convert predicted PDs into a review policy using:\\n\",\n",
    "    \"  - **misclassification costs** (`COST_FN`, `COST_FP`) and\\n\",\n",
    "    \"  - **capacity constraints** (screen top `CAPACITY_PCT` percent of firms).\\n\",\n",
    "    \"\\n\",\n",
    "    \"This is a *risk scoring* workflow: calibrated probabilities and operational interpretability matter more than headline accuracy.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 1.2 Configuration, determinism, and library versions\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Objective options:**\\n\",\n",
    "    \"- **Transition (early-warning):** predict *healthy at t → distressed at t+1*.\\n\",\n",
    "    \"- **State (surveillance):** predict *distress state at t+1* (includes persistence).\\n\",\n",
    "    \"\\n\",\n",
    "    \"The notebook preserves proxy selection (V1/V2/V3); set `PROXY_VERSION` and `OBJECTIVE` in Section 4 (Targets).\\n\"\n",
    "   ],\n",
    "   \"id\": \"4839e631e5199b2b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Core numerics\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import math\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"from dataclasses import dataclass, asdict\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ML / metrics\\n\",\n",
    "    \"from sklearn.model_selection import ParameterGrid\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.impute import KNNImputer\\n\",\n",
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"from sklearn.metrics import (\\n\",\n",
    "    \"    roc_auc_score,\\n\",\n",
    "    \"    average_precision_score,\\n\",\n",
    "    \"    brier_score_loss,\\n\",\n",
    "    \"    confusion_matrix,\\n\",\n",
    "    \"    precision_recall_curve,\\n\",\n",
    "    \"    roc_curve,\\n\",\n",
    "    \")\\n\",\n",
    "    \"from sklearn.calibration import calibration_curve\\n\",\n",
    "    \"from sklearn.isotonic import IsotonicRegression\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Stats / inference\\n\",\n",
    "    \"import statsmodels.api as sm\\n\",\n",
    "    \"from statsmodels.stats.outliers_influence import variance_inflation_factor\\n\",\n",
    "    \"from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Trees / explainability\\n\",\n",
    "    \"import xgboost as xgb\\n\",\n",
    "    \"\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from IPython.display import display\\n\",\n",
    "    \"\\n\",\n",
    "    \"warnings.filterwarnings(\\\"ignore\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# Determinism\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"SEED = 42\\n\",\n",
    "    \"np.random.seed(SEED)\\n\",\n",
    "    \"USING_SYNTHETIC_DATA = False # Global flag for data mode\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"# Configuration (edit here)\\n\",\n",
    "    \"# ----------------------------\\n\",\n",
    "    \"CONFIG = {\\n\",\n",
    "    \"    # Data inputs\\n\",\n",
    "    \"    \\\"DATA_PATH\\\": \\\"data.csv\\\",\\n\",\n",
    "    \"    \\\"VARIABLES_XLSX_PATH\\\": \\\"Variables.xlsx\\\",\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Temporal splitting via label_year = fyear + 1\\n\",\n",
    "    \"    \\\"TRAIN_CUTOFF_LABEL_YEAR\\\": 2022,   # label_year <= cutoff -> train/val pool; later -> test\\n\",\n",
    "    \"    \\\"VAL_YEARS\\\": 1,                    # number of last label years inside the train pool used as validation\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Missingness / imputation\\n\",\n",
    "    \"    \\\"KNN_K\\\": 5,\\n\",\n",
    "    \"    \\\"IMPUTE_LO_Q\\\": 0.01,\\n\",\n",
    "    \"    \\\"IMPUTE_HI_Q\\\": 0.99,\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Preprocessing\\n\",\n",
    "    \"    \\\"WINSOR_LO_Q\\\": 0.01,\\n\",\n",
    "    \"    \\\"WINSOR_HI_Q\\\": 0.99,\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Logit hyperparameter search\\n\",\n",
    "    \"    \\\"LOGIT_C_GRID\\\": [0.01, 0.1, 1.0, 10.0],\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Tree model (XGBoost) parameters (conservative / regularized)\\n\",\n",
    "    \"    \\\"XGB_PARAMS\\\": {\\n\",\n",
    "    \"        \\\"max_depth\\\": 4,\\n\",\n",
    "    \"        \\\"min_child_weight\\\": 5,\\n\",\n",
    "    \"        \\\"subsample\\\": 0.8,\\n\",\n",
    "    \"        \\\"colsample_bytree\\\": 0.8,\\n\",\n",
    "    \"        \\\"eta\\\": 0.05,\\n\",\n",
    "    \"        \\\"reg_lambda\\\": 10.0,\\n\",\n",
    "    \"        \\\"reg_alpha\\\": 0.0,\\n\",\n",
    "    \"        \\\"objective\\\": \\\"binary:logistic\\\",\\n\",\n",
    "    \"        \\\"eval_metric\\\": \\\"aucpr\\\",\\n\",\n",
    "    \"        \\\"tree_method\\\": \\\"hist\\\",\\n\",\n",
    "    \"        \\\"seed\\\": SEED,\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    \\\"XGB_NUM_BOOST_ROUND\\\": 5000,\\n\",\n",
    "    \"    \\\"XGB_EARLY_STOPPING\\\": 200,\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Decision policy parameters (costs + capacity)\\n\",\n",
    "    \"    \\\"COST_FN\\\": 50.0,\\n\",\n",
    "    \"    \\\"COST_FP\\\": 1.0,\\n\",\n",
    "    \"    \\\"CAPACITY_PCT\\\": 0.20,  # screen top 20% by PD as a capacity policy\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Outputs\\n\",\n",
    "    \"    \\\"OUTPUT_DIR\\\": \\\"outputs\\\",\\n\",\n",
    "    \"    \\\"FIG_DIR\\\": \\\"figures\\\",\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"Path(CONFIG[\\\"OUTPUT_DIR\\\"]).mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"Path(CONFIG[\\\"FIG_DIR\\\"]).mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"CONFIG (key parameters):\\\")\\n\",\n",
    "    \"for k in [\\\"DATA_PATH\\\",\\\"TRAIN_CUTOFF_LABEL_YEAR\\\",\\\"VAL_YEARS\\\",\\\"KNN_K\\\",\\\"WINSOR_LO_Q\\\",\\\"WINSOR_HI_Q\\\",\\\"COST_FN\\\",\\\"COST_FP\\\",\\\"CAPACITY_PCT\\\"]:\\n\",\n",
    "    \"    print(f\\\"  {k}: {CONFIG[k]}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nPython:\\\", sys.version.split()[0])\\n\",\n",
    "    \"print(\\\"pandas:\\\", pd.__version__)\\n\",\n",
    "    \"print(\\\"numpy:\\\", np.__version__)\"\n",
    "   ],\n",
    "   \"id\": \"b8f63a92e2bc9c03\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 1.3 Helper utilities (robust ratios, transforms, and reporting)\",\n",
    "   \"id\": \"a96f73c16dd659ba\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"def signed_log1p(x: pd.Series) -> pd.Series:\\n\",\n",
    "    \"    \\\"\\\"\\\"Signed log1p transform: sign(x) * log1p(|x|). Preserves zero and sign, stabilizes tails.\\\"\\\"\\\"\\n\",\n",
    "    \"    x = pd.to_numeric(x, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    return np.sign(x) * np.log1p(np.abs(x))\\n\",\n",
    "    \"\\n\",\n",
    "    \"def safe_divide(numer: pd.Series, denom: pd.Series, denom_floor: float = None) -> pd.Series:\\n\",\n",
    "    \"    \\\"\\\"\\\"Safe divide with optional denominator floor for stability. Returns float with NaN where undefined.\\\"\\\"\\\"\\n\",\n",
    "    \"    numer = pd.to_numeric(numer, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    denom = pd.to_numeric(denom, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    if denom_floor is not None:\\n\",\n",
    "    \"        denom = denom.where(denom.abs() >= denom_floor, other=np.sign(denom).replace(0, 1) * denom_floor)\\n\",\n",
    "    \"    out = numer / denom\\n\",\n",
    "    \"    out = out.replace([np.inf, -np.inf], np.nan)\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"def ensure_nullable_float(s: pd.Series) -> pd.Series:\\n\",\n",
    "    \"    \\\"\\\"\\\"Convert to pandas nullable Float64 to enable NA-aware comparisons (returns <NA> instead of False).\\\"\\\"\\\"\\n\",\n",
    "    \"    return pd.to_numeric(s, errors=\\\"coerce\\\").astype(\\\"Float64\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def winsorize_train_bounds(x: pd.Series, lo: float, hi: float) -> tuple[float, float]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Return winsorization bounds computed on *training* observed values.\\\"\\\"\\\"\\n\",\n",
    "    \"    x = pd.to_numeric(x, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    x_obs = x.dropna()\\n\",\n",
    "    \"    if len(x_obs) == 0:\\n\",\n",
    "    \"        return (np.nan, np.nan)\\n\",\n",
    "    \"    return (float(x_obs.quantile(lo)), float(x_obs.quantile(hi)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"def apply_bounds(x: pd.Series, lo: float, hi: float) -> pd.Series:\\n\",\n",
    "    \"    x = pd.to_numeric(x, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    if np.isnan(lo) or np.isnan(hi):\\n\",\n",
    "    \"        return x\\n\",\n",
    "    \"    return x.clip(lower=lo, upper=hi)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def compute_smd(train: pd.Series, test: pd.Series) -> float:\\n\",\n",
    "    \"    \\\"\\\"\\\"Standardized mean difference (SMD): (mu_train - mu_test)/pooled_sd.\\\"\\\"\\\"\\n\",\n",
    "    \"    a = pd.to_numeric(train, errors=\\\"coerce\\\").dropna()\\n\",\n",
    "    \"    b = pd.to_numeric(test, errors=\\\"coerce\\\").dropna()\\n\",\n",
    "    \"    if len(a) < 2 or len(b) < 2:\\n\",\n",
    "    \"        return np.nan\\n\",\n",
    "    \"    mu_a, mu_b = a.mean(), b.mean()\\n\",\n",
    "    \"    sd_a, sd_b = a.std(ddof=1), b.std(ddof=1)\\n\",\n",
    "    \"    pooled = np.sqrt(0.5*(sd_a**2 + sd_b**2))\\n\",\n",
    "    \"    return float((mu_a - mu_b) / pooled) if pooled > 0 else np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"def logit(p: np.ndarray, eps: float = 1e-6) -> np.ndarray:\\n\",\n",
    "    \"    p = np.clip(p, eps, 1-eps)\\n\",\n",
    "    \"    return np.log(p/(1-p))\\n\",\n",
    "    \"\\n\",\n",
    "    \"def sigmoid(z: np.ndarray) -> np.ndarray:\\n\",\n",
    "    \"    return 1/(1+np.exp(-z))\\n\",\n",
    "    \"\\n\",\n",
    "    \"def print_df(df: pd.DataFrame, n: int = 10, name: str = None):\\n\",\n",
    "    \"    if name:\\n\",\n",
    "    \"        print(f\\\"\\\\n{name} (top {n} rows):\\\")\\n\",\n",
    "    \"    display(df.head(n))\"\n",
    "   ],\n",
    "   \"id\": \"c2e6c6c1fae62314\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 2. Data Collection & Panel Integrity\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 2.1 Load variable dictionary (for documentation)\\n\",\n",
    "    \"\\n\",\n",
    "    \"We load the provided variable dictionary (`Variables.xlsx`) to:\\n\",\n",
    "    \"- validate required Compustat mnemonics exist in the data file,\\n\",\n",
    "    \"- generate appendix-ready variable tables.\\n\",\n",
    "    \"\\n\",\n",
    "    \"This step **does not** transform the modeling data.\"\n",
    "   ],\n",
    "   \"id\": \"99a453245890a56a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"vars_path = Path(CONFIG[\\\"VARIABLES_XLSX_PATH\\\"])\\n\",\n",
    "    \"if vars_path.exists():\\n\",\n",
    "    \"    var_dict = pd.read_excel(vars_path, sheet_name=0)\\n\",\n",
    "    \"    var_dict.columns = [c.strip() for c in var_dict.columns]\\n\",\n",
    "    \"    print(f\\\"Loaded variable dictionary with {len(var_dict)} rows from: {vars_path}\\\")\\n\",\n",
    "    \"    display(var_dict.head(90))\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    var_dict = pd.DataFrame(columns=[\\\"Variable\\\",\\\"Two-word Description\\\",\\\"Category\\\"])\\n\",\n",
    "    \"    print(f\\\"WARNING: variable dictionary not found at {vars_path}. Continuing without it.\\\")\"\n",
    "   ],\n",
    "   \"id\": \"c1de9fa41885cfe5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 2.2 Load raw data (no imputation or transformations)\",\n",
    "   \"id\": \"17ce9cc199dcda3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"data_path = Path(CONFIG[\\\"DATA_PATH\\\"])\\n\",\n",
    "    \"df_raw = pd.read_csv(data_path, low_memory=False)\\n\",\n",
    "    \"print(f\\\"Loaded data from {data_path} with shape {df_raw.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(df_raw.head())\\n\"\n",
    "   ],\n",
    "   \"id\": \"e2004bacc1cb3f38\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 2.3 Enforce panel identifiers, types, sorting, and deduplication\",\n",
    "   \"id\": \"8eb9f2e8a6165aba\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"df = df_raw.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Stable firm identifier\\n\",\n",
    "    \"if \\\"gvkey\\\" not in df.columns:\\n\",\n",
    "    \"    raise ValueError(\\\"Required identifier column `gvkey` not found in the dataset.\\\")\\n\",\n",
    "    \"df[\\\"firm_id\\\"] = df[\\\"gvkey\\\"].astype(str)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fiscal year\\n\",\n",
    "    \"if \\\"fyear\\\" not in df.columns:\\n\",\n",
    "    \"    raise ValueError(\\\"Required time column `fyear` not found in the dataset.\\\")\\n\",\n",
    "    \"df[\\\"fyear\\\"] = pd.to_numeric(df[\\\"fyear\\\"], errors=\\\"coerce\\\").astype(\\\"Int64\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Optional datadate parsing (kept as metadata; not used for splitting)\\n\",\n",
    "    \"if \\\"datadate\\\" in df.columns:\\n\",\n",
    "    \"    df[\\\"datadate\\\"] = pd.to_datetime(df[\\\"datadate\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove firm-year duplicates (keep-last rule, audit count)\\n\",\n",
    "    \"pre_n = len(df)\\n\",\n",
    "    \"dup_mask = df.duplicated(subset=[\\\"firm_id\\\",\\\"fyear\\\"], keep=False)\\n\",\n",
    "    \"n_dups = int(dup_mask.sum())\\n\",\n",
    "    \"if n_dups > 0:\\n\",\n",
    "    \"    print(f\\\"Found {n_dups} duplicated firm-year rows. Applying keep-last rule.\\\")\\n\",\n",
    "    \"    df = df.sort_values([\\\"firm_id\\\",\\\"fyear\\\",\\\"datadate\\\"] if \\\"datadate\\\" in df.columns else [\\\"firm_id\\\",\\\"fyear\\\"])\\n\",\n",
    "    \"    df = df.drop_duplicates(subset=[\\\"firm_id\\\",\\\"fyear\\\"], keep=\\\"last\\\")\\n\",\n",
    "    \"post_n = len(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Enforce sort order for lag/lead safety\\n\",\n",
    "    \"df = df.sort_values([\\\"firm_id\\\",\\\"fyear\\\"]).reset_index(drop=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Integrity checks\\n\",\n",
    "    \"assert df[[\\\"firm_id\\\",\\\"fyear\\\"]].isna().sum().sum() == 0, \\\"Missing firm_id or fyear after typing.\\\"\\n\",\n",
    "    \"assert df.duplicated(subset=[\\\"firm_id\\\",\\\"fyear\\\"]).sum() == 0, \\\"Duplicate firm-year keys remain after dedup.\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Rows: {pre_n:,} -> {post_n:,} after deduplication.\\\")\\n\",\n",
    "    \"print(\\\"Unique firms:\\\", df[\\\"firm_id\\\"].nunique())\\n\",\n",
    "    \"print(\\\"Year range:\\\", int(df[\\\"fyear\\\"].min()), \\\"to\\\", int(df[\\\"fyear\\\"].max()))\"\n",
    "   ],\n",
    "   \"id\": \"3dc09078e567ba29\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 2.4 Raw sample composition (no transformations)\",\n",
    "   \"id\": \"9a388f230d3c0637\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Minimal sample composition diagnostics (kept lightweight for large panels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"by_year = df.groupby(\\\"fyear\\\").agg(\\n\",\n",
    "    \"    n_obs=(\\\"firm_id\\\",\\\"size\\\"),\\n\",\n",
    "    \"    n_firms=(\\\"firm_id\\\",\\\"nunique\\\"),\\n\",\n",
    "    \").reset_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(by_year.tail(12))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Optional: industry composition if SIC exists\\n\",\n",
    "    \"if \\\"sic\\\" in df.columns:\\n\",\n",
    "    \"    df[\\\"sic2\\\"] = pd.to_numeric(df[\\\"sic\\\"], errors=\\\"coerce\\\").astype(\\\"Int64\\\") // 100\\n\",\n",
    "    \"    by_sic2 = df.groupby(\\\"sic2\\\").size().sort_values(ascending=False).head(15).rename(\\\"n_obs\\\").reset_index()\\n\",\n",
    "    \"    display(by_sic2)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Note: `sic` not present; skipping industry composition.\\\")\"\n",
    "   ],\n",
    "   \"id\": \"49b9ad359e218194\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 3. Data Cleaning & Missingness Handling (leakage-aware)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 3.1 Non-imputable identifiers and label-year setup\\n\",\n",
    "    \"\\n\",\n",
    "    \"We drop observations missing non-imputable identifiers (firm, year).  \\n\",\n",
    "    \"We also define `label_year = fyear + 1` as the *outcome year* used for forecasting splits.\"\n",
    "   ],\n",
    "   \"id\": \"e5a264087d7f7534\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Drop rows with missing key identifiers (already asserted, but keep explicit)\\n\",\n",
    "    \"df = df.dropna(subset=[\\\"firm_id\\\",\\\"fyear\\\"]).copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# label_year defines the year of the t+1 distress label\\n\",\n",
    "    \"df[\\\"label_year\\\"] = (df[\\\"fyear\\\"] + 1).astype(\\\"Int64\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove excluded variables from dataframe before split (global removal)\\n\",\n",
    "    \"EXCLUDED_VARS = [\\n\",\n",
    "    \"    \\\"aco_act\\\", \\\"aqc_at\\\", \\\"caps_at\\\", \\\"capx_at\\\", \\\"dp_at\\\",\\n\",\n",
    "    \"    \\\"invch_act\\\", \\\"lco_lct\\\", \\\"mibt_at\\\", \\\"recch_act\\\",\\n\",\n",
    "    \"    \\\"txditc_at\\\", \\\"txp_lct\\\", \\\"xint_lct\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"df = df.drop(columns=EXCLUDED_VARS, errors=\\\"ignore\\\")\\n\",\n",
    "    \"print(f\\\"Dropped excluded variables: {EXCLUDED_VARS}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split masks (defined early; used for leakage-safe preprocessing throughout)\\n\",\n",
    "    \"train_pool_mask = df[\\\"label_year\\\"] <= CONFIG[\\\"TRAIN_CUTOFF_LABEL_YEAR\\\"]\\n\",\n",
    "    \"train_pool_years = sorted(df.loc[train_pool_mask, \\\"label_year\\\"].dropna().unique().tolist())\\n\",\n",
    "    \"if len(train_pool_years) < (CONFIG[\\\"VAL_YEARS\\\"] + 1):\\n\",\n",
    "    \"    raise ValueError(\\\"Not enough label years in train pool to allocate validation years. Adjust TRAIN_CUTOFF_LABEL_YEAR or VAL_YEARS.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"val_years = train_pool_years[-CONFIG[\\\"VAL_YEARS\\\"]:]\\n\",\n",
    "    \"val_mask = df[\\\"label_year\\\"].isin(val_years)\\n\",\n",
    "    \"train_mask = train_pool_mask & (~val_mask)\\n\",\n",
    "    \"test_mask = df[\\\"label_year\\\"] > CONFIG[\\\"TRAIN_CUTOFF_LABEL_YEAR\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"df[\\\"split\\\"] = np.where(test_mask, \\\"test\\\", np.where(val_mask, \\\"val\\\", \\\"train\\\"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Split counts:\\\")\\n\",\n",
    "    \"display(df[\\\"split\\\"].value_counts(dropna=False).to_frame(\\\"n_obs\\\"))\\n\",\n",
    "    \"print(\\\"Validation label_year(s):\\\", val_years)\"\n",
    "   ],\n",
    "   \"id\": \"61b27d76a01c262d\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 3.2 Missingness audit before intervention\",\n",
    "   \"id\": \"15daac3bf8b50f2c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Identify numeric columns eligible for imputation (exclude identifiers)\\n\",\n",
    "    \"id_cols = {\\\"gvkey\\\",\\\"firm_id\\\",\\\"fyear\\\",\\\"label_year\\\",\\\"datadate\\\",\\\"split\\\"}\\n\",\n",
    "    \"numeric_cols = [c for c in df.columns if c not in id_cols and pd.api.types.is_numeric_dtype(df[c])]\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_tbl = (df[numeric_cols].isna().mean().sort_values(ascending=False) * 100).rename(\\\"missing_%\\\").to_frame()\\n\",\n",
    "    \"missing_tbl[\\\"n_missing\\\"] = df[numeric_cols].isna().sum().astype(int)\\n\",\n",
    "    \"missing_tbl[\\\"dtype\\\"] = [str(df[c].dtype) for c in missing_tbl.index]\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(missing_tbl.head(25))\"\n",
    "   ],\n",
    "   \"id\": \"4ce63501894d812a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 3.3 Create missingness indicators (informative signals)\",\n",
    "   \"id\": \"4640bcb365707fc1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Choose a focused set of inputs used for core ratios/events.\\n\",\n",
    "    \"REQUIRED_RAW = [\\n\",\n",
    "    \"    \\\"at\\\",\\\"dlc\\\",\\\"dltt\\\",\\\"seq\\\",\\\"mibt\\\",\\\"niadj\\\",\\n\",\n",
    "    \"    \\\"oibdp\\\",\\\"oancf\\\",\\\"xint\\\",\\n\",\n",
    "    \"    \\\"act\\\",\\\"lct\\\",\\\"che\\\",\\\"rect\\\",\\\"invt\\\",\\n\",\n",
    "    \"    # dividend-related (we will auto-detect among these later)\\n\",\n",
    "    \"    \\\"dv\\\",\\\"dvc\\\",\\\"dvt\\\",\\\"dvp\\\",\\n\",\n",
    "    \"]\\n\",\n",
    "    \"available_required = [c for c in REQUIRED_RAW if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Hard requirement for the distress proxy; fail if absent (unless synthetic mode)\\n\",\n",
    "    \"HARD_REQUIRED = [\\\"at\\\",\\\"dlc\\\",\\\"dltt\\\",\\\"seq\\\",\\\"oibdp\\\",\\\"niadj\\\",\\\"oancf\\\"]\\n\",\n",
    "    \"missing_hard = [c for c in HARD_REQUIRED if c not in df.columns]\\n\",\n",
    "    \"if missing_hard and not USING_SYNTHETIC_DATA:\\n\",\n",
    "    \"    raise ValueError(f\\\"Missing required columns for distress proxy construction: {missing_hard}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for c in available_required:\\n\",\n",
    "    \"    df[f\\\"fmiss_{c}\\\"] = df[c].isna().astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Created missingness flags for:\\\", available_required)\"\n",
    "   ],\n",
    "   \"id\": \"1904a20b8042a074\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 3.4 Training-derived size deciles (used for peer imputation groups)\",\n",
    "   \"id\": \"61d757d8b903e363\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Size is based on log(assets) from TRAIN only, to avoid leakage.\\n\",\n",
    "    \"at_train = pd.to_numeric(df.loc[train_mask, \\\"at\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"log_at_train = np.log(at_train.where(at_train > 0)).dropna()\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(log_at_train) < 50:\\n\",\n",
    "    \"    print(\\\"WARNING: too few non-missing training `at` values for stable size deciles. Using a single size bin.\\\")\\n\",\n",
    "    \"    df[\\\"size_decile\\\"] = 5  # arbitrary mid-bin\\n\",\n",
    "    \"    size_edges = None\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # Use quantile cutpoints computed on training only\\n\",\n",
    "    \"    qs = np.linspace(0, 1, 11)\\n\",\n",
    "    \"    size_edges = log_at_train.quantile(qs).values\\n\",\n",
    "    \"    size_edges[0] = -np.inf\\n\",\n",
    "    \"    size_edges[-1] = np.inf\\n\",\n",
    "    \"\\n\",\n",
    "    \"    log_at_all = np.log(pd.to_numeric(df[\\\"at\\\"], errors=\\\"coerce\\\").where(lambda s: s > 0))\\n\",\n",
    "    \"    df[\\\"size_decile\\\"] = pd.cut(log_at_all, bins=size_edges, labels=False, include_lowest=True).astype(\\\"Float64\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fill NA size_decile with training median decile for downstream stability\\n\",\n",
    "    \"sd_med = float(pd.to_numeric(df.loc[train_mask, \\\"size_decile\\\"], errors=\\\"coerce\\\").median())\\n\",\n",
    "    \"df[\\\"size_decile\\\"] = pd.to_numeric(df[\\\"size_decile\\\"], errors=\\\"coerce\\\").fillna(sd_med).astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Size decile distribution (train):\\\")\\n\",\n",
    "    \"display(df.loc[train_mask, \\\"size_decile\\\"].value_counts().sort_index().to_frame(\\\"n_obs\\\"))\"\n",
    "   ],\n",
    "   \"id\": \"1618e73fdac9c637\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 3.5 Imputation Pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"I build the imputation pipeline in two stages:\\n\",\n",
    "    \"1. KNN on core structural statements (train-fit only).\\n\",\n",
    "    \"2. Peer-median imputation for sparse or secondary items (train-fit only).\\n\",\n",
    "    \"\\n\",\n",
    "    \"Targets are computed from the pre-imputation snapshot, so label construction never depends on imputed values.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"76ddad946e57534e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Snapshot before any imputation\\n\",\n",
    "    \"df_pre_impute_snapshot = df.copy(deep=True)\"\n",
    "   ],\n",
    "   \"id\": \"75590cf6f789a092\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 3.5.1 KNN imputation on core structural items (train-fit; signed-log transform)\\n\",\n",
    "    \"\\n\",\n",
    "    \"I use KNN on core balance sheet and income statement aggregates. These fields are tightly linked (e.g., assets vs. liabilities), so multivariate neighbors tend to preserve accounting structure.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 3.5.2 KNN parameter selection audit\\n\",\n",
    "    \"\\n\",\n",
    "    \"I audit reconstruction error across a grid of $K$ values using training-only complete rows with simulated missingness. The chosen KNN setting is the value configured in `CONFIG[\\\"KNN_K\\\"]`.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"5257fe61a16d0f67\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.impute import KNNImputer\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# pyampute (audit missingness generation)\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from pyampute.ampute import MultivariateAmputation\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    raise ImportError(\\n\",\n",
    "    \"        \\\"pyampute is required for the KNN audit. Install via: pip install pyampute\\\\n\\\"\\n\",\n",
    "    \"        f\\\"Import error: {e}\\\"\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ---------------------------------------------------------------------\\n\",\n",
    "    \"# Core structural variables for KNN (NO fyear / size_decile)\\n\",\n",
    "    \"# ---------------------------------------------------------------------\\n\",\n",
    "    \"knn_cols = [\\n\",\n",
    "    \"    \\\"at\\\", \\\"act\\\", \\\"lct\\\", \\\"che\\\", \\\"rect\\\", \\\"invt\\\", \\\"dlc\\\", \\\"dltt\\\",\\n\",\n",
    "    \"    \\\"seq\\\", \\\"ceq\\\", \\\"lt\\\", \\\"ppent\\\", \\\"intan\\\", \\\"oibdp\\\", \\\"niadj\\\",\\n\",\n",
    "    \"    \\\"oancf\\\", \\\"xint\\\", \\\"dp\\\", \\\"re\\\", \\\"capx\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"knn_cols = [c for c in knn_cols if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"def signed_log1p(x):\\n\",\n",
    "    \"    x = pd.to_numeric(x, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    return np.sign(x) * np.log1p(np.abs(x))\\n\",\n",
    "    \"\\n\",\n",
    "    \"def inverse_signed_log1p(z):\\n\",\n",
    "    \"    z = pd.to_numeric(z, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    return np.sign(z) * (np.expm1(np.abs(z)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ---------------------------------------------------------------------\\n\",\n",
    "    \"# pyampute-based audit: NRMSE on forced-missing cells (TRAIN only)\\n\",\n",
    "    \"# ---------------------------------------------------------------------\\n\",\n",
    "    \"def knn_audit_pyampute_train_only(\\n\",\n",
    "    \"    Z_train: pd.DataFrame,\\n\",\n",
    "    \"    knn_cols: list,\\n\",\n",
    "    \"    k_list=(5, 10, 25, 50, 100),\\n\",\n",
    "    \"    prop_rows_incomplete=0.50,\\n\",\n",
    "    \"    row_subsample=2000,\\n\",\n",
    "    \"    seed=42\\n\",\n",
    "    \"):\\n\",\n",
    "    \"    # complete TRAIN rows only (pyampute requirement)\\n\",\n",
    "    \"    Zc = Z_train.copy().apply(pd.to_numeric, errors=\\\"coerce\\\").dropna()\\n\",\n",
    "    \"    if len(Zc) < 200:\\n\",\n",
    "    \"        print(f\\\"[KNN audit] Not enough complete TRAIN rows: n={len(Zc)}\\\")\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if len(Zc) > row_subsample:\\n\",\n",
    "    \"        Zc = Zc.sample(n=row_subsample, random_state=seed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    std = Zc[knn_cols].std(ddof=0).replace(0, np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # KEY FIX: one-variable patterns (so rows are not fully missing)\\n\",\n",
    "    \"    patterns = [\\n\",\n",
    "    \"        {\\\"incomplete_vars\\\": [c], \\\"mechanism\\\": \\\"MCAR\\\", \\\"freq\\\": 1.0/len(knn_cols)}\\n\",\n",
    "    \"        for c in knn_cols\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    ma = MultivariateAmputation(\\n\",\n",
    "    \"        prop=float(prop_rows_incomplete),\\n\",\n",
    "    \"        patterns=patterns,\\n\",\n",
    "    \"        std=False,\\n\",\n",
    "    \"        seed=int(seed),\\n\",\n",
    "    \"        verbose=False\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Za = ma.fit_transform(Zc)\\n\",\n",
    "    \"    Za = pd.DataFrame(Za, columns=Zc.columns, index=Zc.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    introduced = Za[knn_cols].isna() & Zc[knn_cols].notna()\\n\",\n",
    "    \"    n_amputed = int(introduced.values.sum())\\n\",\n",
    "    \"    if n_amputed == 0:\\n\",\n",
    "    \"        print(\\\"[KNN audit] No cells amputated; increase prop_rows_incomplete.\\\")\\n\",\n",
    "    \"        return None\\n\",\n",
    "    \"\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    for k in k_list:\\n\",\n",
    "    \"        imp = KNNImputer(n_neighbors=int(k), weights=\\\"distance\\\")\\n\",\n",
    "    \"        imp.fit(Zc)\\n\",\n",
    "    \"        Zimp = pd.DataFrame(imp.transform(Za), columns=Za.columns, index=Za.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        per = {}\\n\",\n",
    "    \"        sqerrs = []\\n\",\n",
    "    \"        var_w = []\\n\",\n",
    "    \"        cnt = 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"        for c in knn_cols:\\n\",\n",
    "    \"            m = introduced[c].values\\n\",\n",
    "    \"            if m.sum() == 0 or pd.isna(std[c]) or std[c] <= 0:\\n\",\n",
    "    \"                continue\\n\",\n",
    "    \"            y_true = Zc[c].values[m]\\n\",\n",
    "    \"            y_pred = Zimp[c].values[m]\\n\",\n",
    "    \"            rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\\n\",\n",
    "    \"            nrmse = float(rmse / std[c])\\n\",\n",
    "    \"            per[f\\\"NRMSE_{c}\\\"] = nrmse\\n\",\n",
    "    \"\\n\",\n",
    "    \"            sqerrs.append((y_true - y_pred) ** 2)\\n\",\n",
    "    \"            var_w.append((std[c] ** 2) * m.sum())\\n\",\n",
    "    \"            cnt += int(m.sum())\\n\",\n",
    "    \"\\n\",\n",
    "    \"        pooled_nrmse = np.nan\\n\",\n",
    "    \"        if cnt > 0 and sqerrs:\\n\",\n",
    "    \"            pooled_mse = float(np.mean(np.concatenate(sqerrs)))\\n\",\n",
    "    \"            pooled_rmse = float(np.sqrt(pooled_mse))\\n\",\n",
    "    \"            pooled_std = float(np.sqrt(np.sum(var_w) / cnt))\\n\",\n",
    "    \"            pooled_nrmse = float(pooled_rmse / pooled_std) if pooled_std > 0 else np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"        rows.append({\\n\",\n",
    "    \"            \\\"K\\\": int(k),\\n\",\n",
    "    \"            \\\"amputated_cells\\\": n_amputed,\\n\",\n",
    "    \"            \\\"pooled_NRMSE\\\": pooled_nrmse,\\n\",\n",
    "    \"            **per\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return pd.DataFrame(rows).sort_values(\\\"K\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ---------------------------------------------------------------------\\n\",\n",
    "    \"# Main: build Z (ONLY knn_cols), run audit (TRAIN only), then impute df\\n\",\n",
    "    \"# ---------------------------------------------------------------------\\n\",\n",
    "    \"if len(knn_cols) >= 3:\\n\",\n",
    "    \"    # Build Z (NO fyear / size_decile)\\n\",\n",
    "    \"    Z = df[knn_cols].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Transform magnitudes for distance stability\\n\",\n",
    "    \"    for c in knn_cols:\\n\",\n",
    "    \"        Z[c] = signed_log1p(Z[c])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # ---- pyampute audit (TRAIN only) ----\\n\",\n",
    "    \"    print(\\\"Auditing KNN imputation via pyampute (TRAIN only, forced-missing cells, NRMSE)...\\\")\\n\",\n",
    "    \"    k_options = [5, 10, 25, 50, 100]\\n\",\n",
    "    \"    audit_tbl = knn_audit_pyampute_train_only(\\n\",\n",
    "    \"        Z_train=Z.loc[train_mask, :],\\n\",\n",
    "    \"        knn_cols=knn_cols,\\n\",\n",
    "    \"        k_list=k_options,\\n\",\n",
    "    \"        row_subsample=2000,\\n\",\n",
    "    \"        seed=SEED if \\\"SEED\\\" in globals() else 42\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    if audit_tbl is not None:\\n\",\n",
    "    \"        display(audit_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # ---- Production imputation (train-fit) ----\\n\",\n",
    "    \"    imputer = KNNImputer(n_neighbors=CONFIG[\\\"KNN_K\\\"], weights=\\\"distance\\\")\\n\",\n",
    "    \"    imputer.fit(Z.loc[train_mask, :])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Z_imp = pd.DataFrame(imputer.transform(Z), columns=Z.columns, index=Z.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Invert signed-log transform back for magnitudes and write into df\\n\",\n",
    "    \"    for c in knn_cols:\\n\",\n",
    "    \"        df[c] = inverse_signed_log1p(Z_imp[c])\\n\",\n",
    "    \"\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Skipping KNN imputation: insufficient columns available.\\\")\"\n",
    "   ],\n",
    "   \"id\": \"65eb3c6ba0825df8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 3.6 Train-only peer-median imputation (fyear × size_decile)\\n\",\n",
    "    \"\\n\",\n",
    "    \"I use year-by-size median imputation for sparse flows (dividends, buybacks) where KNN would overfit noise or fill in non-existent activity. The medians are computed on training data only, with size-decile and global fallbacks for unseen groups.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"5baa09481ffdaedb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Secondary/incidental variables for Peer Median\\n\",\n",
    "    \"# Removed raw variables that create excluded ratios: aco, lco, recch, invch, txp, txditc, caps, mibt, aqc\\n\",\n",
    "    \"peer_impute_candidates = [\\n\",\n",
    "    \"    \\\"prstkc\\\",\\n\",\n",
    "    \"    \\\"dv\\\", \\\"dvc\\\", \\\"dvt\\\", \\\"dvp\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"peer_impute_cols = [c for c in peer_impute_candidates if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"group_cols = [\\\"fyear\\\",\\\"size_decile\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"def peer_median_impute(df_in: pd.DataFrame, cols: list[str], train_mask: pd.Series, group_cols: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\\n\",\n",
    "    \"    \\\"\\\"\\\"Impute NaNs using TRAIN-only medians by group_cols, with TRAIN (size_decile) then global median fallback.\\\"\\\"\\\"\\n\",\n",
    "    \"    df_out = df_in.copy()\\n\",\n",
    "    \"    train = df_out.loc[train_mask, group_cols + cols].copy()\\n\",\n",
    "    \"    group_meds = train.groupby(group_cols)[cols].median()\\n\",\n",
    "    \"    global_meds = train[cols].median()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Intermediate fallback for unseen (fyear, size_decile): use TRAIN size_decile medians\\n\",\n",
    "    \"    size_meds = train.groupby([\\\"size_decile\\\"])[cols].median()\\n\",\n",
    "    \"    tmp_size = df_out[[\\\"size_decile\\\"]].merge(size_meds.reset_index(), on=\\\"size_decile\\\", how=\\\"left\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Join group medians (wide) to all rows\\n\",\n",
    "    \"    tmp = df_out[group_cols].merge(group_meds.reset_index(), on=group_cols, how=\\\"left\\\", suffixes=(\\\"\\\", \\\"_peer\\\"))\\n\",\n",
    "    \"    # tmp currently contains the group median columns with original names\\n\",\n",
    "    \"    for c in cols:\\n\",\n",
    "    \"        peer_med = tmp[c]\\n\",\n",
    "    \"        df_out[c] = df_out[c].where(df_out[c].notna(), peer_med)\\n\",\n",
    "    \"        size_med = tmp_size[c]\\n\",\n",
    "    \"        df_out[c] = df_out[c].where(df_out[c].notna(), size_med)\\n\",\n",
    "    \"        df_out[c] = df_out[c].where(df_out[c].notna(), global_meds[c])\\n\",\n",
    "    \"    impact = pd.DataFrame({\\n\",\n",
    "    \"        \\\"col\\\": cols,\\n\",\n",
    "    \"        \\\"n_imputed\\\": [int(df_in[c].isna().sum() - df_out[c].isna().sum()) for c in cols],\\n\",\n",
    "    \"        \\\"train_global_median\\\": [float(global_meds[c]) if pd.notna(global_meds[c]) else np.nan for c in cols],\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"    return df_out, impact\\n\",\n",
    "    \"\\n\",\n",
    "    \"df, peer_impact = peer_median_impute(df, peer_impute_cols, train_mask, group_cols)\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(peer_impact.sort_values(\\\"n_imputed\\\", ascending=False).head(15))\"\n",
    "   ],\n",
    "   \"id\": \"28a38932148614dc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 3.7 Guardrail capping of imputed magnitudes (train quantile bands)\\n\",\n",
    "    \"\\n\",\n",
    "    \"After imputation, I clip imputed values to training-only quantile bands. This prevents imputation artifacts from injecting extreme tails into the modeling features.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"90a10f90413660da\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Apply capping to all columns that underwent imputation (KNN and Peer Median)\\n\",\n",
    "    \"cap_cols = list(set(knn_cols + peer_impute_cols))\\n\",\n",
    "    \"bounds = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for c in cap_cols:\\n\",\n",
    "    \"    lo, hi = winsorize_train_bounds(df_pre_impute_snapshot.loc[train_mask, c], CONFIG[\\\"IMPUTE_LO_Q\\\"], CONFIG[\\\"IMPUTE_HI_Q\\\"])\\n\",\n",
    "    \"    bounds[c] = {\\\"lo\\\": lo, \\\"hi\\\": hi}\\n\",\n",
    "    \"    df[c] = apply_bounds(df[c], lo, hi)\\n\",\n",
    "    \"\\n\",\n",
    "    \"bounds_df = pd.DataFrame({c: (v[\\\"lo\\\"], v[\\\"hi\\\"]) for c,v in bounds.items()}, index=[\\\"lo\\\",\\\"hi\\\"]).T\\n\",\n",
    "    \"bounds_df.index.name = \\\"col\\\"\\n\",\n",
    "    \"display(bounds_df.head(15))\"\n",
    "   ],\n",
    "   \"id\": \"425d134d43b3ef8a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 3.8 Imputation impact audit (pre vs post)\\n\",\n",
    "    \"\\n\",\n",
    "    \"I compare distributional summaries before and after imputation so I can see if imputation is shifting levels or compressing tails.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"8d4bd71ecd31717e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"audit_cols = [c for c in [\\\"at\\\",\\\"dlc\\\",\\\"dltt\\\",\\\"seq\\\",\\\"oibdp\\\",\\\"oancf\\\",\\\"act\\\",\\\"lct\\\"] if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"def dist_summary(x: pd.Series) -> dict:\\n\",\n",
    "    \"    x = pd.to_numeric(x, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        \\\"n\\\": int(x.notna().sum()),\\n\",\n",
    "    \"        \\\"mean\\\": float(x.mean()) if x.notna().any() else np.nan,\\n\",\n",
    "    \"        \\\"p50\\\": float(x.median()) if x.notna().any() else np.nan,\\n\",\n",
    "    \"        \\\"p10\\\": float(x.quantile(0.10)) if x.notna().any() else np.nan,\\n\",\n",
    "    \"        \\\"p90\\\": float(x.quantile(0.90)) if x.notna().any() else np.nan,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"rows = []\\n\",\n",
    "    \"for c in audit_cols:\\n\",\n",
    "    \"    pre = dist_summary(df_pre_impute_snapshot[c])\\n\",\n",
    "    \"    post = dist_summary(df[c])\\n\",\n",
    "    \"    rows.append({\\n\",\n",
    "    \"        \\\"col\\\": c,\\n\",\n",
    "    \"        \\\"n_pre\\\": pre[\\\"n\\\"],\\n\",\n",
    "    \"        \\\"n_post\\\": post[\\\"n\\\"],\\n\",\n",
    "    \"        \\\"mean_pre\\\": pre[\\\"mean\\\"],\\n\",\n",
    "    \"        \\\"mean_post\\\": post[\\\"mean\\\"],\\n\",\n",
    "    \"        \\\"p50_pre\\\": pre[\\\"p50\\\"],\\n\",\n",
    "    \"        \\\"p50_post\\\": post[\\\"p50\\\"],\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"impact_tbl = pd.DataFrame(rows).sort_values(\\\"col\\\")\\n\",\n",
    "    \"display(impact_tbl)\"\n",
    "   ],\n",
    "   \"id\": \"95d48c6fe48e72b4\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 4. Exploratory Data Analysis (EDA)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section is a quick audit of signal and data quality. It uses the imputed feature set (post-cleaning) and reports results by split.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 4.1 Summary statistics by split (key magnitudes)\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"70f134546d925f60\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"eda_cols = [c for c in [\\\"at\\\",\\\"dlc\\\",\\\"dltt\\\",\\\"seq\\\",\\\"oibdp\\\",\\\"oancf\\\",\\\"xint\\\"] if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"def split_describe(df_in: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\\n\",\n",
    "    \"    out = []\\n\",\n",
    "    \"    for sp in [\\\"train\\\",\\\"val\\\",\\\"test\\\"]:\\n\",\n",
    "    \"        d = df_in.loc[df_in[\\\"split\\\"]==sp, cols].describe(percentiles=[0.01,0.1,0.5,0.9,0.99]).T\\n\",\n",
    "    \"        d.insert(0, \\\"split\\\", sp)\\n\",\n",
    "    \"        d.insert(1, \\\"col\\\", d.index)\\n\",\n",
    "    \"        out.append(d.reset_index(drop=True))\\n\",\n",
    "    \"    return pd.concat(out, ignore_index=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"desc_tbl = split_describe(df, eda_cols)\\n\",\n",
    "    \"display(desc_tbl.head(20))\"\n",
    "   ],\n",
    "   \"id\": \"a16d198447ed03e7\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 4.2 Missingness rates after imputation (key inputs)\\n\",\n",
    "   \"id\": \"cc8c3d4171b6747f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Recompute missingness after imputation (exclude prior missingness flags)\\n\",\n",
    "    \"id_cols = {\\\"gvkey\\\",\\\"firm_id\\\",\\\"fyear\\\",\\\"label_year\\\",\\\"datadate\\\",\\\"split\\\"}\\n\",\n",
    "    \"numeric_cols = [\\n\",\n",
    "    \"    c for c in df.columns\\n\",\n",
    "    \"    if c not in id_cols\\n\",\n",
    "    \"    and not c.startswith(\\\"fmiss_\\\")\\n\",\n",
    "    \"    and pd.api.types.is_numeric_dtype(df[c])\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"missing_tbl = (\\n\",\n",
    "    \"    df[numeric_cols].isna().mean().sort_values(ascending=False) * 100\\n\",\n",
    "    \").rename(\\\"missing_%\\\").to_frame()\\n\",\n",
    "    \"missing_tbl[\\\"n_missing\\\"] = df[numeric_cols].isna().sum().astype(int)\\n\",\n",
    "    \"missing_tbl[\\\"dtype\\\"] = [str(df[c].dtype) for c in missing_tbl.index]\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(missing_tbl.head(25))\\n\"\n",
    "   ],\n",
    "   \"id\": \"658407188ba4b6be\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 4.3 Visual sanity-check plots (train vs test distributions)\",\n",
    "   \"id\": \"98a471162098e021\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Lightweight plots to spot gross drift / outliers.\\n\",\n",
    "    \"plot_cols = [c for c in [\\\"at\\\",\\\"dltt\\\",\\\"dlc\\\",\\\"oibdp\\\",\\\"oancf\\\"] if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for c in plot_cols[:3]:\\n\",\n",
    "    \"    a = pd.to_numeric(df.loc[df[\\\"split\\\"]==\\\"train\\\", c], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    b = pd.to_numeric(df.loc[df[\\\"split\\\"]==\\\"test\\\", c], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    plt.figure()\\n\",\n",
    "    \"    plt.hist(np.log1p(a.dropna()), bins=60, alpha=0.5, label=\\\"train\\\")\\n\",\n",
    "    \"    plt.hist(np.log1p(b.dropna()), bins=60, alpha=0.5, label=\\\"test\\\")\\n\",\n",
    "    \"    plt.title(f\\\"log1p({c}) distribution: train vs test\\\")\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / f\\\"eda_log1p_{c}_train_vs_test.png\\\", dpi=140)\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"13e09e690b3a0347\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Engineering & Target Construction\\n\",\n",
    "    \"\\n\",\n",
    "    \"I derive all ratio features and events from the cleaned inputs. The distress targets are still computed from the raw (pre-imputation) snapshot to avoid label leakage.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"786d144b27f96bd7\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Variables to exclude from modeling (removed per requirements)\\n\",\n",
    "    \"EXCLUDED_VARS = [\\n\",\n",
    "    \"    \\\"aco_act\\\", \\\"aqc_at\\\", \\\"caps_at\\\", \\\"capx_at\\\", \\\"dp_at\\\", \\n\",\n",
    "    \"    \\\"invch_act\\\", \\\"lco_lct\\\", \\\"mibt_at\\\", \\\"recch_act\\\", \\n\",\n",
    "    \"    \\\"txditc_at\\\", \\\"txp_lct\\\", \\\"xint_lct\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"FEATURES_V1 = [\\n\",\n",
    "    \"    \\\"ln_at\\\", \\\"cash_at\\\", \\\"current_ratio\\\", \\\"nwc_at\\\", \\n\",\n",
    "    \"    \\\"rect_act\\\", \\\"invt_act\\\", \\n\",\n",
    "    \"    \\\"lt_at\\\", \\\"dlc_at\\\", \\\"dltt_at\\\", \\n\",\n",
    "    \"    \\\"debt_at\\\", \\\"st_debt_share\\\", \\\"ebitda_at\\\", \\n\",\n",
    "    \"    \\\"xint_at\\\", \\\"interest_coverage\\\", \\\"debt_to_ebitda\\\", \\\"ebit_to_capital\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"FEATURES_V2 = [\\n\",\n",
    "    \"    \\\"ln_at\\\", \\\"cash_at\\\", \\\"current_ratio\\\", \\\"nwc_at\\\", \\n\",\n",
    "    \"    \\\"rect_act\\\", \\\"invt_act\\\", \\\"ppent_at\\\", \\\"intan_at\\\", \\n\",\n",
    "    \"    \\\"lt_at\\\", \\\"debt_at\\\", \\\"st_debt_share\\\", \\n\",\n",
    "    \"    \\\"ebitda_at\\\", \\\"xint_at\\\", \\\"interest_coverage\\\", \\\"debt_to_ebitda\\\", \\n\",\n",
    "    \"    \\\"ebit_to_capital\\\", \\\"ocf_to_debt\\\", \\\"fcf_to_debt\\\",\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"FEATURES_V3 = [\\n\",\n",
    "    \"    \\\"ln_at\\\", \\\"cash_at\\\", \\\"current_ratio\\\", \\\"nwc_at\\\", \\n\",\n",
    "    \"    \\\"rect_act\\\", \\\"invt_act\\\", \\n\",\n",
    "    \"    \\\"lt_at\\\", \\\"ceq_at\\\", \\\"re_at\\\", \\n\",\n",
    "    \"    \\\"niadj_at\\\", \\\"loss_indicator\\\", \\n\",\n",
    "    \"    \\\"xint_at\\\", \\\"prstkc_at\\\"\\n\",\n",
    "    \"]\"\n",
    "   ],\n",
    "   \"id\": \"b15b75e8c2858d09\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 5.2 Debt, capital, and operating aggregates\",\n",
    "   \"id\": \"c6761b68b1424a8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Ensure all required raw items are numeric for safe arithmetic\\n\",\n",
    "    \"raw_items = [\\n\",\n",
    "    \"    \\\"at\\\", \\\"che\\\", \\\"act\\\", \\\"lct\\\", \\\"aco\\\", \\\"lco\\\", \\\"rect\\\", \\\"invt\\\", \\\"recch\\\", \\\"invch\\\",\\n\",\n",
    "    \"    \\\"txp\\\", \\\"txditc\\\", \\\"lt\\\", \\\"dlc\\\", \\\"dltt\\\", \\\"oibdp\\\", \\\"dp\\\", \\\"xint\\\", \\\"ceq\\\", \\\"capx\\\",\\n\",\n",
    "    \"    \\\"ppent\\\", \\\"intan\\\", \\\"oancf\\\", \\\"re\\\", \\\"caps\\\", \\\"mibt\\\", \\\"niadj\\\", \\\"aqc\\\", \\\"prstkc\\\", \\\"seq\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"for c in raw_items:\\n\",\n",
    "    \"    if c in df.columns:\\n\",\n",
    "    \"        df[c] = pd.to_numeric(df[c], errors=\\\"coerce\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Debt aggregate\\n\",\n",
    "    \"df[\\\"total_debt\\\"] = df[[\\\"dlc\\\",\\\"dltt\\\"]].sum(axis=1, min_count=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Equity plus minority interest (if available)\\n\",\n",
    "    \"if \\\"mibt\\\" in df.columns:\\n\",\n",
    "    \"    df[\\\"equity_plus_mi\\\"] = df[[\\\"seq\\\",\\\"mibt\\\"]].sum(axis=1, min_count=1)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df[\\\"equity_plus_mi\\\"] = df[\\\"seq\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Total capital and a non-positive capital flag\\n\",\n",
    "    \"df[\\\"total_capital\\\"] = df[[\\\"total_debt\\\",\\\"equity_plus_mi\\\"]].sum(axis=1, min_count=1)\\n\",\n",
    "    \"df[\\\"cap_nonpos_flag\\\"] = (df[\\\"total_capital\\\"] <= 0).astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# EBITDA proxy\\n\",\n",
    "    \"df[\\\"ebitda_proxy\\\"] = df[\\\"oibdp\\\"]\\n\",\n",
    "    \"df[\\\"ebitda_nonpos_flag\\\"] = (df[\\\"ebitda_proxy\\\"] <= 0).astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Log transforms\\n\",\n",
    "    \"df[\\\"ln_at\\\"] = np.log(df[\\\"at\\\"].where(lambda s: s > 0))\\n\",\n",
    "    \"# Legacy name if needed elsewhere\\n\",\n",
    "    \"df[\\\"log_at\\\"] = df[\\\"ln_at\\\"]\\n\"\n",
    "   ],\n",
    "   \"id\": \"c46439b811a0b928\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 5.3 Leverage, coverage, and cash-flow ratios (V1, V2, V3 features)\",\n",
    "   \"id\": \"845c1621907f010f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# --- V1/V2/V3 Shared & Specific Features ---\\n\",\n",
    "    \"# (Using safe_divide which handles division by zero and returns NaN for extreme states)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Basic Ratios\\n\",\n",
    "    \"df[\\\"cash_at\\\"] = safe_divide(df[\\\"che\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"current_ratio\\\"] = safe_divide(df[\\\"act\\\"], df[\\\"lct\\\"])\\n\",\n",
    "    \"df[\\\"nwc_at\\\"] = safe_divide(df[\\\"act\\\"] - df[\\\"lct\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"# Removed: aco_act, lco_lct (excluded variables)\\n\",\n",
    "    \"df[\\\"rect_act\\\"] = safe_divide(df[\\\"rect\\\"], df[\\\"act\\\"])\\n\",\n",
    "    \"df[\\\"invt_act\\\"] = safe_divide(df[\\\"invt\\\"], df[\\\"act\\\"])\\n\",\n",
    "    \"# Removed: recch_act, invch_act, txp_lct, txditc_at (excluded variables)\\n\",\n",
    "    \"df[\\\"lt_at\\\"] = safe_divide(df[\\\"lt\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"dlc_at\\\"] = safe_divide(df[\\\"dlc\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"dltt_at\\\"] = safe_divide(df[\\\"dltt\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"debt_at\\\"] = safe_divide(df[\\\"total_debt\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"st_debt_share\\\"] = safe_divide(df[\\\"dlc\\\"], df[\\\"total_debt\\\"])\\n\",\n",
    "    \"df[\\\"ebitda_at\\\"] = safe_divide(df[\\\"oibdp\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"# Removed: dp_at (excluded variable)\\n\",\n",
    "    \"df[\\\"xint_at\\\"] = safe_divide(df[\\\"xint\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"interest_coverage\\\"] = safe_divide(df[\\\"oibdp\\\"], df[\\\"xint\\\"])\\n\",\n",
    "    \"df[\\\"debt_to_ebitda\\\"] = safe_divide(df[\\\"total_debt\\\"], df[\\\"oibdp\\\"])\\n\",\n",
    "    \"df[\\\"ebit_to_capital\\\"] = safe_divide(df[\\\"oibdp\\\"] - df[\\\"dp\\\"], df[\\\"total_debt\\\"] + df[\\\"ceq\\\"])\\n\",\n",
    "    \"# Removed: capx_at (excluded variable)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V2 extras\\n\",\n",
    "    \"df[\\\"ppent_at\\\"] = safe_divide(df[\\\"ppent\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"intan_at\\\"] = safe_divide(df[\\\"intan\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"ocf_to_debt\\\"] = safe_divide(df[\\\"oancf\\\"], df[\\\"total_debt\\\"])\\n\",\n",
    "    \"df[\\\"fcf_to_debt\\\"] = safe_divide(df[\\\"oancf\\\"] - df[\\\"capx\\\"], df[\\\"total_debt\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V3 extras\\n\",\n",
    "    \"df[\\\"ceq_at\\\"] = safe_divide(df[\\\"ceq\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"# Removed: caps_at, mibt_at (excluded variables)\\n\",\n",
    "    \"df[\\\"niadj_at\\\"] = safe_divide(df[\\\"niadj\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"df[\\\"loss_indicator\\\"] = (df[\\\"niadj\\\"] < 0).astype(float)\\n\",\n",
    "    \"# Removed: xint_lct, aqc_at (excluded variables)\\n\",\n",
    "    \"df[\\\"prstkc_at\\\"] = safe_divide(df[\\\"prstkc\\\"], df[\\\"at\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Legacy mappings for distress proxy definitions (Section 5.4) ---\\n\",\n",
    "    \"# (Keeping sp_ prefix for variables used in distress proxy definition rules)\\n\",\n",
    "    \"ffo_proxy = df[\\\"oancf\\\"] + df[\\\"xint\\\"]\\n\",\n",
    "    \"if \\\"txp\\\" in df.columns:\\n\",\n",
    "    \"    ffo_proxy = ffo_proxy - df[\\\"txp\\\"]\\n\",\n",
    "    \"df[\\\"sp_ffo_to_debt\\\"] = safe_divide(ffo_proxy, df[\\\"total_debt\\\"])\\n\",\n",
    "    \"df[\\\"sp_debt_to_capital\\\"] = safe_divide(df[\\\"total_debt\\\"], df[\\\"total_capital\\\"])\\n\",\n",
    "    \"df[\\\"sp_debt_to_ebitda\\\"] = df[\\\"debt_to_ebitda\\\"]\\n\",\n",
    "    \"df[\\\"sp_interest_coverage\\\"] = df[\\\"interest_coverage\\\"].clip(lower=-50, upper=50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Identify remaining +/-inf (though safe_divide already handles most)\\n\",\n",
    "    \"ratio_cols = [\\\"sp_debt_to_capital\\\",\\\"sp_debt_to_ebitda\\\",\\\"sp_ffo_to_debt\\\",\\\"sp_interest_coverage\\\"]\\n\",\n",
    "    \"for c in ratio_cols:\\n\",\n",
    "    \"    if c in df.columns:\\n\",\n",
    "    \"        df[c] = df[c].replace([np.inf, -np.inf], np.nan)\"\n",
    "   ],\n",
    "   \"id\": \"f2c1506116debb8b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 5.4 Multiple Distress Proxies (fiscal year t) and next-year supervised labels (t+1)\",\n",
    "   \"id\": \"ef19ae17f48f8f1c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Distress proxy thresholds (frozen and documented)\\n\",\n",
    "    \"DISTRESS_RULE = {\\n\",\n",
    "    \"    \\\"FFO_TO_DEBT_LT\\\": 0.15,\\n\",\n",
    "    \"    \\\"DEBT_TO_CAPITAL_GT\\\": 0.55,\\n\",\n",
    "    \"    \\\"DEBT_TO_EBITDA_GT\\\": 4.5,\\n\",\n",
    "    \"    \\\"NEG_EQUITY_SEQ_LE\\\": 0.0,\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Target construction from raw (non-imputed) data ---\\n\",\n",
    "    \"# We compute distress proxies from the raw snapshot (df_pre_impute_snapshot) \\n\",\n",
    "    \"# to ensure that target labels are not contaminated by the imputation process.\\n\",\n",
    "    \"# Imputation is strictly reserved for predictive features.\\n\",\n",
    "    \"\\n\",\n",
    "    \"raw_niadj = ensure_nullable_float(df_pre_impute_snapshot[\\\"niadj\\\"])\\n\",\n",
    "    \"raw_oancf = ensure_nullable_float(df_pre_impute_snapshot[\\\"oancf\\\"])\\n\",\n",
    "    \"raw_seq = ensure_nullable_float(df_pre_impute_snapshot[\\\"seq\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# S&P components from raw items (propagate missingness - Issue 3)\\n\",\n",
    "    \"raw_dlc = ensure_nullable_float(df_pre_impute_snapshot[\\\"dlc\\\"])\\n\",\n",
    "    \"raw_dltt = ensure_nullable_float(df_pre_impute_snapshot[\\\"dltt\\\"])\\n\",\n",
    "    \"raw_total_debt = raw_dlc + raw_dltt\\n\",\n",
    "    \"\\n\",\n",
    "    \"raw_oibdp = ensure_nullable_float(df_pre_impute_snapshot[\\\"oibdp\\\"])\\n\",\n",
    "    \"raw_xint = ensure_nullable_float(df_pre_impute_snapshot[\\\"xint\\\"])\\n\",\n",
    "    \"raw_txp = ensure_nullable_float(df_pre_impute_snapshot[\\\"txp\\\"]) if \\\"txp\\\" in df_pre_impute_snapshot.columns else 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"raw_ffo = raw_oancf + raw_xint - raw_txp\\n\",\n",
    "    \"raw_ffo_to_debt = safe_divide(raw_ffo, raw_total_debt)\\n\",\n",
    "    \"\\n\",\n",
    "    \"raw_mibt = ensure_nullable_float(df_pre_impute_snapshot[\\\"mibt\\\"]) if \\\"mibt\\\" in df_pre_impute_snapshot.columns else pd.Series(np.nan, index=df_pre_impute_snapshot.index)\\n\",\n",
    "    \"raw_equity = ensure_nullable_float(df_pre_impute_snapshot[[\\\"seq\\\",\\\"mibt\\\"]].sum(axis=1, min_count=1)) if \\\"mibt\\\" in df_pre_impute_snapshot.columns else raw_seq\\n\",\n",
    "    \"raw_total_capital = raw_total_debt + raw_equity\\n\",\n",
    "    \"\\n\",\n",
    "    \"raw_debt_to_cap = safe_divide(raw_total_debt, raw_total_capital)\\n\",\n",
    "    \"raw_debt_to_ebitda = safe_divide(raw_total_debt, raw_oibdp)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V1: Loss + NegCFO (Accounting-based)\\n\",\n",
    "    \"# Beaver (1966), Ohlson (1980) logic: niadj < 0 and oancf < 0\\n\",\n",
    "    \"df[\\\"distress_v1_t\\\"] = (raw_niadj < 0) & (raw_oancf < 0)\\n\",\n",
    "    \"# Fix: explicitly set to missing if inputs are missing\\n\",\n",
    "    \"df.loc[raw_niadj.isna() | raw_oancf.isna(), \\\"distress_v1_t\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V2: Negative Equity\\n\",\n",
    "    \"df[\\\"distress_v2_t\\\"] = raw_seq <= DISTRESS_RULE[\\\"NEG_EQUITY_SEQ_LE\\\"]\\n\",\n",
    "    \"# Fix: explicitly set to missing if inputs are missing\\n\",\n",
    "    \"df.loc[raw_seq.isna(), \\\"distress_v2_t\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"# V3: S&P High Leverage Solely (without conditioning on negative equity)\\n\",\n",
    "    \"cond_ffo = raw_ffo_to_debt < DISTRESS_RULE[\\\"FFO_TO_DEBT_LT\\\"]\\n\",\n",
    "    \"cond_cap = raw_debt_to_cap > DISTRESS_RULE[\\\"DEBT_TO_CAPITAL_GT\\\"]\\n\",\n",
    "    \"cond_ebitda = raw_debt_to_ebitda > DISTRESS_RULE[\\\"DEBT_TO_EBITDA_GT\\\"]\\n\",\n",
    "    \"df[\\\"distress_v3_t\\\"] = cond_ffo & cond_cap & cond_ebitda\\n\",\n",
    "    \"# Fix: explicitly set to missing if inputs are missing\\n\",\n",
    "    \"df.loc[raw_ffo_to_debt.isna() | raw_debt_to_cap.isna() | raw_debt_to_ebitda.isna(), \\\"distress_v3_t\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Next-year targets: lead of proxies within firm\\n\",\n",
    "    \"# Fix: Robust adjacency check (exactly fyear + 1) to avoid mislabeling gaps (Issue 1)\\n\",\n",
    "    \"next_fyear = df.groupby(\\\"firm_id\\\")[\\\"fyear\\\"].shift(-1)\\n\",\n",
    "    \"is_adjacent = (next_fyear == (df[\\\"fyear\\\"] + 1))\\n\",\n",
    "    \"\\n\",\n",
    "    \"df[\\\"target_next_v1\\\"] = df.groupby(\\\"firm_id\\\")[\\\"distress_v1_t\\\"].shift(-1)\\n\",\n",
    "    \"df.loc[~is_adjacent, \\\"target_next_v1\\\"] = pd.NA\\n\",\n",
    "    \"df[\\\"target_next_v1\\\"] = df[\\\"target_next_v1\\\"].astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"df[\\\"target_next_v2\\\"] = df.groupby(\\\"firm_id\\\")[\\\"distress_v2_t\\\"].shift(-1)\\n\",\n",
    "    \"df.loc[~is_adjacent, \\\"target_next_v2\\\"] = pd.NA\\n\",\n",
    "    \"df[\\\"target_next_v2\\\"] = df[\\\"target_next_v2\\\"].astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"df[\\\"target_next_v3\\\"] = df.groupby(\\\"firm_id\\\")[\\\"distress_v3_t\\\"].shift(-1)\\n\",\n",
    "    \"df.loc[~is_adjacent, \\\"target_next_v3\\\"] = pd.NA\\n\",\n",
    "    \"df[\\\"target_next_v3\\\"] = df[\\\"target_next_v3\\\"].astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Transition targets (early-warning): 1[distress_t==0 AND distress_{t+1}==1]\\n\",\n",
    "    \"# - Defined only for observations that are *healthy at t* (distress_t==0) and have an adjacent t+1.\\n\",\n",
    "    \"# - Rows with distress_t==1 are set to NA (they are not part of the early-warning risk set).\\n\",\n",
    "    \"for _v in [\\\"v1\\\", \\\"v2\\\", \\\"v3\\\"]:\\n\",\n",
    "    \"    _dcol = f\\\"distress_{_v}_t\\\"\\n\",\n",
    "    \"    _ncol = f\\\"target_next_{_v}\\\"\\n\",\n",
    "    \"    _tcol = f\\\"target_transition_{_v}\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    _dcur = pd.to_numeric(df[_dcol], errors=\\\"coerce\\\")  # {0,1} with NaNs\\n\",\n",
    "    \"    _ncur = pd.to_numeric(df[_ncol], errors=\\\"coerce\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df[_tcol] = pd.NA\\n\",\n",
    "    \"    _ok = is_adjacent & _dcur.notna() & _ncur.notna()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    _healthy = _ok & (_dcur == 0)\\n\",\n",
    "    \"    df.loc[_healthy, _tcol] = (_ncur.loc[_healthy] == 1).astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df[_tcol] = df[_tcol].astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# -------------------------\\n\",\n",
    "    \"# Modeling objective + proxy selection\\n\",\n",
    "    \"# -------------------------\\n\",\n",
    "    \"# PROXY_VERSION: choose among {\\\"v1\\\",\\\"v2\\\",\\\"v3\\\"}.\\n\",\n",
    "    \"# OBJECTIVE:\\n\",\n",
    "    \"#   - \\\"transition\\\": early-warning (healthy at t -> distressed at t+1)   [recommended for claims of \\\"early warning\\\"]\\n\",\n",
    "    \"#   - \\\"state\\\":       surveillance of the t+1 distress state (includes persistence)\\n\",\n",
    "    \"PROXY_VERSION = \\\"v2\\\"\\n\",\n",
    "    \"OBJECTIVE = \\\"transition\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"PROXY_NAME = f\\\"distress_{PROXY_VERSION}_t\\\"\\n\",\n",
    "    \"STATE_TARGET_NAME = f\\\"target_next_{PROXY_VERSION}\\\"\\n\",\n",
    "    \"TRANS_TARGET_NAME = f\\\"target_transition_{PROXY_VERSION}\\\"\\n\",\n",
    "    \"TARGET_NAME = TRANS_TARGET_NAME if OBJECTIVE.lower().startswith(\\\"trans\\\") else STATE_TARGET_NAME\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Label availability / attrition (fixed to check adjacency)\\n\",\n",
    "    \"df[\\\"has_next_year_obs\\\"] = is_adjacent.fillna(False).astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"target_cols = [\\\"target_next_v1\\\", \\\"target_next_v2\\\", \\\"target_next_v3\\\"]\\n\",\n",
    "    \"print(\\\"Distress prevalence (by split) — multiple targets:\\\")\\n\",\n",
    "    \"display(df.groupby(\\\"split\\\")[target_cols].mean())\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Share of observations with next-year observation (attrition diagnostic):\\\")\\n\",\n",
    "    \"display(df.groupby(\\\"split\\\")[\\\"has_next_year_obs\\\"].mean().rename(\\\"has_next_rate\\\").to_frame())\"\n",
    "   ],\n",
    "   \"id\": \"2d99e53af92ab69e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 5.5 Target prevalence and attrition diagnostics (by year and size)\",\n",
    "   \"id\": \"284ee669718b0086\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Target prevalence by label year\\n\",\n",
    "    \"target_cols = [\\\"target_next_v1\\\", \\\"target_next_v2\\\", \\\"target_next_v3\\\"]\\n\",\n",
    "    \"agg_dict = {\\n\",\n",
    "    \"    \\\"n_obs\\\": (\\\"firm_id\\\", \\\"size\\\"),\\n\",\n",
    "    \"    \\\"has_next_rate\\\": (\\\"has_next_year_obs\\\", \\\"mean\\\"),\\n\",\n",
    "    \"}\\n\",\n",
    "    \"for c in target_cols:\\n\",\n",
    "    \"    agg_dict[f\\\"{c}_rate\\\"] = (c, \\\"mean\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"by_label_year = df.groupby([\\\"label_year\\\",\\\"split\\\"]).agg(**agg_dict).reset_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(by_label_year.tail(15))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# By size decile (train pool), to assess composition effects\\n\",\n",
    "    \"agg_dict_size = {\\\"n_obs\\\": (\\\"firm_id\\\", \\\"size\\\")}\\n\",\n",
    "    \"for c in target_cols:\\n\",\n",
    "    \"    agg_dict_size[f\\\"{c}_rate\\\"] = (c, \\\"mean\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"by_size = df.groupby([\\\"size_decile\\\",\\\"split\\\"]).agg(**agg_dict_size).reset_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(by_size.sort_values([\\\"split\\\",\\\"size_decile\\\"]).head(30))\"\n",
    "   ],\n",
    "   \"id\": \"5e05d1b49cb72946\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 5.6 Event indicators (evt_*) for decision support\\n\",\n",
    "    \"\\n\",\n",
    "    \"Events are discrete, interpretable signals designed for operational triage.  \\n\",\n",
    "    \"They are calibrated **using training data only** (when thresholds are estimated), and we explicitly **exclude** events mechanically tied to the distress-definition ratios (leverage/coverage) from the predictive feature set.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Events implemented here (subject to data availability):\\n\",\n",
    "    \"- Dividend cut / suspension / initiation\\n\",\n",
    "    \"- Liquidity squeeze (current ratio < 1.0) and quick-ratio squeeze (< 0.8)\\n\",\n",
    "    \"- EBITDA drop (vs. t-1) and CFO drop (vs. t-1)\"\n",
    "   ],\n",
    "   \"id\": \"5bc978dc1a92f0ff\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Ensure sorting already enforced\\n\",\n",
    "    \"assert df.index.is_monotonic_increasing\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Lag helpers\\n\",\n",
    "    \"def lag(df_in: pd.DataFrame, col: str, n: int = 1) -> pd.Series:\\n\",\n",
    "    \"    \\\"\\\"\\\"Robust firm-level lag that enforces year adjacency (Issue 1).\\\"\\\"\\\"\\n\",\n",
    "    \"    val = df_in.groupby(\\\"firm_id\\\")[col].shift(n)\\n\",\n",
    "    \"    year_lag = df_in.groupby(\\\"firm_id\\\")[\\\"fyear\\\"].shift(n)\\n\",\n",
    "    \"    is_adjacent = (year_lag == (df_in[\\\"fyear\\\"] - n))\\n\",\n",
    "    \"    return val.where(is_adjacent.fillna(False), np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Identify dividend column (prefer dvc if present; else dv / dvt / dvp)\\n\",\n",
    "    \"dividend_candidates = [\\\"dvc\\\",\\\"dv\\\",\\\"dvt\\\",\\\"dvp\\\"]\\n\",\n",
    "    \"div_col = next((c for c in dividend_candidates if c in df.columns), None)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if div_col is None:\\n\",\n",
    "    \"    print(\\\"Dividend column not found (looked for dvc/dv/dvt/dvp). Dividend events will be NaN.\\\")\\n\",\n",
    "    \"    df[\\\"evt_divcut\\\"] = np.nan\\n\",\n",
    "    \"    df[\\\"evt_divsusp\\\"] = np.nan\\n\",\n",
    "    \"    df[\\\"evt_divinit\\\"] = np.nan\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # Use absolute value (guard against sign conventions)\\n\",\n",
    "    \"    df[\\\"dv_obs\\\"] = pd.to_numeric(df[div_col], errors=\\\"coerce\\\").abs()\\n\",\n",
    "    \"    df[\\\"dv_obs_l1\\\"] = lag(df, \\\"dv_obs\\\", 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Liquidity ratios\\n\",\n",
    "    \"if \\\"act\\\" in df.columns and \\\"lct\\\" in df.columns:\\n\",\n",
    "    \"    df[\\\"current_ratio\\\"] = safe_divide(df[\\\"act\\\"], df[\\\"lct\\\"], denom_floor=1e-6)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df[\\\"current_ratio\\\"] = np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"if \\\"act\\\" in df.columns and \\\"lct\\\" in df.columns:\\n\",\n",
    "    \"    if \\\"invt\\\" in df.columns:\\n\",\n",
    "    \"        df[\\\"quick_ratio\\\"] = safe_divide(pd.to_numeric(df[\\\"act\\\"], errors=\\\"coerce\\\") - pd.to_numeric(df[\\\"invt\\\"], errors=\\\"coerce\\\"),\\n\",\n",
    "    \"                                        df[\\\"lct\\\"], denom_floor=1e-6)\\n\",\n",
    "    \"    elif \\\"che\\\" in df.columns and \\\"rect\\\" in df.columns:\\n\",\n",
    "    \"        df[\\\"quick_ratio\\\"] = safe_divide(pd.to_numeric(df[\\\"che\\\"], errors=\\\"coerce\\\") + pd.to_numeric(df[\\\"rect\\\"], errors=\\\"coerce\\\"),\\n\",\n",
    "    \"                                        df[\\\"lct\\\"], denom_floor=1e-6)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        df[\\\"quick_ratio\\\"] = df[\\\"current_ratio\\\"]\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df[\\\"quick_ratio\\\"] = np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"# EBITDA and CFO lags for deterioration events\\n\",\n",
    "    \"if \\\"ebitda_proxy\\\" in df.columns:\\n\",\n",
    "    \"    df[\\\"ebitda_l1\\\"] = lag(df, \\\"ebitda_proxy\\\", 1)\\n\",\n",
    "    \"if \\\"oancf\\\" in df.columns:\\n\",\n",
    "    \"    df[\\\"cfo_l1\\\"] = lag(df, \\\"oancf\\\", 1)\"\n",
    "   ],\n",
    "   \"id\": \"9189e271ed6c321b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 5.5.1 Dividend policy events (training-calibrated cut threshold)\",\n",
    "   \"id\": \"1d333486a6af7c10\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"event_params = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"if div_col is None:\\n\",\n",
    "    \"    pass\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # YoY % change among observed payers with meaningful baseline\\n\",\n",
    "    \"    dv_l1 = pd.to_numeric(df[\\\"dv_obs_l1\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    dv = pd.to_numeric(df[\\\"dv_obs\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    df[\\\"div_pct_change\\\"] = np.where(dv_l1 > 1e-2, (dv - dv_l1) / dv_l1, np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    payer_train = train_mask & (dv_l1 > 0) & pd.notna(df[\\\"div_pct_change\\\"])\\n\",\n",
    "    \"    if payer_train.sum() >= 50:\\n\",\n",
    "    \"        cut_thr = float(np.nanpercentile(df.loc[payer_train, \\\"div_pct_change\\\"], 10))\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        cut_thr = -0.25\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Bound cut threshold to avoid pathological values\\n\",\n",
    "    \"    cut_thr = float(np.clip(cut_thr, -0.50, -0.10))\\n\",\n",
    "    \"    event_params[\\\"DIV_CUT_THR_P10_BOUNDED\\\"] = cut_thr\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Dividend cut: large negative YoY change among payers\\n\",\n",
    "    \"    df[\\\"evt_divcut\\\"] = (df[\\\"div_pct_change\\\"] <= cut_thr).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    df.loc[df[\\\"div_pct_change\\\"].isna(), \\\"evt_divcut\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Suspension: payer last year, ~zero dividend now\\n\",\n",
    "    \"    df[\\\"evt_divsusp\\\"] = ((dv_l1 > 0) & (dv.fillna(0) <= 1e-4)).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    df.loc[dv_l1.isna() | dv.isna(), \\\"evt_divsusp\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Initiation: ~zero last year, dividend now positive\\n\",\n",
    "    \"    df[\\\"evt_divinit\\\"] = ((dv_l1.fillna(0) <= 1e-4) & (dv > 1e-4)).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    df.loc[dv_l1.isna() | dv.isna(), \\\"evt_divinit\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"Dividend cut threshold (train P10 bounded): {cut_thr:.3f}\\\")\\n\",\n",
    "    \"    display(df[[\\\"dv_obs\\\",\\\"dv_obs_l1\\\",\\\"div_pct_change\\\",\\\"evt_divcut\\\",\\\"evt_divsusp\\\",\\\"evt_divinit\\\"]].head(8))\"\n",
    "   ],\n",
    "   \"id\": \"e4daa351ae216007\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 5.5.2 Liquidity squeeze events\",\n",
    "   \"id\": \"ae4b5610be6acc66\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"cr = pd.to_numeric(df[\\\"current_ratio\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"df[\\\"evt_liq_squeeze\\\"] = (cr < 1.0).astype(\\\"Int8\\\")\\n\",\n",
    "    \"df.loc[cr.isna(), \\\"evt_liq_squeeze\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"qr = pd.to_numeric(df[\\\"quick_ratio\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"df[\\\"evt_quick_squeeze\\\"] = (qr < 0.8).astype(\\\"Int8\\\")\\n\",\n",
    "    \"df.loc[qr.isna(), \\\"evt_quick_squeeze\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(df[[\\\"current_ratio\\\",\\\"quick_ratio\\\",\\\"evt_liq_squeeze\\\",\\\"evt_quick_squeeze\\\"]].head(8))\"\n",
    "   ],\n",
    "   \"id\": \"1e161354c6a4120\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 5.5.3 Operating deterioration events (vs. t-1)\",\n",
    "   \"id\": \"b127e75e098c89ca\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# EBITDA drop: requires lagged EBITDA observed and positive\\n\",\n",
    "    \"if \\\"ebitda_proxy\\\" in df.columns:\\n\",\n",
    "    \"    e = pd.to_numeric(df[\\\"ebitda_proxy\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    e_l1 = pd.to_numeric(df[\\\"ebitda_l1\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    ratio = e / e_l1\\n\",\n",
    "    \"    evt = ((e_l1 > 0) & ((ratio < 0.5) | (e <= 0))).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    evt = evt.where(pd.notna(e_l1) & pd.notna(e), other=pd.NA).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    df[\\\"evt_ebitdadrop\\\"] = evt\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df[\\\"evt_ebitdadrop\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"# CFO drop: requires lagged CFO observed and positive\\n\",\n",
    "    \"if \\\"oancf\\\" in df.columns:\\n\",\n",
    "    \"    c = pd.to_numeric(df[\\\"oancf\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    c_l1 = pd.to_numeric(df[\\\"cfo_l1\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    ratio = c / c_l1\\n\",\n",
    "    \"    evt = ((c_l1 > 0) & ((ratio < 0.5) | (c <= 0))).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    evt = evt.where(pd.notna(c_l1) & pd.notna(c), other=pd.NA).astype(\\\"Int8\\\")\\n\",\n",
    "    \"    df[\\\"evt_cfdrop\\\"] = evt\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    df[\\\"evt_cfdrop\\\"] = pd.NA\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(df[[\\\"ebitda_proxy\\\",\\\"ebitda_l1\\\",\\\"evt_ebitdadrop\\\",\\\"oancf\\\",\\\"cfo_l1\\\",\\\"evt_cfdrop\\\"]].head(10))\"\n",
    "   ],\n",
    "   \"id\": \"c0d67b59817d16cc\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 5.5.4 Event dictionary (appendix-ready)\",\n",
    "   \"id\": \"23ad26c5701d48e4\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"event_dict_rows = [\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_divcut\\\", \\\"definition\\\":\\\"Dividend YoY % change <= training P10 threshold (bounded [-0.50,-0.10])\\\", \\\"inputs\\\":div_col or \\\"N/A\\\", \\\"calibration\\\":\\\"train-only\\\"},\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_divsusp\\\", \\\"definition\\\":\\\"Dividend >0 at t-1 and ~0 at t\\\", \\\"inputs\\\":div_col or \\\"N/A\\\", \\\"calibration\\\":\\\"none\\\"},\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_divinit\\\", \\\"definition\\\":\\\"Dividend ~0 at t-1 and >0 at t\\\", \\\"inputs\\\":div_col or \\\"N/A\\\", \\\"calibration\\\":\\\"none\\\"},\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_liq_squeeze\\\", \\\"definition\\\":\\\"Current ratio < 1.0\\\", \\\"inputs\\\":\\\"act,lct\\\", \\\"calibration\\\":\\\"fixed threshold\\\"},\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_quick_squeeze\\\", \\\"definition\\\":\\\"Quick ratio < 0.8\\\", \\\"inputs\\\":\\\"act,lct,invt (or che+rect)\\\", \\\"calibration\\\":\\\"fixed threshold\\\"},\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_ebitdadrop\\\", \\\"definition\\\":\\\"EBITDA <=0 OR EBITDA/EBITDA_{t-1}<0.5 (requires EBITDA_{t-1}>0)\\\", \\\"inputs\\\":\\\"oibdp\\\", \\\"calibration\\\":\\\"fixed threshold\\\"},\\n\",\n",
    "    \"    {\\\"event\\\":\\\"evt_cfdrop\\\", \\\"definition\\\":\\\"CFO <=0 OR CFO/CFO_{t-1}<0.5 (requires CFO_{t-1}>0)\\\", \\\"inputs\\\":\\\"oancf\\\", \\\"calibration\\\":\\\"fixed threshold\\\"},\\n\",\n",
    "    \"]\\n\",\n",
    "    \"event_dict = pd.DataFrame(event_dict_rows)\\n\",\n",
    "    \"event_dict[\\\"parameter\\\"] = event_dict[\\\"event\\\"].map(lambda e: json.dumps({k:v for k,v in event_params.items()}) if e==\\\"evt_divcut\\\" else \\\"\\\")\\n\",\n",
    "    \"display(event_dict)\"\n",
    "   ],\n",
    "   \"id\": \"a5c7ec29fda6ea42\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 6. Preprocessing for Modeling (train-only fitting)\\n\",\n",
    "    \"\\n\",\n",
    "    \"I keep preprocessing leakage-safe:\\n\",\n",
    "    \"- fit medians, winsor bounds, and scalers on **train** only,\\n\",\n",
    "    \"- apply those transforms to all splits,\\n\",\n",
    "    \"- preserve an unprocessed snapshot for walk-forward validation.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"439644583f1adcb\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Features that participate in the distress proxy definition (must be excluded from predictors)\\n\",\n",
    "    \"# We key off PROXY_VERSION (not TARGET_NAME) so the same leakage rules apply to both objectives:\\n\",\n",
    "    \"#   - OBJECTIVE=\\\"state\\\"       -> TARGET_NAME = target_next_vX\\n\",\n",
    "    \"#   - OBJECTIVE=\\\"transition\\\"  -> TARGET_NAME = target_transition_vX\\n\",\n",
    "    \"\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    _pv = PROXY_VERSION\\n\",\n",
    "    \"except NameError:\\n\",\n",
    "    \"    # Backward compatibility if PROXY_VERSION is not defined in the targets cell\\n\",\n",
    "    \"    if TARGET_NAME.endswith(\\\"_v1\\\"):\\n\",\n",
    "    \"        _pv = \\\"v1\\\"\\n\",\n",
    "    \"    elif TARGET_NAME.endswith(\\\"_v2\\\"):\\n\",\n",
    "    \"        _pv = \\\"v2\\\"\\n\",\n",
    "    \"    elif TARGET_NAME.endswith(\\\"_v3\\\"):\\n\",\n",
    "    \"        _pv = \\\"v3\\\"\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        _pv = \\\"v2\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"if _pv == \\\"v1\\\":\\n\",\n",
    "    \"    # v1 uses niadj and oancf\\n\",\n",
    "    \"    DISTRESS_DEFINITION_VARS = {\\\"niadj\\\", \\\"oancf\\\", \\\"niadj_at\\\", \\\"loss_indicator\\\", \\\"ocf_to_debt\\\", \\\"fcf_to_debt\\\"}\\n\",\n",
    "    \"    continuous_feats_raw = [c for c in FEATURES_V1]\\n\",\n",
    "    \"    event_feats = []\\n\",\n",
    "    \"elif _pv == \\\"v2\\\":\\n\",\n",
    "    \"    # v2 uses seq\\n\",\n",
    "    \"    DISTRESS_DEFINITION_VARS = {\\\"seq\\\"}\\n\",\n",
    "    \"    continuous_feats_raw = [c for c in FEATURES_V2]\\n\",\n",
    "    \"    event_feats = []\\n\",\n",
    "    \"elif _pv == \\\"v3\\\":\\n\",\n",
    "    \"    # v3 uses ffo (oancf, xint, txp), debt (dlc, dltt), and equity (seq, mibt)\\n\",\n",
    "    \"    DISTRESS_DEFINITION_VARS = {\\n\",\n",
    "    \"        \\\"sp_ffo_to_debt\\\", \\\"sp_debt_to_capital\\\", \\\"sp_debt_to_ebitda\\\",\\n\",\n",
    "    \"        \\\"oancf\\\", \\\"xint\\\", \\\"txp\\\", \\\"dlc\\\", \\\"dltt\\\", \\\"seq\\\", \\\"mibt\\\", \\\"oibdp\\\",\\n\",\n",
    "    \"        \\\"ocf_to_debt\\\", \\\"fcf_to_debt\\\", \\\"debt_to_ebitda\\\", \\\"interest_coverage\\\"\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    # loss_indicator is binary, treat as event feature to avoid z-scoring\\n\",\n",
    "    \"    continuous_feats_raw = [c for c in FEATURES_V3 if c != \\\"loss_indicator\\\"]\\n\",\n",
    "    \"    event_feats = [\\\"loss_indicator\\\"]\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    DISTRESS_DEFINITION_VARS = set()\\n\",\n",
    "    \"    continuous_feats_raw = [c for c in FEATURES_V2]\\n\",\n",
    "    \"    event_feats = []\\n\",\n",
    "    \"continuous_feats_raw = [c for c in continuous_feats_raw if c in df.columns]\\n\",\n",
    "    \"event_feats = [c for c in event_feats if c in df.columns]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Final model feature list (events in levels; continuous will be z-scored with z_ prefix)\\n\",\n",
    "    \"MODEL_FEATS = [f\\\"z_{c}\\\" for c in continuous_feats_raw] + event_feats\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Leakage audit: ensure no distress-definition variables are included (raw or scaled variants)\\n\",\n",
    "    \"leakage_hits = []\\n\",\n",
    "    \"for v in DISTRESS_DEFINITION_VARS:\\n\",\n",
    "    \"    if v in continuous_feats_raw or v in event_feats or f\\\"z_{v}\\\" in MODEL_FEATS:\\n\",\n",
    "    \"        leakage_hits.append(v)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if leakage_hits:\\n\",\n",
    "    \"    raise ValueError(f\\\"Leakage audit failed: distress-definition variables present in feature set: {leakage_hits}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Continuous (to be scaled):\\\", continuous_feats_raw)\\n\",\n",
    "    \"print(\\\"Events (kept in levels):\\\", event_feats)\\n\",\n",
    "    \"print(\\\"MODEL_FEATS (post-scaling names):\\\", MODEL_FEATS)\"\n",
    "   ],\n",
    "   \"id\": \"2158e3e5d924c461\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 6.2 Modeling sample and target availability\",\n",
    "   \"id\": \"92fbb364a8a8d104\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Modeling requires a defined next-year label\\n\",\n",
    "    \"model_mask = df[TARGET_NAME].notna()\\n\",\n",
    "    \"df_model = df.loc[model_mask].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Modeling sample size:\\\", df_model.shape[0])\\n\",\n",
    "    \"display(df_model[\\\"split\\\"].value_counts().to_frame(\\\"n_obs\\\"))\\n\",\n",
    "    \"# Snapshot for leakage-free walk-forward validation\\n\",\n",
    "    \"df_model_raw = df_model.copy(deep=True)\\n\"\n",
    "   ],\n",
    "   \"id\": \"d9e70f95d6efe1f8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 6.3 Replace infinities and set up train-only median imputation for remaining NaNs\",\n",
    "   \"id\": \"4f16a198f7b28ece\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Replace inf with NaN for preprocessing\\n\",\n",
    "    \"for c in continuous_feats_raw:\\n\",\n",
    "    \"    df_model[c] = pd.to_numeric(df_model[c], errors=\\\"coerce\\\").replace([np.inf, -np.inf], np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train-only medians for remaining NaNs (after earlier imputation steps)\\n\",\n",
    "    \"train_medians = df_model.loc[df_model[\\\"split\\\"]==\\\"train\\\", continuous_feats_raw].median()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for c in continuous_feats_raw:\\n\",\n",
    "    \"    df_model[c] = df_model[c].fillna(train_medians[c])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Event features: coerce to Int8 with missing -> 0 (conservative) but preserve missingness flags separately if desired\\n\",\n",
    "    \"for c in event_feats:\\n\",\n",
    "    \"    df_model[c] = pd.to_numeric(df_model[c], errors=\\\"coerce\\\").fillna(0).astype(\\\"Int8\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"assert df_model[continuous_feats_raw].isna().sum().sum() == 0, \\\"NaNs remain in continuous features after train-median fill.\\\"\"\n",
    "   ],\n",
    "   \"id\": \"d6cffd80d03edd83\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 6.4 Winsorize continuous features (train quantile bounds)\",\n",
    "   \"id\": \"575dcb7d42855cc3\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"winsor_bounds = {}\\n\",\n",
    "    \"for c in continuous_feats_raw:\\n\",\n",
    "    \"    lo, hi = winsorize_train_bounds(df_model.loc[df_model[\\\"split\\\"]==\\\"train\\\", c], CONFIG[\\\"WINSOR_LO_Q\\\"], CONFIG[\\\"WINSOR_HI_Q\\\"])\\n\",\n",
    "    \"    winsor_bounds[c] = (lo, hi)\\n\",\n",
    "    \"    df_model[c] = apply_bounds(df_model[c], lo, hi)\\n\",\n",
    "    \"\\n\",\n",
    "    \"winsor_tbl = pd.DataFrame(\\n\",\n",
    "    \"    [{\\\"feature\\\": c, \\\"lo\\\": winsor_bounds[c][0], \\\"hi\\\": winsor_bounds[c][1]} for c in continuous_feats_raw]\\n\",\n",
    "    \")\\n\",\n",
    "    \"display(winsor_tbl)\"\n",
    "   ],\n",
    "   \"id\": \"f595356f7ca3a9a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 6.5 Standardize continuous features (train-fit scaler; z_ prefix)\",\n",
    "   \"id\": \"d10c2e330dc7d71a\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Standardize continuous features (fit on TRAIN only)\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"df_model[continuous_feats_raw] = df_model[continuous_feats_raw].apply(lambda s: pd.to_numeric(s, errors=\\\"coerce\\\"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_cont = df_model.loc[df_model[\\\"split\\\"] == \\\"train\\\", continuous_feats_raw].astype(float)\\n\",\n",
    "    \"scaler.fit(train_cont)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Z_all = scaler.transform(df_model[continuous_feats_raw].astype(float))\\n\",\n",
    "    \"for j, c in enumerate(continuous_feats_raw):\\n\",\n",
    "    \"    df_model[f\\\"z_{c}\\\"] = Z_all[:, j].astype(float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Final modeling matrix (events forced to clean 0/1 ints)\\n\",\n",
    "    \"z_cols = [f\\\"z_{c}\\\" for c in continuous_feats_raw]\\n\",\n",
    "    \"X = df_model[z_cols + event_feats].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Guardrail check: verify excluded variables are not present in final feature matrix\\n\",\n",
    "    \"EXCLUDED_VARS = [\\n\",\n",
    "    \"    \\\"aco_act\\\", \\\"aqc_at\\\", \\\"caps_at\\\", \\\"capx_at\\\", \\\"dp_at\\\",\\n\",\n",
    "    \"    \\\"invch_act\\\", \\\"lco_lct\\\", \\\"mibt_at\\\", \\\"recch_act\\\",\\n\",\n",
    "    \"    \\\"txditc_at\\\", \\\"txp_lct\\\", \\\"xint_lct\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"EXCLUDED_Z_VARS = [f\\\"z_{v}\\\" for v in EXCLUDED_VARS]\\n\",\n",
    "    \"offending_cols = [c for c in X.columns if c in EXCLUDED_VARS or c in EXCLUDED_Z_VARS]\\n\",\n",
    "    \"if offending_cols:\\n\",\n",
    "    \"    raise ValueError(f\\\"Guardrail check failed: Excluded variables found in final feature matrix X: {offending_cols}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"for c in event_feats:\\n\",\n",
    "    \"    X[c] = pd.to_numeric(X[c], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    X[c] = X[c].fillna(0).astype(\\\"int8\\\")\\n\",\n",
    "    \"    assert set(X[c].unique()).issubset({0, 1}), f\\\"{c} not binary after coercion: {sorted(X[c].unique())}\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"y = df_model[TARGET_NAME].astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split views\\n\",\n",
    "    \"splits = {}\\n\",\n",
    "    \"for sp in [\\\"train\\\", \\\"val\\\", \\\"test\\\"]:\\n\",\n",
    "    \"    mask = df_model[\\\"split\\\"] == sp\\n\",\n",
    "    \"    splits[sp] = {\\\"X\\\": X.loc[mask, :], \\\"y\\\": y.loc[mask], \\\"df\\\": df_model.loc[mask, :]}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print({sp: (v[\\\"X\\\"].shape[0], v[\\\"X\\\"].shape[1]) for sp, v in splits.items()})\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Numeric-safe finiteness check\\n\",\n",
    "    \"assert np.isfinite(X.astype(\\\"float64\\\").to_numpy()).all(), \\\"Non-finite values in modeling matrix.\\\"\\n\"\n",
    "   ],\n",
    "   \"id\": \"32ee881d316383b2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 7. Model Selection & Training\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 7A. Logit model (primary baseline: calibrated PD with interpretable coefficients)\\n\",\n",
    "    \"\\n\",\n",
    "    \"#### 7A.1 Hyperparameter tuning on out-of-time validation year\"\n",
    "   ],\n",
    "   \"id\": \"fe0ab318ddfcc6de\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"train_X, train_y = splits[\\\"train\\\"][\\\"X\\\"], splits[\\\"train\\\"][\\\"y\\\"]\\n\",\n",
    "    \"val_X, val_y = splits[\\\"val\\\"][\\\"X\\\"], splits[\\\"val\\\"][\\\"y\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"results = []\\n\",\n",
    "    \"for C in CONFIG[\\\"LOGIT_C_GRID\\\"]:\\n\",\n",
    "    \"    mdl = LogisticRegression(C=C, solver=\\\"lbfgs\\\", max_iter=2000, random_state=SEED)\\n\",\n",
    "    \"    mdl.fit(train_X, train_y)\\n\",\n",
    "    \"    val_proba = mdl.predict_proba(val_X)[:, 1]\\n\",\n",
    "    \"    results.append({\\n\",\n",
    "    \"        \\\"C\\\": C,\\n\",\n",
    "    \"        \\\"val_roc_auc\\\": roc_auc_score(val_y, val_proba),\\n\",\n",
    "    \"        \\\"val_pr_auc\\\": average_precision_score(val_y, val_proba),\\n\",\n",
    "    \"        \\\"val_brier\\\": brier_score_loss(val_y, val_proba),\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"tune_tbl = pd.DataFrame(results).sort_values(\\\"val_roc_auc\\\", ascending=False)\\n\",\n",
    "    \"display(tune_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"best_C = float(tune_tbl.iloc[0][\\\"C\\\"])\\n\",\n",
    "    \"print(\\\"Selected C:\\\", best_C)\"\n",
    "   ],\n",
    "   \"id\": \"4d7c3ccd8c48fb4f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 7A.2 Fit Logit models and generate PDs\",\n",
    "   \"id\": \"f047fec52a0b8070\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"trainval_mask = df_model[\\\"split\\\"].isin([\\\"train\\\",\\\"val\\\"])\\n\",\n",
    "    \"X_trainval = X.loc[trainval_mask, :]\\n\",\n",
    "    \"y_trainval = y.loc[trainval_mask]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# To ensure 'val' metrics are honest out-of-sample estimates, we use the model \\n\",\n",
    "    \"# trained on 'train' only for the validation split. \\n\",\n",
    "    \"# For the final 'test' performance, we use the model trained on 'train+val'.\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model trained on 'train' ONLY (for honest 'val' evaluation)\\n\",\n",
    "    \"logit_train_only = LogisticRegression(C=best_C, solver=\\\"lbfgs\\\", max_iter=3000, random_state=SEED)\\n\",\n",
    "    \"logit_train_only.fit(train_X, train_y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Model trained on 'train+val' (for final 'test' evaluation)\\n\",\n",
    "    \"logit_trainval = LogisticRegression(C=best_C, solver=\\\"lbfgs\\\", max_iter=3000, random_state=SEED)\\n\",\n",
    "    \"logit_trainval.fit(X_trainval, y_trainval)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Assign predictions\\n\",\n",
    "    \"df_model[\\\"pd_logit\\\"] = np.nan\\n\",\n",
    "    \"# val gets predictions from train-only model (honest out-of-sample)\\n\",\n",
    "    \"df_model.loc[df_model[\\\"split\\\"]==\\\"val\\\", \\\"pd_logit\\\"] = logit_train_only.predict_proba(val_X)[:, 1]\\n\",\n",
    "    \"# test gets predictions from train+val model\\n\",\n",
    "    \"df_model.loc[df_model[\\\"split\\\"]==\\\"test\\\", \\\"pd_logit\\\"] = logit_trainval.predict_proba(splits[\\\"test\\\"][\\\"X\\\"])[:, 1]\\n\",\n",
    "    \"# train gets predictions from train+val model (in-sample)\\n\",\n",
    "    \"df_model.loc[df_model[\\\"split\\\"]==\\\"train\\\", \\\"pd_logit\\\"] = logit_trainval.predict_proba(train_X)[:, 1]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# For legacy compatibility in reporting\\n\",\n",
    "    \"df_model[\\\"pd_logit_val\\\"] = np.where(df_model[\\\"split\\\"]==\\\"val\\\", df_model[\\\"pd_logit\\\"], np.nan)\\n\",\n",
    "    \"df_model[\\\"pd_logit_test\\\"] = np.where(df_model[\\\"split\\\"]==\\\"test\\\", df_model[\\\"pd_logit\\\"], np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Keep logit_clf as the final model for downstream use\\n\",\n",
    "    \"logit_clf = logit_trainval\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Example PDs (Logit):\\\")\\n\",\n",
    "    \"display(df_model[[\\\"firm_id\\\",\\\"fyear\\\",\\\"label_year\\\",\\\"split\\\",TARGET_NAME,\\\"pd_logit\\\"]].head(10))\"\n",
    "   ],\n",
    "   \"id\": \"32bd384b95081a6b\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 7A.3 Inference audit (statsmodels Logit; clustered standard errors)\",\n",
    "   \"id\": \"94aa71e3d65769b2\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import statsmodels.api as sm\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\\n\",\n",
    "    \"# Statsmodels requires numpy arrays; keep column names for tables.\\n\",\n",
    "    \"X_sm = sm.add_constant(X_trainval, has_constant=\\\"add\\\")\\n\",\n",
    "    \"y_sm = y_trainval.astype(float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"logit_sm = sm.Logit(y_sm, X_sm)\\n\",\n",
    "    \"res_sm = logit_sm.fit(disp=False, maxiter=200)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Firm cluster (numeric codes to avoid dtype issues) ---\\n\",\n",
    "    \"firm_raw = df_model.loc[trainval_mask, \\\"firm_id\\\"]\\n\",\n",
    "    \"firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\\n\",\n",
    "    \"\\n\",\n",
    "    \"cov_firm = cov_cluster(res_sm, firm_codes)\\n\",\n",
    "    \"se_firm = np.sqrt(np.diag(cov_firm))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Two-way cluster (firm + year), with feasibility + shape guards ---\\n\",\n",
    "    \"year_raw = df_model.loc[trainval_mask, \\\"label_year\\\"]\\n\",\n",
    "    \"firm_raw = df_model.loc[trainval_mask, \\\"firm_id\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\\n\",\n",
    "    \"year_codes = pd.factorize(year_raw, sort=True)[0].astype(np.int64)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if (np.unique(firm_codes).size < 2) or (np.unique(year_codes).size < 2):\\n\",\n",
    "    \"    # Not enough clusters in one dimension -> two-way clustering not identified\\n\",\n",
    "    \"    se_2 = se_firm.copy()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    cov_2 = cov_cluster_2groups(res_sm, firm_codes, year_codes)\\n\",\n",
    "    \"    cov_2 = np.asarray(cov_2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    k = len(res_sm.params)\\n\",\n",
    "    \"    if cov_2.ndim == 2 and cov_2.shape == (k, k):\\n\",\n",
    "    \"        se_2 = np.sqrt(np.diag(cov_2))\\n\",\n",
    "    \"    elif cov_2.ndim == 1 and cov_2.size == k:\\n\",\n",
    "    \"        # Some statsmodels versions may return only the diagonal variances\\n\",\n",
    "    \"        se_2 = np.sqrt(cov_2)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Unexpected shape -> fall back (safer than crashing)\\n\",\n",
    "    \"        se_2 = se_firm.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"coef = res_sm.params\\n\",\n",
    "    \"p_firm = 2 * (1 - stats.norm.cdf(np.abs(coef / se_firm)))\\n\",\n",
    "    \"p_2 = 2 * (1 - stats.norm.cdf(np.abs(coef / se_2)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"infer_tbl = pd.DataFrame({\\n\",\n",
    "    \"    \\\"coef_logodds\\\": coef,\\n\",\n",
    "    \"    \\\"se_firm\\\": se_firm,\\n\",\n",
    "    \"    \\\"p_firm\\\": p_firm,\\n\",\n",
    "    \"    \\\"se_firm_year\\\": se_2,\\n\",\n",
    "    \"    \\\"p_firm_year\\\": p_2,\\n\",\n",
    "    \"    \\\"odds_ratio\\\": np.exp(coef),\\n\",\n",
    "    \"})\\n\",\n",
    "    \"infer_tbl.index.name = \\\"feature\\\"\\n\",\n",
    "    \"display(infer_tbl)\"\n",
    "   ],\n",
    "   \"id\": \"c87138c570b0f274\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 7A.4 Economic magnitude: MEM marginal effects and IQR-scaled effects\",\n",
    "   \"id\": \"12210366e50a9031\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# MEM marginal effects using statsmodels (on train+val)\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    me = res_sm.get_margeff(at=\\\"mean\\\")\\n\",\n",
    "    \"    me_tbl = me.summary_frame()\\n\",\n",
    "    \"    # Align to inference table index (margeff typically excludes const)\\n\",\n",
    "    \"    me_tbl = me_tbl.reindex(infer_tbl.index)\\n\",\n",
    "    \"    display(me_tbl)\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(\\\"Marginal effects computation failed:\\\", e)\\n\",\n",
    "    \"    me_tbl = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"# IQR-scaled effects for continuous features (using TRAIN distribution, mapped into z-space)\\n\",\n",
    "    \"train_df = df_model.loc[df_model[\\\"split\\\"]==\\\"train\\\", :].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"iqr_rows = []\\n\",\n",
    "    \"for j, raw_c in enumerate(continuous_feats_raw):\\n\",\n",
    "    \"    q25 = float(train_df[raw_c].quantile(0.25))\\n\",\n",
    "    \"    q75 = float(train_df[raw_c].quantile(0.75))\\n\",\n",
    "    \"    iqr = q75 - q25\\n\",\n",
    "    \"    sd = float(scaler.scale_[j]) if scaler.scale_[j] > 0 else np.nan\\n\",\n",
    "    \"    delta_z = iqr / sd if sd and not np.isnan(sd) else np.nan\\n\",\n",
    "    \"    beta = float(infer_tbl.loc[f\\\"z_{raw_c}\\\", \\\"coef_logodds\\\"]) if f\\\"z_{raw_c}\\\" in infer_tbl.index else np.nan\\n\",\n",
    "    \"    logodds_delta = beta * delta_z if not np.isnan(beta) and not np.isnan(delta_z) else np.nan\\n\",\n",
    "    \"    iqr_rows.append({\\n\",\n",
    "    \"        \\\"raw_feature\\\": raw_c,\\n\",\n",
    "    \"        \\\"IQR_raw\\\": iqr,\\n\",\n",
    "    \"        \\\"delta_z_equiv\\\": delta_z,\\n\",\n",
    "    \"        \\\"logodds_change_IQR\\\": logodds_delta,\\n\",\n",
    "    \"        \\\"odds_ratio_IQR\\\": float(np.exp(logodds_delta)) if not np.isnan(logodds_delta) else np.nan,\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"iqr_tbl = pd.DataFrame(iqr_rows)\\n\",\n",
    "    \"display(iqr_tbl)\"\n",
    "   ],\n",
    "   \"id\": \"40181343862d5e18\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 7A.5 Average Partial Effects (APEs) in probability units with cluster-robust uncertainty\\n\",\n",
    "   \"id\": \"231827c9589a35a1\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# APEs (Average Partial Effects) for logit model, using delta-method SEs with cluster-robust covariances\\n\",\n",
    "    \"# Notes:\\n\",\n",
    "    \"# - For logit, dP/dx_j = p*(1-p)*beta_j. The APE is the sample average of this derivative.\\n\",\n",
    "    \"# - We compute APEs on the TRAIN+VAL estimation sample used in statsmodels (X_sm, res_sm).\\n\",\n",
    "    \"# - SEs use the same cluster-robust covariance matrices already computed above (cov_firm and cov_2).\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"def _coerce_cov(V, names):\\n\",\n",
    "    \"    \\\"\\\"\\\"Return numeric (k x k) covariance aligned to names. Fallback logic handles common statsmodels outputs.\\\"\\\"\\\"\\n\",\n",
    "    \"    k = len(names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if isinstance(V, pd.DataFrame):\\n\",\n",
    "    \"        V = V.reindex(index=names, columns=names).to_numpy(dtype=float)\\n\",\n",
    "    \"        return V\\n\",\n",
    "    \"\\n\",\n",
    "    \"    V = np.asarray(V)\\n\",\n",
    "    \"    V = np.squeeze(V)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Handle 3D objects (e.g., (3,k,k) or (k,k,3)): take first covariance slice\\n\",\n",
    "    \"    if V.ndim == 3:\\n\",\n",
    "    \"        if V.shape[1:] == (k, k):\\n\",\n",
    "    \"            V = V[0]\\n\",\n",
    "    \"        elif V.shape[:2] == (k, k):\\n\",\n",
    "    \"            V = V[:, :, 0]\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            V = V.reshape(-1, k, k)[0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Handle diagonal-only variances\\n\",\n",
    "    \"    if V.ndim == 1:\\n\",\n",
    "    \"        if V.size != k:\\n\",\n",
    "    \"            raise ValueError(f\\\"Unexpected 1D covariance length: {V.size} (expected {k})\\\")\\n\",\n",
    "    \"        V = np.diag(V.astype(float))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if V.ndim != 2 or V.shape != (k, k):\\n\",\n",
    "    \"        raise ValueError(f\\\"Unexpected covariance shape: {V.shape} (expected {(k, k)})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    V = V.astype(float)\\n\",\n",
    "    \"    V[~np.isfinite(V)] = 0.0\\n\",\n",
    "    \"    return V\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ---- Align design matrix to params order ----\\n\",\n",
    "    \"X_df = X_sm if isinstance(X_sm, pd.DataFrame) else pd.DataFrame(X_sm)\\n\",\n",
    "    \"b_ser = res_sm.params\\n\",\n",
    "    \"\\n\",\n",
    "    \"names = list(b_ser.index)\\n\",\n",
    "    \"X_df = X_df.loc[:, names]                 # enforce same column order\\n\",\n",
    "    \"X_audit_np = X_df.to_numpy(dtype=float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"b = b_ser.to_numpy(dtype=float)\\n\",\n",
    "    \"k = len(names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predicted probabilities on estimation sample\\n\",\n",
    "    \"eta = X_audit_np @ b\\n\",\n",
    "    \"p = 1.0 / (1.0 + np.exp(-eta))\\n\",\n",
    "    \"w = p * (1.0 - p)\\n\",\n",
    "    \"mw = float(np.mean(w))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# APE_j = beta_j * mean(w)\\n\",\n",
    "    \"ape = b * mw\\n\",\n",
    "    \"if \\\"const\\\" in names:\\n\",\n",
    "    \"    ape[names.index(\\\"const\\\")] = np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Delta-method gradient\\n\",\n",
    "    \"t = (w * (1.0 - 2.0 * p))[:, None] * X_audit_np\\n\",\n",
    "    \"dmw_db = np.mean(t, axis=0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"G = np.full((k, k), np.nan, dtype=float)\\n\",\n",
    "    \"for j in range(k):\\n\",\n",
    "    \"    if names[j] == \\\"const\\\":\\n\",\n",
    "    \"        continue\\n\",\n",
    "    \"    g = dmw_db * b[j]\\n\",\n",
    "    \"    g[j] += mw\\n\",\n",
    "    \"    G[j, :] = g\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Covariances (coerce 2-way; fallback to firm)\\n\",\n",
    "    \"V_firm = _coerce_cov(cov_firm, names)\\n\",\n",
    "    \"if \\\"cov_2\\\" in globals():\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        V_2 = _coerce_cov(cov_2, names)\\n\",\n",
    "    \"    except Exception:\\n\",\n",
    "    \"        V_2 = V_firm\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    V_2 = V_firm\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _se_from_V(V):\\n\",\n",
    "    \"    se = np.full(k, np.nan, dtype=float)\\n\",\n",
    "    \"    for j in range(k):\\n\",\n",
    "    \"        if not np.all(np.isfinite(G[j, :])):\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"        g = G[j, :].astype(float)\\n\",\n",
    "    \"        v = (g @ V @ g).item()  # scalar quadratic form\\n\",\n",
    "    \"        se[j] = np.sqrt(v) if v >= 0 else np.nan\\n\",\n",
    "    \"    return se\\n\",\n",
    "    \"\\n\",\n",
    "    \"se_ape_firm = _se_from_V(V_firm)\\n\",\n",
    "    \"se_ape_2 = _se_from_V(V_2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# p-values (normal approximation)\\n\",\n",
    "    \"z_firm = ape / se_ape_firm\\n\",\n",
    "    \"p_ape_firm = 2 * (1 - stats.norm.cdf(np.abs(z_firm)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"z_2 = ape / se_ape_2\\n\",\n",
    "    \"p_ape_2 = 2 * (1 - stats.norm.cdf(np.abs(z_2)))\\n\",\n",
    "    \"\\n\",\n",
    "    \"ape_tbl = pd.DataFrame({\\n\",\n",
    "    \"    \\\"APE\\\": ape,\\n\",\n",
    "    \"    \\\"se_APE_firm\\\": se_ape_firm,\\n\",\n",
    "    \"    \\\"p_APE_firm\\\": p_ape_firm,\\n\",\n",
    "    \"    \\\"se_APE_firm_year\\\": se_ape_2,\\n\",\n",
    "    \"    \\\"p_APE_firm_year\\\": p_ape_2,\\n\",\n",
    "    \"}, index=pd.Index(names, name=\\\"feature\\\"))\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(ape_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"infer_tbl_with_ape = infer_tbl.join(ape_tbl, how=\\\"left\\\")\\n\",\n",
    "    \"display(infer_tbl_with_ape)\\n\"\n",
    "   ],\n",
    "   \"id\": \"aa7dabccd6914f78\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"### 7B. Tree-based model (XGBoost; nonlinear)\\n\",\n",
    "    \"\\n\",\n",
    "    \"I train a regularized XGBoost model with class-weighted samples and then calibrate the probabilities on the validation split via isotonic regression.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"8fc722a92789cc8\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Build DMatrix objects\\n\",\n",
    "    \"X_tr = splits[\\\"train\\\"][\\\"X\\\"]\\n\",\n",
    "    \"y_tr = splits[\\\"train\\\"][\\\"y\\\"].astype(int)\\n\",\n",
    "    \"X_va = splits[\\\"val\\\"][\\\"X\\\"]\\n\",\n",
    "    \"y_va = splits[\\\"val\\\"][\\\"y\\\"].astype(int)\\n\",\n",
    "    \"X_te = splits[\\\"test\\\"][\\\"X\\\"]\\n\",\n",
    "    \"y_te = splits[\\\"test\\\"][\\\"y\\\"].astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"n_pos = int(y_tr.sum())\\n\",\n",
    "    \"n_neg = int((y_tr==0).sum())\\n\",\n",
    "    \"imbalance = (n_neg / max(n_pos, 1))\\n\",\n",
    "    \"\\n\",\n",
    "    \"w_pos = CONFIG[\\\"COST_FN\\\"] * imbalance\\n\",\n",
    "    \"w_neg = CONFIG[\\\"COST_FP\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"w_tr = np.where(y_tr.values==1, w_pos, w_neg).astype(float)\\n\",\n",
    "    \"w_va = np.where(y_va.values==1, w_pos, w_neg).astype(float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr, feature_names=X_tr.columns.tolist())\\n\",\n",
    "    \"dval   = xgb.DMatrix(X_va, label=y_va, weight=w_va, feature_names=X_tr.columns.tolist())\\n\",\n",
    "    \"dall   = xgb.DMatrix(X, label=y.astype(int), feature_names=X_tr.columns.tolist())\\n\",\n",
    "    \"\\n\",\n",
    "    \"evals = [(dtrain, \\\"train\\\"), (dval, \\\"val\\\")]\\n\",\n",
    "    \"\\n\",\n",
    "    \"xgb_model = xgb.train(\\n\",\n",
    "    \"    params=CONFIG[\\\"XGB_PARAMS\\\"],\\n\",\n",
    "    \"    dtrain=dtrain,\\n\",\n",
    "    \"    num_boost_round=CONFIG[\\\"XGB_NUM_BOOST_ROUND\\\"],\\n\",\n",
    "    \"    evals=evals,\\n\",\n",
    "    \"    early_stopping_rounds=CONFIG[\\\"XGB_EARLY_STOPPING\\\"],\\n\",\n",
    "    \"    verbose_eval=False,\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Best iteration:\\\", xgb_model.best_iteration)\"\n",
    "   ],\n",
    "   \"id\": \"b68c7a51d9219530\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 7B.2 Isotonic calibration on validation set (probability calibration)\",\n",
    "   \"id\": \"6fb6dd35856c246\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Raw probabilities (uncalibrated)\\n\",\n",
    "    \"p_val_raw = xgb_model.predict(dval)\\n\",\n",
    "    \"p_all_raw = xgb_model.predict(dall)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fit isotonic on validation only\\n\",\n",
    "    \"iso = IsotonicRegression(out_of_bounds=\\\"clip\\\")\\n\",\n",
    "    \"iso.fit(p_val_raw, y_va.values.astype(int))\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_model[\\\"pd_tree\\\"] = iso.transform(p_all_raw)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Calibration fitted on validation only.\\\")\\n\",\n",
    "    \"display(df_model[[\\\"split\\\",\\\"pd_tree\\\"]].groupby(\\\"split\\\").mean())\"\n",
    "   ],\n",
    "   \"id\": \"f1c520d73b13d941\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"#### 7B.3 Feature importance and SHAP (optional explainability)\",\n",
    "   \"id\": \"6b221c95e7aa1432\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Gain-based feature importance\\n\",\n",
    "    \"importance = xgb_model.get_score(importance_type=\\\"gain\\\")\\n\",\n",
    "    \"imp_tbl = (pd.DataFrame({\\\"feature\\\": list(importance.keys()), \\\"gain\\\": list(importance.values())})\\n\",\n",
    "    \"             .sort_values(\\\"gain\\\", ascending=False))\\n\",\n",
    "    \"display(imp_tbl.head(20))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Optional: SHAP summary for a subsample (can be expensive on large panels)\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    import shap\\n\",\n",
    "    \"    shap.initjs()\\n\",\n",
    "    \"    sample_n = min(5000, X_tr.shape[0])\\n\",\n",
    "    \"    X_sample = X_tr.sample(sample_n, random_state=SEED)\\n\",\n",
    "    \"    explainer = shap.TreeExplainer(xgb_model)\\n\",\n",
    "    \"    shap_values = explainer.shap_values(X_sample)\\n\",\n",
    "    \"    plt.figure()\\n\",\n",
    "    \"    shap.summary_plot(shap_values, X_sample, show=False)\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / \\\"shap_summary_tree.png\\\", dpi=160)\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(\\\"SHAP skipped:\\\", e)\"\n",
    "   ],\n",
    "   \"id\": \"f0aa9aa4ccd62566\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"#### 7A.5 Walk-forward validation (expanding window)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section refits preprocessing inside each fold using the raw modeling snapshot (before the global train-fit transforms). That keeps the walk-forward results free of preprocessing leakage.\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"3693b3a0ae1984e5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"# =============================================================================\\n\",\n",
    "    \"# Walk-forward (expanding window) validation — Logit and XGBoost (leakage-safe)\\n\",\n",
    "    \"# =============================================================================\\n\",\n",
    "    \"# This implementation refits preprocessing (median fill, winsor bounds, scaler) within each fold.\\n\",\n",
    "    \"# That is required for honest temporal validation.\\n\",\n",
    "    \"\\n\",\n",
    "    \"trainpool_df = df_model_raw.loc[df_model_raw[\\\"split\\\"].isin([\\\"train\\\", \\\"val\\\"]), :].copy()\\n\",\n",
    "    \"years = sorted(trainpool_df[\\\"label_year\\\"].dropna().unique().tolist())\\n\",\n",
    "    \"years = [int(y) for y in years]\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- safe metrics helpers ---\\n\",\n",
    "    \"def _safe_auc(y, p):\\n\",\n",
    "    \"    y = np.asarray(y, int)\\n\",\n",
    "    \"    p = np.asarray(p, float)\\n\",\n",
    "    \"    if len(np.unique(y)) < 2:\\n\",\n",
    "    \"        return np.nan\\n\",\n",
    "    \"    return roc_auc_score(y, p)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _safe_pr(y, p):\\n\",\n",
    "    \"    y = np.asarray(y, int)\\n\",\n",
    "    \"    p = np.asarray(p, float)\\n\",\n",
    "    \"    if len(np.unique(y)) < 2:\\n\",\n",
    "    \"        return np.nan\\n\",\n",
    "    \"    return average_precision_score(y, p)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"N_SPLITS = 4\\n\",\n",
    "    \"if len(years) < (N_SPLITS + 2):\\n\",\n",
    "    \"    print(\\\"Not enough years for walk-forward validation; skipping.\\\")\\n\",\n",
    "    \"    wf_tbl = pd.DataFrame()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    split_idx = np.linspace(2, len(years) - 1, N_SPLITS, dtype=int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def prep_fold(df_tr, df_va):\\n\",\n",
    "    \"        # continuous: median fill (train), winsor clip (train), scaler (train)\\n\",\n",
    "    \"        cont = [c for c in continuous_feats_raw if c in df_tr.columns]\\n\",\n",
    "    \"        Xtr = df_tr[cont].apply(pd.to_numeric, errors=\\\"coerce\\\")\\n\",\n",
    "    \"        Xva = df_va[cont].apply(pd.to_numeric, errors=\\\"coerce\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        med = Xtr.median()\\n\",\n",
    "    \"        Xtr = Xtr.fillna(med)\\n\",\n",
    "    \"        Xva = Xva.fillna(med)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        bounds = {c: winsorize_train_bounds(Xtr[c], CONFIG[\\\"WINSOR_LO_Q\\\"], CONFIG[\\\"WINSOR_HI_Q\\\"]) for c in cont}\\n\",\n",
    "    \"        for c, (lo, hi) in bounds.items():\\n\",\n",
    "    \"            Xtr[c] = apply_bounds(Xtr[c], lo, hi)\\n\",\n",
    "    \"            Xva[c] = apply_bounds(Xva[c], lo, hi)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        scaler = StandardScaler()\\n\",\n",
    "    \"        Ztr = pd.DataFrame(scaler.fit_transform(Xtr), columns=[f\\\"z_{c}\\\" for c in cont], index=df_tr.index)\\n\",\n",
    "    \"        Zva = pd.DataFrame(scaler.transform(Xva), columns=[f\\\"z_{c}\\\" for c in cont], index=df_va.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # events: keep as-is; fill missing with 0 (absence of event)\\n\",\n",
    "    \"        ev = [c for c in event_feats if c in df_tr.columns]\\n\",\n",
    "    \"        if ev:\\n\",\n",
    "    \"            Etr = df_tr[ev].fillna(0.0)\\n\",\n",
    "    \"            Eva = df_va[ev].fillna(0.0)\\n\",\n",
    "    \"            Ztr = pd.concat([Ztr, Etr], axis=1)\\n\",\n",
    "    \"            Zva = pd.concat([Zva, Eva], axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        return Ztr, Zva\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    for k in split_idx:\\n\",\n",
    "    \"        train_years = years[:k]\\n\",\n",
    "    \"        val_year = years[k]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        df_tr = trainpool_df[trainpool_df[\\\"label_year\\\"].isin(train_years)].copy()\\n\",\n",
    "    \"        df_va = trainpool_df[trainpool_df[\\\"label_year\\\"].isin([val_year])].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # drop missing labels for the fold\\n\",\n",
    "    \"        df_tr = df_tr[df_tr[TARGET_NAME].notna()].copy()\\n\",\n",
    "    \"        df_va = df_va[df_va[TARGET_NAME].notna()].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        X_tr, X_va = prep_fold(df_tr, df_va)\\n\",\n",
    "    \"        y_tr = df_tr[TARGET_NAME].astype(int).values\\n\",\n",
    "    \"        y_va = df_va[TARGET_NAME].astype(int).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # ---- Logit ----\\n\",\n",
    "    \"        C_use = float(globals().get(\\\"best_C\\\", 1.0))\\n\",\n",
    "    \"        log_mdl = LogisticRegression(\\n\",\n",
    "    \"            penalty=\\\"l2\\\", C=C_use, solver=\\\"liblinear\\\",\\n\",\n",
    "    \"            class_weight={0: CONFIG[\\\"COST_FP\\\"], 1: CONFIG[\\\"COST_FN\\\"]},\\n\",\n",
    "    \"            random_state=SEED, max_iter=2000\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        log_mdl.fit(X_tr, y_tr)\\n\",\n",
    "    \"        p_va_log = log_mdl.predict_proba(X_va)[:, 1]\\n\",\n",
    "    \"\\n\",\n",
    "    \"        rows.append({\\n\",\n",
    "    \"            \\\"model\\\": \\\"logit\\\",\\n\",\n",
    "    \"            \\\"train_years_min\\\": min(train_years),\\n\",\n",
    "    \"            \\\"train_years_max\\\": max(train_years),\\n\",\n",
    "    \"            \\\"val_year\\\": val_year,\\n\",\n",
    "    \"            \\\"n_train\\\": int(len(y_tr)),\\n\",\n",
    "    \"            \\\"n_val\\\": int(len(y_va)),\\n\",\n",
    "    \"            \\\"roc_auc\\\": _safe_auc(y_va, p_va_log),\\n\",\n",
    "    \"            \\\"pr_auc\\\": _safe_pr(y_va, p_va_log),\\n\",\n",
    "    \"            \\\"brier\\\": float(brier_score_loss(y_va, p_va_log)),\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # ---- XGBoost (same training block as main model; per-fold fit) ----\\n\",\n",
    "    \"        # Ensure y are pandas Series (so .values works exactly like your main cell)\\n\",\n",
    "    \"        y_tr = df_tr[TARGET_NAME].astype(int)\\n\",\n",
    "    \"        y_va = df_va[TARGET_NAME].astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # If a fold has only one class, XGBoost AUC/PR are undefined and training can be unstable.\\n\",\n",
    "    \"        if (y_tr.nunique() < 2) or (y_va.nunique() < 2):\\n\",\n",
    "    \"            rows.append({\\n\",\n",
    "    \"                \\\"model\\\": \\\"tree\\\",\\n\",\n",
    "    \"                \\\"train_years_min\\\": min(train_years),\\n\",\n",
    "    \"                \\\"train_years_max\\\": max(train_years),\\n\",\n",
    "    \"                \\\"val_year\\\": val_year,\\n\",\n",
    "    \"                \\\"n_train\\\": int(len(y_tr)),\\n\",\n",
    "    \"                \\\"n_val\\\": int(len(y_va)),\\n\",\n",
    "    \"                \\\"roc_auc\\\": np.nan,\\n\",\n",
    "    \"                \\\"pr_auc\\\": np.nan,\\n\",\n",
    "    \"                \\\"brier\\\": np.nan,\\n\",\n",
    "    \"                \\\"best_iteration\\\": np.nan,\\n\",\n",
    "    \"                \\\"note\\\": \\\"Skipped: single-class fold\\\"\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            # --- exact same weight logic as your main model cell ---\\n\",\n",
    "    \"            n_pos = int(y_tr.sum())\\n\",\n",
    "    \"            n_neg = int((y_tr == 0).sum())\\n\",\n",
    "    \"            imbalance = (n_neg / max(n_pos, 1))\\n\",\n",
    "    \"\\n\",\n",
    "    \"            w_pos = CONFIG[\\\"COST_FN\\\"] * imbalance\\n\",\n",
    "    \"            w_neg = CONFIG[\\\"COST_FP\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"            w_tr = np.where(y_tr.values == 1, w_pos, w_neg).astype(float)\\n\",\n",
    "    \"            w_va = np.where(y_va.values == 1, w_pos, w_neg).astype(float)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # --- exact same DMatrix pattern as your main model cell ---\\n\",\n",
    "    \"            dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr, feature_names=X_tr.columns.tolist())\\n\",\n",
    "    \"            dval = xgb.DMatrix(X_va, label=y_va, weight=w_va, feature_names=X_tr.columns.tolist())\\n\",\n",
    "    \"\\n\",\n",
    "    \"            evals = [(dtrain, \\\"train\\\"), (dval, \\\"val\\\")]\\n\",\n",
    "    \"\\n\",\n",
    "    \"            xgb_model = xgb.train(\\n\",\n",
    "    \"                params=CONFIG[\\\"XGB_PARAMS\\\"],\\n\",\n",
    "    \"                dtrain=dtrain,\\n\",\n",
    "    \"                num_boost_round=CONFIG[\\\"XGB_NUM_BOOST_ROUND\\\"],\\n\",\n",
    "    \"                evals=evals,\\n\",\n",
    "    \"                early_stopping_rounds=CONFIG[\\\"XGB_EARLY_STOPPING\\\"],\\n\",\n",
    "    \"                verbose_eval=False,\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Raw probabilities (uncalibrated) — same as main cell\\n\",\n",
    "    \"            p_val_raw = xgb_model.predict(dval)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            rows.append({\\n\",\n",
    "    \"                \\\"model\\\": \\\"tree\\\",\\n\",\n",
    "    \"                \\\"train_years_min\\\": min(train_years),\\n\",\n",
    "    \"                \\\"train_years_max\\\": max(train_years),\\n\",\n",
    "    \"                \\\"val_year\\\": val_year,\\n\",\n",
    "    \"                \\\"n_train\\\": int(len(y_tr)),\\n\",\n",
    "    \"                \\\"n_val\\\": int(len(y_va)),\\n\",\n",
    "    \"                \\\"roc_auc\\\": _safe_auc(y_va.values, p_val_raw),\\n\",\n",
    "    \"                \\\"pr_auc\\\": _safe_pr(y_va.values, p_val_raw),\\n\",\n",
    "    \"                \\\"brier\\\": float(brier_score_loss(y_va.values.astype(int), p_val_raw)),\\n\",\n",
    "    \"                \\\"best_iteration\\\": int(getattr(xgb_model, \\\"best_iteration\\\", np.nan)),\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    wf_tbl = pd.DataFrame(rows)\\n\",\n",
    "    \"    display(wf_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\"\n",
    "   ],\n",
    "   \"id\": \"7cd6d479fe9d83fa\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 8. Model Evaluation & Diagnostic Monitoring\\n\",\n",
    "    \"\\n\",\n",
    "    \"All evaluation in this section treats the **test split as untouchable**: no tuning based on test results.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Clean Evaluation Protocol Note:**\\n\",\n",
    "    \"- For **Logit**: The validation (`val`) performance reported below is an honest out-of-sample estimate because it uses a model trained on `train` only. The test performance uses a model trained on `train+val`.\\n\",\n",
    "    \"- For **Tree (XGBoost)**: The validation (`val`) performance is **in-sample** relative to early stopping and isotonic calibration, both of which use the validation set. Therefore, `val` performance for trees will appear optimistic.\\n\",\n",
    "    \"- **Unbiased Performance**: The **test split** results are the only strictly unbiased final performance metrics.\\n\",\n",
    "    \"\\n\",\n",
    "    \"We report:\\n\",\n",
    "    \"- ROC-AUC, PR-AUC, Brier score,\\n\",\n",
    "    \"- calibration curve and calibration slope (reliability),\\n\",\n",
    "    \"- persistence benchmark,\\n\",\n",
    "    \"- collinearity and drift diagnostics.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 8.1 Out-of-sample metrics (val and test) + persistence benchmark\"\n",
    "   ],\n",
    "   \"id\": \"12fdcc1e05a80bd5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\\n\",\n",
    "    \"\\n\",\n",
    "    \"def eval_metrics_safe(y_true: pd.Series, p: np.ndarray) -> dict:\\n\",\n",
    "    \"    y = y_true.astype(int).values\\n\",\n",
    "    \"    out = {\\n\",\n",
    "    \"        \\\"roc_auc\\\": np.nan,\\n\",\n",
    "    \"        \\\"pr_auc\\\": np.nan,\\n\",\n",
    "    \"        \\\"brier\\\": brier_score_loss(y, p),\\n\",\n",
    "    \"        \\\"mean_p\\\": float(np.mean(p)),\\n\",\n",
    "    \"        \\\"event_rate\\\": float(np.mean(y)),\\n\",\n",
    "    \"        \\\"n\\\": int(len(y)),\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    # Guard against single-class slices (can occur under transition objective + small test sets)\\n\",\n",
    "    \"    if np.unique(y).size < 2:\\n\",\n",
    "    \"        # ROC-AUC undefined; PR-AUC equals event rate for a constant predictor\\n\",\n",
    "    \"        out[\\\"pr_auc\\\"] = float(out[\\\"event_rate\\\"])\\n\",\n",
    "    \"        return out\\n\",\n",
    "    \"    out[\\\"roc_auc\\\"] = float(roc_auc_score(y, p))\\n\",\n",
    "    \"    out[\\\"pr_auc\\\"] = float(average_precision_score(y, p))\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"rows = []\\n\",\n",
    "    \"for sp in [\\\"val\\\",\\\"test\\\"]:\\n\",\n",
    "    \"    mask = df_model[\\\"split\\\"] == sp\\n\",\n",
    "    \"    y_sp = df_model.loc[mask, TARGET_NAME]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    rows.append({\\\"split\\\": sp, \\\"model\\\":\\\"logit\\\", **eval_metrics_safe(y_sp, df_model.loc[mask, \\\"pd_logit\\\"].values)})\\n\",\n",
    "    \"    rows.append({\\\"split\\\": sp, \\\"model\\\":\\\"tree_calibrated\\\", **eval_metrics_safe(y_sp, df_model.loc[mask, \\\"pd_tree\\\"].values)})\\n\",\n",
    "    \"\\n\",\n",
    "    \"    obj = str(globals().get(\\\"OBJECTIVE\\\", \\\"state\\\")).lower()\\n\",\n",
    "    \"    if obj.startswith(\\\"trans\\\"):\\n\",\n",
    "    \"        # Under early-warning (transition) objective, PROXY_NAME==0 by construction. Use a simple \\\"always-0\\\" baseline.\\n\",\n",
    "    \"        base = np.zeros(mask.sum(), dtype=float)\\n\",\n",
    "    \"        rows.append({\\\"split\\\": sp, \\\"model\\\":\\\"always_0\\\", **eval_metrics_safe(y_sp, base)})\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Surveillance objective baseline: predict next-year distress = current-year state (persistence)\\n\",\n",
    "    \"        pers = pd.to_numeric(df_model.loc[mask, PROXY_NAME], errors=\\\"coerce\\\").fillna(0).astype(int).values\\n\",\n",
    "    \"        rows.append({\\\"split\\\": sp, \\\"model\\\":\\\"persistence_state_t\\\", **eval_metrics_safe(y_sp, pers)})\\n\",\n",
    "    \"\\n\",\n",
    "    \"metrics_tbl = pd.DataFrame(rows).sort_values([\\\"split\\\",\\\"model\\\"])\\n\",\n",
    "    \"display(metrics_tbl)\"\n",
    "   ],\n",
    "   \"id\": \"b23f0c96467302ce\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 8.1b Early-warning vs Surveillance decomposition (state-conditional evaluation)\\n\",\n",
    "   \"id\": \"e9481283180184c5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# Objective-aware evaluation breakdown.\\n\",\n",
    "    \"# - If OBJECTIVE == \\\"transition\\\": df_model already represents the *risk set* (distress_t==0), so we report overall metrics.\\n\",\n",
    "    \"# - If OBJECTIVE == \\\"state\\\": we additionally break out performance on distress_t==0 (early-warning slice) vs distress_t==1 (surveillance slice).\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\\n\",\n",
    "    \"\\n\",\n",
    "    \"def safe_eval_metrics(y_true: pd.Series, p: np.ndarray) -> dict:\\n\",\n",
    "    \"    y = y_true.astype(int).values\\n\",\n",
    "    \"    out = {\\n\",\n",
    "    \"        \\\"roc_auc\\\": np.nan,\\n\",\n",
    "    \"        \\\"pr_auc\\\": np.nan,\\n\",\n",
    "    \"        \\\"brier\\\": brier_score_loss(y, p),\\n\",\n",
    "    \"        \\\"mean_p\\\": float(np.mean(p)),\\n\",\n",
    "    \"        \\\"event_rate\\\": float(np.mean(y)),\\n\",\n",
    "    \"        \\\"n\\\": int(len(y)),\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    if np.unique(y).size < 2:\\n\",\n",
    "    \"        out[\\\"pr_auc\\\"] = float(out[\\\"event_rate\\\"])\\n\",\n",
    "    \"        return out\\n\",\n",
    "    \"    out[\\\"roc_auc\\\"] = float(roc_auc_score(y, p))\\n\",\n",
    "    \"    out[\\\"pr_auc\\\"] = float(average_precision_score(y, p))\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"def eval_models(df_seg: pd.DataFrame, split_name: str, segment_name: str) -> list:\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    if df_seg.empty:\\n\",\n",
    "    \"        return rows\\n\",\n",
    "    \"    y = df_seg[TARGET_NAME]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for col, mdl in [(\\\"pd_logit\\\",\\\"logit\\\"),\\n\",\n",
    "    \"                     (\\\"pd_tree\\\",\\\"tree_calibrated\\\")]:\\n\",\n",
    "    \"        rows.append({\\n\",\n",
    "    \"            \\\"split\\\": split_name,\\n\",\n",
    "    \"            \\\"segment\\\": segment_name,\\n\",\n",
    "    \"            \\\"model\\\": mdl,\\n\",\n",
    "    \"            **safe_eval_metrics(y, df_seg[col].values),\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Baseline(s)\\n\",\n",
    "    \"    obj = str(globals().get(\\\"OBJECTIVE\\\", \\\"state\\\")).lower()\\n\",\n",
    "    \"    if obj.startswith(\\\"trans\\\"):\\n\",\n",
    "    \"        base = np.zeros(df_seg.shape[0], dtype=float)\\n\",\n",
    "    \"        rows.append({\\n\",\n",
    "    \"            \\\"split\\\": split_name,\\n\",\n",
    "    \"            \\\"segment\\\": segment_name,\\n\",\n",
    "    \"            \\\"model\\\": \\\"always_0\\\",\\n\",\n",
    "    \"            **safe_eval_metrics(y, base),\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        state = pd.to_numeric(df_seg[PROXY_NAME], errors=\\\"coerce\\\").fillna(0).astype(int).values\\n\",\n",
    "    \"        rows.append({\\n\",\n",
    "    \"            \\\"split\\\": split_name,\\n\",\n",
    "    \"            \\\"segment\\\": segment_name,\\n\",\n",
    "    \"            \\\"model\\\": \\\"state_only\\\",\\n\",\n",
    "    \"            **safe_eval_metrics(y, state),\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"    return rows\\n\",\n",
    "    \"\\n\",\n",
    "    \"obj = str(globals().get(\\\"OBJECTIVE\\\", \\\"state\\\")).lower()\\n\",\n",
    "    \"\\n\",\n",
    "    \"seg_rows = []\\n\",\n",
    "    \"for sp in [\\\"val\\\", \\\"test\\\"]:\\n\",\n",
    "    \"    df_sp = df_model.loc[df_model[\\\"split\\\"]==sp, :].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if obj.startswith(\\\"trans\\\"):\\n\",\n",
    "    \"        seg_rows += eval_models(df_sp, sp, f\\\"transition risk set ({PROXY_NAME}=0 by design)\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        # Early-warning vs surveillance slices (conditional on current state)\\n\",\n",
    "    \"        dcur = pd.to_numeric(df_sp[PROXY_NAME], errors=\\\"coerce\\\")\\n\",\n",
    "    \"        df_sp = df_sp.loc[dcur.notna(), :].copy()\\n\",\n",
    "    \"        df_sp[\\\"distress_t_int\\\"] = dcur.loc[dcur.notna()].astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        seg_rows += eval_models(df_sp.loc[df_sp[\\\"distress_t_int\\\"]==0, :], sp, f\\\"early_warning ({PROXY_NAME}=0)\\\")\\n\",\n",
    "    \"        seg_rows += eval_models(df_sp.loc[df_sp[\\\"distress_t_int\\\"]==1, :], sp, f\\\"surveillance ({PROXY_NAME}=1)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"seg_metrics_tbl = pd.DataFrame(seg_rows)\\n\",\n",
    "    \"if not seg_metrics_tbl.empty:\\n\",\n",
    "    \"    seg_metrics_tbl = seg_metrics_tbl.sort_values([\\\"split\\\",\\\"segment\\\",\\\"model\\\"])\\n\",\n",
    "    \"    display(seg_metrics_tbl)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No segment metrics computed (empty segments).\\\")\"\n",
    "   ],\n",
    "   \"id\": \"e022cc13da195bdf\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 8.2 Calibration diagnostics (curve + calibration-in-the-large + slope)\",\n",
    "   \"id\": \"6239dda77e32bb0f\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"def calibration_slope_intercept(y_true: np.ndarray, p: np.ndarray) -> tuple[float,float]:\\n\",\n",
    "    \"    z = logit(p)\\n\",\n",
    "    \"    Xc = sm.add_constant(z, has_constant=\\\"add\\\")\\n\",\n",
    "    \"    mdl = sm.GLM(y_true, Xc, family=sm.families.Binomial())\\n\",\n",
    "    \"    res = mdl.fit()\\n\",\n",
    "    \"    intercept, slope = res.params[0], res.params[1]\\n\",\n",
    "    \"    return float(intercept), float(slope)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def plot_calibration(y_true: np.ndarray, p: np.ndarray, title: str, fname: str):\\n\",\n",
    "    \"    frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=10, strategy=\\\"quantile\\\")\\n\",\n",
    "    \"    plt.figure()\\n\",\n",
    "    \"    plt.plot(mean_pred, frac_pos, marker=\\\"o\\\")\\n\",\n",
    "    \"    plt.plot([0,1],[0,1], linestyle=\\\"--\\\")\\n\",\n",
    "    \"    plt.xlabel(\\\"Mean predicted probability\\\")\\n\",\n",
    "    \"    plt.ylabel(\\\"Fraction of positives\\\")\\n\",\n",
    "    \"    plt.title(title)\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / fname, dpi=160)\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for sp in [\\\"val\\\",\\\"test\\\"]:\\n\",\n",
    "    \"    mask = df_model[\\\"split\\\"] == sp\\n\",\n",
    "    \"    y_sp = df_model.loc[mask, TARGET_NAME].astype(int).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for model_name, pcol in [(\\\"logit\\\",\\\"pd_logit\\\"), (\\\"tree_calibrated\\\",\\\"pd_tree\\\")]:\\n\",\n",
    "    \"        p = df_model.loc[mask, pcol].values\\n\",\n",
    "    \"        icpt, slope = calibration_slope_intercept(y_sp, p)\\n\",\n",
    "    \"        print(f\\\"{sp} | {model_name}: calibration intercept={icpt:.3f}, slope={slope:.3f}\\\")\\n\",\n",
    "    \"        plot_calibration(y_sp, p, f\\\"Calibration curve — {model_name} ({sp})\\\", f\\\"cal_curve_{model_name}_{sp}.png\\\")\"\n",
    "   ],\n",
    "   \"id\": \"112d236f1e8a5406\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 8.3 Temporal stability (walk-forward fold metrics)\",\n",
    "   \"id\": \"e03492a4e4decef\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"if 'wf_tbl' in globals() and len(wf_tbl) > 0:\\n\",\n",
    "    \"    display(wf_tbl)\\n\",\n",
    "    \"    plt.figure()\\n\",\n",
    "    \"    plt.plot(wf_tbl[\\\"val_year\\\"], wf_tbl[\\\"roc_auc\\\"], marker=\\\"o\\\", label=\\\"ROC-AUC\\\")\\n\",\n",
    "    \"    plt.plot(wf_tbl[\\\"val_year\\\"], wf_tbl[\\\"pr_auc\\\"], marker=\\\"o\\\", label=\\\"PR-AUC\\\")\\n\",\n",
    "    \"    plt.title(\\\"Walk-forward validation metrics \\\")\\n\",\n",
    "    \"    plt.xlabel(\\\"Validation label_year\\\")\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / \\\"walkforward_metrics_logit.png\\\", dpi=160)\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"cfa4c1bbede95062\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 8.4 Collinearity checks (VIF + high-correlation pairs)\",\n",
    "   \"id\": \"7b4687c3d2ab293c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# VIF on continuous z-features (train only)\\n\",\n",
    "    \"X_vif = splits[\\\"train\\\"][\\\"X\\\"][[f\\\"z_{c}\\\" for c in continuous_feats_raw]].copy()\\n\",\n",
    "    \"X_vif = sm.add_constant(X_vif, has_constant=\\\"add\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"vif_rows = []\\n\",\n",
    "    \"for i, col in enumerate(X_vif.columns):\\n\",\n",
    "    \"    if col == \\\"const\\\":\\n\",\n",
    "    \"        continue\\n\",\n",
    "    \"    vif_rows.append({\\\"feature\\\": col, \\\"VIF\\\": float(variance_inflation_factor(X_vif.values, i))})\\n\",\n",
    "    \"\\n\",\n",
    "    \"vif_tbl = pd.DataFrame(vif_rows).sort_values(\\\"VIF\\\", ascending=False)\\n\",\n",
    "    \"display(vif_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Correlation screen (continuous only)\\n\",\n",
    "    \"corr = splits[\\\"train\\\"][\\\"X\\\"][[f\\\"z_{c}\\\" for c in continuous_feats_raw]].corr()\\n\",\n",
    "    \"high_pairs = []\\n\",\n",
    "    \"for i in range(len(corr.columns)):\\n\",\n",
    "    \"    for j in range(i+1, len(corr.columns)):\\n\",\n",
    "    \"        v = corr.iloc[i,j]\\n\",\n",
    "    \"        if abs(v) >= 0.85:\\n\",\n",
    "    \"            high_pairs.append((corr.columns[i], corr.columns[j], float(v)))\\n\",\n",
    "    \"high_pairs_tbl = pd.DataFrame(high_pairs, columns=[\\\"feat1\\\",\\\"feat2\\\",\\\"corr\\\"]).sort_values(\\\"corr\\\", key=np.abs, ascending=False)\\n\",\n",
    "    \"display(high_pairs_tbl)\"\n",
    "   ],\n",
    "   \"id\": \"184425b3f3feac23\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 8.5 Drift diagnostics (standardized mean difference: train vs test)\",\n",
    "   \"id\": \"936b5dff2ba956f5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"feat_cols = [f\\\"z_{c}\\\" for c in continuous_feats_raw] + event_feats\\n\",\n",
    "    \"drift_rows = []\\n\",\n",
    "    \"for c in feat_cols:\\n\",\n",
    "    \"    smd = compute_smd(df_model.loc[df_model[\\\"split\\\"]==\\\"train\\\", c], df_model.loc[df_model[\\\"split\\\"]==\\\"test\\\", c])\\n\",\n",
    "    \"    drift_rows.append({\\\"feature\\\": c, \\\"SMD_train_vs_test\\\": smd})\\n\",\n",
    "    \"drift_tbl = pd.DataFrame(drift_rows).sort_values(\\\"SMD_train_vs_test\\\", key=lambda s: s.abs(), ascending=False)\\n\",\n",
    "    \"display(drift_tbl.head(25))\"\n",
    "   ],\n",
    "   \"id\": \"cc4fbb3ba00c47f4\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": \"### 8.6 Probability distributions by class (test split)\",\n",
    "   \"id\": \"adbdc8bf134fc6a5\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 9.a Statistical uncertainty and model comparison on the test set (Cluster bootstrap CIs + firm-clustered pairwise tests)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section adds (i) cluster bootstrap by firm_id confidence intervals for key metrics and (ii) paired cluster bootstrap tests for ROC-AUC differences, with Holm and Bonferroni adjustments for multiple comparisons.\\n\"\n",
    "   ],\n",
    "   \"id\": \"e4cfaba56e71b88c\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from itertools import combinations\\n\",\n",
    "    \"from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ============================================================\\n\",\n",
    "    \"# Firm-clustered uncertainty quantification (panel-robust)\\n\",\n",
    "    \"# ============================================================\\n\",\n",
    "    \"# Rationale:\\n\",\n",
    "    \"# - Firm-year observations are not i.i.d.; errors are correlated within firm over time.\\n\",\n",
    "    \"# - Row-wise (i.i.d.) bootstrap and DeLong tests are therefore overconfident in panels.\\n\",\n",
    "    \"# - We use a *cluster bootstrap by firm_id*: resample firms with replacement and keep\\n\",\n",
    "    \"#   each sampled firm's full time-series block.\\n\",\n",
    "    \"#\\n\",\n",
    "    \"# Outputs:\\n\",\n",
    "    \"# 1) Model-wise cluster-bootstrap percentile CIs for ROC-AUC, PR-AUC, and Brier score.\\n\",\n",
    "    \"# 2) Pairwise *paired* cluster-bootstrap tests for ROC-AUC differences (with Holm/Bonferroni).\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"N_BOOT = 1000  # increase (e.g., 2000) for tighter CIs at higher compute cost\\n\",\n",
    "    \"ALPHA = 0.05\\n\",\n",
    "    \"SEED_BOOT = 42\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _cluster_groups(df: pd.DataFrame, cluster_col: str):\\n\",\n",
    "    \"    cl = df[cluster_col].astype(str).values\\n\",\n",
    "    \"    uniq, inv = np.unique(cl, return_inverse=True)\\n\",\n",
    "    \"    groups = [np.where(inv == k)[0] for k in range(len(uniq))]\\n\",\n",
    "    \"    return groups\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _metric_safe(y: np.ndarray, p: np.ndarray, metric: str) -> float:\\n\",\n",
    "    \"    y = np.asarray(y).astype(int)\\n\",\n",
    "    \"    p = np.asarray(p).astype(float)\\n\",\n",
    "    \"    if metric == \\\"roc_auc\\\":\\n\",\n",
    "    \"        if np.unique(y).size < 2:\\n\",\n",
    "    \"            return np.nan\\n\",\n",
    "    \"        return float(roc_auc_score(y, p))\\n\",\n",
    "    \"    if metric == \\\"pr_auc\\\":\\n\",\n",
    "    \"        # Average precision requires positives to be meaningful; return NaN if no positives.\\n\",\n",
    "    \"        if y.sum() == 0 or y.sum() == len(y):\\n\",\n",
    "    \"            return np.nan\\n\",\n",
    "    \"        return float(average_precision_score(y, p))\\n\",\n",
    "    \"    if metric == \\\"brier\\\":\\n\",\n",
    "    \"        return float(brier_score_loss(y, p))\\n\",\n",
    "    \"    raise ValueError(f\\\"Unknown metric: {metric}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def cluster_bootstrap_ci(\\n\",\n",
    "    \"    df: pd.DataFrame,\\n\",\n",
    "    \"    y_col: str,\\n\",\n",
    "    \"    p_col: str,\\n\",\n",
    "    \"    metric: str,\\n\",\n",
    "    \"    cluster_col: str = \\\"firm_id\\\",\\n\",\n",
    "    \"    n_boot: int = 1000,\\n\",\n",
    "    \"    alpha: float = 0.05,\\n\",\n",
    "    \"    seed: int = 42,\\n\",\n",
    "    \"):\\n\",\n",
    "    \"    y = df[y_col].astype(int).values\\n\",\n",
    "    \"    p = df[p_col].astype(float).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"    point = _metric_safe(y, p, metric)\\n\",\n",
    "    \"    groups = _cluster_groups(df, cluster_col)\\n\",\n",
    "    \"    G = len(groups)\\n\",\n",
    "    \"    if G == 0:\\n\",\n",
    "    \"        return point, np.nan, np.nan, 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    rng = np.random.default_rng(seed)\\n\",\n",
    "    \"    vals = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for _ in range(n_boot):\\n\",\n",
    "    \"        # sample clusters with replacement (same number of clusters)\\n\",\n",
    "    \"        sampled = rng.integers(0, G, size=G)\\n\",\n",
    "    \"        idx = np.concatenate([groups[g] for g in sampled])\\n\",\n",
    "    \"        v = _metric_safe(y[idx], p[idx], metric)\\n\",\n",
    "    \"        if v == v:  # not NaN\\n\",\n",
    "    \"            vals.append(v)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if len(vals) == 0:\\n\",\n",
    "    \"        return point, np.nan, np.nan, 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    lo = float(np.quantile(vals, alpha/2))\\n\",\n",
    "    \"    hi = float(np.quantile(vals, 1 - alpha/2))\\n\",\n",
    "    \"    return point, lo, hi, len(vals)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def cluster_bootstrap_diff_test(\\n\",\n",
    "    \"    df: pd.DataFrame,\\n\",\n",
    "    \"    y_col: str,\\n\",\n",
    "    \"    p1_col: str,\\n\",\n",
    "    \"    p2_col: str,\\n\",\n",
    "    \"    metric: str = \\\"roc_auc\\\",\\n\",\n",
    "    \"    cluster_col: str = \\\"firm_id\\\",\\n\",\n",
    "    \"    n_boot: int = 1000,\\n\",\n",
    "    \"    alpha: float = 0.05,\\n\",\n",
    "    \"    seed: int = 42,\\n\",\n",
    "    \"):\\n\",\n",
    "    \"    y = df[y_col].astype(int).values\\n\",\n",
    "    \"    p1 = df[p1_col].astype(float).values\\n\",\n",
    "    \"    p2 = df[p2_col].astype(float).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"    point = _metric_safe(y, p1, metric) - _metric_safe(y, p2, metric)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    groups = _cluster_groups(df, cluster_col)\\n\",\n",
    "    \"    G = len(groups)\\n\",\n",
    "    \"    if G == 0:\\n\",\n",
    "    \"        return point, np.nan, np.nan, np.nan, 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    rng = np.random.default_rng(seed)\\n\",\n",
    "    \"    diffs = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for _ in range(n_boot):\\n\",\n",
    "    \"        sampled = rng.integers(0, G, size=G)\\n\",\n",
    "    \"        idx = np.concatenate([groups[g] for g in sampled])\\n\",\n",
    "    \"        m1 = _metric_safe(y[idx], p1[idx], metric)\\n\",\n",
    "    \"        m2 = _metric_safe(y[idx], p2[idx], metric)\\n\",\n",
    "    \"        if (m1 == m1) and (m2 == m2):\\n\",\n",
    "    \"            diffs.append(m1 - m2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if len(diffs) == 0:\\n\",\n",
    "    \"        return point, np.nan, np.nan, np.nan, 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    diffs = np.asarray(diffs, dtype=float)\\n\",\n",
    "    \"    lo = float(np.quantile(diffs, alpha/2))\\n\",\n",
    "    \"    hi = float(np.quantile(diffs, 1 - alpha/2))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Two-sided p-value from the bootstrap sign distribution (paired)\\n\",\n",
    "    \"    p_le0 = float(np.mean(diffs <= 0))\\n\",\n",
    "    \"    p_ge0 = float(np.mean(diffs >= 0))\\n\",\n",
    "    \"    pval = 2 * min(p_le0, p_ge0)\\n\",\n",
    "    \"    pval = float(min(max(pval, 0.0), 1.0))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return point, lo, hi, pval, len(diffs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# -------------------------\\n\",\n",
    "    \"# Multiple-testing adjustment helpers\\n\",\n",
    "    \"# -------------------------\\n\",\n",
    "    \"def p_adjust_bonferroni(pvals: np.ndarray) -> np.ndarray:\\n\",\n",
    "    \"    p = np.asarray(pvals, dtype=float)\\n\",\n",
    "    \"    return np.minimum(p * len(p), 1.0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def p_adjust_holm(pvals: np.ndarray) -> np.ndarray:\\n\",\n",
    "    \"    p = np.asarray(pvals, dtype=float)\\n\",\n",
    "    \"    m = len(p)\\n\",\n",
    "    \"    order = np.argsort(p)\\n\",\n",
    "    \"    adj = np.empty(m, dtype=float)\\n\",\n",
    "    \"    for i, idx in enumerate(order):\\n\",\n",
    "    \"        adj[idx] = (m - i) * p[idx]\\n\",\n",
    "    \"    # enforce monotonicity in sorted order\\n\",\n",
    "    \"    adj_sorted = np.maximum.accumulate(adj[order])\\n\",\n",
    "    \"    adj[order] = np.minimum(adj_sorted, 1.0)\\n\",\n",
    "    \"    return adj\\n\",\n",
    "    \"\\n\",\n",
    "    \"# -------------------------\\n\",\n",
    "    \"# Run on test set (df_model + TARGET_NAME)\\n\",\n",
    "    \"# -------------------------\\n\",\n",
    "    \"mask_te = df_model[\\\"split\\\"] == \\\"test\\\"\\n\",\n",
    "    \"df_te = df_model.loc[mask_te, :].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Collect probability columns available (extend easily)\\n\",\n",
    "    \"candidate_cols = [\\n\",\n",
    "    \"    (\\\"logit\\\", \\\"pd_logit\\\"),\\n\",\n",
    "    \"    (\\\"tree_calibrated\\\", \\\"pd_tree\\\"),\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"models = {name: col for name, col in candidate_cols if col in df_te.columns}\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(models) == 0:\\n\",\n",
    "    \"    print(\\\"No model probability columns found in df_model (expected pd_logit / pd_tree).\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # --- Cluster bootstrap CIs for each model (and baseline if desired)\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    for name, col in models.items():\\n\",\n",
    "    \"        for metric in [\\\"roc_auc\\\", \\\"pr_auc\\\", \\\"brier\\\"]:\\n\",\n",
    "    \"            pt, lo, hi, n_eff = cluster_bootstrap_ci(\\n\",\n",
    "    \"                df_te, TARGET_NAME, col, metric=metric, cluster_col=\\\"firm_id\\\", n_boot=N_BOOT, alpha=ALPHA, seed=SEED_BOOT\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            rows.append({\\n\",\n",
    "    \"                \\\"model\\\": name,\\n\",\n",
    "    \"                \\\"metric\\\": metric,\\n\",\n",
    "    \"                \\\"point\\\": pt,\\n\",\n",
    "    \"                \\\"ci_lo\\\": lo,\\n\",\n",
    "    \"                \\\"ci_hi\\\": hi,\\n\",\n",
    "    \"                \\\"boot_repl_used\\\": n_eff,\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    ci_tbl = pd.DataFrame(rows).sort_values([\\\"metric\\\", \\\"model\\\"])\\n\",\n",
    "    \"    display(ci_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # --- Pairwise paired cluster-bootstrap tests (ROC-AUC diff)\\n\",\n",
    "    \"    if len(models) < 2:\\n\",\n",
    "    \"        print(\\\"Skipping pairwise model comparisons: need at least two model probability columns.\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        comp_rows = []\\n\",\n",
    "    \"        for (n1, c1), (n2, c2) in combinations(models.items(), 2):\\n\",\n",
    "    \"            diff_pt, diff_lo, diff_hi, pval, n_eff = cluster_bootstrap_diff_test(\\n\",\n",
    "    \"                df_te, TARGET_NAME, c1, c2, metric=\\\"roc_auc\\\", cluster_col=\\\"firm_id\\\", n_boot=N_BOOT, alpha=ALPHA, seed=123\\n\",\n",
    "    \"            )\\n\",\n",
    "    \"            comp_rows.append({\\n\",\n",
    "    \"                \\\"model_1\\\": n1,\\n\",\n",
    "    \"                \\\"model_2\\\": n2,\\n\",\n",
    "    \"                \\\"roc_auc_diff_(1-2)\\\": diff_pt,\\n\",\n",
    "    \"                \\\"diff_ci_lo\\\": diff_lo,\\n\",\n",
    "    \"                \\\"diff_ci_hi\\\": diff_hi,\\n\",\n",
    "    \"                \\\"p_value\\\": pval,\\n\",\n",
    "    \"                \\\"boot_repl_used\\\": n_eff,\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"\\n\",\n",
    "    \"        comp_tbl = pd.DataFrame(comp_rows)\\n\",\n",
    "    \"        if not comp_tbl.empty:\\n\",\n",
    "    \"            comp_tbl[\\\"p_bonferroni\\\"] = p_adjust_bonferroni(comp_tbl[\\\"p_value\\\"].values)\\n\",\n",
    "    \"            comp_tbl[\\\"p_holm\\\"] = p_adjust_holm(comp_tbl[\\\"p_value\\\"].values)\\n\",\n",
    "    \"            display(comp_tbl.sort_values(\\\"p_value\\\"))\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"No pairwise comparisons computed.\\\")\"\n",
    "   ],\n",
    "   \"id\": \"8415fff5d00dce39\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"mask = df_model[\\\"split\\\"]==\\\"test\\\"\\n\",\n",
    "    \"y_true = df_model.loc[mask, TARGET_NAME].astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name, pcol in [(\\\"logit\\\",\\\"pd_logit\\\"), (\\\"tree_calibrated\\\",\\\"pd_tree\\\")]:\\n\",\n",
    "    \"    p = df_model.loc[mask, pcol]\\n\",\n",
    "    \"    plt.figure()\\n\",\n",
    "    \"    plt.hist(p[y_true==0], bins=50, alpha=0.6, label=\\\"y=0\\\")\\n\",\n",
    "    \"    plt.hist(p[y_true==1], bins=50, alpha=0.6, label=\\\"y=1\\\")\\n\",\n",
    "    \"    plt.title(f\\\"Test PD histogram by class — {model_name}\\\")\\n\",\n",
    "    \"    plt.xlabel(\\\"Predicted PD\\\")\\n\",\n",
    "    \"    plt.legend()\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / f\\\"pd_hist_{model_name}_test.png\\\", dpi=160)\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ],\n",
    "   \"id\": \"b9f4677778b3b920\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"## 9b. Operational Risk Management Layer (Events + PDs)\\n\",\n",
    "    \"This section uses a **two-layer** design:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Model layer (prediction):** calibrated probability of next-year distress (**PD**) from accounting ratios and structural predictors.\\n\",\n",
    "    \"- **Indicator layer (events):** discrete `evt_*` early-warning indicators **not used as predictors**. They serve governance, monitoring, and decision support.\\n\",\n",
    "    \"\\n\",\n",
    "    \"This structure matches four operational functions commonly discussed in risk-management systems:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Risk awareness:** documented prior knowledge of which indicators flag trouble (event dictionary + empirical lift).\\n\",\n",
    "    \"2. **Monitoring and warning:** continuous tracking of event activation/persistence and PD levels over the panel.\\n\",\n",
    "    \"3. **Communication:** translating signals into decision-maker-friendly views (risk tiers/deciles, transitions, reason codes).\\n\",\n",
    "    \"4. **Response capability:** predefined action rules (screen / monitor / no action) based on PDs and events under explicit costs and capacity constraints.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 9.1 Risk awareness — event dictionary and conditional risk (lift)\"\n",
    "   ],\n",
    "   \"id\": \"118aa5ece6f7109e\"\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"EVT_COLS = event_dict[\\\"event\\\"].tolist()\\n\",\n",
    "    \"print(\\\"Decision-support events:\\\", EVT_COLS)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Optional: enrich the event dictionary with a simple mechanism taxonomy (appendix-ready)\\n\",\n",
    "    \"event_dict_enriched = event_dict.copy()\\n\",\n",
    "    \"mech_map = {\\n\",\n",
    "    \"    \\\"evt_divcut\\\": \\\"Payout policy\\\",\\n\",\n",
    "    \"    \\\"evt_divsusp\\\": \\\"Payout policy\\\",\\n\",\n",
    "    \"    \\\"evt_divinit\\\": \\\"Payout policy\\\",\\n\",\n",
    "    \"    \\\"evt_liq_squeeze\\\": \\\"Liquidity\\\",\\n\",\n",
    "    \"    \\\"evt_quick_squeeze\\\": \\\"Liquidity\\\",\\n\",\n",
    "    \"    \\\"evt_ebitdadrop\\\": \\\"Operating deterioration\\\",\\n\",\n",
    "    \"    \\\"evt_cfdrop\\\": \\\"Operating deterioration\\\",\\n\",\n",
    "    \"}\\n\",\n",
    "    \"event_dict_enriched[\\\"mechanism\\\"] = event_dict_enriched[\\\"event\\\"].map(mech_map).fillna(\\\"Other/unspecified\\\")\\n\",\n",
    "    \"display(event_dict_enriched)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def event_lift_table(df_in: pd.DataFrame, events: list[str], y_col: str) -> pd.DataFrame:\\n\",\n",
    "    \"    # Event lift with explicit missingness handling.\\n\",\n",
    "    \"    # - prevalence_obs: among observations where the event is observed (not NA)\\n\",\n",
    "    \"    # - missing_rate: definitional missingness (insufficient inputs)\\n\",\n",
    "    \"    # - cond_distress_rate: P(y=1 | evt=1, evt observed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    base = df_in[y_col].astype(float).mean()\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    for e in events:\\n\",\n",
    "    \"        if e not in df_in.columns:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"        s = pd.to_numeric(df_in[e], errors=\\\"coerce\\\")  # may contain NA by construction\\n\",\n",
    "    \"        miss = float(s.isna().mean())\\n\",\n",
    "    \"        obs = s.notna()\\n\",\n",
    "    \"        if obs.sum() == 0:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"        s_obs = s[obs].astype(int)\\n\",\n",
    "    \"        n_event = int((s_obs == 1).sum())\\n\",\n",
    "    \"        if n_event == 0:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"\\n\",\n",
    "    \"        rate = df_in.loc[obs & (s == 1), y_col].astype(float).mean()\\n\",\n",
    "    \"        prev = float((s_obs == 1).mean())\\n\",\n",
    "    \"\\n\",\n",
    "    \"        rows.append({\\n\",\n",
    "    \"            \\\"event\\\": e,\\n\",\n",
    "    \"            \\\"mechanism\\\": mech_map.get(e, \\\"Other/unspecified\\\"),\\n\",\n",
    "    \"            \\\"n_obs_event\\\": int(obs.sum()),\\n\",\n",
    "    \"            \\\"n_event\\\": n_event,\\n\",\n",
    "    \"            \\\"missing_rate\\\": miss,\\n\",\n",
    "    \"            \\\"prevalence_obs\\\": prev,\\n\",\n",
    "    \"            \\\"cond_distress_rate\\\": float(rate),\\n\",\n",
    "    \"            \\\"base_rate\\\": float(base),\\n\",\n",
    "    \"            \\\"lift_vs_base\\\": float(rate/base) if base > 0 else np.nan,\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    out = pd.DataFrame(rows)\\n\",\n",
    "    \"    if not out.empty:\\n\",\n",
    "    \"        out = out.sort_values([\\\"lift_vs_base\\\", \\\"n_event\\\"], ascending=[False, False])\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"for sp in [\\\"train\\\", \\\"test\\\"]:\\n\",\n",
    "    \"    df_sp = df_model.loc[df_model[\\\"split\\\"] == sp, :].copy()\\n\",\n",
    "    \"    print(f\\\"\\\\nEvent lift (labels: {TARGET_NAME}) — {sp}\\\")\\n\",\n",
    "    \"    display(event_lift_table(df_sp, EVT_COLS, TARGET_NAME).head(25))\"\n",
    "   ],\n",
    "   \"id\": \"248684e18918374f\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"35162ffd\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 9.2 Monitoring and warning — event dynamics, persistence, and PD×event risk grids\\n\",\n",
    "    \"\\n\",\n",
    "    \"Monitoring should reflect (i) **activation** (0→1), (ii) **persistence** (1→1), and (iii) how event regimes interact with PDs.\\n\",\n",
    "    \"We treat events as *operational indicators* (not predictors) and monitor them jointly with calibrated PDs.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"aaa8fd1b\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2026-01-15T15:18:44.138132Z\",\n",
    "     \"start_time\": \"2026-01-15T15:18:42.904809Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# --- 9.2A Event activation and persistence (adjacency-safe) ---\\n\",\n",
    "    \"def transition_stats(df_in: pd.DataFrame, event: str) -> dict:\\n\",\n",
    "    \"    # Robust transition stats that enforce year adjacency and handle NaNs.\\n\",\n",
    "    \"    s = pd.to_numeric(df_in[event], errors=\\\"coerce\\\")\\n\",\n",
    "    \"    s_l1 = lag(df_in, event, 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    valid = s.notna() & s_l1.notna()\\n\",\n",
    "    \"    if valid.sum() == 0:\\n\",\n",
    "    \"        return {\\\"event\\\": event, \\\"activation_01_rate\\\": np.nan, \\\"persistence_11_rate\\\": np.nan, \\\"n_transitions\\\": 0}\\n\",\n",
    "    \"\\n\",\n",
    "    \"    s0 = s_l1[valid].astype(int)\\n\",\n",
    "    \"    s1 = s[valid].astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    act_01 = ((s0 == 0) & (s1 == 1)).mean()\\n\",\n",
    "    \"    pers_11 = ((s0 == 1) & (s1 == 1)).mean()\\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        \\\"event\\\": event,\\n\",\n",
    "    \"        \\\"activation_01_rate\\\": float(act_01),\\n\",\n",
    "    \"        \\\"persistence_11_rate\\\": float(pers_11),\\n\",\n",
    "    \"        \\\"n_transitions\\\": int(valid.sum()),\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"rows = [transition_stats(df_model, e) for e in EVT_COLS]\\n\",\n",
    "    \"trans_tbl = pd.DataFrame(rows)\\n\",\n",
    "    \"if not trans_tbl.empty:\\n\",\n",
    "    \"    trans_tbl = trans_tbl.sort_values(\\\"activation_01_rate\\\", ascending=False)\\n\",\n",
    "    \"display(trans_tbl)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- 9.2B Monitoring summary by fiscal year (panel-level tracking) ---\\n\",\n",
    "    \"def monitoring_by_year(df_in: pd.DataFrame, p_col: str, y_col: str, evt_cols: list[str]) -> pd.DataFrame:\\n\",\n",
    "    \"    d = df_in[[\\\"fyear\\\", \\\"split\\\", p_col, y_col] + evt_cols].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Event aggregation: triggered count; missingness summarized separately.\\n\",\n",
    "    \"    evt_mat = d[evt_cols].apply(pd.to_numeric, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    d[\\\"evt_missing_rate_mean\\\"] = evt_mat.isna().mean(axis=1)\\n\",\n",
    "    \"    d[\\\"evt_count\\\"] = (evt_mat.fillna(0) == 1).sum(axis=1)\\n\",\n",
    "    \"    d[\\\"evt_any\\\"] = (d[\\\"evt_count\\\"] > 0).astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    out = (d.groupby([\\\"split\\\", \\\"fyear\\\"])\\n\",\n",
    "    \"             .agg(\\n\",\n",
    "    \"                 n=(\\\"fyear\\\",\\\"size\\\"),\\n\",\n",
    "    \"                 mean_pd=(p_col,\\\"mean\\\"),\\n\",\n",
    "    \"                 realized_rate=(y_col,\\\"mean\\\"),\\n\",\n",
    "    \"                 evt_any_rate=(\\\"evt_any\\\",\\\"mean\\\"),\\n\",\n",
    "    \"                 mean_evt_count=(\\\"evt_count\\\",\\\"mean\\\"),\\n\",\n",
    "    \"                 mean_evt_missing=(\\\"evt_missing_rate_mean\\\",\\\"mean\\\"),\\n\",\n",
    "    \"             )\\n\",\n",
    "    \"             .reset_index()\\n\",\n",
    "    \"             .sort_values([\\\"split\\\",\\\"fyear\\\"]))\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nMonitoring by year — calibrated tree PD (pd_tree)\\\")\\n\",\n",
    "    \"display(monitoring_by_year(df_model, \\\"pd_tree\\\", TARGET_NAME, EVT_COLS).head(40))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- 9.2C PD × Event risk grid (operational triangulation) ---\\n\",\n",
    "    \"def pd_event_grid(df_in: pd.DataFrame, p_col: str, y_col: str, evt_cols: list[str], n_bins: int = 10) -> pd.DataFrame:\\n\",\n",
    "    \"    d = df_in[[p_col, y_col] + evt_cols].dropna(subset=[p_col, y_col]).copy()\\n\",\n",
    "    \"    evt_mat = d[evt_cols].apply(pd.to_numeric, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    d[\\\"evt_count\\\"] = (evt_mat.fillna(0) == 1).sum(axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    d[\\\"evt_bucket\\\"] = pd.cut(d[\\\"evt_count\\\"], bins=[-0.1, 0.5, 1.5, 10**6], labels=[\\\"0\\\", \\\"1\\\", \\\"2+\\\"])\\n\",\n",
    "    \"    d[\\\"pd_decile\\\"] = pd.qcut(d[p_col], q=n_bins, labels=False, duplicates=\\\"drop\\\") + 1\\n\",\n",
    "    \"\\n\",\n",
    "    \"    g = (d.groupby([\\\"pd_decile\\\",\\\"evt_bucket\\\"])\\n\",\n",
    "    \"           .agg(\\n\",\n",
    "    \"               n=(\\\"pd_decile\\\",\\\"size\\\"),\\n\",\n",
    "    \"               mean_pd=(p_col,\\\"mean\\\"),\\n\",\n",
    "    \"               realized_rate=(y_col,\\\"mean\\\"),\\n\",\n",
    "    \"           )\\n\",\n",
    "    \"           .reset_index())\\n\",\n",
    "    \"    return g.sort_values([\\\"pd_decile\\\",\\\"evt_bucket\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTest split PD × Events grid — calibrated tree\\\")\\n\",\n",
    "    \"display(pd_event_grid(df_model.loc[df_model[\\\"split\\\"]==\\\"test\\\", :], \\\"pd_tree\\\", TARGET_NAME, EVT_COLS, n_bins=10))\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"               event  activation_01_rate  persistence_11_rate  n_transitions\\n\",\n",
    "       \"6         evt_cfdrop            0.143467             0.021998          37730\\n\",\n",
    "       \"4  evt_quick_squeeze            0.129288             0.128074          45302\\n\",\n",
    "       \"0         evt_divcut            0.125557             0.023596          15045\\n\",\n",
    "       \"3    evt_liq_squeeze            0.119553             0.109068          45302\\n\",\n",
    "       \"5     evt_ebitdadrop            0.112722             0.015637          37730\\n\",\n",
    "       \"2        evt_divinit            0.022184             0.000000          37730\\n\",\n",
    "       \"1        evt_divsusp            0.020726             0.000000          37730\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>event</th>\\n\",\n",
    "       \"      <th>activation_01_rate</th>\\n\",\n",
    "       \"      <th>persistence_11_rate</th>\\n\",\n",
    "       \"      <th>n_transitions</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>evt_cfdrop</td>\\n\",\n",
    "       \"      <td>0.143467</td>\\n\",\n",
    "       \"      <td>0.021998</td>\\n\",\n",
    "       \"      <td>37730</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>evt_quick_squeeze</td>\\n\",\n",
    "       \"      <td>0.129288</td>\\n\",\n",
    "       \"      <td>0.128074</td>\\n\",\n",
    "       \"      <td>45302</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>evt_divcut</td>\\n\",\n",
    "       \"      <td>0.125557</td>\\n\",\n",
    "       \"      <td>0.023596</td>\\n\",\n",
    "       \"      <td>15045</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>evt_liq_squeeze</td>\\n\",\n",
    "       \"      <td>0.119553</td>\\n\",\n",
    "       \"      <td>0.109068</td>\\n\",\n",
    "       \"      <td>45302</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>evt_ebitdadrop</td>\\n\",\n",
    "       \"      <td>0.112722</td>\\n\",\n",
    "       \"      <td>0.015637</td>\\n\",\n",
    "       \"      <td>37730</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>evt_divinit</td>\\n\",\n",
    "       \"      <td>0.022184</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>37730</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>evt_divsusp</td>\\n\",\n",
    "       \"      <td>0.020726</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>37730</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Monitoring by year — calibrated tree PD (pd_tree)\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"   split  fyear     n   mean_pd  realized_rate  evt_any_rate  mean_evt_count  \\\\\\n\",\n",
    "       \"0   test   2022  5601  0.046864         0.0391      0.485449        0.863417   \\n\",\n",
    "       \"1   test   2023  5383  0.049923       0.036225      0.476129        0.846926   \\n\",\n",
    "       \"2  train   2014  5953  0.051915       0.047707      0.285570        0.492861   \\n\",\n",
    "       \"3  train   2015  5686  0.051800       0.038516      0.503342        0.903975   \\n\",\n",
    "       \"4  train   2016  5560  0.050084          0.025      0.483813         0.87536   \\n\",\n",
    "       \"5  train   2017  5513  0.050408       0.035008      0.474515        0.838926   \\n\",\n",
    "       \"6  train   2018  5389  0.048251         0.0347      0.465207        0.810726   \\n\",\n",
    "       \"7  train   2019  5390  0.047938       0.027458      0.494434        0.889796   \\n\",\n",
    "       \"8  train   2020  5468  0.046573       0.019386      0.483723        0.912399   \\n\",\n",
    "       \"9    val   2021  5750  0.040174       0.040174      0.465565        0.827652   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   mean_evt_missing  \\n\",\n",
    "       \"0          0.128548  \\n\",\n",
    "       \"1          0.113559  \\n\",\n",
    "       \"2          0.714286  \\n\",\n",
    "       \"3          0.119115  \\n\",\n",
    "       \"4          0.117806  \\n\",\n",
    "       \"5          0.119665  \\n\",\n",
    "       \"6          0.119556  \\n\",\n",
    "       \"7          0.126451  \\n\",\n",
    "       \"8          0.128436  \\n\",\n",
    "       \"9          0.142161  \"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>split</th>\\n\",\n",
    "       \"      <th>fyear</th>\\n\",\n",
    "       \"      <th>n</th>\\n\",\n",
    "       \"      <th>mean_pd</th>\\n\",\n",
    "       \"      <th>realized_rate</th>\\n\",\n",
    "       \"      <th>evt_any_rate</th>\\n\",\n",
    "       \"      <th>mean_evt_count</th>\\n\",\n",
    "       \"      <th>mean_evt_missing</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>test</td>\\n\",\n",
    "       \"      <td>2022</td>\\n\",\n",
    "       \"      <td>5601</td>\\n\",\n",
    "       \"      <td>0.046864</td>\\n\",\n",
    "       \"      <td>0.0391</td>\\n\",\n",
    "       \"      <td>0.485449</td>\\n\",\n",
    "       \"      <td>0.863417</td>\\n\",\n",
    "       \"      <td>0.128548</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>test</td>\\n\",\n",
    "       \"      <td>2023</td>\\n\",\n",
    "       \"      <td>5383</td>\\n\",\n",
    "       \"      <td>0.049923</td>\\n\",\n",
    "       \"      <td>0.036225</td>\\n\",\n",
    "       \"      <td>0.476129</td>\\n\",\n",
    "       \"      <td>0.846926</td>\\n\",\n",
    "       \"      <td>0.113559</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2014</td>\\n\",\n",
    "       \"      <td>5953</td>\\n\",\n",
    "       \"      <td>0.051915</td>\\n\",\n",
    "       \"      <td>0.047707</td>\\n\",\n",
    "       \"      <td>0.285570</td>\\n\",\n",
    "       \"      <td>0.492861</td>\\n\",\n",
    "       \"      <td>0.714286</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2015</td>\\n\",\n",
    "       \"      <td>5686</td>\\n\",\n",
    "       \"      <td>0.051800</td>\\n\",\n",
    "       \"      <td>0.038516</td>\\n\",\n",
    "       \"      <td>0.503342</td>\\n\",\n",
    "       \"      <td>0.903975</td>\\n\",\n",
    "       \"      <td>0.119115</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2016</td>\\n\",\n",
    "       \"      <td>5560</td>\\n\",\n",
    "       \"      <td>0.050084</td>\\n\",\n",
    "       \"      <td>0.025</td>\\n\",\n",
    "       \"      <td>0.483813</td>\\n\",\n",
    "       \"      <td>0.87536</td>\\n\",\n",
    "       \"      <td>0.117806</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2017</td>\\n\",\n",
    "       \"      <td>5513</td>\\n\",\n",
    "       \"      <td>0.050408</td>\\n\",\n",
    "       \"      <td>0.035008</td>\\n\",\n",
    "       \"      <td>0.474515</td>\\n\",\n",
    "       \"      <td>0.838926</td>\\n\",\n",
    "       \"      <td>0.119665</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2018</td>\\n\",\n",
    "       \"      <td>5389</td>\\n\",\n",
    "       \"      <td>0.048251</td>\\n\",\n",
    "       \"      <td>0.0347</td>\\n\",\n",
    "       \"      <td>0.465207</td>\\n\",\n",
    "       \"      <td>0.810726</td>\\n\",\n",
    "       \"      <td>0.119556</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2019</td>\\n\",\n",
    "       \"      <td>5390</td>\\n\",\n",
    "       \"      <td>0.047938</td>\\n\",\n",
    "       \"      <td>0.027458</td>\\n\",\n",
    "       \"      <td>0.494434</td>\\n\",\n",
    "       \"      <td>0.889796</td>\\n\",\n",
    "       \"      <td>0.126451</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>2020</td>\\n\",\n",
    "       \"      <td>5468</td>\\n\",\n",
    "       \"      <td>0.046573</td>\\n\",\n",
    "       \"      <td>0.019386</td>\\n\",\n",
    "       \"      <td>0.483723</td>\\n\",\n",
    "       \"      <td>0.912399</td>\\n\",\n",
    "       \"      <td>0.128436</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>val</td>\\n\",\n",
    "       \"      <td>2021</td>\\n\",\n",
    "       \"      <td>5750</td>\\n\",\n",
    "       \"      <td>0.040174</td>\\n\",\n",
    "       \"      <td>0.040174</td>\\n\",\n",
    "       \"      <td>0.465565</td>\\n\",\n",
    "       \"      <td>0.827652</td>\\n\",\n",
    "       \"      <td>0.142161</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Test split PD × Events grid — calibrated tree\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"    pd_decile evt_bucket     n   mean_pd  realized_rate\\n\",\n",
    "       \"0           1          0  1842  0.001021       0.001629\\n\",\n",
    "       \"1           1          1   857  0.001004            0.0\\n\",\n",
    "       \"2           1         2+   880  0.000936            0.0\\n\",\n",
    "       \"3           2          0   984  0.004044       0.002033\\n\",\n",
    "       \"4           2          1   398  0.004044       0.002513\\n\",\n",
    "       \"5           2         2+   489  0.004039       0.002045\\n\",\n",
    "       \"6           3          0   366  0.005634       0.008197\\n\",\n",
    "       \"7           3          1   124  0.005634       0.008065\\n\",\n",
    "       \"8           3         2+   201  0.005634       0.004975\\n\",\n",
    "       \"9           4          0   269  0.012273       0.007435\\n\",\n",
    "       \"10          4          1    86  0.013071            0.0\\n\",\n",
    "       \"11          4         2+   136  0.012594            0.0\\n\",\n",
    "       \"12          5          0   665  0.023608       0.016541\\n\",\n",
    "       \"13          5          1   213  0.023466       0.004695\\n\",\n",
    "       \"14          5         2+   323  0.023654       0.009288\\n\",\n",
    "       \"15          6          0   527  0.035951       0.036053\\n\",\n",
    "       \"16          6          1   164  0.035165       0.012195\\n\",\n",
    "       \"17          6         2+   298  0.035511       0.033557\\n\",\n",
    "       \"18          7          0   644  0.107774       0.086957\\n\",\n",
    "       \"19          7          1   196  0.106830        0.05102\\n\",\n",
    "       \"20          7         2+   412  0.107748       0.099515\\n\",\n",
    "       \"21          8          0   405  0.343911       0.276543\\n\",\n",
    "       \"22          8          1   129  0.328541       0.232558\\n\",\n",
    "       \"23          8         2+   376  0.345815       0.279255\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>pd_decile</th>\\n\",\n",
    "       \"      <th>evt_bucket</th>\\n\",\n",
    "       \"      <th>n</th>\\n\",\n",
    "       \"      <th>mean_pd</th>\\n\",\n",
    "       \"      <th>realized_rate</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1842</td>\\n\",\n",
    "       \"      <td>0.001021</td>\\n\",\n",
    "       \"      <td>0.001629</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>857</td>\\n\",\n",
    "       \"      <td>0.001004</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>880</td>\\n\",\n",
    "       \"      <td>0.000936</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>984</td>\\n\",\n",
    "       \"      <td>0.004044</td>\\n\",\n",
    "       \"      <td>0.002033</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>398</td>\\n\",\n",
    "       \"      <td>0.004044</td>\\n\",\n",
    "       \"      <td>0.002513</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>489</td>\\n\",\n",
    "       \"      <td>0.004039</td>\\n\",\n",
    "       \"      <td>0.002045</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>366</td>\\n\",\n",
    "       \"      <td>0.005634</td>\\n\",\n",
    "       \"      <td>0.008197</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>124</td>\\n\",\n",
    "       \"      <td>0.005634</td>\\n\",\n",
    "       \"      <td>0.008065</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>201</td>\\n\",\n",
    "       \"      <td>0.005634</td>\\n\",\n",
    "       \"      <td>0.004975</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>269</td>\\n\",\n",
    "       \"      <td>0.012273</td>\\n\",\n",
    "       \"      <td>0.007435</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>10</th>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>86</td>\\n\",\n",
    "       \"      <td>0.013071</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>11</th>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>136</td>\\n\",\n",
    "       \"      <td>0.012594</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>12</th>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>665</td>\\n\",\n",
    "       \"      <td>0.023608</td>\\n\",\n",
    "       \"      <td>0.016541</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>13</th>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>213</td>\\n\",\n",
    "       \"      <td>0.023466</td>\\n\",\n",
    "       \"      <td>0.004695</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>14</th>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>323</td>\\n\",\n",
    "       \"      <td>0.023654</td>\\n\",\n",
    "       \"      <td>0.009288</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>15</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>527</td>\\n\",\n",
    "       \"      <td>0.035951</td>\\n\",\n",
    "       \"      <td>0.036053</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>16</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>164</td>\\n\",\n",
    "       \"      <td>0.035165</td>\\n\",\n",
    "       \"      <td>0.012195</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>17</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>298</td>\\n\",\n",
    "       \"      <td>0.035511</td>\\n\",\n",
    "       \"      <td>0.033557</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>18</th>\\n\",\n",
    "       \"      <td>7</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>644</td>\\n\",\n",
    "       \"      <td>0.107774</td>\\n\",\n",
    "       \"      <td>0.086957</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>19</th>\\n\",\n",
    "       \"      <td>7</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>196</td>\\n\",\n",
    "       \"      <td>0.106830</td>\\n\",\n",
    "       \"      <td>0.05102</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>20</th>\\n\",\n",
    "       \"      <td>7</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>412</td>\\n\",\n",
    "       \"      <td>0.107748</td>\\n\",\n",
    "       \"      <td>0.099515</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>21</th>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>405</td>\\n\",\n",
    "       \"      <td>0.343911</td>\\n\",\n",
    "       \"      <td>0.276543</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>22</th>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>129</td>\\n\",\n",
    "       \"      <td>0.328541</td>\\n\",\n",
    "       \"      <td>0.232558</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>23</th>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>2+</td>\\n\",\n",
    "       \"      <td>376</td>\\n\",\n",
    "       \"      <td>0.345815</td>\\n\",\n",
    "       \"      <td>0.279255</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 110\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"89c18d2c\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 9.3 Communication — risk tiers, transitions, and reason codes\\n\",\n",
    "    \"\\n\",\n",
    "    \"Communication should translate model outputs and indicator triggers into decision-maker-friendly artifacts:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Risk tiers/deciles:** expected vs realized risk by PD bucket.\\n\",\n",
    "    \"- **Transitions:** PD movements and event activations/persistence.\\n\",\n",
    "    \"- **Reason codes:** simple, interpretable attributions for material PD jumps (based on newly triggered events).\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"48e1cb6a\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2026-01-15T15:18:45.962756Z\",\n",
    "     \"start_time\": \"2026-01-15T15:18:44.581242Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"def decile_table(df_in: pd.DataFrame, p_col: str, y_col: str) -> pd.DataFrame:\\n\",\n",
    "    \"    d = df_in[[p_col, y_col]].dropna().copy()\\n\",\n",
    "    \"    d[\\\"decile\\\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\\\"drop\\\") + 1\\n\",\n",
    "    \"    out = d.groupby(\\\"decile\\\").agg(\\n\",\n",
    "    \"        n=(\\\"decile\\\",\\\"size\\\"),\\n\",\n",
    "    \"        mean_pd=(p_col,\\\"mean\\\"),\\n\",\n",
    "    \"        realized_rate=(y_col,\\\"mean\\\"),\\n\",\n",
    "    \"    ).reset_index()\\n\",\n",
    "    \"    out[\\\"calibration_gap\\\"] = out[\\\"realized_rate\\\"] - out[\\\"mean_pd\\\"]\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name, pcol in [(\\\"logit\\\",\\\"pd_logit\\\"), (\\\"tree_calibrated\\\",\\\"pd_tree\\\")]:\\n\",\n",
    "    \"    print(f\\\"\\\\nTest deciles — {model_name}\\\")\\n\",\n",
    "    \"    dt = decile_table(df_model.loc[df_model[\\\"split\\\"]==\\\"test\\\", :], pcol, TARGET_NAME)\\n\",\n",
    "    \"    display(dt)\\n\",\n",
    "    \"    # --- 9.3A Reason codes for large PD jumps (event-based) ---\\n\",\n",
    "    \"# When PD decile increases materially year-over-year, summarize which events newly activated.\\n\",\n",
    "    \"\\n\",\n",
    "    \"def reason_codes_for_pd_jumps(df_in: pd.DataFrame, p_col: str, evt_cols: list[str], min_decile_jump: int = 3, split: str = \\\"test\\\") -> pd.DataFrame:\\n\",\n",
    "    \"    d = df_in.loc[df_in[\\\"split\\\"] == split, [\\\"firm_id\\\",\\\"fyear\\\", p_col] + evt_cols].copy()\\n\",\n",
    "    \"    d = d.sort_values([\\\"firm_id\\\",\\\"fyear\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # PD deciles within the split (communication tiering)\\n\",\n",
    "    \"    d[\\\"pd_decile\\\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\\\"drop\\\") + 1\\n\",\n",
    "    \"    d[\\\"pd_decile_l1\\\"] = lag(d, \\\"pd_decile\\\", 1)\\n\",\n",
    "    \"    d[\\\"decile_jump\\\"] = d[\\\"pd_decile\\\"] - d[\\\"pd_decile_l1\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    jump_mask = d[\\\"decile_jump\\\"].notna() & (d[\\\"decile_jump\\\"] >= min_decile_jump)\\n\",\n",
    "    \"    if int(jump_mask.sum()) == 0:\\n\",\n",
    "    \"        return pd.DataFrame(columns=[\\\"event\\\",\\\"n_new_activation_in_jumps\\\",\\\"share_of_jumps\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    n_jumps = int(jump_mask.sum())\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    for e in evt_cols:\\n\",\n",
    "    \"        s = pd.to_numeric(d[e], errors=\\\"coerce\\\")\\n\",\n",
    "    \"        s_l1 = lag(d, e, 1)\\n\",\n",
    "    \"        valid = jump_mask & s.notna() & s_l1.notna()\\n\",\n",
    "    \"        if int(valid.sum()) == 0:\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"        new_act = int(((s_l1[valid].astype(int) == 0) & (s[valid].astype(int) == 1)).sum())\\n\",\n",
    "    \"        if new_act > 0:\\n\",\n",
    "    \"            rows.append({\\n\",\n",
    "    \"                \\\"event\\\": e,\\n\",\n",
    "    \"                \\\"n_new_activation_in_jumps\\\": new_act,\\n\",\n",
    "    \"                \\\"share_of_jumps\\\": float(new_act / n_jumps),\\n\",\n",
    "    \"            })\\n\",\n",
    "    \"\\n\",\n",
    "    \"    out = pd.DataFrame(rows).sort_values(\\\"n_new_activation_in_jumps\\\", ascending=False)\\n\",\n",
    "    \"    return out\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nReason codes — events newly activating during large PD jumps (test split)\\\")\\n\",\n",
    "    \"display(reason_codes_for_pd_jumps(df_model, \\\"pd_tree\\\", EVT_COLS, min_decile_jump=3, split=\\\"test\\\").head(20))\\n\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Test deciles — logit\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"   decile     n   mean_pd  realized_rate  calibration_gap\\n\",\n",
    "       \"0       1  1099  0.008035       0.007279        -0.000756\\n\",\n",
    "       \"1       2  1098  0.012008       0.010929        -0.001079\\n\",\n",
    "       \"2       3  1098  0.014934       0.013661        -0.001272\\n\",\n",
    "       \"3       4  1099  0.018323       0.020928         0.002606\\n\",\n",
    "       \"4       5  1098  0.022729        0.02459         0.001861\\n\",\n",
    "       \"5       6  1098  0.028702       0.034608         0.005906\\n\",\n",
    "       \"6       7  1099  0.036131       0.049136         0.013004\\n\",\n",
    "       \"7       8  1098  0.044149       0.046448         0.002299\\n\",\n",
    "       \"8       9  1098  0.054753       0.062842         0.008088\\n\",\n",
    "       \"9      10  1099  0.093882        0.10646         0.012579\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>decile</th>\\n\",\n",
    "       \"      <th>n</th>\\n\",\n",
    "       \"      <th>mean_pd</th>\\n\",\n",
    "       \"      <th>realized_rate</th>\\n\",\n",
    "       \"      <th>calibration_gap</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1099</td>\\n\",\n",
    "       \"      <td>0.008035</td>\\n\",\n",
    "       \"      <td>0.007279</td>\\n\",\n",
    "       \"      <td>-0.000756</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1098</td>\\n\",\n",
    "       \"      <td>0.012008</td>\\n\",\n",
    "       \"      <td>0.010929</td>\\n\",\n",
    "       \"      <td>-0.001079</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>1098</td>\\n\",\n",
    "       \"      <td>0.014934</td>\\n\",\n",
    "       \"      <td>0.013661</td>\\n\",\n",
    "       \"      <td>-0.001272</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>1099</td>\\n\",\n",
    "       \"      <td>0.018323</td>\\n\",\n",
    "       \"      <td>0.020928</td>\\n\",\n",
    "       \"      <td>0.002606</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>1098</td>\\n\",\n",
    "       \"      <td>0.022729</td>\\n\",\n",
    "       \"      <td>0.02459</td>\\n\",\n",
    "       \"      <td>0.001861</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>1098</td>\\n\",\n",
    "       \"      <td>0.028702</td>\\n\",\n",
    "       \"      <td>0.034608</td>\\n\",\n",
    "       \"      <td>0.005906</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>7</td>\\n\",\n",
    "       \"      <td>1099</td>\\n\",\n",
    "       \"      <td>0.036131</td>\\n\",\n",
    "       \"      <td>0.049136</td>\\n\",\n",
    "       \"      <td>0.013004</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>1098</td>\\n\",\n",
    "       \"      <td>0.044149</td>\\n\",\n",
    "       \"      <td>0.046448</td>\\n\",\n",
    "       \"      <td>0.002299</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>9</td>\\n\",\n",
    "       \"      <td>1098</td>\\n\",\n",
    "       \"      <td>0.054753</td>\\n\",\n",
    "       \"      <td>0.062842</td>\\n\",\n",
    "       \"      <td>0.008088</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>10</td>\\n\",\n",
    "       \"      <td>1099</td>\\n\",\n",
    "       \"      <td>0.093882</td>\\n\",\n",
    "       \"      <td>0.10646</td>\\n\",\n",
    "       \"      <td>0.012579</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Test deciles — tree_calibrated\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"   decile     n   mean_pd  realized_rate  calibration_gap\\n\",\n",
    "       \"0       1  3579  0.000996       0.000838        -0.000158\\n\",\n",
    "       \"1       2  1871  0.004043       0.002138        -0.001905\\n\",\n",
    "       \"2       3   691  0.005634       0.007236         0.001602\\n\",\n",
    "       \"3       4   491  0.012502       0.004073        -0.008428\\n\",\n",
    "       \"4       5  1201  0.023595        0.01249        -0.011106\\n\",\n",
    "       \"5       6   989  0.035688       0.031345        -0.004344\\n\",\n",
    "       \"6       7  1252  0.107618       0.085463        -0.022155\\n\",\n",
    "       \"7       8   910  0.342519       0.271429        -0.071091\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>decile</th>\\n\",\n",
    "       \"      <th>n</th>\\n\",\n",
    "       \"      <th>mean_pd</th>\\n\",\n",
    "       \"      <th>realized_rate</th>\\n\",\n",
    "       \"      <th>calibration_gap</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>3579</td>\\n\",\n",
    "       \"      <td>0.000996</td>\\n\",\n",
    "       \"      <td>0.000838</td>\\n\",\n",
    "       \"      <td>-0.000158</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1871</td>\\n\",\n",
    "       \"      <td>0.004043</td>\\n\",\n",
    "       \"      <td>0.002138</td>\\n\",\n",
    "       \"      <td>-0.001905</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>691</td>\\n\",\n",
    "       \"      <td>0.005634</td>\\n\",\n",
    "       \"      <td>0.007236</td>\\n\",\n",
    "       \"      <td>0.001602</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>491</td>\\n\",\n",
    "       \"      <td>0.012502</td>\\n\",\n",
    "       \"      <td>0.004073</td>\\n\",\n",
    "       \"      <td>-0.008428</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>1201</td>\\n\",\n",
    "       \"      <td>0.023595</td>\\n\",\n",
    "       \"      <td>0.01249</td>\\n\",\n",
    "       \"      <td>-0.011106</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>989</td>\\n\",\n",
    "       \"      <td>0.035688</td>\\n\",\n",
    "       \"      <td>0.031345</td>\\n\",\n",
    "       \"      <td>-0.004344</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>7</td>\\n\",\n",
    "       \"      <td>1252</td>\\n\",\n",
    "       \"      <td>0.107618</td>\\n\",\n",
    "       \"      <td>0.085463</td>\\n\",\n",
    "       \"      <td>-0.022155</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>910</td>\\n\",\n",
    "       \"      <td>0.342519</td>\\n\",\n",
    "       \"      <td>0.271429</td>\\n\",\n",
    "       \"      <td>-0.071091</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Reason codes — events newly activating during large PD jumps (test split)\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"               event  n_new_activation_in_jumps  share_of_jumps\\n\",\n",
    "       \"6         evt_cfdrop                         82        0.168724\\n\",\n",
    "       \"5     evt_ebitdadrop                         75        0.154321\\n\",\n",
    "       \"3    evt_liq_squeeze                         72        0.148148\\n\",\n",
    "       \"4  evt_quick_squeeze                         69        0.141975\\n\",\n",
    "       \"0         evt_divcut                         23        0.047325\\n\",\n",
    "       \"1        evt_divsusp                         12        0.024691\\n\",\n",
    "       \"2        evt_divinit                          9        0.018519\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>event</th>\\n\",\n",
    "       \"      <th>n_new_activation_in_jumps</th>\\n\",\n",
    "       \"      <th>share_of_jumps</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>evt_cfdrop</td>\\n\",\n",
    "       \"      <td>82</td>\\n\",\n",
    "       \"      <td>0.168724</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>evt_ebitdadrop</td>\\n\",\n",
    "       \"      <td>75</td>\\n\",\n",
    "       \"      <td>0.154321</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>evt_liq_squeeze</td>\\n\",\n",
    "       \"      <td>72</td>\\n\",\n",
    "       \"      <td>0.148148</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>evt_quick_squeeze</td>\\n\",\n",
    "       \"      <td>69</td>\\n\",\n",
    "       \"      <td>0.141975</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>evt_divcut</td>\\n\",\n",
    "       \"      <td>23</td>\\n\",\n",
    "       \"      <td>0.047325</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>evt_divsusp</td>\\n\",\n",
    "       \"      <td>12</td>\\n\",\n",
    "       \"      <td>0.024691</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>evt_divinit</td>\\n\",\n",
    "       \"      <td>9</td>\\n\",\n",
    "       \"      <td>0.018519</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 111\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"2fc0a52a\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 9.4 Response capability — predefined action rules under costs and capacity\\n\",\n",
    "    \"\\n\",\n",
    "    \"We translate PDs and `evt_*` indicators into an operational policy with three actions:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- **Screen / Review** (capacity-limited): highest-risk firms warrant immediate attention.\\n\",\n",
    "    \"- **Monitor more closely**: elevated risk, but not high enough for immediate screening.\\n\",\n",
    "    \"- **No action**: routine monitoring only.\\n\",\n",
    "    \"\\n\",\n",
    "    \"We compare:\\n\",\n",
    "    \"- **PD-only policy** (threshold on PD),\\n\",\n",
    "    \"- **Hybrid policy** (PD + event burden) that can prioritize “indicator-led” cases without retraining the model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"66ca9b6f\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2026-01-15T15:18:47.935949Z\",\n",
    "     \"start_time\": \"2026-01-15T15:18:46.515554Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"COST_FN = float(CONFIG[\\\"COST_FN\\\"])\\n\",\n",
    "    \"COST_FP = float(CONFIG[\\\"COST_FP\\\"])\\n\",\n",
    "    \"CAPACITY_PCT = float(CONFIG[\\\"CAPACITY_PCT\\\"])\\n\",\n",
    "    \"MONITOR_PCT = float(CONFIG.get(\\\"MONITOR_PCT\\\", min(0.20, 2*CAPACITY_PCT)))  # fallback: monitor top 20% or 2x capacity\\n\",\n",
    "    \"\\n\",\n",
    "    \"def expected_cost(y_true: np.ndarray, y_hat: np.ndarray) -> float:\\n\",\n",
    "    \"    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\\n\",\n",
    "    \"    return COST_FN*fn + COST_FP*fp\\n\",\n",
    "    \"\\n\",\n",
    "    \"def apply_pd_only_policy(p: np.ndarray, thr_screen: float, thr_monitor: float) -> dict:\\n\",\n",
    "    \"    screen = (p >= thr_screen).astype(int)\\n\",\n",
    "    \"    monitor = ((p >= thr_monitor) & (p < thr_screen)).astype(int)\\n\",\n",
    "    \"    return {\\\"screen\\\": screen, \\\"monitor\\\": monitor}\\n\",\n",
    "    \"\\n\",\n",
    "    \"def apply_hybrid_policy(p: np.ndarray, evt_count: np.ndarray, alpha: float = 0.05, beta: float = 0.10) -> dict:\\n\",\n",
    "    \"    \\\"\\\"\\\"Hybrid prioritization score:\\n\",\n",
    "    \"      score = p + alpha*1{evt_any} + beta*1{evt_count>=2}\\n\",\n",
    "    \"    Screening/monitoring are then capacity-based on the score.\\\"\\\"\\\"\\n\",\n",
    "    \"    evt_any = (evt_count > 0).astype(int)\\n\",\n",
    "    \"    score = p + alpha*evt_any + beta*(evt_count >= 2).astype(int)\\n\",\n",
    "    \"    thr_score_screen = float(np.quantile(score, 1-CAPACITY_PCT))\\n\",\n",
    "    \"    thr_score_monitor = float(np.quantile(score, 1-MONITOR_PCT))\\n\",\n",
    "    \"    screen = (score >= thr_score_screen).astype(int)\\n\",\n",
    "    \"    monitor = ((score >= thr_score_monitor) & (score < thr_score_screen)).astype(int)\\n\",\n",
    "    \"    return {\\\"screen\\\": screen, \\\"monitor\\\": monitor, \\\"score\\\": score, \\\"thr_score_screen\\\": thr_score_screen, \\\"thr_score_monitor\\\": thr_score_monitor}\\n\",\n",
    "    \"\\n\",\n",
    "    \"def build_evt_count(df_in: pd.DataFrame, evt_cols: list[str]) -> np.ndarray:\\n\",\n",
    "    \"    evt_mat = df_in[evt_cols].apply(pd.to_numeric, errors=\\\"coerce\\\")\\n\",\n",
    "    \"    return (evt_mat.fillna(0) == 1).sum(axis=1).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Threshold selection (validation only) for PD-only policy ---\\n\",\n",
    "    \"grid = np.linspace(0.01, 0.99, 99)\\n\",\n",
    "    \"mask_val = df_model[\\\"split\\\"] == \\\"val\\\"\\n\",\n",
    "    \"y_val = df_model.loc[mask_val, TARGET_NAME].astype(int).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"thr_tbls = {}\\n\",\n",
    "    \"for model_name, pcol in [(\\\"logit\\\",\\\"pd_logit\\\"), (\\\"tree_calibrated\\\",\\\"pd_tree\\\")]:\\n\",\n",
    "    \"    p_val = df_model.loc[mask_val, pcol].values\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Cost-opt threshold\\n\",\n",
    "    \"    costs = []\\n\",\n",
    "    \"    for thr in grid:\\n\",\n",
    "    \"        costs.append(expected_cost(y_val, (p_val >= thr).astype(int)))\\n\",\n",
    "    \"    thr_cost_opt = float(grid[int(np.argmin(costs))])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Capacity and monitoring thresholds (operational)\\n\",\n",
    "    \"    thr_capacity = float(np.quantile(p_val, 1-CAPACITY_PCT))\\n\",\n",
    "    \"    thr_monitor = float(np.quantile(p_val, 1-MONITOR_PCT))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    thr_tbls[model_name] = {\\\"thr_cost_opt\\\": thr_cost_opt, \\\"thr_capacity\\\": thr_capacity, \\\"thr_monitor\\\": thr_monitor}\\n\",\n",
    "    \"\\n\",\n",
    "    \"    plt.figure()\\n\",\n",
    "    \"    plt.plot(grid, costs)\\n\",\n",
    "    \"    plt.title(f\\\"Validation expected cost vs PD threshold — {model_name}\\\")\\n\",\n",
    "    \"    plt.xlabel(\\\"PD threshold\\\")\\n\",\n",
    "    \"    plt.ylabel(\\\"Expected misclassification cost\\\")\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / f\\\"cost_curve_{model_name}_val.png\\\", dpi=160)\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"display(pd.DataFrame(thr_tbls).T)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Policy comparison on TEST: PD-only vs Hybrid (PD + events) ---\\n\",\n",
    "    \"mask_test = df_model[\\\"split\\\"] == \\\"test\\\"\\n\",\n",
    "    \"y_test = df_model.loc[mask_test, TARGET_NAME].astype(int).values\\n\",\n",
    "    \"evt_count_test = build_evt_count(df_model.loc[mask_test, :], EVT_COLS)\\n\",\n",
    "    \"\\n\",\n",
    "    \"rows = []\\n\",\n",
    "    \"for model_name, pcol in [(\\\"logit\\\",\\\"pd_logit\\\"), (\\\"tree_calibrated\\\",\\\"pd_tree\\\")]:\\n\",\n",
    "    \"    p_test = df_model.loc[mask_test, pcol].values\\n\",\n",
    "    \"\\n\",\n",
    "    \"    thr_screen = thr_tbls[model_name][\\\"thr_capacity\\\"]\\n\",\n",
    "    \"    thr_monitor = thr_tbls[model_name][\\\"thr_monitor\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # PD-only (screen decision)\\n\",\n",
    "    \"    polA = apply_pd_only_policy(p_test, thr_screen, thr_monitor)\\n\",\n",
    "    \"    costA = expected_cost(y_test, polA[\\\"screen\\\"])\\n\",\n",
    "    \"    capA = float(polA[\\\"screen\\\"].mean())\\n\",\n",
    "    \"    tprA = float(((polA[\\\"screen\\\"]==1) & (y_test==1)).sum() / max(1, (y_test==1).sum()))\\n\",\n",
    "    \"    ppvA = float(((polA[\\\"screen\\\"]==1) & (y_test==1)).sum() / max(1, (polA[\\\"screen\\\"]==1).sum()))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Hybrid (screen decision derived from capacity on composite score)\\n\",\n",
    "    \"    polB = apply_hybrid_policy(p_test, evt_count_test, alpha=0.05, beta=0.10)\\n\",\n",
    "    \"    costB = expected_cost(y_test, polB[\\\"screen\\\"])\\n\",\n",
    "    \"    capB = float(polB[\\\"screen\\\"].mean())\\n\",\n",
    "    \"    tprB = float(((polB[\\\"screen\\\"]==1) & (y_test==1)).sum() / max(1, (y_test==1).sum()))\\n\",\n",
    "    \"    ppvB = float(((polB[\\\"screen\\\"]==1) & (y_test==1)).sum() / max(1, (polB[\\\"screen\\\"]==1).sum()))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    rows.append({\\n\",\n",
    "    \"        \\\"model\\\": model_name,\\n\",\n",
    "    \"        \\\"policy\\\": \\\"PD-only\\\",\\n\",\n",
    "    \"        \\\"screen_rate\\\": capA,\\n\",\n",
    "    \"        \\\"monitor_rate\\\": float(polA[\\\"monitor\\\"].mean()),\\n\",\n",
    "    \"        \\\"tpr_screen\\\": tprA,\\n\",\n",
    "    \"        \\\"ppv_screen\\\": ppvA,\\n\",\n",
    "    \"        \\\"expected_cost\\\": costA,\\n\",\n",
    "    \"        \\\"thr_screen_pd\\\": thr_screen,\\n\",\n",
    "    \"        \\\"thr_monitor_pd\\\": thr_monitor,\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"    rows.append({\\n\",\n",
    "    \"        \\\"model\\\": model_name,\\n\",\n",
    "    \"        \\\"policy\\\": \\\"Hybrid (PD + events)\\\",\\n\",\n",
    "    \"        \\\"screen_rate\\\": capB,\\n\",\n",
    "    \"        \\\"monitor_rate\\\": float(polB[\\\"monitor\\\"].mean()),\\n\",\n",
    "    \"        \\\"tpr_screen\\\": tprB,\\n\",\n",
    "    \"        \\\"ppv_screen\\\": ppvB,\\n\",\n",
    "    \"        \\\"expected_cost\\\": costB,\\n\",\n",
    "    \"        \\\"thr_screen_score\\\": polB[\\\"thr_score_screen\\\"],\\n\",\n",
    "    \"        \\\"thr_monitor_score\\\": polB[\\\"thr_score_monitor\\\"],\\n\",\n",
    "    \"        \\\"alpha_evt_any\\\": 0.05,\\n\",\n",
    "    \"        \\\"beta_evt_2plus\\\": 0.10,\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"policy_cmp = pd.DataFrame(rows).sort_values([\\\"model\\\",\\\"policy\\\"])\\n\",\n",
    "    \"print(\\\"\\\\nPolicy comparison on TEST (screen decision):\\\")\\n\",\n",
    "    \"display(policy_cmp)\\n\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Figure size 640x480 with 1 Axes>\"\n",
    "      ],\n",
    "      \"image/png\": \"iVBORw0KGgoAAAANSUhEUgAAAnUAAAHWCAYAAAARl3+JAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAboNJREFUeJzt3XlYVGX/BvB7gGFYhBFQGFBEUETcFwrFFPclydRKC19SM7MslZRcKnPJtLTMzNIWUzO3t0zz7WcImVoq7qK57ywKgizDvs08vz+MkyOoMzoww3B/rmuunHOeOed7GIa5e855niMTQggQERERUY1mZeoCiIiIiOjRMdQRERERWQCGOiIiIiILwFBHREREZAEY6oiIiIgsAEMdERERkQVgqCMiIiKyAAx1RERERBaAoY6IiIjIAjDUkdENGTIE9vb2yM7OvmebESNGQC6X4+bNm3pvVyaTYfbs2dLz3bt3QyaTYffu3Q987ahRo9C4cWO993WnL7/8EqtXr66w/Nq1a5DJZJWuI/2sX78eS5YsqZJtN27cGKNGjaqSbT+sgoICzJ49W6/f2epQ/hkqf1hbW8PDwwPPPfcczp49K7Ur/10vf8jlcri5ueGxxx7Dm2++idOnT+u1v/sd/+zZsyGTyXDr1i1jHd4jqYp6unfvju7duz+wnan/thjyt/VR3P0ZvXHjBmbPno34+Pgq3a8lY6gjoxszZgyKioqwfv36Ster1Wps2bIFYWFh8PDweOj9dOjQAXFxcejQocNDb0Mf9wp1np6eiIuLw8CBA6t0/5asKkOdOSooKMCcOXPMJtSVmz9/PuLi4rBr1y5MmzYNsbGx6NKlC65fv67TbsKECYiLi8OePXuwdu1aDB48GNu2bUPbtm2xaNGiB+7HXI+fTGPLli2YOXOm9PzGjRuYM2cOQ90jsDF1AWR5BgwYAC8vL3z33XcYP358hfUbNmxAYWEhxowZ80j7cXZ2RqdOnR5pG49CoVCYdP9ExuLv7y/9Lnfr1g1169bFmDFjsHr1arzzzjtSu0aNGun8zj/55JOYPHkyhg4diqlTp6JVq1YYMGBAtdcvhEBRURHs7e2rfd/08Nq3b2/qEiwOe+rI6KytrTFy5EgcPXoUf//9d4X1q1atgqenJwYMGID09HSMHz8eLVq0QJ06deDu7o6ePXvir7/+euB+7nWKYPXq1QgICIBCoUBgYCC+//77Sl8/Z84cBAcHw9XVFc7OzujQoQNWrlwJIYTUpnHjxjh9+jT27NkjnXoqP417r1Mke/fuRa9eveDk5AQHBweEhITg//7v/yrUKJPJsGvXLrz22muoV68e3NzcMHToUNy4ceOBxw4AR44cwaBBg+Dq6go7Ozu0b98e//3vf6X1t27dgre3N0JCQlBaWiotP3PmDBwdHRERESEt6969O1q1aoW//voLnTp1gr29PRo0aICZM2dCo9Ho7LekpATz5s1D8+bNoVAoUL9+fYwePRrp6ekValy/fj06d+6MOnXqoE6dOmjXrh1Wrlwp7fP//u//kJCQoHNqz9D9lJaWYurUqVCpVHBwcMATTzyBQ4cO6fUzBIDi4mLMnTsXgYGBsLOzg5ubG3r06IH9+/dLbYqKijBjxgz4+vrC1tYWDRo0wOuvv17hEoM//vgD3bt3h5ubG+zt7dGoUSM888wzKCgowLVr11C/fn0At3/3yo/3XqeI09PTYWtrq9OTUe7cuXOQyWRYunQpgNs9YFFRUfD19YWdnR1cXV0RFBSEDRs26P1zuFN5cEtISHhgW3t7e6xcuRJyufy+vXX6Hv/NmzfxwgsvQKlUwsPDAy+99BLUarVOG5lMhjfeeAMrVqxAYGAgFAoF1qxZAwC4ePEiwsPD4e7uLv0N+OKLL3Rer9VqMW/ePAQEBMDe3h5169ZFmzZt8Nlnn1WoW5969P39qMyNGzcwbNgwODk5QalUYvjw4UhNTX3g60xh27Zt6Ny5MxwcHODk5IQ+ffogLi6uQrtffvkFbdq0gUKhgJ+fHz777DPpdPad7jz9unv3bjz22GMAgNGjR0u/H3deckN6EERV4OLFi0Imk4nIyEid5adPnxYAxPTp04UQQpw7d0689tprYuPGjWL37t3i119/FWPGjBFWVlZi165dOq8FIGbNmiU937VrlwCg027VqlUCgHj66afF//73P/HDDz+Ipk2bCm9vb+Hj46OzvVGjRomVK1eK2NhYERsbK95//31hb28v5syZI7U5duyY8PPzE+3btxdxcXEiLi5OHDt2TAghxNWrVwUAsWrVKqn97t27hVwuFx07dhSbNm0SW7duFX379hUymUxs3LixQp1+fn5iwoQJYseOHeLbb78VLi4uokePHg/8+f7xxx/C1tZWdO3aVWzatElER0eLUaNGVahn7969wsbGRrz55ptCCCHy8/NFixYtRPPmzUVeXp7ULjQ0VLi5uQkvLy+xdOlSsWPHDjFx4kQBQLz++utSO41GI/r37y8cHR3FnDlzRGxsrPj2229FgwYNRIsWLURBQYHUdubMmQKAGDp0qPjxxx9FTEyMWLx4sZg5c6YQ4vbvQpcuXYRKpZJ+tnFxcQbvZ+TIkUImk4m33npL2keDBg2Es7OzGDly5H1/jqWlpaJHjx7CxsZGREVFie3bt4tt27aJt99+W2zYsEEIIYRWqxX9+vUTNjY2YubMmSImJkZ8/PHHwtHRUbRv314UFRVJvw92dnaiT58+YuvWrWL37t1i3bp1IiIiQmRlZYmioiIRHR0tAIgxY8ZIx3vp0qV71jdkyBDh7e0tNBqNzvKpU6cKW1tbcevWLSGEEOPGjRMODg5i8eLFYteuXeLXX38VH374ofj888/ve/zln6Eff/xRZ/kvv/wiAIi3335bOjYAYtGiRffcVqdOnYRCoRClpaWVrn/Q8c+aNUsAEAEBAeK9994TsbGxYvHixUKhUIjRo0frbAuAaNCggWjTpo1Yv369+OOPP8SpU6fE6dOnhVKpFK1btxbff/+9iImJEVOmTBFWVlZi9uzZ0usXLFggrK2txaxZs8TOnTtFdHS0WLJkiU4bfevR9/dDiNufs9DQUOl5QUGBCAwMFEqlUnz++efS565Ro0YVPsvVqbK/revWrRMARN++fcXWrVvFpk2bRMeOHYWtra3466+/pHa//fabsLKyEt27dxdbtmwRP/74owgODhaNGzcWd0cOHx8f6TOqVqulv4vvvvuu9PuRlJRUHYdsMRjqqMqEhoaKevXqiZKSEmnZlClTBABx4cKFSl9TVlYmSktLRa9evcSQIUN01j0o1Gk0GuHl5SU6dOggtFqt1O7atWtCLpdXCHV30mg0orS0VMydO1e4ubnpvL5ly5Y6f4jLVRbqOnXqJNzd3UVubq7OMbVq1Uo0bNhQ2m75H6/x48frbHPhwoUCgEhJSblnrUII0bx5c9G+ffsKX6BhYWHC09NTJwR89NFHAoDYsmWLGDlypLC3txcnT57UeV1oaKgAIH755Red5WPHjhVWVlYiISFBCCHEhg0bBACxefNmnXaHDx8WAMSXX34phBDiypUrwtraWowYMeK+xzFw4MBK3xd993P27FkBQAqt5cq/gB4U6r7//nsBQHzzzTf3bFMeRBYuXKizfNOmTQKA+Prrr4UQQvz0008CgIiPj7/nttLT0yv8Ht/Ptm3bBAARExMjLSsrKxNeXl7imWeekZa1atVKDB48WK9t3qn8M7Rp0yZRWloqCgoKxJ9//imaNm0qrK2txYkTJ4QQ+oW64cOHCwDi5s2b92xzv+MvD1F3/5zHjx8v7OzsdD6TAIRSqRSZmZk6bfv16ycaNmwo1Gq1zvI33nhD2NnZSe3DwsJEu3bt7lmnIfXo+/shRMVQt3z58nt+7swp1JX/bW3durXO35bc3Fzh7u4uQkJCpGWPPfaY8Pb2FsXFxTrt3Nzc7hvqhPj3822q47YEPP1KVWbMmDG4desWtm3bBgAoKyvDDz/8gK5du8Lf319qt2LFCnTo0AF2dnawsbGBXC7Hzp07dUbf6eP8+fO4ceMGwsPDdbr5fXx8EBISUqH9H3/8gd69e0OpVMLa2hpyuRzvvfceMjIykJaWZvDx5ufn4+DBg3j22WdRp04dabm1tTUiIiKQnJyM8+fP67xm0KBBOs/btGkD4P6nvS5duoRz585hxIgRAG7/XMsfTz75JFJSUnT289Zbb2HgwIF44YUXsGbNGnz++edo3bp1he06OTlVqCc8PBxarRZ//vknAODXX39F3bp18dRTT+nst127dlCpVNKp8NjYWGg0Grz++usP+rFVSt/97Nq1CwCkn0W5YcOGwcbmwZcM//bbb7Czs8NLL710zzZ//PEHAFQ4Tfjcc8/B0dERO3fuBAC0a9cOtra2eOWVV7BmzRpcuXJF38O9pwEDBkClUmHVqlXSsh07duDGjRs6NT/++OP47bffMH36dOzevRuFhYUG7Wf48OGQy+VwcHBAt27doNFo8NNPP0m/j/oQd1y28Cgq+0wUFRVV+Ez27NkTLi4u0vOioiLs3LkTQ4YMgYODQ4XPRVFREQ4cOADg9s/rxIkTGD9+PHbs2IGcnJyHrkff34/K7Nq1656fO33ceYyGPgxR/rc1IiICVlb/xoY6dergmWeewYEDB1BQUID8/HwcOXIEgwcPhq2trU67p556yqB90sNhqKMq8+yzz0KpVEpfSNu3b8fNmzd1BkgsXrwYr732GoKDg7F582YcOHAAhw8fRv/+/Q3+YsrIyAAAqFSqCuvuXnbo0CH07dsXAPDNN99g3759OHz4sHRRuKH7BoCsrCwIIeDp6VlhnZeXl06N5dzc3HSeKxSKB+6/fBqYqKgoyOVynUf5wJQ7p2Eov26pqKgIKpVK51q6O1U2Ern851Ze982bN5GdnQ1bW9sK+05NTZX2W37dW8OGDe95HPej737u9Z7b2NhU+NlWJj09HV5eXjpfVHfLyMiAjY2NdD1YOZlMBpVKJdXQpEkT/P7773B3d8frr7+OJk2aoEmTJpVep6UvGxsbREREYMuWLdL1WatXr4anpyf69esntVu6dCmmTZuGrVu3okePHnB1dcXgwYNx8eJFvfbz0Ucf4fDhwzh27BgSExNx5coVDB482KBaExISoFAo4OrqatDr7qbvZ+Luz1lGRgbKysrw+eefV/idefLJJwH8+7mYMWMGPv74Yxw4cAADBgyAm5sbevXqhSNHjhhcj76/H5XJyMi47+fuQe4+TkMehig/hnv9bdNqtcjKypL+BlZ2TI8y0wHpj6NfqcrY29vjhRdewDfffIOUlBR89913cHJywnPPPSe1+eGHH9C9e3csX75c57W5ubkG76/8j29lFxnfvWzjxo2Qy+X49ddfYWdnJy3funWrwfst5+LiAisrK6SkpFRYVz74oV69eg+9/XLl25gxYwaGDh1aaZuAgADp3ykpKXj99dfRrl07nD59GlFRUdIF9neqbM7A8p9b+c+2fEBHdHR0pft1cnICAOkLLjk5Gd7e3voemkTf/dz5njdo0EBaX1ZWdt8v03L169fH3r17odVq7xns3NzcUFZWhvT0dJ0vbiEEUlNTpYu7AaBr167o2rUrNBoNjhw5gs8//xyRkZHw8PDA888//+ADr8To0aOxaNEibNy4EcOHD8e2bdsQGRkJa2trqY2joyPmzJmDOXPm4ObNm1Kv3VNPPYVz5849cB9+fn4ICgp6qPoA4Pr16zh69ChCQ0P16iE1hrsvundxcZF6xe/VQ+zr6wvgdliePHkyJk+ejOzsbPz+++94++230a9fPyQlJcHBwUHvOgz5/ajstZUN6tF3oMThw4f1rvNRlH/O7vW3zcrKCi4uLhBCQCaT3fdvCVUt9tRRlRozZgw0Gg0WLVqE7du34/nnn9f5gymTyaT/8y138uTJSkdUPUhAQAA8PT2xYcMGnVNBCQkJOiMZy/drY2Oj88VYWFiItWvXVtiuQqHQq+fO0dERwcHB+Pnnn3Xaa7Va/PDDD2jYsCGaNWtm8HHdLSAgAP7+/jhx4gSCgoIqfZSHHo1GgxdeeAEymQy//fYbFixYgM8//xw///xzhe3m5uZKp8rLrV+/HlZWVujWrRsAICwsDBkZGdBoNJXutzxM9u3bF9bW1hXC+t3u9bPVdz/lE7muW7dO5/X//e9/9TrFNGDAABQVFd13ktdevXoBuP0/IHfavHkz8vPzpfV3sra2RnBwsDTq8tixY9LxAob1BAcGBiI4OBirVq3C+vXrUVxcjNGjR9+zvYeHB0aNGoUXXngB58+fR0FBgd77ehiFhYV4+eWXUVZWhqlTp9637cMcv74cHBzQo0cPHD9+HG3atKn096ay3tu6devi2Wefxeuvv47MzExcu3bNoP0+zO9HuR49etzzc6ePe33+9XkYIiAgAA0aNMD69et1/rbm5+dj8+bN0ohYR0dHBAUFYevWrSgpKZHa5eXl4ddff33gfqry96O2YE8dVamgoCC0adMGS5YsgRCiwtx0YWFheP/99zFr1iyEhobi/PnzmDt3Lnx9fQ2+7sPKygrvv/8+Xn75ZQwZMgRjx45FdnY2Zs+eXeF0xsCBA7F48WKEh4fjlVdeQUZGBj7++OMKARMAWrdujY0bN2LTpk3w8/ODnZ1dpdekAcCCBQvQp08f9OjRA1FRUbC1tcWXX36JU6dOYcOGDRV6Fx7WV199hQEDBqBfv34YNWoUGjRogMzMTJw9exbHjh3Djz/+CACYNWsW/vrrL8TExEClUmHKlCnYs2cPxowZg/bt20s9F8Dt/xt/7bXXkJiYiGbNmmH79u345ptv8Nprr6FRo0YAgOeffx7r1q3Dk08+iUmTJuHxxx+HXC5HcnIydu3ahaeffhpDhgxB48aN8fbbb+P9999HYWGhNCXEmTNncOvWLcyZM0f62f78889Yvnw5OnbsCCsrKwQFBem9n8DAQPznP//BkiVLIJfL0bt3b5w6dQoff/wxnJ2dH/hzfOGFF7Bq1Sq8+uqrOH/+PHr06AGtVouDBw8iMDAQzz//PPr06YN+/fph2rRpyMnJQZcuXXDy5EnMmjUL7du3l05nr1ixAn/88QcGDhyIRo0aoaioCN999x0AoHfv3gBu9zD6+Pjgl19+Qa9eveDq6op69eo98G4nL730EsaNG4cbN24gJCREpycWAIKDgxEWFoY2bdrAxcUFZ8+exdq1a6UvW2NJTEzEgQMHoNVqoVarcfz4cXz33XdISEjAJ598Il3ScC8Pe/z6+uyzz/DEE0+ga9eueO2119C4cWPk5ubi0qVL+N///idd//bUU0+hVatWCAoKQv369ZGQkIAlS5bAx8dH53pffej7+1GZF198EZ9++ilefPFFfPDBB/D398f27duxY8eOR/o5GJuVlRUWLlyIESNGICwsDOPGjUNxcTEWLVqE7OxsfPjhh1LbuXPnYuDAgejXrx8mTZok/U99nTp1kJmZed/9NGnSBPb29li3bh0CAwNRp04deHl5SZevkB5MNkSDao3PPvtMABAtWrSosK64uFhERUWJBg0aCDs7O9GhQwexdetWMXLkyAqjIqHHlCZCCPHtt98Kf39/YWtrK5o1aya+++67Srf33XffiYCAAKFQKISfn59YsGCBWLlypQAgrl69KrW7du2a6Nu3r3BychIApO1UNvpVCCH++usv0bNnT+Ho6Cjs7e1Fp06dxP/+9z+dNuWjXw8fPqyz/F7HVJkTJ06IYcOGCXd3dyGXy4VKpRI9e/YUK1asEEIIERMTI6ysrCqMNMzIyBCNGjUSjz32mDRCLTQ0VLRs2VLs3r1bBAUFCYVCITw9PcXbb79dYYRtaWmp+Pjjj0Xbtm2FnZ2dqFOnjmjevLkYN26cuHjxok7b77//Xjz22GNSu/bt2+v8vDIzM8Wzzz4r6tatK2Qymc7oOH33U1xcLKZMmSLc3d2FnZ2d6NSpk4iLi6swsu5eCgsLxXvvvSf9zri5uYmePXuK/fv367SZNm2a8PHxEXK5XHh6eorXXntNZGVlSW3i4uLEkCFDhI+Pj1AoFMLNzU2EhoaKbdu26ezv999/F+3btxcKhUKvEbpC3J7uwd7e/p4jdadPny6CgoKEi4uL9Pv85ptvSlOe3Mu9pjS5W/nvevnD2tpauLi4iI4dO4rIyEhx+vTpBx5DuXsdf/lo0/T0dJ325Z+VOz+TuGuqnbtrfemll0SDBg2EXC4X9evXFyEhIWLevHlSm08++USEhISIevXqCVtbW9GoUSMxZswYce3aNamNIfXo8/shRMXRr0IIkZycLJ555hlRp04d4eTkJJ555hmxf/9+sxr9Wm7r1q0iODhY2NnZCUdHR9GrVy+xb9++Cq/fsmWLaN26tfSz/fDDD8XEiROFi4uLTrvKPqMbNmwQzZs3F3K53KCR4nSbTAgjDVkiohqre/fuuHXrFk6dOmXqUojIwpSWlqJdu3Zo0KABYmJiTF2ORePpVyIiIjKaMWPGoE+fPvD09ERqaipWrFiBs2fPPtJIcNIPQx0REREZTW5uLqKiopCeng65XI4OHTpg+/bt0rWlVHV4+pWIiIjIAnBKEyIiIiILwFBHREREZAEY6oiIiIgsAAdKGJFWq8WNGzfg5ORktElmiYiIqHYTQiA3N/eB96pmqDOiGzduPNR9LomIiIgeJCkpCQ0bNrzneoY6Iyq/32ZSUpJetygiIiIiepCcnBx4e3tLOeNeGOqMqPyUq7OzM0MdERERGdWDLu3iQAkiIiIiC8BQR0RERGQBGOqIiIiILABDHREREZEFYKgjIiIisgAMdUREREQWgKGOiIiIyAIw1BERERFZAIY6IiIiIgvAUEdERERkARjqiIiIiCwAQx0RERGRBWCoIyIiIrIANqYugIjI3OQVlyE9t9jUZRBRDeJoaw13ZzuT1sBQR0T0j7ziMnz95xV88+cVFJZqTF0OEdUgA1t74osRHUxaA0MdEdV6pRotNh5KxGc7L+JWXgmA2//XbWUlM3FlRFRT2MmtTV0CQx0R3Z8QArsvpCPucgaEEKYu556sZDLYWMsgt7b65yGDlUwGmez+waxUo8Wmw0m4eisfAOBbzxFT+wWgfyvVA19LRGROGOqI6J6OXMvER9HncPhalqlLqXL16thiUu9meP4xb8itOYaMiGoehjoiquB8ai4W7TiH38+mAQAUNlYY0r4BlA5yE1d2b1qtQKlGoFSjRdk//9Xo2bMYoHLCi50bo46CfxKJqObiXzAiC5OUWYDFsRew8+xNCAFYWclgbXX7VKSVDNDnjGJabjGEAKytZBgW1BCTejWDSmnaUV1ERHR/DHVEFiIrvwTLdl3C2rgElGi0j7y9J1urMKVvAJrUr2OE6oiIqKox1BFVs8vpefjt7xTIZDI42FrDwdYa9rY2sJdbw8ZKBiur2z1q1v9c5K9Pz9qxxCws330ZuUVlAIAuTd0wqVcz1HdSQKMV0Aoh/VcfdR1s0aCu/aMcJhERVTOGOqJqkpZbhCW/X8Smw0nQaKtmFGmgpzOmD2iObv71OHKTiKiWYagjqmLlE9p++9cVFJTcntC2W7P6UDkrUFCiQWGJBvklZSgs1UKr/bdHrbx3TR91FDYYGdIYg9s14NxqRES1FEMdkZEcupqJj2POI++fU6DlbqgLkV1QCgBo510Xbz8ZiMd9XU1RIhERWTCGOiIjOJmcjdGrDiG/pPJbS3FCWyIiqmoMdUSP6HJ6HkatOoz8Eg1Cmrjh1dAmOusVNlbo4OPCCW2JiKhKMdQRPYIUdSEivj2IzPwStGmoxNcvBnECWyIiMgl2HRA9pKz8EkSsPIQb6iL41XfEqlGPMdAREZHJMNQRPQR1YSlGrz6MS2l5UDnbYe2YYLjVUZi6LCIiqsXYrUBkgOIyDX44kIhlf1xEVkEp6jrIsXbM45yol4iITI6hjkgPWq3A/07ewMcx55GUWQgAaFLfEZ8Obwd/DycTV0dERMRQR/RAey/ewkfR5/D3dTUAwN1JgTf7NMNzHRvChiNaiYjITDDUEd3DyeRsfBR9DvsuZQC4fdeGV0P98NITvnCw5UeHiIjMC7+ZiO5yOT0Pn8Scx/a/UwEAttZWGNGpEd7o0ZSDIYiIyGwx1BH943J6Hr7YdQm/xN+ARisgkwFD2jfAm72bwdvVwdTlERER3RdDHdV6F27m4vM/LuHXkzcgxO1lvQPd8Va/5ghQcRAEERHVDAx1VCtk5BXj45jzyC0qg7WVDNYyGaysZMjIK8au8+lSu96BHpjQsynaetc1XbFEREQPgaGOaoWZv5ySrpGrzIBWKrzRsylaeimrsSoiIiLjYagji/f7mZvY/ncqrK1kmNK3GWytraAVAhotYCUDejR3RzPONUdERDWcSSfZ+vPPP/HUU0/By8sLMpkMW7du1Vn/888/o1+/fqhXrx5kMhni4+MrbKO4uBgTJkxAvXr14OjoiEGDBiE5OVmnTVZWFiIiIqBUKqFUKhEREYHs7GydNomJiXjqqafg6OiIevXqYeLEiSgpKTHyEVN1yy8uw3u/nAIAvNzVF+O7N8XLXf3wSrcmeK17E4wLbcJAR0REFsGkoS4/Px9t27bFsmXL7rm+S5cu+PDDD++5jcjISGzZsgUbN27E3r17kZeXh7CwMGg0GqlNeHg44uPjER0djejoaMTHxyMiIkJar9FoMHDgQOTn52Pv3r3YuHEjNm/ejClTphjvYMkkPom5gBvqIni72iOyVzNTl0NERFR1hJkAILZs2VLpuqtXrwoA4vjx4zrLs7OzhVwuFxs3bpSWXb9+XVhZWYno6GghhBBnzpwRAMSBAwekNnFxcQKAOHfunBBCiO3btwsrKytx/fp1qc2GDRuEQqEQarVa72NQq9UCgEGvoapzMilb+E7/VfhM+1XsPp9m6nKIiIgeir75okbf4+jo0aMoLS1F3759pWVeXl5o1aoV9u/fDwCIi4uDUqlEcHCw1KZTp05QKpU6bVq1agUvLy+pTb9+/VBcXIyjR49W09GQMZVptJj+80loBfB0Oy+ENqtv6pKIiIiqVI0eKJGamgpbW1u4uLjoLPfw8EBqaqrUxt3dvcJr3d3dddp4eHjorHdxcYGtra3UpjLFxcUoLi6Wnufk5Dz0sZBxrd5/Dadv5EBpL8fMsBamLoeIiKjK1eieunsRQkAmk0nP7/z3o7S524IFC6TBF0qlEt7e3o9YORnDtVv5+CTmAgDg7Sebox5v7UVERLVAjQ51KpUKJSUlyMrK0lmelpYm9bypVCrcvHmzwmvT09N12tzdI5eVlYXS0tIKPXh3mjFjBtRqtfRISkp61EOiR5SqLkLEdwdRWKpBsK8rhgUxaBMRUe1Qo0Ndx44dIZfLERsbKy1LSUnBqVOnEBISAgDo3Lkz1Go1Dh06JLU5ePAg1Gq1TptTp04hJSVFahMTEwOFQoGOHTvec/8KhQLOzs46DzKdzPwSRKw8iKTMQvi4OeDz8Pb37WklIiKyJCa9pi4vLw+XLl2Snl+9ehXx8fFwdXVFo0aNkJmZicTERNy4cQMAcP78eQC3e9ZUKhWUSiXGjBmDKVOmwM3NDa6uroiKikLr1q3Ru3dvAEBgYCD69++PsWPH4quvvgIAvPLKKwgLC0NAQAAAoG/fvmjRogUiIiKwaNEiZGZmIioqCmPHjmVQqyFyi0ox8rtDuJiWB5WzHX4YEwx3JztTl0VERFR9qmMo7r3s2rVLAKjwGDlypBBCiFWrVlW6ftasWdI2CgsLxRtvvCFcXV2Fvb29CAsLE4mJiTr7ycjIECNGjBBOTk7CyclJjBgxQmRlZem0SUhIEAMHDhT29vbC1dVVvPHGG6KoqMig4+GUJqZRWFImnluxX/hM+1W0nxsjLt7MMXVJRERERqNvvpAJIYRp4qTlycnJgVKphFqtZg9fFcgpKsU3f15BRn4JFDZWsJNbQ2FjhUNXM7H/cgacFDbY8EontGrA+7cSEZHl0Ddf1OgpTaj2yC4oQcTKQ/j7urrS9QobK6wc9RgDHRER1VoMdWT2buUV4z/fHsS51Fy4OtoiopMPSjVaFJVqUVymgVYAzwU1RIdGLg/eGBERkYViqCOzlpZThPBvD+JSWh7qOymw/uVg+Hs4mbosIiIis8NQR2brRnYhwr85gGsZBfBU2mHdy8Hwq1/H1GURERGZJYY6MktJmQV44ZsDSM4qREMXe2wY2wnerg6mLouIiMhsMdSR2UnIyMcLXx/ADXURGrs5YN3YTmhQ197UZREREZk1hjoyK5fT8xD+zQHczClGk/qOWD+2EzycOYkwERHRgzDUkdm4eDMX4d8eRHpuMZp51MG6lzuhvpPC1GURERHVCAx1ZBbOpeZgxDcHkZFfguYqJ6x7ORhudRjoiIiI9MVQRyaXmFGAF74+gKyCUrRq4Iy1LwXDxdHW1GURERHVKAx1ZFIarUDUjyeQVVCK1g2U+GFMMJQOclOXRUREVONYmboAqt1W7buKQ9cy4WhrjS9HdGCgIyIiekgMdWQyF2/mYuGO8wCAmWEtOA8dERHRI2CoI5Mo1Wgx5ccTKCnTontAfQx/zNvUJREREdVoDHVkEst3X8bJZDWU9nJ89EwbyGQyU5dERERUozHUUbU7dV2NpTsvAgDmPt2SkwsTEREZAUMdVavcolJM+e8JlGkFBrRSYVBbL1OXREREZBE4pQlVm0tpeRi39ggup+ejXh1bzBvciqddiYiIjIShjqrFjtOpmPLfE8grLoOn0g5fRXTkHSOIiIiMiKGOqpRGK/Bp7AUs23UJABDs64ovRnRAPQY6IiIio2KooypTUqbFqz8cxR/n0gAAL3XxxYwnm0NuzUs5iYiIjI2hjqrM1uPX8ce5NNjJrfDh0DYY3L6BqUsiIiKyWOwyoSohhMB3+64CAN7s3YyBjoiIqIox1FGVOHg1E+dSc2Evt8bzjzUydTlEREQWj6GOqsSqf3rphnRoAKWD3MTVEBERWT6GOjK6pMwCxJ65CQAYHdLYtMUQERHVEgx1ZHRrDyRAK4AnmtaDv4eTqcshIiKqFRjqyKgKSsqw8VAiAGB0l8amLYaIiKgWYagjo/r52HXkFJXBx80BPQLcTV0OERFRrcFQR0YjhMDq/dcAACM7N4aVFe/rSkREVF0Y6sho9l66hUtpeXC0tcazQQ1NXQ4REVGtwlBHRrN63zUAwHNB3nC24zQmRERE1cngUDd37lwUFBRUWF5YWIi5c+capSiqeZKzCvDH+dv3eH2xs4+JqyEiIqp9DA51c+bMQV5eXoXlBQUFmDNnjlGKoppn/+UMCAF09HGBX/06pi6HiIio1jE41AkhIJNVvAD+xIkTcHV1NUpRVPMcuZYJAHjcl78DREREpmCjb0MXFxfIZDLIZDI0a9ZMJ9hpNBrk5eXh1VdfrZIiyfwduZYFAHissYuJKyEiIqqd9A51S5YsgRACL730EubMmQOlUimts7W1RePGjdG5c+cqKZLM2628Yly5lQ8A6NiIPXVERESmoHeoGzlyJADA19cXXbp0gY2N3i8lC1feSxfg4QSlA0e9EhERmYLB19Q5OTnh7Nmz0vNffvkFgwcPxttvv42SkhKjFkc1Q/n1dB156pWIiMhkDA5148aNw4ULFwAAV65cwfDhw+Hg4IAff/wRU6dONXqBZP4OJ/B6OiIiIlMzONRduHAB7dq1AwD8+OOPCA0Nxfr167F69Wps3rzZ2PWRmSss0eD0dTUAIMiH19MRERGZykNNaaLVagEAv//+O5588kkAgLe3N27dumXc6sjsxSdlo0wroHK2Q0MXe1OXQ0REVGsZHOqCgoIwb948rF27Fnv27MHAgQMBAFevXoWHh4fRCyTzVn49XVBjl0rnLyQiIqLqYXCoW7JkCY4dO4Y33ngD77zzDpo2bQoA+OmnnxASEmLQtv7880889dRT8PLygkwmw9atW3XWCyEwe/ZseHl5wd7eHt27d8fp06d12hQXF2PChAmoV68eHB0dMWjQICQnJ+u0ycrKQkREBJRKJZRKJSIiIpCdna3TJjExEU899RQcHR1Rr149TJw4kQM/9PDv9XQ89UpERGRKBoe6Nm3a4O+//4ZarcasWbOk5YsWLcKaNWsM2lZ+fj7atm2LZcuWVbp+4cKFWLx4MZYtW4bDhw9DpVKhT58+yM3NldpERkZiy5Yt2LhxI/bu3Yu8vDyEhYVBo9FIbcLDwxEfH4/o6GhER0cjPj4eERER0nqNRoOBAwciPz8fe/fuxcaNG7F582ZMmTLFoOOpbTRagWP/hLogDpIgIiIyLfGQjhw5ItauXSt++OEHcfTo0YfdjASA2LJli/Rcq9UKlUolPvzwQ2lZUVGRUCqVYsWKFUIIIbKzs4VcLhcbN26U2ly/fl1YWVmJ6OhoIYQQZ86cEQDEgQMHpDZxcXECgDh37pwQQojt27cLKysrcf36danNhg0bhEKhEGq1Wu9jUKvVAoBBr6nJTl3PFj7TfhUt34sWZRqtqcshIiKySPrmC4N76tLS0tCjRw889thjmDhxIt544w0EBQWhV69eSE9PN1rYvHr1KlJTU9G3b19pmUKhQGhoKPbv3w8AOHr0KEpLS3XaeHl5oVWrVlKbuLg4KJVKBAcHS206deoEpVKp06ZVq1bw8vKS2vTr1w/FxcU4evSo0Y7J0pRPOtzBxwXWVryejoiIyJQMDnUTJkxAbm4uTp8+jczMTGRlZeHUqVPIycnBxIkTjVZYamoqAFQYfOHh4SGtS01Nha2tLVxcXO7bxt3dvcL23d3dddrcvR8XFxfY2tpKbSpTXFyMnJwcnUdtcrh8kIQPT70SERGZmsGhLjo6GsuXL0dgYKC0rEWLFvjiiy/w22+/GbU4ABVGVAohHjjK8u42lbV/mDZ3W7BggTT4QqlUwtvb+751WRIhxL+hjtfTERERmZzBoU6r1UIur3h/T7lcLs1fZwwqlQoAKvSUpaWlSb1qKpUKJSUlyMrKum+bmzdvVth+enq6Tpu795OVlYXS0tL7TtMyY8YMqNVq6ZGUlGTgUdZcyVmFuJlTDBsrGdp51zV1OURERLWewaGuZ8+emDRpEm7cuCEtu379Ot5880306tXLaIX5+vpCpVIhNjZWWlZSUoI9e/ZIU6d07NgRcrlcp01KSgpOnToltencuTPUajUOHToktTl48CDUarVOm1OnTiElJUVqExMTA4VCgY4dO96zRoVCAWdnZ51HbXEk4XYvXcsGSjjY2pi4GiIiIjL423jZsmV4+umn0bhxY3h7e0MmkyExMRGtW7fGDz/8YNC28vLycOnSJen51atXER8fD1dXVzRq1AiRkZGYP38+/P394e/vj/nz58PBwQHh4eEAAKVSiTFjxmDKlClwc3ODq6sroqKi0Lp1a/Tu3RsAEBgYiP79+2Ps2LH46quvAACvvPIKwsLCEBAQAADo27cvWrRogYiICCxatAiZmZmIiorC2LFja1VQM0T5IInHeD0dERGRWTA41Hl7e+PYsWOIjY3FuXPnIIRAixYtpBBliCNHjqBHjx7S88mTJwMARo4cidWrV2Pq1KkoLCzE+PHjkZWVheDgYMTExMDJyUl6zaeffgobGxsMGzYMhYWF6NWrF1avXg1ra2upzbp16zBx4kRplOygQYN05saztrbG//3f/2H8+PHo0qUL7O3tER4ejo8//tjgY6otykNdECcdJiIiMgsyIYQwdRGWIicnB0qlEmq12qJ7+NQFpWg7NwYAcOTd3qhXR2HiioiIiCyXvvnC4GvqJk6ciKVLl1ZYvmzZMkRGRhq6OaqBzt+8fUePhi72DHRERERmwuBQt3nzZnTp0qXC8pCQEPz0009GKYrMW2JmAQDAx83BxJUQERFROYNDXUZGBpRKZYXlzs7OuHXrllGKIvOW9E+oa+TKUEdERGQuDA51TZs2RXR0dIXlv/32G/z8/IxSFJm38lDnzVBHRERkNgwe/Tp58mS88cYbSE9PR8+ePQEAO3fuxCeffIIlS5YYuz4yQ4nsqSMiIjI7Boe6l156CcXFxfjggw/w/vvvAwAaN26M5cuX48UXXzR6gWR+GOqIiIjMz0PdCuC1117Da6+9hvT0dNjb26NOnTrGrovMVFGpBmm5xQAAbxeGOiIiInPxSPd3ql+/vrHqoBoiOet2L52TwgZ1HSreA5iIiIhMw+CBElS7Jd4xSEImk5m4GiIiIirHUEcGSczg9XRERETmiKGODJKYWQgAaMSJh4mIiMwKQx0ZJJFz1BEREZmlhxoosXPnTuzcuRNpaWnQarU667777jujFEbmqXyghLeLvYkrISIiojsZHOrmzJmDuXPnIigoCJ6enrxYvhYRQnCOOiIiIjNlcKhbsWIFVq9ejYiIiKqoh8xYRn4JCko0kMmABuypIyIiMisGX1NXUlKCkJCQqqiFzFx5L52nsx0UNtYmroaIiIjuZHCoe/nll7F+/fqqqIXMXBIHSRAREZktg0+/FhUV4euvv8bvv/+ONm3aQC7XvavA4sWLjVYcmReGOiIiIvNlcKg7efIk2rVrBwA4deqUzjoOmrBsHCRBRERkvgwOdbt27aqKOqgGYKgjIiIyX480+XBycjKuX79urFrIzCX9czcJnn4lIiIyPwaHOq1Wi7lz50KpVMLHxweNGjVC3bp18f7771eYiJgsR0mZFjfU/9wijKGOiIjI7Bh8+vWdd97BypUr8eGHH6JLly4QQmDfvn2YPXs2ioqK8MEHH1RFnWRi17MLIQRgL7dGvTq2pi6HiIiI7mJwqFuzZg2+/fZbDBo0SFrWtm1bNGjQAOPHj2eos1D/jny154AYIiIiM2Tw6dfMzEw0b968wvLmzZsjMzPTKEWR+eEgCSIiIvNmcKhr27Ytli1bVmH5smXL0LZtW6MUReaHc9QRERGZN4NPvy5cuBADBw7E77//js6dO0Mmk2H//v1ISkrC9u3bq6JGMgPsqSMiIjJvBvfUhYaG4sKFCxgyZAiys7ORmZmJoUOH4vz58+jatWtV1EhmgKGOiIjIvBncUwcAXl5eHBBRy/D0KxERkXnTK9SdPHkSrVq1gpWVFU6ePHnftm3atDFKYWQ+1AWlyCkqAwB4uzDUERERmSO9Ql27du2QmpoKd3d3tGvXDjKZDEKICu1kMhk0Go3RiyTTKj/1Wt9JAXtbaxNXQ0RERJXRK9RdvXoV9evXl/5NtQuvpyMiIjJ/eoU6Hx8f6d8JCQkICQmBjY3uS8vKyrB//36dtmQZGOqIiIjMn8GjX3v06FHpJMNqtRo9evQwSlFkXpKyOEiCiIjI3Bkc6oQQld4mKiMjA46OjkYpisyLNPLVxd7ElRAREdG96D2lydChQwHcHgwxatQoKBQKaZ1Go8HJkycREhJi/ArJ5Hj6lYiIyPzpHeqUSiWA2z11Tk5OsLf/t9fG1tYWnTp1wtixY41fIZlUmUaL61mFAIBGbgx1RERE5krvULdq1SoAQOPGjREVFcVTrbVEiroIZVoBW2sreDjZmbocIiIiugeD7ygxa9asqqiDzNSJ5GwAQDNVHVhZVbyWkoiIiMzDQ90m7KeffsJ///tfJCYmoqSkRGfdsWPHjFIYmYdjCdkAgA6NXExbCBEREd2XwaNfly5ditGjR8Pd3R3Hjx/H448/Djc3N1y5cgUDBgyoihrJhI4lZgFgqCMiIjJ3Boe6L7/8El9//TWWLVsGW1tbTJ06FbGxsZg4cSLUanVV1EgmUlSqwekbt9/Tjj4MdURERObM4FCXmJgoTV1ib2+P3NxcAEBERAQ2bNhg3OrIpE5dV6NUI1CvjgINOUcdERGRWTM41KlUKmRkZAC4ffuwAwcOALh9T1ghhHGrA5Cbm4vIyEj4+PjA3t4eISEhOHz4sLReCIHZs2fDy8sL9vb26N69O06fPq2zjeLiYkyYMAH16tWDo6MjBg0ahOTkZJ02WVlZiIiIgFKphFKpREREBLKzs41+PDXJv6de61Y64TQRERGZD4NDXc+ePfG///0PADBmzBi8+eab6NOnD4YPH44hQ4YYvcCXX34ZsbGxWLt2Lf7++2/07dsXvXv3xvXr1wEACxcuxOLFi7Fs2TIcPnwYKpUKffr0kXoQASAyMhJbtmzBxo0bsXfvXuTl5SEsLAwajUZqEx4ejvj4eERHRyM6Ohrx8fGIiIgw+vHUJEcTboc6nnolIiKqAYSBNBqNKC0tlZ5v2rRJTJgwQXz22WeiuLjY0M3dV0FBgbC2tha//vqrzvK2bduKd955R2i1WqFSqcSHH34orSsqKhJKpVKsWLFCCCFEdna2kMvlYuPGjVKb69evCysrKxEdHS2EEOLMmTMCgDhw4IDUJi4uTgAQ586d07tetVotAAi1Wv1Qx2tOtFqtCJoXK3ym/SoOXc0wdTlERES1lr75wuCeOisrK9jY/DsTyrBhw7B06VJMnDgRtra2RgubAFBWVgaNRgM7O91Jb+3t7bF3715cvXoVqamp6Nu3r7ROoVAgNDQU+/fvBwAcPXoUpaWlOm28vLzQqlUrqU1cXByUSiWCg4OlNp06dYJSqZTa1DbJWYVIzy2GjZUMrRsoTV0OERERPYDBoW7VqlX48ccfKyz/8ccfsWbNGqMUVc7JyQmdO3fG+++/jxs3bkCj0eCHH37AwYMHkZKSgtTUVACAh4eHzus8PDykdampqbC1tYWLi8t927i7u1fYv7u7u9SmMsXFxcjJydF5WIry6+laejnDTm5t4mqIiIjoQQwOdR9++CHq1atXYbm7uzvmz59vlKLutHbtWggh0KBBAygUCixduhTh4eGwtv43aNx9Eb8Q4oEX9t/dprL2D9rOggULpIEVSqUS3t7e+h6W2Tv2z/V0HXg9HRERUY1gcKhLSEiAr69vheU+Pj5ITEw0SlF3atKkCfbs2YO8vDwkJSXh0KFDKC0tha+vL1QqFQBU6E1LS0uTeu9UKhVKSkqQlZV13zY3b96ssO/09PQKvYB3mjFjBtRqtfRISkp6pGM1J8cSswFw0mEiIqKawuBQ5+7ujpMnT1ZYfuLECbi5uRmlqMo4OjrC09MTWVlZ2LFjB55++mkp2MXGxkrtSkpKsGfPHmkuvY4dO0Iul+u0SUlJwalTp6Q2nTt3hlqtxqFDh6Q2Bw8ehFqtltpURqFQwNnZWedhCQpKynAm5fapZPbUERER1QwG3/v1+eefx8SJE+Hk5IRu3boBAPbs2YNJkybh+eefN3qBO3bsgBACAQEBuHTpEt566y0EBARg9OjRkMlkiIyMxPz58+Hv7w9/f3/Mnz8fDg4OCA8PBwAolUqMGTMGU6ZMgZubG1xdXREVFYXWrVujd+/eAIDAwED0798fY8eOxVdffQUAeOWVVxAWFoaAgACjH5O5O5mshkYroHK2g5fS7sEvICIiIpMzONTNmzcPCQkJ6NWrlzQKVqvV4sUXX6ySa+rUajVmzJiB5ORkuLq64plnnsEHH3wAuVwOAJg6dSoKCwsxfvx4ZGVlITg4GDExMXBycpK28emnn8LGxgbDhg1DYWEhevXqhdWrV+tcl7du3TpMnDhRGiU7aNAgLFu2zOjHUxNIkw77cNJhIiKimkImxMPdBuLChQs4ceIE7O3t0bp1a/j4+Bi7thonJycHSqUSarW6Rp+KfXnNEfx+9ibeHRiIl7v6mbocIiKiWk3ffGFwT125Zs2aoVmzZg/7cjJTQog7eup4PR0REVFNoVeomzx5Mt5//304Ojpi8uTJ9227ePFioxRGppGQUYDM/BLYWluhpVfN7W0kIiKqbfQKdcePH0dpaSkA4NixY/e8zorXX9V85b10rRo4Q2HDSYeJiIhqCr1C3WeffSadw929e3dV1kMmdrR80mHOT0dERFSj6DVPXfv27XHr1i0AgJ+fHzIyMqq0KDKd8kmHO/J6OiIiohpFr1BXt25dXL16FQBw7do1aLXaKi2KTCO/uAznUznpMBERUU2k1+nXZ555BqGhofD09IRMJkNQUJDOHG93unLlilELpOpzKS0PWgHUd1LAw5mTDhMREdUkeoW6r7/+GkOHDsWlS5cwceJEjB07VmdyX7IMCZkFAABfN0cTV0JERESG0nueuv79+wMAjh49ikmTJjHUWaCEW/kAgEZuDiauhIiIiAxl8OTDq1atqoo6yAxcy7jdU9eYoY6IiKjG0SvUDR06FKtXr4azszOGDh1637Y///yzUQqj6peYWd5Tx9OvRERENY1eoU6pVEoTCyuVyiotiEyHPXVEREQ1l16h7s5Trjz9apkKSsqQnlsMAPBxZU8dERFRTaPXPHV3KiwsREFBgfQ8ISEBS5YsQUxMjFELo+qV8E8vXV0HOZQOchNXQ0RERIYyONQ9/fTT+P777wEA2dnZePzxx/HJJ5/g6aefxvLly41eIFWPhIzb19P58Ho6IiKiGsngUHfs2DF07doVAPDTTz9BpVIhISEB33//PZYuXWr0Aql6lPfU+bjyejoiIqKayOBQV1BQIM1RFxMTg6FDh8LKygqdOnVCQkKC0Quk6sFBEkRERDWbwaGuadOm2Lp1K5KSkrBjxw707dsXAJCWlgZnZ2ejF0jVo3w6E55+JSIiqpkMDnXvvfceoqKi0LhxYwQHB6Nz584AbvfatW/f3ugFUvW4duuf06/sqSMiIqqRDL6jxLPPPosnnngCKSkpaNu2rbS8V69eGDJkiFGLo+pRXKZBiroQAHvqiIiIaiqDQx0AqFQqqFQqAEBOTg7++OMPBAQEoHnz5kYtjqpHclYhtAJwsLVGvTq2pi6HiIiIHoLBp1+HDRuGZcuWAbg9Z11QUBCGDRuGNm3aYPPmzUYvkKrendOZlN85hIiIiGoWg0Pdn3/+KU1psmXLFgghkJ2djaVLl2LevHlGL5CqHqczISIiqvkMDnVqtRqurq4AgOjoaDzzzDNwcHDAwIEDcfHiRaMXSFVPCnX1GOqIiIhqKoNDnbe3N+Li4pCfn4/o6GhpSpOsrCzY2dkZvUCqeuWnXxtzkAQREVGNZfBAicjISIwYMQJ16tSBj48PunfvDuD2adnWrVsbuz6qBjz9SkREVPMZHOrGjx+P4OBgJCYmok+fPrCyut3Z5+fnx2vqaiCNViApq/z0K3vqiIiIaqqHmtKkY8eO6Nixo86ygQMHGqUgql43sgtRqhGwtbaCypmnz4mIiGqqhwp1ycnJ2LZtGxITE1FSUqKzbvHixUYpjKpH+alXb1d7WFtxOhMiIqKayuBQt3PnTgwaNAi+vr44f/48WrVqhWvXrkEIgQ4dOlRFjVSFEjI5SIKIiMgSGDz6dcaMGZgyZQpOnToFOzs7bN68GUlJSQgNDcVzzz1XFTVSFSrvqWvEe74SERHVaAaHurNnz2LkyJEAABsbGxQWFqJOnTqYO3cuPvroI6MXSFXr2i321BEREVkCg0Odo6MjiouLAQBeXl64fPmytO7WrVvGq4yqRWIme+qIiIgsgcHX1HXq1An79u1DixYtMHDgQEyZMgV///03fv75Z3Tq1KkqaqQqIoSQTr+yp46IiKhmMzjULV68GHl5eQCA2bNnIy8vD5s2bULTpk3x6aefGr1AqjrpucUoLNXASgY0qGtv6nKIiIjoERgc6vz8/KR/Ozg44MsvvzRqQVR9rv3TS9fAxR62NgafiSciIiIzwm/yWuwa7/lKRERkMfTqqXNxcYFMpt/EtJmZmY9UEFWfxPLpTHjPVyIiohpPr1C3ZMmSKi6DTIE9dURERJZDr1BXPi8dWRZOZ0JERGQ5DL6mbvv27dixY0eF5TExMfjtt9+MUhRVPSEErnLiYSIiIothcKibPn06NBpNheVarRbTp083SlFU9dSFpcgtKgPAa+qIiIgsgcGh7uLFi2jRokWF5c2bN8elS5eMUhRVvYz8EgCAk50N7G2tTVwNERERPSqDQ51SqcSVK1cqLL906RIcHXkar6ZQF5YCAJT2chNXQkRERMZgcKgbNGgQIiMjde75eunSJUyZMgWDBg0yanFlZWV499134evrC3t7e/j5+WHu3LnQarVSGyEEZs+eDS8vL9jb26N79+44ffq0znaKi4sxYcIE1KtXD46Ojhg0aBCSk5N12mRlZSEiIgJKpRJKpRIRERHIzs426vGYk5x/Qp2zHUMdERGRJTA41C1atAiOjo5o3rw5fH194evri8DAQLi5ueHjjz82anEfffQRVqxYgWXLluHs2bNYuHAhFi1ahM8//1xqs3DhQixevBjLli3D4cOHoVKp0KdPH+Tm5kptIiMjsWXLFmzcuBF79+5FXl4ewsLCdK4NDA8PR3x8PKKjoxEdHY34+HhEREQY9XjMCXvqiIiILItMCCEMfZEQArGxsThx4gTs7e3Rpk0bdOvWzejFhYWFwcPDAytXrpSWPfPMM3BwcMDatWshhICXlxciIyMxbdo0ALd75Tw8PPDRRx9h3LhxUKvVqF+/PtauXYvhw4cDAG7cuAFvb29s374d/fr1w9mzZ9GiRQscOHAAwcHBAIADBw6gc+fOOHfuHAICAvSqNycnB0qlEmq1Gs7Ozkb+aRjX2gMJmLn1FPq19MBXEUGmLoeIiIjuQd988VC3CZPJZOjbty/eeustvPHGG2jTps1DF3o/TzzxBHbu3IkLFy4AAE6cOIG9e/fiySefBABcvXoVqamp6Nu3r/QahUKB0NBQ7N+/HwBw9OhRlJaW6rTx8vJCq1atpDZxcXFQKpVSoAOATp06QalUSm0qU1xcjJycHJ1HTcHTr0RERJbF4FD30UcfYdOmTdLzYcOGwc3NDQ0aNMCJEyeMWty0adPwwgsvoHnz5pDL5Wjfvj0iIyPxwgsvAABSU1MBAB4eHjqv8/DwkNalpqbC1tYWLi4u923j7u5eYf/u7u5Sm8osWLBAugZPqVTC29v74Q+2muXw9CsREZFFMTjUffXVV1J4iY2NRWxsLH777TcMGDAAb731llGL27RpE3744QesX78ex44dw5o1a/Dxxx9jzZo1Ou3uvi+tEOKB96q9u01l7R+0nRkzZkCtVkuPpKQkfQ7LLOQU/dNTx1BHRERkEfS6TdidUlJSpFD366+/YtiwYejbty8aN26sc/rSGN566y1Mnz4dzz//PACgdevWSEhIwIIFCzBy5EioVCoAt3vaPD09pdelpaVJvXcqlQolJSXIysrS6a1LS0tDSEiI1ObmzZsV9p+enl6hF/BOCoUCCoXi0Q/UBDhQgoiIyLIY3FPn4uIi9UhFR0ejd+/eAG73alV2p4lHUVBQACsr3RKtra2lKU18fX2hUqkQGxsrrS8pKcGePXukwNaxY0fI5XKdNikpKTh16pTUpnPnzlCr1Th06JDU5uDBg1Cr1VIbS5NTePtuEs72Bud6IiIiMkMGf6MPHToU4eHh8Pf3R0ZGBgYMGAAAiI+PR9OmTY1a3FNPPYUPPvgAjRo1QsuWLXH8+HEsXrwYL730EoDbp0wjIyMxf/58+Pv7w9/fH/Pnz4eDgwPCw8MB3J4secyYMZgyZQrc3Nzg6uqKqKgotG7dWgqkgYGB6N+/P8aOHYuvvvoKAPDKK68gLCxM75GvNU356Vf21BEREVkGg0Pdp59+isaNGyMpKQkLFy5EnTp1ANzu/Ro/frxRi/v8888xc+ZMjB8/HmlpafDy8sK4cePw3nvvSW2mTp2KwsJCjB8/HllZWQgODkZMTAycnJx0araxscGwYcNQWFiIXr16YfXq1bC2/vf2WOvWrcPEiROlUbKDBg3CsmXLjHo85kTN0a9EREQW5aHmqaPK1aR56trPjUFWQSli3uyGZh5OD34BERERmYS++UKvnrpt27ZhwIABkMvl2LZt233bGvtWYWR8QgjkFN2+po6nX4mIiCyDXqFu8ODB0lxugwcPvmc7mUxm9MESZHz5JRpotLc7aHn6lYiIyDLoFerKR5ve/W+qmconHra1toKd/KFuKkJERERmht/otZA0SMLe5oGTNBMREVHN8FCTlB06dAi7d+9GWlpahZ67xYsXG6Uwqjq87ysREZHlMTjUzZ8/H++++y4CAgLg4eHxwFttkfn5t6eOoY6IiMhSGBzqPvvsM3z33XcYNWpUFZRD1aF85CtDHRERkeUw+Jo6KysrdOnSpSpqoWqSw/u+EhERWRyDQ92bb76JL774oipqoWry790keN9XIiIiS2Hwt3pUVBQGDhyIJk2aoEWLFpDLdXt7fv75Z6MVR1Wj/L6vPP1KRERkOQwOdRMmTMCuXbvQo0cPuLm5cXBEDaTm6VciIiKLY3Co+/7777F582YMHDiwKuqhapBT+M9ACU5pQkREZDEMvqbO1dUVTZo0qYpaqJqUn35lTx0REZHlMDjUzZ49G7NmzUJBQUFV1EPVIOeOO0oQERGRZTD4W33p0qW4fPkyPDw80Lhx4woDJY4dO2a04qhq8I4SRERElsfgUDd48OAqKIOqEwdKEBERWR6DQ92sWbOqog6qJmUaLfJLNAA4pQkREZElMfiaOqrZym8RBnDyYSIiIkvCUFfLlF9P52hrDRtrvv1ERESWgt/qtQzvJkFERGSZGOpqGQ6SICIiskwMdbUM7yZBRERkmfS6Un7y5Ml6b3Dx4sUPXQxVPXUhT78SERFZIr1C3fHjx3WeHz16FBqNBgEBAQCACxcuwNraGh07djR+hWRU/15Tx5GvRERElkSvb/Zdu3ZJ/168eDGcnJywZs0auLi4AACysrIwevRodO3atWqqJKPh3SSIiIgsk8HX1H3yySdYsGCBFOgAwMXFBfPmzcMnn3xi1OLI+DhQgoiIyDIZHOpycnJw8+bNCsvT0tKQm5trlKKo6pRPPsxr6oiIiCyLwaFuyJAhGD16NH766SckJycjOTkZP/30E8aMGYOhQ4dWRY1kROypIyIiskwGXy2/YsUKREVF4T//+Q9KS28HBBsbG4wZMwaLFi0yeoFkXP9eU8eBEkRERJbE4G92BwcHfPnll1i0aBEuX74MIQSaNm0KR0fHqqiPjIx3lCAiIrJMDz35cEpKClJSUtCsWTM4OjpCCGHMuqiK5PD0KxERkUUyONRlZGSgV69eaNasGZ588kmkpKQAAF5++WVMmTLF6AWS8Qgh/r2jBEMdERGRRTE41L355puQy+VITEyEg4ODtHz48OGIjo42anFkXEWlWpRotADYU0dERGRpDL6mLiYmBjt27EDDhg11lvv7+yMhIcFohZHxlV9PZyUDHG2tTVwNERERGZPBPXX5+fk6PXTlbt26BYVCYZSiqGrk3HHfV5lMZuJqiIiIyJgMDnXdunXD999/Lz2XyWTQarVYtGgRevToYdTiyLg4Rx0REZHlMvj066JFi9C9e3ccOXIEJSUlmDp1Kk6fPo3MzEzs27evKmokI5GmM+F9X4mIiCyOwT11LVq0wMmTJ/H444+jT58+yM/Px9ChQ3H8+HE0adKkKmokI2FPHRERkeUyuKcuMTER3t7emDNnTqXrGjVqZJTCyPj+nc6Ed5MgIiKyNAb31Pn6+iI9Pb3C8oyMDPj6+hqlKKoanHiYiIjIchkc6oQQlY6czMvLg52dnVGKoqqhLuQ1dURERJZK7/NwkydPBnB7tOvMmTN1pjXRaDQ4ePAg2rVrZ/QCyXh431ciIiLLpXeoO378OIDbPXV///03bG1tpXW2trZo27YtoqKijF8hGY26kKGOiIjIUul9+nXXrl3YtWsXRo4cid9++016vmvXLuzYsQNfffUV/P39jV5g48aNIZPJKjxef/11ALdD5uzZs+Hl5QV7e3t0794dp0+f1tlGcXExJkyYgHr16sHR0RGDBg1CcnKyTpusrCxERERAqVRCqVQiIiIC2dnZRj8eU5IGSthxoAQREZGlMfiauiVLlqCsrKzC8szMTOTk5BilqDsdPnwYKSkp0iM2NhYA8NxzzwEAFi5ciMWLF2PZsmU4fPgwVCoV+vTpg9zcXGkbkZGR2LJlCzZu3Ii9e/ciLy8PYWFh0Gg0Upvw8HDEx8cjOjoa0dHRiI+PR0REhNGPx5TKT79yoAQREZEFEgbq37+/+OKLLyosX758uRgwYIChmzPYpEmTRJMmTYRWqxVarVaoVCrx4YcfSuuLioqEUqkUK1asEEIIkZ2dLeRyudi4caPU5vr168LKykpER0cLIYQ4c+aMACAOHDggtYmLixMAxLlz5/SuTa1WCwBCrVY/6mFWiS4f7hQ+034VRxMyTV0KERER6UnffGFwT93BgwcrvR1Y9+7dcfDgwUcOmfdTUlKCH374AS+99BJkMhmuXr2K1NRU9O3bV2qjUCgQGhqK/fv3AwCOHj2K0tJSnTZeXl5o1aqV1CYuLg5KpRLBwcFSm06dOkGpVEptKlNcXIycnBydhznL4ehXIiIii2VwqCsuLq709GtpaSkKCwuNUtS9bN26FdnZ2Rg1ahQAIDU1FQDg4eGh087Dw0Nal5qaCltbW7i4uNy3jbu7e4X9ubu7S20qs2DBAukaPKVSCW9v74c+tqqm1QrkFt9+33j6lYiIyPIYHOoee+wxfP311xWWr1ixAh07djRKUfeycuVKDBgwAF5eXjrL7543T9xjLr37tams/YO2M2PGDKjVaumRlJSkz2GYRG5xGYS4/W/eUYKIiMjyGPzt/sEHH6B37944ceIEevXqBQDYuXMnDh8+jJiYGKMXWC4hIQG///47fv75Z2mZSqUCcLunzdPTU1qelpYm9d6pVCqUlJQgKytLp7cuLS0NISEhUpubN29W2Gd6enqFXsA7KRQKKBSKRzuwalJ+6tVObgWFjbWJqyEiIiJjM7inrkuXLoiLi0PDhg3x3//+F//73//QtGlTnDx5El27dq2KGgEAq1atgru7OwYOHCgt8/X1hUqlkkbEArevu9uzZ48U2Dp27Ai5XK7TJiUlBadOnZLadO7cGWq1GocOHZLaHDx4EGq1WmpT0/FuEkRERJbtoc7DtWvXDuvXrzd2Lfek1WqxatUqjBw5EjY2/5Ysk8kQGRmJ+fPnw9/fH/7+/pg/fz4cHBwQHh4OAFAqlRgzZgymTJkCNzc3uLq6IioqCq1bt0bv3r0BAIGBgejfvz/Gjh2Lr776CgDwyiuvICwsDAEBAdV2nFWJd5MgIiKybA8V6i5fvoxVq1bhypUrWLJkCdzd3REdHQ1vb2+0bNnS2DXi999/R2JiIl566aUK66ZOnYrCwkKMHz8eWVlZCA4ORkxMDJycnKQ2n376KWxsbDBs2DAUFhaiV69eWL16Nayt/z0NuW7dOkycOFEaJTto0CAsW7bM6MdiKuWnXzlIgoiIyDLJhCi/fF4/e/bswYABA9ClSxf8+eefOHv2LPz8/LBw4UIcOnQIP/30U1XVavZycnKgVCqhVqvh7Oxs6nJ0/PdwEqZuPokeAfWxavTjpi6HiIiI9KRvvjD4mrrp06dj3rx5iI2N1bn/a48ePRAXF/dw1VKVU7OnjoiIyKIZHOr+/vtvDBkypMLy+vXrIyMjwyhFkfHxmjoiIiLLZnCoq1u3LlJSUiosP378OBo0aGCUosj4eDcJIiIiy2ZwqAsPD8e0adOQmpoKmUwGrVaLffv2ISoqCi+++GJV1EhGwNOvREREls3gUPfBBx+gUaNGaNCgAfLy8tCiRQt069YNISEhePfdd6uiRjKCnKLbtwjj3SSIiIgsk8Hf8HK5HOvWrcPcuXNx/PhxaLVatG/fHv7+/lVRHxkJe+qIiIgs20N32zRp0gR+fn4AKr9vKpkXXlNHRERk2Qw+/QoAK1euRKtWrWBnZwc7Ozu0atUK3377rbFrIyPi6FciIiLLZnBP3cyZM/Hpp59iwoQJ6Ny5MwAgLi4Ob775Jq5du4Z58+YZvUh6dDz9SkREZNkMDnXLly/HN998gxdeeEFaNmjQILRp0wYTJkxgqDNDxWUaFJVqAfD0KxERkaUy+PSrRqNBUFBQheUdO3ZEWVmZUYoi48rKv91LZyUD6thx9CsREZElMjjU/ec//8Hy5csrLP/6668xYsQIoxRFxnUtIx8A4O3qAGsrDmohIiKyRA/VbbNy5UrExMSgU6dOAIADBw4gKSkJL774IiZPniy1W7x4sXGqpEdy9dbtUOdbz9HElRAREVFVMTjUnTp1Ch06dAAAXL58GcDt+77Wr18fp06dktpxmhPzwVBHRERk+QwOdbt27aqKOqgKXUm/Her8GOqIiIgslsHX1N28efOe606ePPlIxVDVuHorDwDgW6+OiSshIiKiqmJwqGvdujW2bdtWYfnHH3+M4OBgoxRFxlOm0SIxswAA4FufPXVERESWyuBQN23aNAwfPhyvvvoqCgsLcf36dfTs2ROLFi3Cpk2bqqJGegTJWYUo1QgobKzg6Wxn6nKIiIioihgc6qZMmYIDBw5g3759aNOmDdq0aQN7e3ucPHkSgwYNqooa6RHcOUjCitOZEBERWayHuvern58fWrZsiWvXriEnJwfDhg2Dh4eHsWsjI7jCka9ERES1gsGhrryH7tKlSzh58iSWL1+OCRMmYNiwYcjKyqqKGukR/DtIgqGOiIjIkhkc6nr27Inhw4cjLi4OgYGBePnll3H8+HEkJyejdevWVVEjPQLOUUdERFQ7GDxPXUxMDEJDQ3WWNWnSBHv37sUHH3xgtMLIOK6Wz1FXn9OZEBERWTKDe+ruDnTShqysMHPmzEcuiIynsESDG+oiAJx4mIiIyNLpHeqefPJJqNVq6fkHH3yA7Oxs6XlGRgZatGhh1OLo0VzLuN1LV9dBDhdHWxNXQ0RERFVJ71C3Y8cOFBcXS88/+ugjZGZmSs/Lyspw/vx541ZHj4TX0xEREdUeeoc6IcR9n5P5YagjIiKqPR5qnjqqGa6UD5JgqCMiIrJ4eoc6mUwGmUxWYRmZr3/nqOPIVyIiIkun95QmQgiMGjUKCoUCAFBUVIRXX30Vjo63e4HuvN6OzAPvJkFERFR76B3qRo4cqfP8P//5T4U2L7744qNXREaRlV+C7IJSAEDjeg4mroaIiIiqmt6hbtWqVVVZBxlZeS+dp9IODrYGzzFNRERENQwHSlgojnwlIiKqXRjqLNS/gyQY6oiIiGoDhjoLxZ46IiKi2oWhzkKVz1HXpD6nMyEiIqoNGOoskFYrpPu+sqeOiIiodmCos0CpOUUoKtXCxkqGhi72pi6HiIiIqgFDnQUqv56ukZsDbKz5FhMREdUG/Ma3QOVz1PGer0RERLUHQ50FuprO6+mIiIhqG4Y6C/TvHHUc+UpERFRbMNRZoCuco46IiKjWMftQd/36dfznP/+Bm5sbHBwc0K5dOxw9elRaL4TA7Nmz4eXlBXt7e3Tv3h2nT5/W2UZxcTEmTJiAevXqwdHREYMGDUJycrJOm6ysLERERECpVEKpVCIiIgLZ2dnVcYhGVVKmRVJmAQDArz5DHRERUW1h1qEuKysLXbp0gVwux2+//YYzZ87gk08+Qd26daU2CxcuxOLFi7Fs2TIcPnwYKpUKffr0QW5urtQmMjISW7ZswcaNG7F3717k5eUhLCwMGo1GahMeHo74+HhER0cjOjoa8fHxiIiIqM7DNYr0vGJoBSC3lsHdSWHqcoiIiKiayIQQwtRF3Mv06dOxb98+/PXXX5WuF0LAy8sLkZGRmDZtGoDbvXIeHh746KOPMG7cOKjVatSvXx9r167F8OHDAQA3btyAt7c3tm/fjn79+uHs2bNo0aIFDhw4gODgYADAgQMH0LlzZ5w7dw4BAQF61ZuTkwOlUgm1Wg1nZ2cj/AQMdyIpG09/sQ+eSjvEzehlkhqIiIjIePTNF2bdU7dt2zYEBQXhueeeg7u7O9q3b49vvvlGWn/16lWkpqaib9++0jKFQoHQ0FDs378fAHD06FGUlpbqtPHy8kKrVq2kNnFxcVAqlVKgA4BOnTpBqVRKbSpTXFyMnJwcnYeppecWAwDqs5eOiIioVjHrUHflyhUsX74c/v7+2LFjB1599VVMnDgR33//PQAgNTUVAODh4aHzOg8PD2ldamoqbG1t4eLict827u7uFfbv7u4utanMggULpGvwlEolvL29H/5gjeRW3u1QV68OQx0REVFtYtahTqvVokOHDpg/fz7at2+PcePGYezYsVi+fLlOO5lMpvNcCFFh2d3ublNZ+wdtZ8aMGVCr1dIjKSlJn8OqUlJPHUMdERFRrWLWoc7T0xMtWrTQWRYYGIjExEQAgEqlAoAKvWlpaWlS751KpUJJSQmysrLu2+bmzZsV9p+enl6hF/BOCoUCzs7OOg9Tk3rqnGxNXAkRERFVJ7MOdV26dMH58+d1ll24cAE+Pj4AAF9fX6hUKsTGxkrrS0pKsGfPHoSEhAAAOnbsCLlcrtMmJSUFp06dktp07twZarUahw4dktocPHgQarVaalNTpOexp46IiKg2sjF1Affz5ptvIiQkBPPnz8ewYcNw6NAhfP311/j6668B3D5lGhkZifnz58Pf3x/+/v6YP38+HBwcEB4eDgBQKpUYM2YMpkyZAjc3N7i6uiIqKgqtW7dG7969Adzu/evfvz/Gjh2Lr776CgDwyiuvICwsTO+Rr+biVm4JAKAeB0oQERHVKmYd6h577DFs2bIFM2bMwNy5c+Hr64slS5ZgxIgRUpupU6eisLAQ48ePR1ZWFoKDgxETEwMnJyepzaeffgobGxsMGzYMhYWF6NWrF1avXg1ra2upzbp16zBx4kRplOygQYOwbNmy6jtYI2FPHRERUe1k1vPU1TTmME9d61k7kFtchp1TQtGkPu/9SkREVNNZxDx1ZJiiUg1yi8sAcJ46IiKi2oahzoKUT2dia2MFJ4VZn1knIiIiI2OosyB3Xk/3oHn6iIiIyLIw1FmQW7nlc9Tx1CsREVFtw1BnQTjylYiIqPZiqLMg5XPU1efdJIiIiGodhjoLkp5XBIA9dURERLURQ50F4d0kiIiIai+GOgvCa+qIiIhqL4Y6C3Irj6NfiYiIaiuGOgtSPvkwe+qIiIhqH4Y6C5FfXIaCEg0A9tQRERHVRgx1FqL81Ku93BqOttYmroaIiIiqG0Odhfj3ejpb3iKMiIioFmKosxC8no6IiKh2Y6izEOl5/8xRx1BHRERUKzHUWQipp46DJIiIiGolhjoLIV1Tx546IiKiWomhzkKwp46IiKh2Y6izEOypIyIiqt0Y6iwEe+qIiIhqN4Y6CyCEkHrqOKUJERFR7cRQZwHyistQVKoFcHvyYSIiIqp9GOoswK1/5qhztLWGg62NiashIiIiU2CoswC8no6IiIgY6iwAR74SERERQ50FYE8dERERMdRZAPbUEREREUOdBWBPHRERETHUWQD21BERERFDnQVgTx0REREx1FmA8nnq6tXhxMNERES1FUNdDSeEYE8dERERMdTVdDlFZSjR/HOLMF5TR0REVGsx1NVw5YMknOxsYCe3NnE1REREZCoMdTWcdOqVvXRERES1GkNdDSdNZ8Lr6YiIiGo1hroajj11REREBDDU1XjlPXUc+UpERFS7MdTVIEmZBSgu0+gs43QmREREBDDU1RilGi1eXnMET372Fw5cyZCWc+JhIiIiAhjqaoxrt/KRkV+My+n5eP7rA5jy3xPIzC9hTx0REREBYKirMfw9nLBzcneMCG4EmQzYfCwZPT/ZjcvpeQA48TAREVFtZ9ahbvbs2ZDJZDoPlUolrRdCYPbs2fDy8oK9vT26d++O06dP62yjuLgYEyZMQL169eDo6IhBgwYhOTlZp01WVhYiIiKgVCqhVCoRERGB7Ozs6jhEgygd5PhgSGtsfi0EzVVOyC4oRUHJ7Wvs2FNHRERUu5l1qAOAli1bIiUlRXr8/fff0rqFCxdi8eLFWLZsGQ4fPgyVSoU+ffogNzdXahMZGYktW7Zg48aN2Lt3L/Ly8hAWFgaN5t8BB+Hh4YiPj0d0dDSio6MRHx+PiIiIaj1OQ3Ro5IJfJzyBd54MhL3cGh7OCk5pQkREVMvJhBDC1EXcy+zZs7F161bEx8dXWCeEgJeXFyIjIzFt2jQAt3vlPDw88NFHH2HcuHFQq9WoX78+1q5di+HDhwMAbty4AW9vb2zfvh39+vXD2bNn0aJFCxw4cADBwcEAgAMHDqBz5844d+4cAgIC9K43JycHSqUSarUazs7Oj/4D0GefRaUQAlDay6tlf0RERFS99M0XZt9Td/HiRXh5ecHX1xfPP/88rly5AgC4evUqUlNT0bdvX6mtQqFAaGgo9u/fDwA4evQoSktLddp4eXmhVatWUpu4uDgolUop0AFAp06doFQqpTb3UlxcjJycHJ1HdXO2kzPQERERkXmHuuDgYHz//ffYsWMHvvnmG6SmpiIkJAQZGRlITU0FAHh4eOi8xsPDQ1qXmpoKW1tbuLi43LeNu7t7hX27u7tLbe5lwYIF0nV4SqUS3t7eD32sRERERI/CrEPdgAED8Mwzz6B169bo3bs3/u///g8AsGbNGqmNTCbTeY0QosKyu93dprL2+mxnxowZUKvV0iMpKemBx0RERERUFcw61N3N0dERrVu3xsWLF6VRsHf3pqWlpUm9dyqVCiUlJcjKyrpvm5s3b1bYV3p6eoVewLspFAo4OzvrPIiIiIhMoUaFuuLiYpw9exaenp7w9fWFSqVCbGystL6kpAR79uxBSEgIAKBjx46Qy+U6bVJSUnDq1CmpTefOnaFWq3Ho0CGpzcGDB6FWq6U2RERERObOxtQF3E9UVBSeeuopNGrUCGlpaZg3bx5ycnIwcuRIyGQyREZGYv78+fD394e/vz/mz58PBwcHhIeHAwCUSiXGjBmDKVOmwM3NDa6uroiKipJO5wJAYGAg+vfvj7Fjx+Krr74CALzyyisICwszaOQrERERkSmZdahLTk7GCy+8gFu3bqF+/fro1KkTDhw4AB8fHwDA1KlTUVhYiPHjxyMrKwvBwcGIiYmBk5OTtI1PP/0UNjY2GDZsGAoLC9GrVy+sXr0a1tbWUpt169Zh4sSJ0ijZQYMGYdmyZdV7sERERESPwKznqatpTDFPHREREVk2i5mnjoiIiIgejKGOiIiIyAIw1BERERFZAIY6IiIiIgvAUEdERERkARjqiIiIiCwAQx0RERGRBTDryYdrmvIp/3JyckxcCREREVmK8lzxoKmFGeqMKDc3FwDg7e1t4kqIiIjI0uTm5kKpVN5zPe8oYURarRY3btyAk5MTZDLZI20rJycH3t7eSEpK4t0pzADfD/PB98K88P0wH3wvzIsx3w8hBHJzc+Hl5QUrq3tfOceeOiOysrJCw4YNjbpNZ2dnfjjNCN8P88H3wrzw/TAffC/Mi7Hej/v10JXjQAkiIiIiC8BQR0RERGQBGOrMlEKhwKxZs6BQKExdCoHvhznhe2Fe+H6YD74X5sUU7wcHShARERFZAPbUEREREVkAhjoiIiIiC8BQR0RERGQBGOpM6Msvv4Svry/s7OzQsWNH/PXXX/dtv2fPHnTs2BF2dnbw8/PDihUrqqlSy2fIe/Hzzz+jT58+qF+/PpydndG5c2fs2LGjGqu1fIZ+Nsrt27cPNjY2aNeuXdUWWIsY+l4UFxfjnXfegY+PDxQKBZo0aYLvvvuumqq1fIa+H+vWrUPbtm3h4OAAT09PjB49GhkZGdVUreX6888/8dRTT8HLywsymQxbt2594Guq5TtckEls3LhRyOVy8c0334gzZ86ISZMmCUdHR5GQkFBp+ytXrggHBwcxadIkcebMGfHNN98IuVwufvrpp2qu3PIY+l5MmjRJfPTRR+LQoUPiwoULYsaMGUIul4tjx45Vc+WWydD3o1x2drbw8/MTffv2FW3btq2eYi3cw7wXgwYNEsHBwSI2NlZcvXpVHDx4UOzbt68aq7Zchr4ff/31l7CyshKfffaZuHLlivjrr79Ey5YtxeDBg6u5csuzfft28c4774jNmzcLAGLLli33bV9d3+EMdSby+OOPi1dffVVnWfPmzcX06dMrbT916lTRvHlznWXjxo0TnTp1qrIaawtD34vKtGjRQsyZM8fYpdVKD/t+DB8+XLz77rti1qxZDHVGYuh78dtvvwmlUikyMjKqo7xax9D3Y9GiRcLPz09n2dKlS0XDhg2rrMbaSJ9QV13f4Tz9agIlJSU4evQo+vbtq7O8b9++2L9/f6WviYuLq9C+X79+OHLkCEpLS6usVkv3MO/F3bRaLXJzc+Hq6loVJdYqD/t+rFq1CpcvX8asWbOqusRa42Hei23btiEoKAgLFy5EgwYN0KxZM0RFRaGwsLA6SrZoD/N+hISEIDk5Gdu3b4cQAjdv3sRPP/2EgQMHVkfJdIfq+g7nvV9N4NatW9BoNPDw8NBZ7uHhgdTU1Epfk5qaWmn7srIy3Lp1C56enlVWryV7mPfibp988gny8/MxbNiwqiixVnmY9+PixYuYPn06/vrrL9jY8E+asTzMe3HlyhXs3bsXdnZ22LJlC27duoXx48cjMzOT19U9ood5P0JCQrBu3ToMHz4cRUVFKCsrw6BBg/D5559XR8l0h+r6DmdPnQnJZDKd50KICsse1L6y5WQ4Q9+Lchs2bMDs2bOxadMmuLu7V1V5tY6+74dGo0F4eDjmzJmDZs2aVVd5tYohnw2tVguZTIZ169bh8ccfx5NPPonFixdj9erV7K0zEkPejzNnzmDixIl47733cPToUURHR+Pq1at49dVXq6NUukt1fIfzf2tNoF69erC2tq7wf1dpaWkVknw5lUpVaXsbGxu4ublVWa2W7mHei3KbNm3CmDFj8OOPP6J3795VWWatYej7kZubiyNHjuD48eN44403ANwOFkII2NjYICYmBj179qyW2i3Nw3w2PD090aBBAyiVSmlZYGAghBBITk6Gv79/ldZsyR7m/ViwYAG6dOmCt956CwDQpk0bODo6omvXrpg3bx7P8FSj6voOZ0+dCdja2qJjx46IjY3VWR4bG4uQkJBKX9O5c+cK7WNiYhAUFAS5XF5ltVq6h3kvgNs9dKNGjcL69et5fYoRGfp+ODs74++//0Z8fLz0ePXVVxEQEID4+HgEBwdXV+kW52E+G126dMGNGzeQl5cnLbtw4QKsrKzQsGHDKq3X0j3M+1FQUAArK92veWtrawD/9hJR9ai273CjDrsgvZUPTV+5cqU4c+aMiIyMFI6OjuLatWtCCCGmT58uIiIipPblw6HffPNNcebMGbFy5UpOaWIkhr4X69evFzY2NuKLL74QKSkp0iM7O9tUh2BRDH0/7sbRr8Zj6HuRm5srGjZsKJ599llx+vRpsWfPHuHv7y9efvllUx2CRTH0/Vi1apWwsbERX375pbh8+bLYu3evCAoKEo8//ripDsFi5ObmiuPHj4vjx48LAGLx4sXi+PHj0vQypvoOZ6gzoS+++EL4+PgIW1tb0aFDB7Fnzx5p3ciRI0VoaKhO+927d4v27dsLW1tb0bhxY7F8+fJqrthyGfJehIaGCgAVHiNHjqz+wi2UoZ+NOzHUGZeh78XZs2dF7969hb29vWjYsKGYPHmyKCgoqOaqLZeh78fSpUtFixYthL29vfD09BQjRowQycnJ1Vy15dm1a9d9vwdM9R0uE4J9sEREREQ1Ha+pIyIiIrIADHVEREREFoChjoiIiMgCMNQRERERWQCGOiIiIiILwFBHREREZAEY6oiIiIgsAEMdERERkQVgqCMiegSjRo3C4MGDq32/3bt3R2Rk5CNtY/bs2WjXrt1925jq+IjIcAx1RGQxRo0aBZlMBplMBrlcDj8/P0RFRSE/Px8AcO3aNWm9TCaDk5MTWrZsiddffx0XL16877bLXxsfH18NR0JEZDiGOiKyKP3790dKSgquXLmCefPm4csvv0RUVJROm99//x0pKSk4ceIE5s+fj7Nnz6Jt27bYuXNntdRYUlJSLfshotqFoY6ILIpCoYBKpYK3tzfCw8MxYsQIbN26VaeNm5sbVCoV/Pz88PTTT+P3339HcHAwxowZA41GU+l2fX19AQDt27eHTCZD9+7dddZ//PHH8PT0hJubG15//XWUlpZK6xo3box58+Zh1KhRUCqVGDt2LABg//796NatG+zt7eHt7Y2JEydKvYoA8OWXX8Lf3x92dnbw8PDAs88+q7NPrVaLqVOnwtXVFSqVCrNnz9ZZn5iYiKeffhp16tSBs7Mzhg0bhps3b97zZ6fRaDB58mTUrVsXbm5umDp1Knh7cKKag6GOiCyavb29TsCqjJWVFSZNmoSEhAQcPXq00jaHDh0C8G8v388//yyt27VrFy5fvoxdu3ZhzZo1WL16NVavXq3z+kWLFqFVq1Y4evQoZs6cib///hv9+vXD0KFDcfLkSWzatAl79+7FG2+8AQA4cuQIJk6ciLlz5+L8+fOIjo5Gt27ddLa5Zs0aODo64uDBg1i4cCHmzp2L2NhYAIAQAoMHD0ZmZib27NmD2NhYXL58GcOHD7/nz+GTTz7Bd999h5UrV2Lv3r3IzMzEli1b7vuzIyIzIoiILMTIkSPF008/LT0/ePCgcHNzE8OGDRNCCHH16lUBQBw/frzCa8+ePSsAiE2bNlW67Xu9duTIkcLHx0eUlZVJy5577jkxfPhw6bmPj48YPHiwzusiIiLEK6+8orPsr7/+ElZWVqKwsFBs3rxZODs7i5ycnErrCQ0NFU888YTOsscee0xMmzZNCCFETEyMsLa2FomJidL606dPCwDi0KFDQgghZs2aJdq2bSut9/T0FB9++KH0vLS0VDRs2FDnZ0pE5os9dURkUX799VfUqVMHdnZ26Ny5M7p164bPP//8ga8T/5xmlMlkBu+zZcuWsLa2lp57enoiLS1Np01QUJDO86NHj2L16tWoU6eO9OjXrx+0Wi2uXr2KPn36wMfHB35+foiIiMC6detQUFCgs402bdroPL9zv2fPnoW3tze8vb2l9S1atEDdunVx9uzZCsegVquRkpKCzp07S8tsbGwq1E1E5svG1AUQERlTjx49sHz5csjlcnh5eUEul+v1uvKgU37tnCHu3odMJoNWq9VZ5ujoqPNcq9Vi3LhxmDhxYoXtNWrUCLa2tjh27Bh2796NmJgYvPfee5g9ezYOHz6MunXrPnC/QohKA+q9lhNRzceeOiKyKI6OjmjatCl8fHz0DnRarRZLly6Fr68v2rdvX2kbW1tbALjnQApDdejQAadPn0bTpk0rPMr3ZWNjg969e2PhwoU4efIkrl27hj/++EOv7bdo0QKJiYlISkqSlp05cwZqtRqBgYEV2iuVSnh6euLAgQPSsrKysnteY0hE5oc9dURU62RkZCA1NRUFBQU4deoUlixZgkOHDuH//u//dE6j3snd3R329vaIjo5Gw4YNYWdnB6VS+dA1TJs2DZ06dcLrr7+OsWPHwtHREWfPnkVsbCw+//xz/Prrr7hy5Qq6desGFxcXbN++HVqtFgEBAXptv3fv3mjTpg1GjBiBJUuWoKysDOPHj0doaOg9T6lOmjQJH374Ifz9/REYGIjFixcjOzv7oY+RiKoXe+qIqNbp3bs3PD090bp1a0yfPh2BgYE4efIkevTocc/X2NjYYOnSpfjqq6/g5eWFp59++pFqaNOmDfbs2YOLFy+ia9euaN++PWbOnAlPT08AQN26dfHzzz+jZ8+eCAwMxIoVK7Bhwwa0bNlSr+3LZDJs3boVLi4u6NatG3r37g0/Pz9s2rTpnq+ZMmUKXnzxRYwaNQqdO3eGk5MThgwZ8kjHSUTVRyYEJyEiIiIiqunYU0dERERkARjqiIiIiCwAQx0RERGRBWCoIyIiIrIADHVEREREFoChjoiIiMgCMNQRERERWQCGOiIiIiILwFBHREREZAEY6oiIiIgsAEMdERERkQVgqCMiIiKyAP8PSIGrMw4hlJ0AAAAASUVORK5CYII=\"\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Figure size 640x480 with 1 Axes>\"\n",
    "      ],\n",
    "      \"image/png\": \"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\"\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"                 thr_cost_opt  thr_capacity  thr_monitor\\n\",\n",
    "       \"logit                    0.02      0.045829     0.045829\\n\",\n",
    "       \"tree_calibrated          0.02      0.037344     0.037344\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>thr_cost_opt</th>\\n\",\n",
    "       \"      <th>thr_capacity</th>\\n\",\n",
    "       \"      <th>thr_monitor</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>logit</th>\\n\",\n",
    "       \"      <td>0.02</td>\\n\",\n",
    "       \"      <td>0.045829</td>\\n\",\n",
    "       \"      <td>0.045829</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>tree_calibrated</th>\\n\",\n",
    "       \"      <td>0.02</td>\\n\",\n",
    "       \"      <td>0.037344</td>\\n\",\n",
    "       \"      <td>0.037344</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"Policy comparison on TEST (screen decision):\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"             model                policy  screen_rate  monitor_rate  \\\\\\n\",\n",
    "       \"1            logit  Hybrid (PD + events)     0.200018           0.0   \\n\",\n",
    "       \"0            logit               PD-only     0.230517           0.0   \\n\",\n",
    "       \"3  tree_calibrated  Hybrid (PD + events)     0.216315           0.0   \\n\",\n",
    "       \"2  tree_calibrated               PD-only     0.248361           0.0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   tpr_screen  ppv_screen  expected_cost  thr_screen_pd  thr_monitor_pd  \\\\\\n\",\n",
    "       \"1    0.381643    0.071916        14839.0            NaN             NaN   \\n\",\n",
    "       \"0    0.487923    0.079779        12930.0       0.045829        0.045829   \\n\",\n",
    "       \"3    0.741546    0.129209         7419.0            NaN             NaN   \\n\",\n",
    "       \"2    0.903382    0.137097         4354.0       0.037344        0.037344   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   thr_screen_score  thr_monitor_score  alpha_evt_any  beta_evt_2plus  \\n\",\n",
    "       \"1          0.165905           0.165905           0.05             0.1  \\n\",\n",
    "       \"0               NaN                NaN            NaN             NaN  \\n\",\n",
    "       \"3          0.155634           0.155634           0.05             0.1  \\n\",\n",
    "       \"2               NaN                NaN            NaN             NaN  \"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>model</th>\\n\",\n",
    "       \"      <th>policy</th>\\n\",\n",
    "       \"      <th>screen_rate</th>\\n\",\n",
    "       \"      <th>monitor_rate</th>\\n\",\n",
    "       \"      <th>tpr_screen</th>\\n\",\n",
    "       \"      <th>ppv_screen</th>\\n\",\n",
    "       \"      <th>expected_cost</th>\\n\",\n",
    "       \"      <th>thr_screen_pd</th>\\n\",\n",
    "       \"      <th>thr_monitor_pd</th>\\n\",\n",
    "       \"      <th>thr_screen_score</th>\\n\",\n",
    "       \"      <th>thr_monitor_score</th>\\n\",\n",
    "       \"      <th>alpha_evt_any</th>\\n\",\n",
    "       \"      <th>beta_evt_2plus</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>logit</td>\\n\",\n",
    "       \"      <td>Hybrid (PD + events)</td>\\n\",\n",
    "       \"      <td>0.200018</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.381643</td>\\n\",\n",
    "       \"      <td>0.071916</td>\\n\",\n",
    "       \"      <td>14839.0</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>0.165905</td>\\n\",\n",
    "       \"      <td>0.165905</td>\\n\",\n",
    "       \"      <td>0.05</td>\\n\",\n",
    "       \"      <td>0.1</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>logit</td>\\n\",\n",
    "       \"      <td>PD-only</td>\\n\",\n",
    "       \"      <td>0.230517</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.487923</td>\\n\",\n",
    "       \"      <td>0.079779</td>\\n\",\n",
    "       \"      <td>12930.0</td>\\n\",\n",
    "       \"      <td>0.045829</td>\\n\",\n",
    "       \"      <td>0.045829</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>tree_calibrated</td>\\n\",\n",
    "       \"      <td>Hybrid (PD + events)</td>\\n\",\n",
    "       \"      <td>0.216315</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.741546</td>\\n\",\n",
    "       \"      <td>0.129209</td>\\n\",\n",
    "       \"      <td>7419.0</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>0.155634</td>\\n\",\n",
    "       \"      <td>0.155634</td>\\n\",\n",
    "       \"      <td>0.05</td>\\n\",\n",
    "       \"      <td>0.1</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>tree_calibrated</td>\\n\",\n",
    "       \"      <td>PD-only</td>\\n\",\n",
    "       \"      <td>0.248361</td>\\n\",\n",
    "       \"      <td>0.0</td>\\n\",\n",
    "       \"      <td>0.903382</td>\\n\",\n",
    "       \"      <td>0.137097</td>\\n\",\n",
    "       \"      <td>4354.0</td>\\n\",\n",
    "       \"      <td>0.037344</td>\\n\",\n",
    "       \"      <td>0.037344</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"      <td>NaN</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 112\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"6e71b677\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 9.4.1 Decision curve analysis (net benefit)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Decision curves provide an alternative view of “response capability”: the net benefit of acting at different PD thresholds (treat-all vs treat-none baselines).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"fce9eda2\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2026-01-15T15:18:49.065393Z\",\n",
    "     \"start_time\": \"2026-01-15T15:18:48.396631Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"def net_benefit(y_true: np.ndarray, p: np.ndarray, pt: float) -> float:\\n\",\n",
    "    \"    y_hat = (p >= pt).astype(int)\\n\",\n",
    "    \"    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\\n\",\n",
    "    \"    n = len(y_true)\\n\",\n",
    "    \"    w = pt/(1-pt)\\n\",\n",
    "    \"    return (tp/n) - (fp/n)*w\\n\",\n",
    "    \"\\n\",\n",
    "    \"mask = df_model[\\\"split\\\"]==\\\"test\\\"\\n\",\n",
    "    \"y_test_np = df_model.loc[mask, TARGET_NAME].astype(int).values\\n\",\n",
    "    \"\\n\",\n",
    "    \"pts = np.linspace(0.01, 0.50, 50)\\n\",\n",
    "    \"plt.figure()\\n\",\n",
    "    \"for model_name, pcol in [(\\\"logit\\\",\\\"pd_logit\\\"), (\\\"tree_calibrated\\\",\\\"pd_tree\\\")]:\\n\",\n",
    "    \"    p = df_model.loc[mask, pcol].values\\n\",\n",
    "    \"    nb = [net_benefit(y_test_np, p, pt) for pt in pts]\\n\",\n",
    "    \"    plt.plot(pts, nb, label=model_name)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Treat-all and treat-none baselines\\n\",\n",
    "    \"event_rate = y_test_np.mean()\\n\",\n",
    "    \"nb_all = [event_rate - (1-event_rate)*(pt/(1-pt)) for pt in pts]\\n\",\n",
    "    \"nb_none = [0 for _ in pts]\\n\",\n",
    "    \"plt.plot(pts, nb_all, linestyle=\\\"--\\\", label=\\\"treat-all\\\")\\n\",\n",
    "    \"plt.plot(pts, nb_none, linestyle=\\\"--\\\", label=\\\"treat-none\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title(\\\"Decision curves (test split): net benefit vs threshold probability\\\")\\n\",\n",
    "    \"plt.xlabel(\\\"Threshold probability (pt)\\\")\\n\",\n",
    "    \"plt.ylabel(\\\"Net benefit\\\")\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig(Path(CONFIG[\\\"FIG_DIR\\\"]) / \\\"decision_curves_test.png\\\", dpi=160)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"<Figure size 640x480 with 1 Axes>\"\n",
    "      ],\n",
    "      \"image/png\": \"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\"\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 113\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"11412605\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 9.5 Scenario analysis (liquidity insurance vs liquidity fragility)\\n\",\n",
    "    \"\\n\",\n",
    "    \"Scenario analysis is a **communication and response** instrument: a structured way to translate plausible managerial / creditor actions and stress environments into PD sensitivity and triage policies—not as causal inference.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Below are scenario-analysis use cases that are materially more defensible (and operationally useful) than \\\"raise current ratio to 1.2\\\" or \\\"CFO +10% of assets,\\\" while still fitting the two-layer architecture (PD model + non-predictor event layer):\\n\",\n",
    "    \"\\n\",\n",
    "    \"**2) Liquidity insurance vs liquidity fragility scenarios (cash, working capital, and credit lines)**\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Why it is a better use case:**\\n\",\n",
    "    \"- Instead of targeting an arbitrary current ratio, use liquidity scenarios that map to liquidity insurance mechanisms documented in the literature: cash buffers and bank lines of credit.\\n\",\n",
    "    \"- Corporate cash holdings are a fundamental margin of safety with systematic determinants and implications.\\n\",\n",
    "    \"- Lines of credit are a core liquidity management instrument; their availability is state-contingent and interacts with profitability/cash flow.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**What to implement (scenario templates):**\\n\",\n",
    "    \"- **Cash buffer stress:** \\\"cash burn\\\" scenario: `che ← che − Δ` (bounded at 0), optionally `oancf ← oancf − Δ` if you want a consistent flow hit.\\n\",\n",
    "    \"- **Working-capital release** (high realism, accounting-consistent): Reduce receivables and inventory (`rect`, `invt`) by a fraction; increase cash by the same amount. This is typically more plausible than \\\"CFO +10% of assets\\\" because it corresponds to collections and inventory liquidation.\\n\",\n",
    "    \"- **Liquidity squeeze + maturity wall:** shift a portion of `dltt` into `dlc` (or increase `dlc` share) to mimic refinancing risk; recompute short-term debt share and liquidity ratios.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Decision-support outputs:**\\n\",\n",
    "    \"- PD sensitivity to liquidity burn speed (months of runway proxy; even with annual data, you can approximate).\\n\",\n",
    "    \"- A liquidity \\\"traffic light\\\" that combines PD tier + liquidity events (`evt_liq_squeeze` / `evt_quick_squeeze`) for escalation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"350a73f0\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2026-01-15T15:18:53.358981Z\",\n",
    "     \"start_time\": \"2026-01-15T15:18:49.473501Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"# =============================================================================\\n\",\n",
    "    \"# 9.5 Scenario analysis (liquidity insurance vs. fragility)\\n\",\n",
    "    \"# =============================================================================\\n\",\n",
    "    \"# Key design choice:\\n\",\n",
    "    \"# - Do NOT re-run dataset-wide cleaning here (medians, winsor bounds, scaler are already fit upstream).\\n\",\n",
    "    \"# - For scenarios, start from the already-clean base feature vector (df_model[continuous_feats_raw]) and\\n\",\n",
    "    \"#   ONLY overwrite features that are mechanically affected by the raw accounting perturbation.\\n\",\n",
    "    \"# - Then apply the *same* fitted (train) transforms: median fill -> winsor clip -> scaler transform.\\n\",\n",
    "    \"\\n\",\n",
    "    \"import traceback, sys, time\\n\",\n",
    "    \"print(\\\"[9.5] start\\\")\\n\",\n",
    "    \"t0 = time.time()\\n\",\n",
    "    \"def _checkpoint(msg): print(f\\\"[9.5] {msg} (t={time.time()-t0:.2f}s)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _safe_div(n, d):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        n_f = float(n); d_f = float(d)\\n\",\n",
    "    \"        if pd.isna(n_f) or pd.isna(d_f) or d_f == 0:\\n\",\n",
    "    \"            return np.nan\\n\",\n",
    "    \"        return n_f / d_f\\n\",\n",
    "    \"    except Exception:\\n\",\n",
    "    \"        return np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _build_continuous_features_from_raw(row_raw: pd.Series) -> dict:\\n\",\n",
    "    \"    \\\"\\\"\\\"Compute only the continuous model features needed, from raw accounting items.\\\"\\\"\\\"\\n\",\n",
    "    \"    at    = row_raw.get(\\\"at\\\", np.nan)\\n\",\n",
    "    \"    che   = row_raw.get(\\\"che\\\", np.nan)\\n\",\n",
    "    \"    act   = row_raw.get(\\\"act\\\", np.nan)\\n\",\n",
    "    \"    lct   = row_raw.get(\\\"lct\\\", np.nan)\\n\",\n",
    "    \"    rect  = row_raw.get(\\\"rect\\\", np.nan)\\n\",\n",
    "    \"    invt  = row_raw.get(\\\"invt\\\", np.nan)\\n\",\n",
    "    \"    lt    = row_raw.get(\\\"lt\\\", np.nan)\\n\",\n",
    "    \"    dlc   = row_raw.get(\\\"dlc\\\", np.nan)\\n\",\n",
    "    \"    dltt  = row_raw.get(\\\"dltt\\\", np.nan)\\n\",\n",
    "    \"    oibdp = row_raw.get(\\\"oibdp\\\", np.nan)\\n\",\n",
    "    \"    dp    = row_raw.get(\\\"dp\\\", np.nan)\\n\",\n",
    "    \"    xint  = row_raw.get(\\\"xint\\\", np.nan)\\n\",\n",
    "    \"    ceq   = row_raw.get(\\\"ceq\\\", np.nan)\\n\",\n",
    "    \"    capx  = row_raw.get(\\\"capx\\\", np.nan)\\n\",\n",
    "    \"    ppent = row_raw.get(\\\"ppent\\\", np.nan)\\n\",\n",
    "    \"    intan = row_raw.get(\\\"intan\\\", np.nan)\\n\",\n",
    "    \"    oancf = row_raw.get(\\\"oancf\\\", np.nan)\\n\",\n",
    "    \"    re    = row_raw.get(\\\"re\\\", np.nan)\\n\",\n",
    "    \"    niadj = row_raw.get(\\\"niadj\\\", np.nan)\\n\",\n",
    "    \"    prstkc = row_raw.get(\\\"prstkc\\\", np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    d_vals = [v for v in [dlc, dltt] if pd.notna(v)]\\n\",\n",
    "    \"    total_debt = float(np.sum(d_vals)) if len(d_vals) > 0 else np.nan\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat = {}\\n\",\n",
    "    \"    feat[\\\"ln_at\\\"] = np.log(at) if pd.notna(at) and at > 0 else np.nan\\n\",\n",
    "    \"    feat[\\\"cash_at\\\"] = _safe_div(che, at)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"current_ratio\\\"] = _safe_div(act, lct)\\n\",\n",
    "    \"    if pd.notna(act) and pd.notna(invt) and pd.notna(lct) and lct != 0:\\n\",\n",
    "    \"        feat[\\\"quick_ratio\\\"] = _safe_div(act - invt, lct)\\n\",\n",
    "    \"    elif pd.notna(che) and pd.notna(rect) and pd.notna(lct) and lct != 0:\\n\",\n",
    "    \"        feat[\\\"quick_ratio\\\"] = _safe_div(che + rect, lct)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        feat[\\\"quick_ratio\\\"] = feat[\\\"current_ratio\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"nwc_at\\\"] = _safe_div((act - lct), at)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"rect_act\\\"] = _safe_div(rect, act)\\n\",\n",
    "    \"    feat[\\\"invt_act\\\"] = _safe_div(invt, act)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"lt_at\\\"] = _safe_div(lt, at)\\n\",\n",
    "    \"    feat[\\\"dlc_at\\\"] = _safe_div(dlc, at)\\n\",\n",
    "    \"    feat[\\\"dltt_at\\\"] = _safe_div(dltt, at)\\n\",\n",
    "    \"    feat[\\\"debt_at\\\"] = _safe_div(total_debt, at)\\n\",\n",
    "    \"    feat[\\\"st_debt_share\\\"] = _safe_div(dlc, total_debt)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"ebitda_at\\\"] = _safe_div(oibdp, at)\\n\",\n",
    "    \"    feat[\\\"xint_at\\\"] = _safe_div(xint, at)\\n\",\n",
    "    \"    feat[\\\"interest_coverage\\\"] = _safe_div(oibdp, xint)\\n\",\n",
    "    \"    feat[\\\"debt_to_ebitda\\\"] = _safe_div(total_debt, oibdp)\\n\",\n",
    "    \"    feat[\\\"ebit_to_capital\\\"] = _safe_div((oibdp - dp), (total_debt + ceq))\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"ppent_at\\\"] = _safe_div(ppent, at)\\n\",\n",
    "    \"    feat[\\\"intan_at\\\"] = _safe_div(intan, at)\\n\",\n",
    "    \"    feat[\\\"ocf_to_debt\\\"] = _safe_div(oancf, total_debt)\\n\",\n",
    "    \"    feat[\\\"fcf_to_debt\\\"] = _safe_div((oancf - capx), total_debt)\\n\",\n",
    "    \"    feat[\\\"re_at\\\"] = _safe_div(re, at)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat[\\\"ceq_at\\\"] = _safe_div(ceq, at)\\n\",\n",
    "    \"    feat[\\\"niadj_at\\\"] = _safe_div(niadj, at)\\n\",\n",
    "    \"    feat[\\\"prstkc_at\\\"] = _safe_div(prstkc, at)\\n\",\n",
    "    \"    return feat\\n\",\n",
    "    \"\\n\",\n",
    "    \"def build_model_features_from_raw_scenario(row_raw: pd.Series, base_feature_row: pd.Series) -> pd.DataFrame:\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Build the model feature vector for a scenario without redoing dataset-wide cleaning.\\n\",\n",
    "    \"    - Start from already-clean feature values (base_feature_row[continuous_feats_raw]).\\n\",\n",
    "    \"    - Overwrite features mechanically implied by the scenario raw row.\\n\",\n",
    "    \"    - Apply the fitted preprocessing (train medians, winsor bounds, scaler).\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    out_cont = pd.Series({c: float(base_feature_row[c]) for c in continuous_feats_raw})\\n\",\n",
    "    \"\\n\",\n",
    "    \"    feat_updates = _build_continuous_features_from_raw(row_raw)\\n\",\n",
    "    \"    for k, v in feat_updates.items():\\n\",\n",
    "    \"        if k in out_cont.index:\\n\",\n",
    "    \"            out_cont[k] = v\\n\",\n",
    "    \"\\n\",\n",
    "    \"    out = pd.DataFrame([out_cont.to_dict()])\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for c in continuous_feats_raw:\\n\",\n",
    "    \"        v = out[c].replace([np.inf, -np.inf], np.nan)\\n\",\n",
    "    \"        v = v.fillna(train_medians[c])\\n\",\n",
    "    \"        lo, hi = winsor_bounds[c]\\n\",\n",
    "    \"        v = apply_bounds(v, lo, hi)\\n\",\n",
    "    \"        out[c] = v\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Z = scaler.transform(out[continuous_feats_raw].astype(float))\\n\",\n",
    "    \"    for j, c in enumerate(continuous_feats_raw):\\n\",\n",
    "    \"        out[f\\\"z_{c}\\\"] = Z[:, j]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # keep events from base (decision-support layer not redefined here)\\n\",\n",
    "    \"    for e in event_feats:\\n\",\n",
    "    \"        out[e] = int(base_feature_row[e]) if e in base_feature_row.index else 0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return out[[f\\\"z_{c}\\\" for c in continuous_feats_raw] + event_feats]\\n\",\n",
    "    \"\\n\",\n",
    "    \"def predict_pd_from_features(X_row: pd.DataFrame) -> dict:\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        pd_logit = float(logit_clf.predict_proba(X_row)[:, 1][0])\\n\",\n",
    "    \"        drow = xgb.DMatrix(X_row, feature_names=X_row.columns.tolist())\\n\",\n",
    "    \"        pd_tree_raw = float(xgb_model.predict(drow)[0])\\n\",\n",
    "    \"        pd_tree = float(iso.transform([pd_tree_raw])[0])\\n\",\n",
    "    \"        return {\\\"pd_logit\\\": pd_logit, \\\"pd_tree\\\": pd_tree}\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(\\\"[9.5] Exception in predict_pd_from_features:\\\", repr(e))\\n\",\n",
    "    \"        traceback.print_exc()\\n\",\n",
    "    \"        raise\\n\",\n",
    "    \"\\n\",\n",
    "    \"def compute_liquidity_from_raw_row(row_data: pd.Series) -> dict:\\n\",\n",
    "    \"    act  = row_data.get(\\\"act\\\", np.nan)\\n\",\n",
    "    \"    lct  = row_data.get(\\\"lct\\\", np.nan)\\n\",\n",
    "    \"    invt = row_data.get(\\\"invt\\\", np.nan)\\n\",\n",
    "    \"    che  = row_data.get(\\\"che\\\", np.nan)\\n\",\n",
    "    \"    rect = row_data.get(\\\"rect\\\", np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    cr = _safe_div(act, lct)\\n\",\n",
    "    \"    if pd.notna(act) and pd.notna(invt) and pd.notna(lct) and lct != 0:\\n\",\n",
    "    \"        qr = _safe_div(act - invt, lct)\\n\",\n",
    "    \"    elif pd.notna(che) and pd.notna(rect) and pd.notna(lct) and lct != 0:\\n\",\n",
    "    \"        qr = _safe_div(che + rect, lct)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        qr = cr\\n\",\n",
    "    \"\\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        \\\"current_ratio\\\": cr,\\n\",\n",
    "    \"        \\\"quick_ratio\\\": qr,\\n\",\n",
    "    \"        \\\"evt_liq_squeeze\\\": 1.0 if (pd.notna(cr) and cr < 1.0) else 0.0,\\n\",\n",
    "    \"        \\\"evt_quick_squeeze\\\": 1.0 if (pd.notna(qr) and qr < 0.8) else 0.0,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"def get_traffic_light(pd_logit: float, evt_liq: float, evt_quick: float) -> str:\\n\",\n",
    "    \"    if pd_logit < 0.2:\\n\",\n",
    "    \"        pd_tier = \\\"Low\\\"\\n\",\n",
    "    \"    elif pd_logit < 0.5:\\n\",\n",
    "    \"        pd_tier = \\\"Medium\\\"\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        pd_tier = \\\"High\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"    has_liq = (evt_liq > 0.5) or (evt_quick > 0.5)\\n\",\n",
    "    \"    if pd_tier == \\\"Low\\\" and not has_liq:\\n\",\n",
    "    \"        return \\\"Green\\\"\\n\",\n",
    "    \"    if pd_tier == \\\"High\\\" and has_liq:\\n\",\n",
    "    \"        return \\\"Red\\\"\\n\",\n",
    "    \"    return \\\"Yellow\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def sensitivity_audit(base_X: pd.DataFrame, scen_X: pd.DataFrame, threshold: float = 1e-4, top_k: int = 15) -> pd.DataFrame:\\n\",\n",
    "    \"    rows = []\\n\",\n",
    "    \"    for feat in continuous_feats_raw:\\n\",\n",
    "    \"        zb = float(base_X[f\\\"z_{feat}\\\"].iloc[0])\\n\",\n",
    "    \"        zs = float(scen_X[f\\\"z_{feat}\\\"].iloc[0])\\n\",\n",
    "    \"        delta = zs - zb\\n\",\n",
    "    \"        rows.append({\\\"feature\\\": feat, \\\"z_base\\\": zb, \\\"z_scenario\\\": zs, \\\"z_delta\\\": delta})\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df_audit = pd.DataFrame(rows, columns=[\\\"feature\\\", \\\"z_base\\\", \\\"z_scenario\\\", \\\"z_delta\\\"])\\n\",\n",
    "    \"    df_audit[\\\"abs_z_delta\\\"] = df_audit[\\\"z_delta\\\"].abs()\\n\",\n",
    "    \"    df_audit = df_audit.sort_values(\\\"abs_z_delta\\\", ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df_sig = df_audit.loc[df_audit[\\\"abs_z_delta\\\"] > threshold].copy() if threshold > 0 else df_audit.copy()\\n\",\n",
    "    \"    df_top = df_audit.head(int(top_k)).copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    df_top.attrs[\\\"material_count\\\"] = int(len(df_sig))\\n\",\n",
    "    \"    df_top.attrs[\\\"material_table\\\"] = df_sig\\n\",\n",
    "    \"    return df_top\\n\",\n",
    "    \"\\n\",\n",
    "    \"# -----------------------------------------------------------------------------\\n\",\n",
    "    \"# Select a sensitivity-safe representative observation\\n\",\n",
    "    \"# -----------------------------------------------------------------------------\\n\",\n",
    "    \"_checkpoint(\\\"select representative observation\\\")\\n\",\n",
    "    \"test_df = df_model.loc[df_model[\\\"split\\\"] == \\\"test\\\", :].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Keep rect/invt in key_items even though WC release is deleted: quick ratio uses invt.\\n\",\n",
    "    \"key_items = [\\\"at\\\",\\\"che\\\",\\\"act\\\",\\\"lct\\\",\\\"rect\\\",\\\"invt\\\",\\\"dlc\\\",\\\"dltt\\\",\\\"oibdp\\\",\\\"xint\\\",\\\"oancf\\\",\\\"capx\\\",\\\"ceq\\\"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"cand_mask = (test_df[\\\"pd_logit\\\"].between(0.15, 0.85)) & (test_df[\\\"pd_tree\\\"].between(0.15, 0.85))\\n\",\n",
    "    \"\\n\",\n",
    "    \"candidate_indices = []\\n\",\n",
    "    \"for idx in test_df.loc[cand_mask].index:\\n\",\n",
    "    \"    row_chk = df.loc[idx, :]\\n\",\n",
    "    \"    if not all(pd.notna(row_chk.get(k, np.nan)) for k in key_items):\\n\",\n",
    "    \"        continue\\n\",\n",
    "    \"    cr = _safe_div(row_chk.get(\\\"act\\\", np.nan), row_chk.get(\\\"lct\\\", np.nan))\\n\",\n",
    "    \"    if pd.notna(cr) and (0.2 <= cr <= 5.0):\\n\",\n",
    "    \"        candidate_indices.append(idx)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(candidate_indices) == 0:\\n\",\n",
    "    \"    print(\\\"Warning: No observation meets strict criteria. Relaxing PD bounds to [0.10, 0.90].\\\")\\n\",\n",
    "    \"    cand_mask = (test_df[\\\"pd_logit\\\"].between(0.10, 0.90)) & (test_df[\\\"pd_tree\\\"].between(0.10, 0.90))\\n\",\n",
    "    \"    for idx in test_df.loc[cand_mask].index:\\n\",\n",
    "    \"        row_chk = df.loc[idx, :]\\n\",\n",
    "    \"        if not all(pd.notna(row_chk.get(k, np.nan)) for k in key_items):\\n\",\n",
    "    \"            continue\\n\",\n",
    "    \"        cr = _safe_div(row_chk.get(\\\"act\\\", np.nan), row_chk.get(\\\"lct\\\", np.nan))\\n\",\n",
    "    \"        if pd.notna(cr) and (0.2 <= cr <= 5.0):\\n\",\n",
    "    \"            candidate_indices.append(idx)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(candidate_indices) == 0:\\n\",\n",
    "    \"    print(\\\"Warning: Fallback to highest-PD test observation with required raw items.\\\")\\n\",\n",
    "    \"    for idx in test_df.sort_values(\\\"pd_logit\\\", ascending=False).index:\\n\",\n",
    "    \"        row_chk = df.loc[idx, :]\\n\",\n",
    "    \"        if all(pd.notna(row_chk.get(k, np.nan)) for k in key_items):\\n\",\n",
    "    \"            candidate_indices = [idx]\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(candidate_indices) == 0:\\n\",\n",
    "    \"    raise ValueError(\\\"No suitable representative observation found. Inspect data quality and keys.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"rep_idx = test_df.loc[candidate_indices, \\\"pd_logit\\\"].idxmax()\\n\",\n",
    "    \"\\n\",\n",
    "    \"row0_raw  = df.loc[rep_idx, :].copy()\\n\",\n",
    "    \"row0_feat = df_model.loc[rep_idx, :].copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# base feature row already contains z_ columns from upstream pipeline\\n\",\n",
    "    \"base_X = row0_feat[[f\\\"z_{c}\\\" for c in continuous_feats_raw] + event_feats].to_frame().T\\n\",\n",
    "    \"base_pd = {\\\"pd_logit\\\": float(row0_feat[\\\"pd_logit\\\"]), \\\"pd_tree\\\": float(row0_feat[\\\"pd_tree\\\"])}\\n\",\n",
    "    \"base_liq = compute_liquidity_from_raw_row(row0_raw)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Representative observation (sensitivity-safe selection):\\\")\\n\",\n",
    "    \"display(df_model.loc[rep_idx, [\\\"firm_id\\\",\\\"fyear\\\",\\\"label_year\\\",\\\"pd_logit\\\",\\\"pd_tree\\\",\\\"target_next_v1\\\",\\\"target_next_v2\\\",\\\"target_next_v3\\\"]])\\n\",\n",
    "    \"print(\\\"Base PDs:\\\", base_pd)\\n\",\n",
    "    \"print(f\\\"Base liquidity: CR={base_liq['current_ratio']:.3f}, QR={base_liq['quick_ratio']:.3f}, \\\"\\n\",\n",
    "    \"      f\\\"evt_liq={base_liq['evt_liq_squeeze']:.0f}, evt_quick={base_liq['evt_quick_squeeze']:.0f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== Raw Accounting Sanity Check (Base) ===\\\")\\n\",\n",
    "    \"display(pd.DataFrame([{\\\"scenario\\\":\\\"base\\\", **{k: base_liq[k] for k in [\\\"current_ratio\\\",\\\"quick_ratio\\\",\\\"evt_liq_squeeze\\\",\\\"evt_quick_squeeze\\\"]}}]))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# -----------------------------------------------------------------------------\\n\",\n",
    "    \"# Run scenarios (ONLY cash burn + maturity wall)\\n\",\n",
    "    \"# -----------------------------------------------------------------------------\\n\",\n",
    "    \"_checkpoint(\\\"run scenarios\\\")\\n\",\n",
    "    \"scenario_rows = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"def _append_result(name: str, row_s_raw: pd.Series):\\n\",\n",
    "    \"    Xs = build_model_features_from_raw_scenario(row_s_raw, row0_feat)\\n\",\n",
    "    \"    pds = predict_pd_from_features(Xs)\\n\",\n",
    "    \"    liq = compute_liquidity_from_raw_row(row_s_raw)\\n\",\n",
    "    \"    scenario_rows.append({\\n\",\n",
    "    \"        \\\"scenario\\\": name,\\n\",\n",
    "    \"        **pds,\\n\",\n",
    "    \"        \\\"current_ratio\\\": liq[\\\"current_ratio\\\"],\\n\",\n",
    "    \"        \\\"quick_ratio\\\": liq[\\\"quick_ratio\\\"],\\n\",\n",
    "    \"        \\\"evt_liq_squeeze\\\": liq[\\\"evt_liq_squeeze\\\"],\\n\",\n",
    "    \"        \\\"evt_quick_squeeze\\\": liq[\\\"evt_quick_squeeze\\\"],\\n\",\n",
    "    \"        \\\"traffic_light\\\": get_traffic_light(pds[\\\"pd_logit\\\"], liq[\\\"evt_liq_squeeze\\\"], liq[\\\"evt_quick_squeeze\\\"]),\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"    return Xs\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Base\\n\",\n",
    "    \"_ = _append_result(\\\"base\\\", row0_raw)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# (A) Cash burn: burn fraction of ACT, reduce che/act/at; reduce ceq partially for rough coherence\\n\",\n",
    "    \"act_base = float(row0_raw.get(\\\"act\\\", 0.0) if pd.notna(row0_raw.get(\\\"act\\\", np.nan)) else 0.0)\\n\",\n",
    "    \"burn_rates = [0.10, 0.20, 0.30]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for burn in burn_rates:\\n\",\n",
    "    \"    row_s = row0_raw.copy()\\n\",\n",
    "    \"    delta = burn * act_base\\n\",\n",
    "    \"\\n\",\n",
    "    \"    che0 = float(row_s.get(\\\"che\\\", 0.0) if pd.notna(row_s.get(\\\"che\\\", np.nan)) else 0.0)\\n\",\n",
    "    \"    act0 = float(row_s.get(\\\"act\\\", 0.0) if pd.notna(row_s.get(\\\"act\\\", np.nan)) else 0.0)\\n\",\n",
    "    \"    at0  = float(row_s.get(\\\"at\\\", 0.0)  if pd.notna(row_s.get(\\\"at\\\", np.nan))  else 0.0)\\n\",\n",
    "    \"    ceq0 = row_s.get(\\\"ceq\\\", np.nan)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    row_s[\\\"che\\\"] = max(0.0, che0 - delta)\\n\",\n",
    "    \"    row_s[\\\"act\\\"] = max(0.0, act0 - delta)\\n\",\n",
    "    \"    row_s[\\\"at\\\"]  = max(1e-6, at0 - delta)  # keep positive for ln_at\\n\",\n",
    "    \"    if pd.notna(ceq0):\\n\",\n",
    "    \"        row_s[\\\"ceq\\\"] = max(0.0, float(ceq0) - 0.5 * delta)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Xs = _append_result(f\\\"cash_burn_{int(burn*100)}pct\\\", row_s)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    audit_top = sensitivity_audit(base_X, Xs, threshold=1e-4, top_k=15)\\n\",\n",
    "    \"    mat_n = audit_top.attrs.get(\\\"material_count\\\", 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"\\\\n=== Sensitivity Audit: cash_burn_{int(burn*100)}pct ===\\\")\\n\",\n",
    "    \"    print(f\\\"Features changed (|Δz|>1e-4): {mat_n}\\\")\\n\",\n",
    "    \"    display(audit_top)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# (C) Maturity wall: reclassify dltt->dlc and increase lct accordingly (dlc is part of lct)\\n\",\n",
    "    \"dlc0 = float(row0_raw.get(\\\"dlc\\\", 0.0) if pd.notna(row0_raw.get(\\\"dlc\\\", np.nan)) else 0.0)\\n\",\n",
    "    \"dltt0 = float(row0_raw.get(\\\"dltt\\\", 0.0) if pd.notna(row0_raw.get(\\\"dltt\\\", np.nan)) else 0.0)\\n\",\n",
    "    \"lct0 = float(row0_raw.get(\\\"lct\\\", 0.0) if pd.notna(row0_raw.get(\\\"lct\\\", np.nan)) else 0.0)\\n\",\n",
    "    \"total_debt0 = dlc0 + dltt0\\n\",\n",
    "    \"\\n\",\n",
    "    \"shift_rates = [0.10, 0.20]\\n\",\n",
    "    \"for sh in shift_rates:\\n\",\n",
    "    \"    row_s = row0_raw.copy()\\n\",\n",
    "    \"    shift_amt = sh * total_debt0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    row_s[\\\"dltt\\\"] = max(0.0, dltt0 - shift_amt)\\n\",\n",
    "    \"    row_s[\\\"dlc\\\"]  = dlc0 + shift_amt\\n\",\n",
    "    \"    row_s[\\\"lct\\\"]  = lct0 + shift_amt\\n\",\n",
    "    \"\\n\",\n",
    "    \"    Xs = _append_result(f\\\"maturity_wall_{int(sh*100)}pct\\\", row_s)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    audit_top = sensitivity_audit(base_X, Xs, threshold=1e-4, top_k=15)\\n\",\n",
    "    \"    mat_n = audit_top.attrs.get(\\\"material_count\\\", 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(f\\\"\\\\n=== Sensitivity Audit: maturity_wall_{int(sh*100)}pct ===\\\")\\n\",\n",
    "    \"    print(f\\\"Features changed (|Δz|>1e-4): {mat_n}\\\")\\n\",\n",
    "    \"    display(audit_top)\\n\",\n",
    "    \"\\n\",\n",
    "    \"scenario_tbl = pd.DataFrame(scenario_rows)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== Scenario Analysis Results ===\\\")\\n\",\n",
    "    \"cols = [\\\"scenario\\\",\\\"pd_logit\\\",\\\"pd_tree\\\",\\\"current_ratio\\\",\\\"quick_ratio\\\",\\\"evt_liq_squeeze\\\",\\\"evt_quick_squeeze\\\",\\\"traffic_light\\\"]\\n\",\n",
    "    \"display(scenario_tbl[cols])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n=== Liquidity Traffic Light Summary ===\\\")\\n\",\n",
    "    \"traffic_summary = scenario_tbl[[\\\"scenario\\\",\\\"pd_logit\\\",\\\"evt_liq_squeeze\\\",\\\"evt_quick_squeeze\\\",\\\"traffic_light\\\"]].copy()\\n\",\n",
    "    \"traffic_summary[\\\"pd_tier\\\"] = traffic_summary[\\\"pd_logit\\\"].apply(lambda x: \\\"Low\\\" if x < 0.2 else (\\\"Medium\\\" if x < 0.5 else \\\"High\\\"))\\n\",\n",
    "    \"display(traffic_summary)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"[9.5] finished OK\\\")\\n\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[9.5] start\\n\",\n",
    "      \"[9.5] select representative observation (t=0.00s)\\n\",\n",
    "      \"Representative observation (sensitivity-safe selection):\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"firm_id              27016\\n\",\n",
    "       \"fyear                 2023\\n\",\n",
    "       \"label_year            2024\\n\",\n",
    "       \"pd_logit          0.583143\\n\",\n",
    "       \"pd_tree           0.272727\\n\",\n",
    "       \"target_next_v1           1\\n\",\n",
    "       \"target_next_v2           1\\n\",\n",
    "       \"target_next_v3           0\\n\",\n",
    "       \"Name: 45608, dtype: object\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Base PDs: {'pd_logit': 0.5831425472726429, 'pd_tree': 0.27272728085517883}\\n\",\n",
    "      \"Base liquidity: CR=0.277, QR=0.277, evt_liq=1, evt_quick=1\\n\",\n",
    "      \"\\n\",\n",
    "      \"=== Raw Accounting Sanity Check (Base) ===\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"  scenario  current_ratio  quick_ratio  evt_liq_squeeze  evt_quick_squeeze\\n\",\n",
    "       \"0     base       0.276596     0.276596              1.0                1.0\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>scenario</th>\\n\",\n",
    "       \"      <th>current_ratio</th>\\n\",\n",
    "       \"      <th>quick_ratio</th>\\n\",\n",
    "       \"      <th>evt_liq_squeeze</th>\\n\",\n",
    "       \"      <th>evt_quick_squeeze</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>base</td>\\n\",\n",
    "       \"      <td>0.276596</td>\\n\",\n",
    "       \"      <td>0.276596</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[9.5] run scenarios (t=0.08s)\\n\",\n",
    "      \"\\n\",\n",
    "      \"=== Sensitivity Audit: cash_burn_10pct ===\\n\",\n",
    "      \"Features changed (|Δz|>1e-4): 5\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              feature    z_base  z_scenario   z_delta  abs_z_delta\\n\",\n",
    "       \"4            rect_act  0.555840    0.643948  0.088108     0.088108\\n\",\n",
    "       \"1             cash_at  1.513440    1.537595  0.024154     0.024154\\n\",\n",
    "       \"12            xint_at  0.892877    0.908309  0.015432     0.015432\\n\",\n",
    "       \"9             debt_at  0.583707    0.594866  0.011160     0.011160\\n\",\n",
    "       \"3              nwc_at -0.192743   -0.192974 -0.000232     0.000232\\n\",\n",
    "       \"8               lt_at -0.249906   -0.249806  0.000100     0.000100\\n\",\n",
    "       \"2       current_ratio -0.221931   -0.221966 -0.000036     0.000036\\n\",\n",
    "       \"0               ln_at -2.879563   -2.879563  0.000000     0.000000\\n\",\n",
    "       \"7            intan_at -0.171901   -0.171901  0.000000     0.000000\\n\",\n",
    "       \"5            invt_act -0.175649   -0.175649  0.000000     0.000000\\n\",\n",
    "       \"6            ppent_at -0.193461   -0.193461  0.000000     0.000000\\n\",\n",
    "       \"10      st_debt_share  2.179918    2.179918  0.000000     0.000000\\n\",\n",
    "       \"11          ebitda_at -7.136859   -7.136859  0.000000     0.000000\\n\",\n",
    "       \"13  interest_coverage -0.554619   -0.554619  0.000000     0.000000\\n\",\n",
    "       \"14     debt_to_ebitda -0.182357   -0.182357  0.000000     0.000000\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>feature</th>\\n\",\n",
    "       \"      <th>z_base</th>\\n\",\n",
    "       \"      <th>z_scenario</th>\\n\",\n",
    "       \"      <th>z_delta</th>\\n\",\n",
    "       \"      <th>abs_z_delta</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>rect_act</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.643948</td>\\n\",\n",
    "       \"      <td>0.088108</td>\\n\",\n",
    "       \"      <td>0.088108</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_at</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>1.537595</td>\\n\",\n",
    "       \"      <td>0.024154</td>\\n\",\n",
    "       \"      <td>0.024154</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>12</th>\\n\",\n",
    "       \"      <td>xint_at</td>\\n\",\n",
    "       \"      <td>0.892877</td>\\n\",\n",
    "       \"      <td>0.908309</td>\\n\",\n",
    "       \"      <td>0.015432</td>\\n\",\n",
    "       \"      <td>0.015432</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>debt_at</td>\\n\",\n",
    "       \"      <td>0.583707</td>\\n\",\n",
    "       \"      <td>0.594866</td>\\n\",\n",
    "       \"      <td>0.011160</td>\\n\",\n",
    "       \"      <td>0.011160</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>nwc_at</td>\\n\",\n",
    "       \"      <td>-0.192743</td>\\n\",\n",
    "       \"      <td>-0.192974</td>\\n\",\n",
    "       \"      <td>-0.000232</td>\\n\",\n",
    "       \"      <td>0.000232</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>lt_at</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>-0.249806</td>\\n\",\n",
    "       \"      <td>0.000100</td>\\n\",\n",
    "       \"      <td>0.000100</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>current_ratio</td>\\n\",\n",
    "       \"      <td>-0.221931</td>\\n\",\n",
    "       \"      <td>-0.221966</td>\\n\",\n",
    "       \"      <td>-0.000036</td>\\n\",\n",
    "       \"      <td>0.000036</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>ln_at</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>intan_at</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>invt_act</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>ppent_at</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>10</th>\\n\",\n",
    "       \"      <td>st_debt_share</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>11</th>\\n\",\n",
    "       \"      <td>ebitda_at</td>\\n\",\n",
    "       \"      <td>-7.136859</td>\\n\",\n",
    "       \"      <td>-7.136859</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>13</th>\\n\",\n",
    "       \"      <td>interest_coverage</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>14</th>\\n\",\n",
    "       \"      <td>debt_to_ebitda</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"=== Sensitivity Audit: cash_burn_20pct ===\\n\",\n",
    "      \"Features changed (|Δz|>1e-4): 6\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              feature    z_base  z_scenario   z_delta  abs_z_delta\\n\",\n",
    "       \"4            rect_act  0.555840    0.754083  0.198244     0.198244\\n\",\n",
    "       \"1             cash_at  1.513440    1.562443  0.049003     0.049003\\n\",\n",
    "       \"12            xint_at  0.892877    0.924185  0.031308     0.031308\\n\",\n",
    "       \"9             debt_at  0.583707    0.606347  0.022640     0.022640\\n\",\n",
    "       \"3              nwc_at -0.192743   -0.193213 -0.000470     0.000470\\n\",\n",
    "       \"8               lt_at -0.249906   -0.249703  0.000203     0.000203\\n\",\n",
    "       \"2       current_ratio -0.221931   -0.222002 -0.000072     0.000072\\n\",\n",
    "       \"0               ln_at -2.879563   -2.879563  0.000000     0.000000\\n\",\n",
    "       \"7            intan_at -0.171901   -0.171901  0.000000     0.000000\\n\",\n",
    "       \"5            invt_act -0.175649   -0.175649  0.000000     0.000000\\n\",\n",
    "       \"6            ppent_at -0.193461   -0.193461  0.000000     0.000000\\n\",\n",
    "       \"10      st_debt_share  2.179918    2.179918  0.000000     0.000000\\n\",\n",
    "       \"11          ebitda_at -7.136859   -7.136859  0.000000     0.000000\\n\",\n",
    "       \"13  interest_coverage -0.554619   -0.554619  0.000000     0.000000\\n\",\n",
    "       \"14     debt_to_ebitda -0.182357   -0.182357  0.000000     0.000000\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>feature</th>\\n\",\n",
    "       \"      <th>z_base</th>\\n\",\n",
    "       \"      <th>z_scenario</th>\\n\",\n",
    "       \"      <th>z_delta</th>\\n\",\n",
    "       \"      <th>abs_z_delta</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>rect_act</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.754083</td>\\n\",\n",
    "       \"      <td>0.198244</td>\\n\",\n",
    "       \"      <td>0.198244</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_at</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>1.562443</td>\\n\",\n",
    "       \"      <td>0.049003</td>\\n\",\n",
    "       \"      <td>0.049003</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>12</th>\\n\",\n",
    "       \"      <td>xint_at</td>\\n\",\n",
    "       \"      <td>0.892877</td>\\n\",\n",
    "       \"      <td>0.924185</td>\\n\",\n",
    "       \"      <td>0.031308</td>\\n\",\n",
    "       \"      <td>0.031308</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>debt_at</td>\\n\",\n",
    "       \"      <td>0.583707</td>\\n\",\n",
    "       \"      <td>0.606347</td>\\n\",\n",
    "       \"      <td>0.022640</td>\\n\",\n",
    "       \"      <td>0.022640</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>nwc_at</td>\\n\",\n",
    "       \"      <td>-0.192743</td>\\n\",\n",
    "       \"      <td>-0.193213</td>\\n\",\n",
    "       \"      <td>-0.000470</td>\\n\",\n",
    "       \"      <td>0.000470</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>lt_at</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>-0.249703</td>\\n\",\n",
    "       \"      <td>0.000203</td>\\n\",\n",
    "       \"      <td>0.000203</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>current_ratio</td>\\n\",\n",
    "       \"      <td>-0.221931</td>\\n\",\n",
    "       \"      <td>-0.222002</td>\\n\",\n",
    "       \"      <td>-0.000072</td>\\n\",\n",
    "       \"      <td>0.000072</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>ln_at</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>intan_at</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>invt_act</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>ppent_at</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>10</th>\\n\",\n",
    "       \"      <td>st_debt_share</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>11</th>\\n\",\n",
    "       \"      <td>ebitda_at</td>\\n\",\n",
    "       \"      <td>-7.136859</td>\\n\",\n",
    "       \"      <td>-7.136859</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>13</th>\\n\",\n",
    "       \"      <td>interest_coverage</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>14</th>\\n\",\n",
    "       \"      <td>debt_to_ebitda</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"=== Sensitivity Audit: cash_burn_30pct ===\\n\",\n",
    "      \"Features changed (|Δz|>1e-4): 7\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              feature    z_base  z_scenario   z_delta  abs_z_delta\\n\",\n",
    "       \"4            rect_act  0.555840    0.895686  0.339847     0.339847\\n\",\n",
    "       \"1             cash_at  1.513440    1.588017  0.074577     0.074577\\n\",\n",
    "       \"12            xint_at  0.892877    0.940524  0.047648     0.047648\\n\",\n",
    "       \"9             debt_at  0.583707    0.618163  0.034456     0.034456\\n\",\n",
    "       \"3              nwc_at -0.192743   -0.193458 -0.000715     0.000715\\n\",\n",
    "       \"8               lt_at -0.249906   -0.249598  0.000308     0.000308\\n\",\n",
    "       \"2       current_ratio -0.221931   -0.222038 -0.000107     0.000107\\n\",\n",
    "       \"0               ln_at -2.879563   -2.879563  0.000000     0.000000\\n\",\n",
    "       \"7            intan_at -0.171901   -0.171901  0.000000     0.000000\\n\",\n",
    "       \"5            invt_act -0.175649   -0.175649  0.000000     0.000000\\n\",\n",
    "       \"6            ppent_at -0.193461   -0.193461  0.000000     0.000000\\n\",\n",
    "       \"10      st_debt_share  2.179918    2.179918  0.000000     0.000000\\n\",\n",
    "       \"11          ebitda_at -7.136859   -7.136859  0.000000     0.000000\\n\",\n",
    "       \"13  interest_coverage -0.554619   -0.554619  0.000000     0.000000\\n\",\n",
    "       \"14     debt_to_ebitda -0.182357   -0.182357  0.000000     0.000000\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>feature</th>\\n\",\n",
    "       \"      <th>z_base</th>\\n\",\n",
    "       \"      <th>z_scenario</th>\\n\",\n",
    "       \"      <th>z_delta</th>\\n\",\n",
    "       \"      <th>abs_z_delta</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>rect_act</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.895686</td>\\n\",\n",
    "       \"      <td>0.339847</td>\\n\",\n",
    "       \"      <td>0.339847</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_at</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>1.588017</td>\\n\",\n",
    "       \"      <td>0.074577</td>\\n\",\n",
    "       \"      <td>0.074577</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>12</th>\\n\",\n",
    "       \"      <td>xint_at</td>\\n\",\n",
    "       \"      <td>0.892877</td>\\n\",\n",
    "       \"      <td>0.940524</td>\\n\",\n",
    "       \"      <td>0.047648</td>\\n\",\n",
    "       \"      <td>0.047648</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>debt_at</td>\\n\",\n",
    "       \"      <td>0.583707</td>\\n\",\n",
    "       \"      <td>0.618163</td>\\n\",\n",
    "       \"      <td>0.034456</td>\\n\",\n",
    "       \"      <td>0.034456</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>nwc_at</td>\\n\",\n",
    "       \"      <td>-0.192743</td>\\n\",\n",
    "       \"      <td>-0.193458</td>\\n\",\n",
    "       \"      <td>-0.000715</td>\\n\",\n",
    "       \"      <td>0.000715</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>lt_at</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>-0.249598</td>\\n\",\n",
    "       \"      <td>0.000308</td>\\n\",\n",
    "       \"      <td>0.000308</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>current_ratio</td>\\n\",\n",
    "       \"      <td>-0.221931</td>\\n\",\n",
    "       \"      <td>-0.222038</td>\\n\",\n",
    "       \"      <td>-0.000107</td>\\n\",\n",
    "       \"      <td>0.000107</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>ln_at</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>intan_at</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>invt_act</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>ppent_at</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>10</th>\\n\",\n",
    "       \"      <td>st_debt_share</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>11</th>\\n\",\n",
    "       \"      <td>ebitda_at</td>\\n\",\n",
    "       \"      <td>-7.136859</td>\\n\",\n",
    "       \"      <td>-7.136859</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>13</th>\\n\",\n",
    "       \"      <td>interest_coverage</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>14</th>\\n\",\n",
    "       \"      <td>debt_to_ebitda</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"=== Sensitivity Audit: maturity_wall_10pct ===\\n\",\n",
    "      \"Features changed (|Δz|>1e-4): 5\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              feature    z_base  z_scenario       z_delta   abs_z_delta\\n\",\n",
    "       \"9             debt_at  0.583707    0.662425  7.871851e-02  7.871851e-02\\n\",\n",
    "       \"3              nwc_at -0.192743   -0.254496 -6.175284e-02  6.175284e-02\\n\",\n",
    "       \"16        ocf_to_debt -0.114182   -0.112933  1.248666e-03  1.248666e-03\\n\",\n",
    "       \"17        fcf_to_debt  0.028396    0.029498  1.102202e-03  1.102202e-03\\n\",\n",
    "       \"2       current_ratio -0.221931   -0.222257 -3.262240e-04  3.262240e-04\\n\",\n",
    "       \"14     debt_to_ebitda -0.182357   -0.182358 -8.653001e-07  8.653001e-07\\n\",\n",
    "       \"1             cash_at  1.513440    1.513440  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"0               ln_at -2.879563   -2.879563  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"5            invt_act -0.175649   -0.175649  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"4            rect_act  0.555840    0.555840  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"8               lt_at -0.249906   -0.249906  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"7            intan_at -0.171901   -0.171901  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"6            ppent_at -0.193461   -0.193461  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"10      st_debt_share  2.179918    2.179918  0.000000e+00  0.000000e+00\\n\",\n",
    "       \"13  interest_coverage -0.554619   -0.554619  0.000000e+00  0.000000e+00\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>feature</th>\\n\",\n",
    "       \"      <th>z_base</th>\\n\",\n",
    "       \"      <th>z_scenario</th>\\n\",\n",
    "       \"      <th>z_delta</th>\\n\",\n",
    "       \"      <th>abs_z_delta</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>debt_at</td>\\n\",\n",
    "       \"      <td>0.583707</td>\\n\",\n",
    "       \"      <td>0.662425</td>\\n\",\n",
    "       \"      <td>7.871851e-02</td>\\n\",\n",
    "       \"      <td>7.871851e-02</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>nwc_at</td>\\n\",\n",
    "       \"      <td>-0.192743</td>\\n\",\n",
    "       \"      <td>-0.254496</td>\\n\",\n",
    "       \"      <td>-6.175284e-02</td>\\n\",\n",
    "       \"      <td>6.175284e-02</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>16</th>\\n\",\n",
    "       \"      <td>ocf_to_debt</td>\\n\",\n",
    "       \"      <td>-0.114182</td>\\n\",\n",
    "       \"      <td>-0.112933</td>\\n\",\n",
    "       \"      <td>1.248666e-03</td>\\n\",\n",
    "       \"      <td>1.248666e-03</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>17</th>\\n\",\n",
    "       \"      <td>fcf_to_debt</td>\\n\",\n",
    "       \"      <td>0.028396</td>\\n\",\n",
    "       \"      <td>0.029498</td>\\n\",\n",
    "       \"      <td>1.102202e-03</td>\\n\",\n",
    "       \"      <td>1.102202e-03</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>current_ratio</td>\\n\",\n",
    "       \"      <td>-0.221931</td>\\n\",\n",
    "       \"      <td>-0.222257</td>\\n\",\n",
    "       \"      <td>-3.262240e-04</td>\\n\",\n",
    "       \"      <td>3.262240e-04</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>14</th>\\n\",\n",
    "       \"      <td>debt_to_ebitda</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>-0.182358</td>\\n\",\n",
    "       \"      <td>-8.653001e-07</td>\\n\",\n",
    "       \"      <td>8.653001e-07</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_at</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>ln_at</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>invt_act</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>rect_act</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>lt_at</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>intan_at</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>ppent_at</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>10</th>\\n\",\n",
    "       \"      <td>st_debt_share</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>13</th>\\n\",\n",
    "       \"      <td>interest_coverage</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"      <td>0.000000e+00</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"=== Sensitivity Audit: maturity_wall_20pct ===\\n\",\n",
    "      \"Features changed (|Δz|>1e-4): 5\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              feature    z_base  z_scenario   z_delta  abs_z_delta\\n\",\n",
    "       \"9             debt_at  0.583707    0.741144  0.157437     0.157437\\n\",\n",
    "       \"3              nwc_at -0.192743   -0.316248 -0.123506     0.123506\\n\",\n",
    "       \"16        ocf_to_debt -0.114182   -0.111892  0.002289     0.002289\\n\",\n",
    "       \"17        fcf_to_debt  0.028396    0.030416  0.002021     0.002021\\n\",\n",
    "       \"2       current_ratio -0.221931   -0.222272 -0.000341     0.000341\\n\",\n",
    "       \"14     debt_to_ebitda -0.182357   -0.182358 -0.000002     0.000002\\n\",\n",
    "       \"1             cash_at  1.513440    1.513440  0.000000     0.000000\\n\",\n",
    "       \"0               ln_at -2.879563   -2.879563  0.000000     0.000000\\n\",\n",
    "       \"5            invt_act -0.175649   -0.175649  0.000000     0.000000\\n\",\n",
    "       \"4            rect_act  0.555840    0.555840  0.000000     0.000000\\n\",\n",
    "       \"8               lt_at -0.249906   -0.249906  0.000000     0.000000\\n\",\n",
    "       \"7            intan_at -0.171901   -0.171901  0.000000     0.000000\\n\",\n",
    "       \"6            ppent_at -0.193461   -0.193461  0.000000     0.000000\\n\",\n",
    "       \"10      st_debt_share  2.179918    2.179918  0.000000     0.000000\\n\",\n",
    "       \"13  interest_coverage -0.554619   -0.554619  0.000000     0.000000\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>feature</th>\\n\",\n",
    "       \"      <th>z_base</th>\\n\",\n",
    "       \"      <th>z_scenario</th>\\n\",\n",
    "       \"      <th>z_delta</th>\\n\",\n",
    "       \"      <th>abs_z_delta</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>debt_at</td>\\n\",\n",
    "       \"      <td>0.583707</td>\\n\",\n",
    "       \"      <td>0.741144</td>\\n\",\n",
    "       \"      <td>0.157437</td>\\n\",\n",
    "       \"      <td>0.157437</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>nwc_at</td>\\n\",\n",
    "       \"      <td>-0.192743</td>\\n\",\n",
    "       \"      <td>-0.316248</td>\\n\",\n",
    "       \"      <td>-0.123506</td>\\n\",\n",
    "       \"      <td>0.123506</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>16</th>\\n\",\n",
    "       \"      <td>ocf_to_debt</td>\\n\",\n",
    "       \"      <td>-0.114182</td>\\n\",\n",
    "       \"      <td>-0.111892</td>\\n\",\n",
    "       \"      <td>0.002289</td>\\n\",\n",
    "       \"      <td>0.002289</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>17</th>\\n\",\n",
    "       \"      <td>fcf_to_debt</td>\\n\",\n",
    "       \"      <td>0.028396</td>\\n\",\n",
    "       \"      <td>0.030416</td>\\n\",\n",
    "       \"      <td>0.002021</td>\\n\",\n",
    "       \"      <td>0.002021</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>current_ratio</td>\\n\",\n",
    "       \"      <td>-0.221931</td>\\n\",\n",
    "       \"      <td>-0.222272</td>\\n\",\n",
    "       \"      <td>-0.000341</td>\\n\",\n",
    "       \"      <td>0.000341</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>14</th>\\n\",\n",
    "       \"      <td>debt_to_ebitda</td>\\n\",\n",
    "       \"      <td>-0.182357</td>\\n\",\n",
    "       \"      <td>-0.182358</td>\\n\",\n",
    "       \"      <td>-0.000002</td>\\n\",\n",
    "       \"      <td>0.000002</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_at</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>1.513440</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>ln_at</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>-2.879563</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>invt_act</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>-0.175649</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>rect_act</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.555840</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>lt_at</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>-0.249906</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>intan_at</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>-0.171901</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>ppent_at</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>-0.193461</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>10</th>\\n\",\n",
    "       \"      <td>st_debt_share</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>2.179918</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>13</th>\\n\",\n",
    "       \"      <td>interest_coverage</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>-0.554619</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"      <td>0.000000</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"=== Scenario Analysis Results ===\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              scenario  pd_logit   pd_tree  current_ratio  quick_ratio  \\\\\\n\",\n",
    "       \"0                 base  0.583143  0.272727       0.276596     0.276596   \\n\",\n",
    "       \"1      cash_burn_10pct  0.582841  0.272727       0.248936     0.248936   \\n\",\n",
    "       \"2      cash_burn_20pct  0.582523  0.272727       0.221277     0.221277   \\n\",\n",
    "       \"3      cash_burn_30pct  0.582183  0.272727       0.193617     0.193617   \\n\",\n",
    "       \"4  maturity_wall_10pct  0.586777  0.272727       0.024668     0.024668   \\n\",\n",
    "       \"5  maturity_wall_20pct  0.590404  0.272727       0.012910     0.012910   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   evt_liq_squeeze  evt_quick_squeeze traffic_light  \\n\",\n",
    "       \"0              1.0                1.0           Red  \\n\",\n",
    "       \"1              1.0                1.0           Red  \\n\",\n",
    "       \"2              1.0                1.0           Red  \\n\",\n",
    "       \"3              1.0                1.0           Red  \\n\",\n",
    "       \"4              1.0                1.0           Red  \\n\",\n",
    "       \"5              1.0                1.0           Red  \"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>scenario</th>\\n\",\n",
    "       \"      <th>pd_logit</th>\\n\",\n",
    "       \"      <th>pd_tree</th>\\n\",\n",
    "       \"      <th>current_ratio</th>\\n\",\n",
    "       \"      <th>quick_ratio</th>\\n\",\n",
    "       \"      <th>evt_liq_squeeze</th>\\n\",\n",
    "       \"      <th>evt_quick_squeeze</th>\\n\",\n",
    "       \"      <th>traffic_light</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>base</td>\\n\",\n",
    "       \"      <td>0.583143</td>\\n\",\n",
    "       \"      <td>0.272727</td>\\n\",\n",
    "       \"      <td>0.276596</td>\\n\",\n",
    "       \"      <td>0.276596</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_burn_10pct</td>\\n\",\n",
    "       \"      <td>0.582841</td>\\n\",\n",
    "       \"      <td>0.272727</td>\\n\",\n",
    "       \"      <td>0.248936</td>\\n\",\n",
    "       \"      <td>0.248936</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>cash_burn_20pct</td>\\n\",\n",
    "       \"      <td>0.582523</td>\\n\",\n",
    "       \"      <td>0.272727</td>\\n\",\n",
    "       \"      <td>0.221277</td>\\n\",\n",
    "       \"      <td>0.221277</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>cash_burn_30pct</td>\\n\",\n",
    "       \"      <td>0.582183</td>\\n\",\n",
    "       \"      <td>0.272727</td>\\n\",\n",
    "       \"      <td>0.193617</td>\\n\",\n",
    "       \"      <td>0.193617</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>maturity_wall_10pct</td>\\n\",\n",
    "       \"      <td>0.586777</td>\\n\",\n",
    "       \"      <td>0.272727</td>\\n\",\n",
    "       \"      <td>0.024668</td>\\n\",\n",
    "       \"      <td>0.024668</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>maturity_wall_20pct</td>\\n\",\n",
    "       \"      <td>0.590404</td>\\n\",\n",
    "       \"      <td>0.272727</td>\\n\",\n",
    "       \"      <td>0.012910</td>\\n\",\n",
    "       \"      <td>0.012910</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"\\n\",\n",
    "      \"=== Liquidity Traffic Light Summary ===\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"              scenario  pd_logit  evt_liq_squeeze  evt_quick_squeeze  \\\\\\n\",\n",
    "       \"0                 base  0.583143              1.0                1.0   \\n\",\n",
    "       \"1      cash_burn_10pct  0.582841              1.0                1.0   \\n\",\n",
    "       \"2      cash_burn_20pct  0.582523              1.0                1.0   \\n\",\n",
    "       \"3      cash_burn_30pct  0.582183              1.0                1.0   \\n\",\n",
    "       \"4  maturity_wall_10pct  0.586777              1.0                1.0   \\n\",\n",
    "       \"5  maturity_wall_20pct  0.590404              1.0                1.0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"  traffic_light pd_tier  \\n\",\n",
    "       \"0           Red    High  \\n\",\n",
    "       \"1           Red    High  \\n\",\n",
    "       \"2           Red    High  \\n\",\n",
    "       \"3           Red    High  \\n\",\n",
    "       \"4           Red    High  \\n\",\n",
    "       \"5           Red    High  \"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>scenario</th>\\n\",\n",
    "       \"      <th>pd_logit</th>\\n\",\n",
    "       \"      <th>evt_liq_squeeze</th>\\n\",\n",
    "       \"      <th>evt_quick_squeeze</th>\\n\",\n",
    "       \"      <th>traffic_light</th>\\n\",\n",
    "       \"      <th>pd_tier</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>base</td>\\n\",\n",
    "       \"      <td>0.583143</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"      <td>High</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>cash_burn_10pct</td>\\n\",\n",
    "       \"      <td>0.582841</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"      <td>High</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>cash_burn_20pct</td>\\n\",\n",
    "       \"      <td>0.582523</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"      <td>High</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>cash_burn_30pct</td>\\n\",\n",
    "       \"      <td>0.582183</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"      <td>High</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>maturity_wall_10pct</td>\\n\",\n",
    "       \"      <td>0.586777</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"      <td>High</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>maturity_wall_20pct</td>\\n\",\n",
    "       \"      <td>0.590404</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>1.0</td>\\n\",\n",
    "       \"      <td>Red</td>\\n\",\n",
    "       \"      <td>High</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    },\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"[9.5] finished OK\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 114\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"757172aa\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Results Summary & Interpretation Guardrails\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 10.1 Interpretation guardrails (publication-ready language)\\n\",\n",
    "    \"\\n\",\n",
    "    \"- The label is a **constructed proxy** for balance-sheet/coverage stress; it is not a legal default outcome.\\n\",\n",
    "    \"- Coefficients and SHAP values are **associational and predictive**, not causal effects.\\n\",\n",
    "    \"- Even with leakage controls, residual mechanical endogeneity may remain because accounting choices jointly affect both predictors and the proxy label.\\n\",\n",
    "    \"- Attrition (missing next-year observations) can create sample-selection distortions; diagnostics are reported via `has_next_year_obs`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 10.2 Replication artifacts\\n\",\n",
    "    \"\\n\",\n",
    "    \"The following tables/exports are written to `outputs/` for downstream paper workflow:\\n\",\n",
    "    \"- `config_summary.json`\\n\",\n",
    "    \"- `distress_rule.json`\\n\",\n",
    "    \"- `event_dictionary.csv`\\n\",\n",
    "    \"- `logit_inference_table.csv`\\n\",\n",
    "    \"- `metrics_table.csv`\\n\",\n",
    "    \"- `predictions.csv`\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 10.3 Export tables, thresholds, and predictions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"b9838ad0\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2026-01-15T15:18:54.471848Z\",\n",
    "     \"start_time\": \"2026-01-15T15:18:53.832075Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"out_dir = Path(CONFIG[\\\"OUTPUT_DIR\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Config + distress rule\\n\",\n",
    "    \"(out_dir / \\\"config_summary.json\\\").write_text(json.dumps(CONFIG, indent=2))\\n\",\n",
    "    \"(out_dir / \\\"distress_rule.json\\\").write_text(json.dumps(DISTRESS_RULE, indent=2))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Event dictionary\\n\",\n",
    "    \"event_dict.to_csv(out_dir / \\\"event_dictionary.csv\\\", index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Logit inference table\\n\",\n",
    "    \"infer_tbl.reset_index().to_csv(out_dir / \\\"logit_inference_table.csv\\\", index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Metrics table\\n\",\n",
    "    \"metrics_tbl.to_csv(out_dir / \\\"metrics_table.csv\\\", index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Predictions export (replication-friendly)\\n\",\n",
    "    \"export_cols = [\\\"firm_id\\\",\\\"gvkey\\\",\\\"fyear\\\",\\\"label_year\\\",\\\"split\\\",\\\"target_next_v1\\\",\\\"target_next_v2\\\",\\\"target_next_v3\\\",\\\"pd_logit\\\",\\\"pd_tree\\\"]\\n\",\n",
    "    \"export_cols = [c for c in export_cols if c in df_model.columns]\\n\",\n",
    "    \"export_cols += [c for c in event_feats if c in df_model.columns]\\n\",\n",
    "    \"pred_export = df_model[export_cols].copy()\\n\",\n",
    "    \"pred_export.to_csv(out_dir / \\\"predictions.csv\\\", index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Wrote artifacts to:\\\", out_dir.resolve())\\n\",\n",
    "    \"print_df(pred_export, n=10, name=\\\"predictions.csv preview\\\")\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Wrote artifacts to: /Users/test/Desktop/Test Models/AIinFinance/outputs\\n\",\n",
    "      \"\\n\",\n",
    "      \"predictions.csv preview (top 10 rows):\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"  firm_id  gvkey  fyear  label_year  split  target_next_v1  target_next_v2  \\\\\\n\",\n",
    "       \"0   10000  10000   2014        2015  train               0               0   \\n\",\n",
    "       \"1   10000  10000   2015        2016  train               0               0   \\n\",\n",
    "       \"2   10000  10000   2016        2017  train               0               0   \\n\",\n",
    "       \"3   10000  10000   2017        2018  train               0               0   \\n\",\n",
    "       \"4   10000  10000   2018        2019  train               0               0   \\n\",\n",
    "       \"5   10000  10000   2019        2020  train               0               0   \\n\",\n",
    "       \"6   10000  10000   2020        2021  train               0               0   \\n\",\n",
    "       \"7   10000  10000   2021        2022    val               0               0   \\n\",\n",
    "       \"8   10000  10000   2022        2023   test               0               0   \\n\",\n",
    "       \"9   10000  10000   2023        2024   test               0               0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"   target_next_v3  pd_logit   pd_tree  \\n\",\n",
    "       \"0               0  0.026615  0.001177  \\n\",\n",
    "       \"1               0  0.019026  0.001177  \\n\",\n",
    "       \"2               0  0.026174  0.008772  \\n\",\n",
    "       \"3               0  0.026061  0.001177  \\n\",\n",
    "       \"4               0  0.025683  0.004044  \\n\",\n",
    "       \"5               0  0.019330  0.004044  \\n\",\n",
    "       \"6               0  0.014818  0.001177  \\n\",\n",
    "       \"7               0  0.021182  0.001177  \\n\",\n",
    "       \"8               0  0.016790  0.001177  \\n\",\n",
    "       \"9               0  0.015704  0.001177  \"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>firm_id</th>\\n\",\n",
    "       \"      <th>gvkey</th>\\n\",\n",
    "       \"      <th>fyear</th>\\n\",\n",
    "       \"      <th>label_year</th>\\n\",\n",
    "       \"      <th>split</th>\\n\",\n",
    "       \"      <th>target_next_v1</th>\\n\",\n",
    "       \"      <th>target_next_v2</th>\\n\",\n",
    "       \"      <th>target_next_v3</th>\\n\",\n",
    "       \"      <th>pd_logit</th>\\n\",\n",
    "       \"      <th>pd_tree</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2014</td>\\n\",\n",
    "       \"      <td>2015</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.026615</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2015</td>\\n\",\n",
    "       \"      <td>2016</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.019026</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2016</td>\\n\",\n",
    "       \"      <td>2017</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.026174</td>\\n\",\n",
    "       \"      <td>0.008772</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2017</td>\\n\",\n",
    "       \"      <td>2018</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.026061</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2018</td>\\n\",\n",
    "       \"      <td>2019</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.025683</td>\\n\",\n",
    "       \"      <td>0.004044</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>5</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2019</td>\\n\",\n",
    "       \"      <td>2020</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.019330</td>\\n\",\n",
    "       \"      <td>0.004044</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>6</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2020</td>\\n\",\n",
    "       \"      <td>2021</td>\\n\",\n",
    "       \"      <td>train</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.014818</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>7</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2021</td>\\n\",\n",
    "       \"      <td>2022</td>\\n\",\n",
    "       \"      <td>val</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.021182</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>8</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2022</td>\\n\",\n",
    "       \"      <td>2023</td>\\n\",\n",
    "       \"      <td>test</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.016790</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>9</th>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>10000</td>\\n\",\n",
    "       \"      <td>2023</td>\\n\",\n",
    "       \"      <td>2024</td>\\n\",\n",
    "       \"      <td>test</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0.015704</td>\\n\",\n",
    "       \"      <td>0.001177</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"display_data\",\n",
    "     \"jetTransient\": {\n",
    "      \"display_id\": null\n",
    "     }\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 115\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"50eece1d\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 10.4 Deployment and maintenance (future work)\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook produces a research-grade replication pipeline. For production use (not required for journal replication), a minimal MLOps extension would include:\\n\",\n",
    "    \"- scheduled re-scoring and monitoring for drift in feature distributions and target prevalence,\\n\",\n",
    "    \"- retraining triggers and versioned model registry,\\n\",\n",
    "    \"- data validation contracts (schema + unit tests) for the upstream Compustat extraction process.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "b0d866a5e55d5395"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
