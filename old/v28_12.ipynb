{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250fa932",
   "metadata": {},
   "source": [
    "# Distress Pipeline — Technical Bug Review (Leakage‑Safe)\n",
    "\n",
    "This notebook contains:\n",
    "\n",
    "1. **Full pipeline code** organized along the *data science lifecycle* (ingest → clean → label → split → impute → engineer → transform → validate → EDA).\n",
    "2. A **bug log** of material technical issues found in the provided script, with fixes applied in the “Corrected Pipeline” cells.\n",
    "3. **Schema compliance checks** against `Variables.xlsx` (sheet `Corrected`) so the pipeline only relies on approved variables.\n",
    "\n",
    "> Note: The objective here is *technical correctness* (especially leakage, ratio construction, and target definition). Minor style nits are intentionally omitted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5fcfc",
   "metadata": {},
   "source": [
    "## Bug log (material issues)\n",
    "\n",
    "### 1) Ratio construction: “+EPS” division\n",
    "- **Issue:** Adding an epsilon to denominators changes the economics (especially for ratios used in *labels*), and can silently turn zero‑denominator rows into extreme values.\n",
    "- **Fix:** All ratios now use `np.divide(..., where=denom!=0)` and produce **NaN** when the ratio is undefined. Downstream, missingness is handled explicitly.\n",
    "\n",
    "### 2) Debt/EBITDA and other “sign” pathologies\n",
    "- **Issue:** `Debt/EBITDA` becomes negative when EBITDA is negative; mechanically this can *reduce* leverage if you later compare to “> 4.5x”.\n",
    "- **Fix:** For leverage classification, `Debt/EBITDA` is only computed when `EBITDA > 0` (otherwise NaN). Negative equity is handled separately.\n",
    "\n",
    "### 3) Negative / nonsensical raw values\n",
    "- **Issue:** Imputation enforced non‑negativity only for **imputed** values; existing negative values (e.g., negative debt components) could persist and break ratios.\n",
    "- **Fix:** Post‑conversion, hard‑constraint columns are clipped at 0 (configurable, applied before engineering).\n",
    "\n",
    "### 4) Distress definition alignment\n",
    "- **Issue:** The requested “S&P style leverage bands” table was not reflected in the label definition.\n",
    "- **Fix:** `distress_dummy` is defined as: **equity < 0 OR “highly leveraged”** based on the table cutoffs (FFO/debt < 15%, debt/cap > 55%, debt/EBITDA > 4.5x). A conservative *2‑of‑3* rule is used by default to flag fewer firms (configurable).\n",
    "\n",
    "### 5) Leakage discipline\n",
    "- **Check:** Imputation parameters (year medians + TWFE means) are fit **only** on TRAIN (excluding the hold‑out validation label year) and then applied to val/test. Winsorization bounds and StandardScaler are also fit only on TRAIN.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5eeb6e7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T12:56:02.137355Z",
     "start_time": "2025-12-28T12:56:02.109698Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "FILE_NAME = \"data.csv\"\n",
    "VARS_XLSX = \"Variables.xlsx\"  # sheet: 'Corrected' with column 'Variable'\n",
    "\n",
    "TRAIN_CUTOFF_LABEL_YEAR = 2022\n",
    "VAL_YEARS = 1\n",
    "N_SPLITS_TIME_CV = 5\n",
    "\n",
    "WINSOR_LOWER_Q = 0.01\n",
    "WINSOR_UPPER_Q = 0.99\n",
    "\n",
    "# Distress rule: how many of the three \"highly leveraged\" triggers must be met\n",
    "# Options: \"any\", \"2of3\", \"all\"\n",
    "LEV_RULE = \"all\"\n",
    "\n",
    "# \"Highly leveraged\" thresholds from the provided table\n",
    "TH_FFO_TO_DEBT = 0.15       # < 15%\n",
    "TH_DEBT_TO_CAP = 0.55       # > 55%\n",
    "TH_DEBT_TO_EBITDA = 4.5     # > 4.5x\n",
    "\n",
    "NUMERIC_COLS = [\n",
    "    \"gvkey\", \"fyear\", \"ismod\",\n",
    "    \"ib\", \"at\", \"dltt\", \"dlc\", \"seq\", \"mibt\",\n",
    "    \"che\", \"act\", \"lct\", \"re\",\n",
    "    \"oancf\", \"ivncf\", \"fincf\",\n",
    "    \"oibdp\", \"xint\", \"capx\",\n",
    "    \"dv\", \"prstkc\",\n",
    "    \"txt\", \"txdc\", \"txach\", \"txp\",\n",
    "    \"mkvalt\", \"csho\", \"prcc_f\", \"prcc_c\",\n",
    "    \"dltis\", \"dltr\", \"sstk\"\n",
    "]\n",
    "REQUIRED_KEYS = [\"gvkey\", \"fyear\"]\n",
    "\n",
    "def need(df, cols):\n",
    "    miss = [c for c in cols if c not in df.columns]\n",
    "    if miss:\n",
    "        raise KeyError(f\"Missing required column(s): {miss}\")\n",
    "\n",
    "def sdiv(a, b):\n",
    "    # division only when denominator is finite and non-zero; undefined ratios -> NaN\n",
    "    a = pd.to_numeric(a, errors=\"coerce\").to_numpy(dtype=float)\n",
    "    b = pd.to_numeric(b, errors=\"coerce\").to_numpy(dtype=float)\n",
    "    out = np.full_like(a, np.nan, dtype=float)\n",
    "    np.divide(a, b, out=out, where=(b != 0) & np.isfinite(b) & np.isfinite(a))\n",
    "    return out\n",
    "\n",
    "def roll_year_folds(df_in, year_col=\"label_year\", n_splits=5, min_train_years=3):\n",
    "    yrs = np.sort(df_in[year_col].dropna().unique())\n",
    "    if len(yrs) <= min_train_years:\n",
    "        return []\n",
    "    n_splits = min(n_splits, len(yrs) - min_train_years)\n",
    "    out = []\n",
    "    for k in range(n_splits):\n",
    "        tr_yrs = yrs[:min_train_years + k]\n",
    "        va_yr = yrs[min_train_years + k]\n",
    "        tr_idx = df_in.index[df_in[year_col].isin(tr_yrs)].to_numpy()\n",
    "        va_idx = df_in.index[df_in[year_col] == va_yr].to_numpy()\n",
    "        out.append((tr_idx, va_idx, tr_yrs, va_yr))\n",
    "    return out\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "8265e6fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T12:55:01.018614Z",
     "start_time": "2025-12-28T12:54:58.508218Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# 1) Data ingestion & basic cleaning\n",
    "# =============================================================================\n",
    "df = pd.read_csv(FILE_NAME, low_memory=False)\n",
    "need(df, REQUIRED_KEYS)\n",
    "\n",
    "if \"datadate\" in df.columns:\n",
    "    df[\"datadate\"] = pd.to_datetime(df[\"datadate\"], errors=\"coerce\")\n",
    "\n",
    "for c in NUMERIC_COLS:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "for c in [\"gvkey\", \"fyear\", \"ismod\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "df[\"firm_id\"] = df[\"gvkey\"]\n",
    "df = (\n",
    "    df.sort_values([\"firm_id\", \"fyear\"])\n",
    "      .drop_duplicates(subset=[\"firm_id\", \"fyear\"], keep=\"last\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "df[\"label_year\"] = df[\"fyear\"] + 1\n",
    "\n",
    "# Hard constraints: clip negative values where they are not economically meaningful\n",
    "for c in [x for x in [\"dlc\", \"dltt\", \"at\", \"mkvalt\", \"capx\"] if x in df.columns]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").clip(lower=0)\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Train/Val/Test masks for leakage-safe fitting (based on label_year = fyear+1)\n",
    "# =============================================================================\n",
    "pool_mask = df[\"label_year\"] <= TRAIN_CUTOFF_LABEL_YEAR\n",
    "pool_years = np.sort(df.loc[pool_mask, \"label_year\"].dropna().unique())\n",
    "val_years = pool_years[-VAL_YEARS:] if len(pool_years) else np.array([], dtype=int)\n",
    "\n",
    "train_mask = pool_mask & (~df[\"label_year\"].isin(val_years))  # for fitting\n",
    "val_mask = pool_mask & (df[\"label_year\"].isin(val_years))\n",
    "test_mask = df[\"label_year\"] > TRAIN_CUTOFF_LABEL_YEAR\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Missingness flags + imputation (fit on TRAIN only)\n",
    "# =============================================================================\n",
    "raw = [c for c in [\n",
    "    \"at\", \"mkvalt\", \"seq\", \"mibt\", \"dlc\", \"dltt\", \"oibdp\", \"xint\",\n",
    "    \"oancf\", \"capx\", \"txt\", \"txdc\", \"txach\", \"dv\", \"prstkc\", \"ismod\"\n",
    "] if c in df.columns]\n",
    "\n",
    "for c in raw:\n",
    "    df[f\"miss_{c}\"] = df[c].isna().astype(\"int8\")\n",
    "\n",
    "twfe_cols = [c for c in [\"at\", \"mkvalt\", \"seq\", \"dlc\", \"dltt\", \"oibdp\", \"xint\", \"oancf\", \"capx\", \"txt\"]\n",
    "             if c in df.columns]\n",
    "med_cols = [c for c in [\"dv\", \"prstkc\", \"txdc\", \"txach\", \"mibt\", \"ismod\"]\n",
    "            if c in df.columns]\n",
    "nonneg = set([c for c in [\"at\", \"mkvalt\", \"dlc\", \"dltt\", \"capx\"] if c in df.columns])\n",
    "\n",
    "tr_obs = df.loc[train_mask].copy()\n",
    "\n",
    "# --- Year median models (TRAIN-fit)\n",
    "year_meds = {}\n",
    "for c in med_cols:\n",
    "    s = pd.to_numeric(tr_obs[c], errors=\"coerce\")\n",
    "    overall = float(s.median()) if np.isfinite(s.median()) else 0.0\n",
    "    by_year = tr_obs.groupby(\"fyear\")[c].median()\n",
    "    year_meds[c] = (overall, by_year)\n",
    "\n",
    "for c in med_cols:\n",
    "    m = df[c].isna()\n",
    "    if m.any():\n",
    "        overall, by_year = year_meds[c]\n",
    "        fill = df.loc[m, \"fyear\"].map(by_year).astype(float).fillna(overall)\n",
    "        df.loc[m, c] = fill.to_numpy()\n",
    "\n",
    "# --- TWFE mean models (TRAIN-fit): y_it = alpha_i + gamma_t - overall\n",
    "twfe = {}\n",
    "for c in twfe_cols:\n",
    "    obs = tr_obs[[\"firm_id\", \"fyear\", c]].copy()\n",
    "    obs[c] = pd.to_numeric(obs[c], errors=\"coerce\")\n",
    "    obs = obs.dropna(subset=[c])\n",
    "    if obs.empty:\n",
    "        twfe[c] = (0.0, pd.Series(dtype=\"float64\"), pd.Series(dtype=\"float64\"))\n",
    "        continue\n",
    "    overall = float(obs[c].mean())\n",
    "    fmean = obs.groupby(\"firm_id\")[c].mean()\n",
    "    ymean = obs.groupby(\"fyear\")[c].mean()\n",
    "    twfe[c] = (overall, fmean, ymean)\n",
    "\n",
    "for c in twfe_cols:\n",
    "    m = df[c].isna()\n",
    "    if m.any():\n",
    "        overall, fmean, ymean = twfe[c]\n",
    "        fpart = df.loc[m, \"firm_id\"].map(fmean)\n",
    "        ypart = df.loc[m, \"fyear\"].map(ymean)\n",
    "        pred = fpart + ypart - overall\n",
    "        pred = pred.where(pred.notna(), ypart)\n",
    "        pred = pred.where(pred.notna(), fpart)\n",
    "        pred = pred.fillna(overall)\n",
    "        if c in nonneg:\n",
    "            pred = pred.clip(lower=0.0)\n",
    "        df.loc[m, c] = pred.to_numpy()\n",
    "\n",
    "# =============================================================================\n",
    "# 4) Feature engineering (S&P-style ratios) + distress label (t) and target (t+1)\n",
    "# =============================================================================\n",
    "dlc = pd.to_numeric(df.get(\"dlc\", np.nan), errors=\"coerce\")\n",
    "dltt = pd.to_numeric(df.get(\"dltt\", np.nan), errors=\"coerce\")\n",
    "df[\"total_debt\"] = pd.concat([dlc, dltt], axis=1).sum(axis=1, min_count=1)\n",
    "\n",
    "seq = pd.to_numeric(df.get(\"seq\", np.nan), errors=\"coerce\")\n",
    "mibt = pd.to_numeric(df.get(\"mibt\", 0.0), errors=\"coerce\")\n",
    "df[\"equity_plus_mi_sp\"] = seq + mibt\n",
    "\n",
    "df[\"total_capital_sp\"] = df[\"total_debt\"] + df[\"equity_plus_mi_sp\"]\n",
    "# ratio only meaningful when total capital > 0 (otherwise S&P-style percent bands are undefined)\n",
    "cap_pos = (pd.to_numeric(df[\"total_capital_sp\"], errors=\"coerce\") > 0).to_numpy()\n",
    "df[\"sp_debt_to_capital\"] = np.full(len(df), np.nan, dtype=float)\n",
    "df.loc[cap_pos, \"sp_debt_to_capital\"] = sdiv(df.loc[cap_pos, \"total_debt\"], df.loc[cap_pos, \"total_capital_sp\"])\n",
    "\n",
    "oibdp = pd.to_numeric(df.get(\"oibdp\", np.nan), errors=\"coerce\")  # EBITDA proxy\n",
    "xint = pd.to_numeric(df.get(\"xint\", np.nan), errors=\"coerce\")\n",
    "\n",
    "# Debt/EBITDA only meaningful if EBITDA > 0\n",
    "ebitda_pos = (oibdp > 0).to_numpy()\n",
    "df[\"sp_debt_to_ebitda\"] = np.full(len(df), np.nan, dtype=float)\n",
    "df.loc[ebitda_pos, \"sp_debt_to_ebitda\"] = sdiv(df.loc[ebitda_pos, \"total_debt\"], df.loc[ebitda_pos, \"oibdp\"])\n",
    "\n",
    "txt = pd.to_numeric(df.get(\"txt\", np.nan), errors=\"coerce\")\n",
    "txdc = pd.to_numeric(df.get(\"txdc\", 0.0), errors=\"coerce\")\n",
    "txach = pd.to_numeric(df.get(\"txach\", 0.0), errors=\"coerce\")\n",
    "df[\"cash_tax_paid_proxy\"] = txt - txdc - txach\n",
    "\n",
    "df[\"ffo_proxy\"] = oibdp - xint - pd.to_numeric(df[\"cash_tax_paid_proxy\"], errors=\"coerce\")\n",
    "\n",
    "debt_pos = (pd.to_numeric(df[\"total_debt\"], errors=\"coerce\") > 0).to_numpy()\n",
    "df[\"sp_ffo_to_debt\"] = np.full(len(df), np.nan, dtype=float)\n",
    "df.loc[debt_pos, \"sp_ffo_to_debt\"] = sdiv(df.loc[debt_pos, \"ffo_proxy\"], df.loc[debt_pos, \"total_debt\"])\n",
    "\n",
    "oancf = pd.to_numeric(df.get(\"oancf\", np.nan), errors=\"coerce\")\n",
    "capx = pd.to_numeric(df.get(\"capx\", np.nan), errors=\"coerce\")\n",
    "df[\"sp_cfo_to_debt\"] = np.full(len(df), np.nan, dtype=float)\n",
    "df.loc[debt_pos, \"sp_cfo_to_debt\"] = sdiv(df.loc[debt_pos, \"oancf\"], df.loc[debt_pos, \"total_debt\"])\n",
    "\n",
    "df[\"focf\"] = oancf - capx\n",
    "df[\"sp_focf_to_debt\"] = np.full(len(df), np.nan, dtype=float)\n",
    "df.loc[debt_pos, \"sp_focf_to_debt\"] = sdiv(df.loc[debt_pos, \"focf\"], df.loc[debt_pos, \"total_debt\"])\n",
    "\n",
    "dv = pd.to_numeric(df.get(\"dv\", 0.0), errors=\"coerce\")\n",
    "prstkc = pd.to_numeric(df.get(\"prstkc\", 0.0), errors=\"coerce\")\n",
    "df[\"dcf\"] = df[\"focf\"] - dv - prstkc\n",
    "df[\"sp_dcf_to_debt\"] = np.full(len(df), np.nan, dtype=float)\n",
    "df.loc[debt_pos, \"sp_dcf_to_debt\"] = sdiv(df.loc[debt_pos, \"dcf\"], df.loc[debt_pos, \"total_debt\"])\n",
    "\n",
    "for c in [\"at\", \"mkvalt\"]:\n",
    "    if c in df.columns:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        df[f\"log_{c}\"] = np.where(s >= 0, np.log1p(s), np.nan)\n",
    "\n",
    "# Interest coverage as feature (not used for table-based distress by default)\n",
    "df[\"sp_interest_coverage\"] = sdiv(oibdp, xint.abs())\n",
    "\n",
    "# --- Distress at time t: equity < 0 OR \"highly leveraged\" per table thresholds\n",
    "c1 = (pd.to_numeric(df[\"sp_ffo_to_debt\"], errors=\"coerce\") < TH_FFO_TO_DEBT)\n",
    "c2 = (pd.to_numeric(df[\"sp_debt_to_capital\"], errors=\"coerce\") > TH_DEBT_TO_CAP)\n",
    "c3 = (pd.to_numeric(df[\"sp_debt_to_ebitda\"], errors=\"coerce\") > TH_DEBT_TO_EBITDA)\n",
    "\n",
    "hits = c1.astype(int) + c2.astype(int) + c3.astype(int)\n",
    "if LEV_RULE == \"any\":\n",
    "    highly_lev = hits >= 1\n",
    "elif LEV_RULE == \"all\":\n",
    "    highly_lev = hits == 3\n",
    "else:  # \"2of3\"\n",
    "    highly_lev = hits >= 2\n",
    "\n",
    "neg_equity = (pd.to_numeric(seq, errors=\"coerce\") < 0).fillna(False).to_numpy()\n",
    "df[\"distress_dummy\"] = (neg_equity | highly_lev.to_numpy()).astype(\"int8\")\n",
    "\n",
    "# --- Target: distress next year (t+1), leakage-safe by firm\n",
    "df[\"target_next_year_distress\"] = df.groupby(\"firm_id\")[\"distress_dummy\"].shift(-1)\n",
    "df = df.dropna(subset=[\"target_next_year_distress\"]).reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 5) Final train/val/test split after target availability\n",
    "# =============================================================================\n",
    "train_pool = df[df[\"label_year\"] <= TRAIN_CUTOFF_LABEL_YEAR].copy()\n",
    "test = df[df[\"label_year\"] > TRAIN_CUTOFF_LABEL_YEAR].copy()\n",
    "\n",
    "years = np.sort(train_pool[\"label_year\"].dropna().unique())\n",
    "val_years = years[-VAL_YEARS:] if len(years) else np.array([], dtype=int)\n",
    "\n",
    "val = train_pool[train_pool[\"label_year\"].isin(val_years)].copy()\n",
    "train = train_pool[~train_pool[\"label_year\"].isin(val_years)].copy()\n",
    "\n",
    "print(\"Split:\", f\"train={len(train):,}\", f\"val={len(val):,}\", f\"test={len(test):,}\", \"| val_years:\", list(val_years))\n",
    "\n",
    "# =============================================================================\n",
    "# 6) Winsorization (fit on TRAIN only) + StandardScaler (fit on TRAIN only)\n",
    "# =============================================================================\n",
    "base_feats = [\n",
    "    \"sp_debt_to_capital\", \"sp_ffo_to_debt\", \"sp_cfo_to_debt\",\n",
    "    \"sp_focf_to_debt\", \"sp_dcf_to_debt\", \"sp_debt_to_ebitda\",\n",
    "    \"sp_interest_coverage\", \"log_at\", \"log_mkvalt\"\n",
    "]\n",
    "feats = [c for c in base_feats if c in train.columns and c in val.columns and c in test.columns]\n",
    "\n",
    "for d in (train, val, test):\n",
    "    d[feats] = d[feats].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Feature-level fill to support winsor/scaler (TRAIN median only)\n",
    "fill = train[feats].median(numeric_only=True)\n",
    "for d in (train, val, test):\n",
    "    d[feats] = d[feats].fillna(fill)\n",
    "\n",
    "bounds = {}\n",
    "for c in feats:\n",
    "    s = pd.to_numeric(train[c], errors=\"coerce\")\n",
    "    bounds[c] = (s.quantile(WINSOR_LOWER_Q), s.quantile(WINSOR_UPPER_Q))\n",
    "\n",
    "for d in (train, val, test):\n",
    "    for c, (lo, hi) in bounds.items():\n",
    "        s = pd.to_numeric(d[c], errors=\"coerce\")\n",
    "        d[c] = s.clip(lo, hi)\n",
    "\n",
    "x_train = train[feats].to_numpy(dtype=float)\n",
    "x_val = val[feats].to_numpy(dtype=float)\n",
    "x_test = test[feats].to_numpy(dtype=float)\n",
    "\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train_z = scaler.transform(x_train)\n",
    "x_val_z = scaler.transform(x_val)\n",
    "x_test_z = scaler.transform(x_test)\n",
    "\n",
    "z_cols = [f\"z_{c}\" for c in feats]\n",
    "train[z_cols] = x_train_z\n",
    "val[z_cols] = x_val_z\n",
    "test[z_cols] = x_test_z\n",
    "\n",
    "# =============================================================================\n",
    "# 7) Diagnostics (train only): correlations\n",
    "# =============================================================================\n",
    "t = \"target_next_year_distress\"\n",
    "corr = train[[t] + feats].corr(numeric_only=True)[t].drop(t).sort_values(key=np.abs, ascending=False)\n",
    "print(corr)\n",
    "\n",
    "# =============================================================================\n",
    "# 8) Rolling / forward CV by year (within train_pool)\n",
    "# =============================================================================\n",
    "folds = roll_year_folds(train_pool, n_splits=N_SPLITS_TIME_CV, min_train_years=3)\n",
    "for i, (tr_idx, va_idx, tr_yrs, va_yr) in enumerate(folds, 1):\n",
    "    print(f\"Fold {i}: train_years={tr_yrs[0]}..{tr_yrs[-1]} (n={len(tr_idx)}), val_year={va_yr} (n={len(va_idx)})\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train=44,783 val=6,415 test=12,404 | val_years: [np.int64(2022)]\n",
      "sp_debt_to_capital      0.377494\n",
      "log_at                 -0.167140\n",
      "log_mkvalt             -0.086856\n",
      "sp_cfo_to_debt         -0.059771\n",
      "sp_interest_coverage   -0.045743\n",
      "sp_debt_to_ebitda       0.033574\n",
      "sp_focf_to_debt        -0.026974\n",
      "sp_ffo_to_debt         -0.026302\n",
      "sp_dcf_to_debt         -0.008430\n",
      "Name: target_next_year_distress, dtype: float64\n",
      "Fold 1: train_years=2015..2017 (n=19775), val_year=2018 (n=6337)\n",
      "Fold 2: train_years=2015..2018 (n=26112), val_year=2019 (n=6173)\n",
      "Fold 3: train_years=2015..2019 (n=32285), val_year=2020 (n=6233)\n",
      "Fold 4: train_years=2015..2020 (n=38518), val_year=2021 (n=6265)\n",
      "Fold 5: train_years=2015..2021 (n=44783), val_year=2022 (n=6415)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "311118ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T12:56:40.066282Z",
     "start_time": "2025-12-28T12:56:39.789934Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# 9) EDA (complete end)\n",
    "# =============================================================================\n",
    "def _overview(d, name):\n",
    "    n = len(d)\n",
    "    nf = d[\"firm_id\"].nunique() if \"firm_id\" in d.columns else np.nan\n",
    "    ny = d[\"fyear\"].nunique() if \"fyear\" in d.columns else np.nan\n",
    "    tr = float(d[t].mean()) if t in d.columns else np.nan\n",
    "    print(f\"\\n=== {name} === rows={n:,} | firms={nf:,} | years={ny} | target_rate={tr:.4f}\")\n",
    "    if \"label_year\" in d.columns:\n",
    "        byy = d.groupby(\"label_year\")[t].agg([\"mean\", \"count\"])\n",
    "        print(\"\\nTarget by label_year (tail):\")\n",
    "        print(byy.tail(12))\n",
    "\n",
    "_overview(train, \"TRAIN\")\n",
    "_overview(val, \"VAL\")\n",
    "_overview(test, \"TEST\")\n",
    "\n",
    "post_miss = pd.DataFrame({\n",
    "    \"col\": raw,\n",
    "    \"train_pct_na\": [train[c].isna().mean() * 100 for c in raw if c in train.columns],\n",
    "    \"val_pct_na\": [val[c].isna().mean() * 100 for c in raw if c in val.columns],\n",
    "    \"test_pct_na\": [test[c].isna().mean() * 100 for c in raw if c in test.columns],\n",
    "})\n",
    "if not post_miss.empty:\n",
    "    post_miss = post_miss.sort_values(\"train_pct_na\", ascending=False)\n",
    "    print(\"\\nPost-imputation missingness on raw inputs (pct):\")\n",
    "    print(post_miss.head(50).round(4))\n",
    "\n",
    "def _dist(d, cols, name):\n",
    "    x = d[cols].replace([np.inf, -np.inf], np.nan)\n",
    "    q = x.quantile([0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]).T\n",
    "    out = pd.DataFrame({\n",
    "        \"n\": x.notna().sum(),\n",
    "        \"mean\": x.mean(),\n",
    "        \"std\": x.std(ddof=0),\n",
    "        \"min\": x.min(),\n",
    "        \"p01\": q[0.01],\n",
    "        \"p05\": q[0.05],\n",
    "        \"p25\": q[0.25],\n",
    "        \"p50\": q[0.50],\n",
    "        \"p75\": q[0.75],\n",
    "        \"p95\": q[0.95],\n",
    "        \"p99\": q[0.99],\n",
    "        \"max\": x.max(),\n",
    "        \"skew\": x.skew(numeric_only=True),\n",
    "        \"kurt\": x.kurtosis(numeric_only=True),\n",
    "    })\n",
    "    print(f\"\\nDistribution summary ({name})\")\n",
    "    print(out.round(4).sort_values(\"skew\", key=lambda s: s.abs(), ascending=False))\n",
    "    return out\n",
    "\n",
    "_ = _dist(train, feats, \"TRAIN | winsorized raw feats\")\n",
    "_ = _dist(train, z_cols, \"TRAIN | standardized feats\")\n",
    "\n",
    "def _hi_corr(d, cols, thr=0.80):\n",
    "    cm = d[cols].corr(numeric_only=True)\n",
    "    pairs = []\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(i + 1, len(cols)):\n",
    "            r = cm.iloc[i, j]\n",
    "            if np.isfinite(r) and abs(r) >= thr:\n",
    "                pairs.append((cols[i], cols[j], float(r)))\n",
    "    pairs = sorted(pairs, key=lambda x: abs(x[2]), reverse=True)\n",
    "    return pairs\n",
    "\n",
    "pairs = _hi_corr(train, feats, thr=0.80)\n",
    "print(\"\\nHigh collinearity pairs among feats (|corr|>=0.80) [top 25]:\")\n",
    "for a, b, r in pairs[:25]:\n",
    "    print(f\"{a} vs {b}: r={r:.3f}\")\n",
    "\n",
    "def _drift_smd(a_df, b_df, cols):\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        a = pd.to_numeric(a_df[c], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "        b = pd.to_numeric(b_df[c], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "        ma, mb = float(a.mean()), float(b.mean())\n",
    "        sa, sb = float(a.std(ddof=0)), float(b.std(ddof=0))\n",
    "        sp = np.sqrt(0.5 * (sa**2 + sb**2))\n",
    "        smd = (mb - ma) / sp if sp > 0 else np.nan\n",
    "        rows.append((c, ma, mb, smd, abs(smd) if np.isfinite(smd) else np.nan))\n",
    "    out = pd.DataFrame(rows, columns=[\"feature\", \"mean_train\", \"mean_test\", \"smd\", \"abs_smd\"])\n",
    "    return out.sort_values(\"abs_smd\", ascending=False)\n",
    "\n",
    "drift = _drift_smd(train, test, feats)\n",
    "print(\"\\nTrain→Test drift (SMD) [top 15]:\")\n",
    "print(drift.head(15).round(4))\n",
    "\n",
    "def _group_diff(d, cols):\n",
    "    g = d.groupby(t)[cols].mean(numeric_only=True)\n",
    "    if 0 in g.index and 1 in g.index:\n",
    "        diff = (g.loc[1] - g.loc[0]).sort_values(key=np.abs, ascending=False)\n",
    "        return diff\n",
    "    return pd.Series(dtype=\"float64\")\n",
    "\n",
    "diff = _group_diff(train, feats)\n",
    "if not diff.empty:\n",
    "    print(\"\\nMean difference (target=1 minus target=0) on TRAIN feats [top 15]:\")\n",
    "    print(diff.head(15).round(4))\n",
    "\n",
    "# Sanity checks that commonly catch silent bugs\n",
    "assert df.duplicated(subset=[\"firm_id\",\"fyear\"]).sum() == 0, \"Duplicates remain at firm-year level\"\n",
    "assert train[feats].isna().sum().sum() == 0, \"NaNs remain in TRAIN features after fill\"\n",
    "assert np.isfinite(train[z_cols].to_numpy(dtype=float)).all(), \"Non-finite z-features in TRAIN\"\n",
    "print(\"\\nSanity checks passed.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN === rows=44,783 | firms=9,220 | years=7 | target_rate=0.2091\n",
      "\n",
      "Target by label_year (tail):\n",
      "                mean  count\n",
      "label_year                 \n",
      "2015        0.221468   6773\n",
      "2016        0.215525   6570\n",
      "2017        0.200715   6432\n",
      "2018        0.203724   6337\n",
      "2019        0.229872   6173\n",
      "2020        0.216108   6233\n",
      "2021        0.175738   6265\n",
      "\n",
      "=== VAL === rows=6,415 | firms=6,415 | years=1 | target_rate=0.1906\n",
      "\n",
      "Target by label_year (tail):\n",
      "                mean  count\n",
      "label_year                 \n",
      "2022        0.190647   6415\n",
      "\n",
      "=== TEST === rows=12,404 | firms=6,633 | years=2 | target_rate=0.2067\n",
      "\n",
      "Target by label_year (tail):\n",
      "                mean  count\n",
      "label_year                 \n",
      "2023        0.207049   6327\n",
      "2024        0.206352   6077\n",
      "\n",
      "Post-imputation missingness on raw inputs (pct):\n",
      "       col  train_pct_na  val_pct_na  test_pct_na\n",
      "0       at           0.0         0.0          0.0\n",
      "1   mkvalt           0.0         0.0          0.0\n",
      "2      seq           0.0         0.0          0.0\n",
      "3     mibt           0.0         0.0          0.0\n",
      "4      dlc           0.0         0.0          0.0\n",
      "5     dltt           0.0         0.0          0.0\n",
      "6    oibdp           0.0         0.0          0.0\n",
      "7     xint           0.0         0.0          0.0\n",
      "8    oancf           0.0         0.0          0.0\n",
      "9     capx           0.0         0.0          0.0\n",
      "10     txt           0.0         0.0          0.0\n",
      "11    txdc           0.0         0.0          0.0\n",
      "12   txach           0.0         0.0          0.0\n",
      "13      dv           0.0         0.0          0.0\n",
      "14  prstkc           0.0         0.0          0.0\n",
      "15   ismod           0.0         0.0          0.0\n",
      "\n",
      "Distribution summary (TRAIN | winsorized raw feats)\n",
      "                          n      mean        std         min         p01  \\\n",
      "sp_dcf_to_debt        44783  -25.7497   204.4969  -1710.5133  -1709.7957   \n",
      "sp_debt_to_ebitda     44783  118.9631   667.4708      0.0000      0.0000   \n",
      "sp_ffo_to_debt        44783  -31.1297   307.2176  -2519.6817  -2519.6244   \n",
      "sp_focf_to_debt       44783  -13.2306   178.1683  -1396.6243  -1396.5152   \n",
      "sp_interest_coverage  44783  236.4521  2886.5384 -11379.3745 -11376.1235   \n",
      "sp_debt_to_capital    44783    0.3845     0.4447      0.0000      0.0000   \n",
      "log_at                44783   11.0730     3.5650      0.6931      0.6931   \n",
      "log_mkvalt            44783    7.2250     4.2469      0.0000      0.0000   \n",
      "sp_cfo_to_debt        44783    4.7247   154.9581   -938.1816   -937.9581   \n",
      "\n",
      "                           p05     p25      p50      p75       p95  \\\n",
      "sp_dcf_to_debt        -32.3947 -0.2708  -0.0161   0.0927    3.1470   \n",
      "sp_debt_to_ebitda       0.0000  1.6168   2.4492   3.4596   31.2099   \n",
      "sp_ffo_to_debt        -36.7125 -0.1878   0.0838   0.2848    8.2280   \n",
      "sp_focf_to_debt       -20.2979 -0.1573   0.0465   0.1932    7.0222   \n",
      "sp_interest_coverage -213.6667 -0.0192   2.3182   8.9043  420.2945   \n",
      "sp_debt_to_capital      0.0000  0.0157   0.2903   0.5582    1.0013   \n",
      "log_at                  4.3694  8.8541  11.4487  13.7914   16.0542   \n",
      "log_mkvalt              0.6681  3.9637   6.6841  10.3161   13.9839   \n",
      "sp_cfo_to_debt         -7.4785  0.0001   0.1329   0.3421   17.1656   \n",
      "\n",
      "                             p99         max    skew     kurt  \n",
      "sp_dcf_to_debt          357.6861    357.7370 -6.8804  51.4862  \n",
      "sp_debt_to_ebitda      5165.2032   5166.1163  6.4043  41.6494  \n",
      "sp_ffo_to_debt          767.5352    767.7539 -6.3293  48.0915  \n",
      "sp_focf_to_debt         613.8415    614.0150 -5.2146  41.6549  \n",
      "sp_interest_coverage  21388.5576  21414.6093  4.2811  34.8720  \n",
      "sp_debt_to_capital        2.7859      2.7876  2.3962   8.8910  \n",
      "log_at                   17.8535     17.8537 -0.6152   0.1416  \n",
      "log_mkvalt               16.3771     16.3773  0.2930  -0.8811  \n",
      "sp_cfo_to_debt          935.4829    935.5521  0.2886  28.3812  \n",
      "\n",
      "Distribution summary (TRAIN | standardized feats)\n",
      "                            n  mean  std     min     p01     p05     p25  \\\n",
      "z_sp_dcf_to_debt        44783  -0.0  1.0 -8.2386 -8.2351 -0.0325  0.1246   \n",
      "z_sp_debt_to_ebitda     44783   0.0  1.0 -0.1782 -0.1782 -0.1782 -0.1758   \n",
      "z_sp_ffo_to_debt        44783  -0.0  1.0 -8.1003 -8.1001 -0.0182  0.1007   \n",
      "z_sp_focf_to_debt       44783   0.0  1.0 -7.7645 -7.7639 -0.0397  0.0734   \n",
      "z_sp_interest_coverage  44783   0.0  1.0 -4.0241 -4.0230 -0.1559 -0.0819   \n",
      "z_sp_debt_to_capital    44783   0.0  1.0 -0.8646 -0.8646 -0.8646 -0.8293   \n",
      "z_log_at                44783   0.0  1.0 -2.9116 -2.9116 -1.8804 -0.6224   \n",
      "z_log_mkvalt            44783   0.0  1.0 -1.7012 -1.7012 -1.5439 -0.7679   \n",
      "z_sp_cfo_to_debt        44783  -0.0  1.0 -6.0849 -6.0835 -0.0788 -0.0305   \n",
      "\n",
      "                           p50     p75     p95     p99     max    skew  \\\n",
      "z_sp_dcf_to_debt        0.1258  0.1264  0.1413  1.8750  1.8753 -6.8804   \n",
      "z_sp_debt_to_ebitda    -0.1746 -0.1730 -0.1315  7.5602  7.5616  6.4043   \n",
      "z_sp_ffo_to_debt        0.1016  0.1023  0.1281  2.5997  2.6004 -6.3293   \n",
      "z_sp_focf_to_debt       0.0745  0.0753  0.1137  3.5196  3.5205 -5.2146   \n",
      "z_sp_interest_coverage -0.0811 -0.0788  0.0637  7.3278  7.3369  4.2811   \n",
      "z_sp_debt_to_capital   -0.2118  0.3906  1.3870  5.3999  5.4038  2.3962   \n",
      "z_log_at                0.1054  0.7625  1.3973  1.9020  1.9020 -0.6152   \n",
      "z_log_mkvalt           -0.1274  0.7278  1.5915  2.1550  2.1551  0.2930   \n",
      "z_sp_cfo_to_debt       -0.0296 -0.0283  0.0803  6.0065  6.0070  0.2886   \n",
      "\n",
      "                           kurt  \n",
      "z_sp_dcf_to_debt        51.4862  \n",
      "z_sp_debt_to_ebitda     41.6494  \n",
      "z_sp_ffo_to_debt        48.0915  \n",
      "z_sp_focf_to_debt       41.6549  \n",
      "z_sp_interest_coverage  34.8720  \n",
      "z_sp_debt_to_capital     8.8910  \n",
      "z_log_at                 0.1416  \n",
      "z_log_mkvalt            -0.8811  \n",
      "z_sp_cfo_to_debt        28.3812  \n",
      "\n",
      "High collinearity pairs among feats (|corr|>=0.80) [top 25]:\n",
      "sp_focf_to_debt vs sp_dcf_to_debt: r=0.899\n",
      "\n",
      "Train→Test drift (SMD) [top 15]:\n",
      "                feature  mean_train  mean_test     smd  abs_smd\n",
      "8            log_mkvalt      7.2250     7.7328  0.1224   0.1224\n",
      "2        sp_cfo_to_debt      4.7247    -8.0341 -0.0915   0.0915\n",
      "7                log_at     11.0730    11.3644  0.0836   0.0836\n",
      "0    sp_debt_to_capital      0.3845     0.4150  0.0690   0.0690\n",
      "6  sp_interest_coverage    236.4521   149.4930 -0.0294   0.0294\n",
      "3       sp_focf_to_debt    -13.2306   -17.9904 -0.0285   0.0285\n",
      "1        sp_ffo_to_debt    -31.1297   -33.4050 -0.0079   0.0079\n",
      "4        sp_dcf_to_debt    -25.7497   -24.6350  0.0058   0.0058\n",
      "5     sp_debt_to_ebitda    118.9631   117.0417 -0.0029   0.0029\n",
      "\n",
      "Mean difference (target=1 minus target=0) on TRAIN feats [top 15]:\n",
      "sp_interest_coverage   -324.6736\n",
      "sp_debt_to_ebitda        55.1038\n",
      "sp_cfo_to_debt          -22.7747\n",
      "sp_ffo_to_debt          -19.8694\n",
      "sp_focf_to_debt         -11.8173\n",
      "sp_dcf_to_debt           -4.2387\n",
      "log_at                   -1.4652\n",
      "log_mkvalt               -0.9070\n",
      "sp_debt_to_capital        0.4128\n",
      "dtype: float64\n",
      "\n",
      "Sanity checks passed.\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
