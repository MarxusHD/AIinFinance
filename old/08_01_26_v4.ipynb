{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ad9bfb",
   "metadata": {},
   "source": [
    "# Next-Year Financial Distress Prediction (Compustat Annual Panel) — Reproducible ML Pipeline\n",
    "\n",
    "**Goal.** Predict the probability that a firm is in *financial distress* in fiscal year **t+1** using accounting (and permitted market) information available at fiscal year **t**.\n",
    "\n",
    "**Important scope note.** The outcome is an **engineered distress proxy** (high leverage / balance-sheet stress), not a realized legal default or bankruptcy. The notebook is therefore a **predictive measurement and decision-support pipeline**, not a causal identification design.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook structure (Data Science Lifecycle — 10 phases)\n",
    "\n",
    "1. Problem Definition & Setup  \n",
    "2. Data Collection & Panel Integrity  \n",
    "3. Data Cleaning & Missingness Handling (leakage-aware)  \n",
    "4. Exploratory Data Analysis (EDA)  \n",
    "5. Feature Engineering & Target Construction  \n",
    "6. Preprocessing for Modeling (train-only fitting)  \n",
    "7. Model Selection & Training (7A Logit; 7B Trees)  \n",
    "8. Model Evaluation & Diagnostic Monitoring  \n",
    "9. Operational Risk Management Layer (Events + PDs)\n",
    "10. Results Summary, Guardrails, and Replication Artifacts\n",
    "\n",
    "> This organization mirrors the course lifecycle guidance and the project's technical review action items (see provided PDF and technical report).\n",
    "\n",
    "## How to run (replication package convention)\n",
    "\n",
    "1. Place `data.csv` in the project root (or update `CONFIG[\"DATA_PATH\"]` in Section 1).\n",
    "2. Keep `Variables.xlsx` (variable dictionary) alongside the notebook for automatic documentation.\n",
    "3. Run **Kernel → Restart & Run All**.\n",
    "\n",
    "The notebook creates an `outputs/` folder containing:\n",
    "- a predictions export (`predictions.csv`),\n",
    "- configuration and threshold tables,\n",
    "- model summary tables suitable for an appendix,\n",
    "- figures saved as PNG for paper workflow.\n",
    "\n",
    "## 1. Problem Definition & Setup\n",
    "\n",
    "### 1.1 Prediction target, success metrics, and decision objective\n",
    "\n",
    "- **Target (supervised label):** `target_next_v1`, `target_next_v2`, or `target_next_v3` (separate distress proxies). Downstream modeling uses `target_next_v2` by default.  \n",
    "- **Primary performance metrics (out-of-sample):**\n",
    "  - ROC-AUC (ranking quality),\n",
    "  - PR-AUC (class imbalance),\n",
    "  - Brier score (probability accuracy / calibration).\n",
    "- **Decision objective (screening):** convert predicted PDs into a review policy using:\n",
    "  - **misclassification costs** (`COST_FN`, `COST_FP`) and\n",
    "  - **capacity constraints** (screen top `CAPACITY_PCT` percent of firms).\n",
    "\n",
    "This is a *risk scoring* workflow: calibrated probabilities and operational interpretability matter more than headline accuracy.\n",
    "\n",
    "### 1.2 Configuration, determinism, and library versions"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f7594c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:58:37.530261Z",
     "start_time": "2026-01-08T16:58:34.448036Z"
    }
   },
   "source": [
    "# Core numerics\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML / metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Stats / inference\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\n",
    "from scipy import stats\n",
    "\n",
    "# Trees / explainability\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# Determinism\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "USING_SYNTHETIC_DATA = False # Global flag for data mode\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration (edit here)\n",
    "# ----------------------------\n",
    "CONFIG = {\n",
    "    # Data inputs\n",
    "    \"DATA_PATH\": \"data.csv\",\n",
    "    \"VARIABLES_XLSX_PATH\": \"Variables.xlsx\",\n",
    "\n",
    "    # Temporal splitting via label_year = fyear + 1\n",
    "    \"TRAIN_CUTOFF_LABEL_YEAR\": 2022,   # label_year <= cutoff -> train/val pool; later -> test\n",
    "    \"VAL_YEARS\": 1,                    # number of last label years inside the train pool used as validation\n",
    "\n",
    "    # Missingness / imputation\n",
    "    \"KNN_K\": 25,\n",
    "    \"IMPUTE_LO_Q\": 0.01,\n",
    "    \"IMPUTE_HI_Q\": 0.99,\n",
    "\n",
    "    # Preprocessing\n",
    "    \"WINSOR_LO_Q\": 0.01,\n",
    "    \"WINSOR_HI_Q\": 0.99,\n",
    "\n",
    "    # Logit hyperparameter search\n",
    "    \"LOGIT_C_GRID\": [0.01, 0.1, 1.0, 10.0],\n",
    "\n",
    "    # Tree model (XGBoost) parameters (conservative / regularized)\n",
    "    \"XGB_PARAMS\": {\n",
    "        \"max_depth\": 3,\n",
    "        \"min_child_weight\": 10,\n",
    "        \"subsample\": 0.7,\n",
    "        \"colsample_bytree\": 0.7,\n",
    "        \"eta\": 0.05,\n",
    "        \"reg_lambda\": 10.0,\n",
    "        \"reg_alpha\": 0.1,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": SEED,\n",
    "    },\n",
    "    \"XGB_NUM_BOOST_ROUND\": 5000,\n",
    "    \"XGB_EARLY_STOPPING\": 100,\n",
    "\n",
    "    # Decision policy parameters (costs + capacity)\n",
    "    \"COST_FN\": 10.0,\n",
    "    \"COST_FP\": 1.0,\n",
    "    \"CAPACITY_PCT\": 0.20,  # screen top 20% by PD as a capacity policy\n",
    "\n",
    "    # Outputs\n",
    "    \"OUTPUT_DIR\": \"outputs\",\n",
    "    \"FIG_DIR\": \"figures\",\n",
    "}\n",
    "\n",
    "Path(CONFIG[\"OUTPUT_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(CONFIG[\"FIG_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CONFIG (key parameters):\")\n",
    "for k in [\"DATA_PATH\",\"TRAIN_CUTOFF_LABEL_YEAR\",\"VAL_YEARS\",\"KNN_K\",\"WINSOR_LO_Q\",\"WINSOR_HI_Q\",\"COST_FN\",\"COST_FP\",\"CAPACITY_PCT\"]:\n",
    "    print(f\"  {k}: {CONFIG[k]}\")\n",
    "print(\"\\nPython:\", sys.version.split()[0])\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG (key parameters):\n",
      "  DATA_PATH: data.csv\n",
      "  TRAIN_CUTOFF_LABEL_YEAR: 2022\n",
      "  VAL_YEARS: 1\n",
      "  KNN_K: 25\n",
      "  WINSOR_LO_Q: 0.01\n",
      "  WINSOR_HI_Q: 0.99\n",
      "  COST_FN: 10.0\n",
      "  COST_FP: 1.0\n",
      "  CAPACITY_PCT: 0.2\n",
      "\n",
      "Python: 3.13.5\n",
      "pandas: 2.3.1\n",
      "numpy: 2.2.5\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b26c8dff",
   "metadata": {},
   "source": [
    "### 1.3 Helper utilities (robust ratios, transforms, and reporting)"
   ]
  },
  {
   "cell_type": "code",
   "id": "76a360d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:58:37.600029Z",
     "start_time": "2026-01-08T16:58:37.553855Z"
    }
   },
   "source": [
    "def signed_log1p(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Signed log1p transform: sign(x) * log1p(|x|). Preserves zero and sign, stabilizes tails.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "def safe_divide(numer: pd.Series, denom: pd.Series, denom_floor: float = None) -> pd.Series:\n",
    "    \"\"\"Safe divide with optional denominator floor for stability. Returns float with NaN where undefined.\"\"\"\n",
    "    numer = pd.to_numeric(numer, errors=\"coerce\")\n",
    "    denom = pd.to_numeric(denom, errors=\"coerce\")\n",
    "    if denom_floor is not None:\n",
    "        denom = denom.where(denom.abs() >= denom_floor, other=np.sign(denom).replace(0, 1) * denom_floor)\n",
    "    out = numer / denom\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    return out\n",
    "\n",
    "def ensure_nullable_float(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert to pandas nullable Float64 to enable NA-aware comparisons (returns <NA> instead of False).\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "def winsorize_train_bounds(x: pd.Series, lo: float, hi: float) -> tuple[float, float]:\n",
    "    \"\"\"Return winsorization bounds computed on *training* observed values.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    x_obs = x.dropna()\n",
    "    if len(x_obs) == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (float(x_obs.quantile(lo)), float(x_obs.quantile(hi)))\n",
    "\n",
    "def apply_bounds(x: pd.Series, lo: float, hi: float) -> pd.Series:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if np.isnan(lo) or np.isnan(hi):\n",
    "        return x\n",
    "    return x.clip(lower=lo, upper=hi)\n",
    "\n",
    "def compute_smd(train: pd.Series, test: pd.Series) -> float:\n",
    "    \"\"\"Standardized mean difference (SMD): (mu_train - mu_test)/pooled_sd.\"\"\"\n",
    "    a = pd.to_numeric(train, errors=\"coerce\").dropna()\n",
    "    b = pd.to_numeric(test, errors=\"coerce\").dropna()\n",
    "    if len(a) < 2 or len(b) < 2:\n",
    "        return np.nan\n",
    "    mu_a, mu_b = a.mean(), b.mean()\n",
    "    sd_a, sd_b = a.std(ddof=1), b.std(ddof=1)\n",
    "    pooled = np.sqrt(0.5*(sd_a**2 + sd_b**2))\n",
    "    return float((mu_a - mu_b) / pooled) if pooled > 0 else np.nan\n",
    "\n",
    "def logit(p: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def print_df(df: pd.DataFrame, n: int = 10, name: str = None):\n",
    "    if name:\n",
    "        print(f\"\\n{name} (top {n} rows):\")\n",
    "    display(df.head(n))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "cde14739",
   "metadata": {},
   "source": [
    "## 2. Data Collection & Panel Integrity\n",
    "\n",
    "### 2.1 Load variable dictionary (for documentation)\n",
    "\n",
    "We load the provided variable dictionary (`Variables.xlsx`) to:\n",
    "- validate required Compustat mnemonics exist in the data file,\n",
    "- generate appendix-ready variable tables.\n",
    "\n",
    "This step **does not** transform the modeling data."
   ]
  },
  {
   "cell_type": "code",
   "id": "70e93db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:58:37.666410Z",
     "start_time": "2026-01-08T16:58:37.607566Z"
    }
   },
   "source": [
    "vars_path = Path(CONFIG[\"VARIABLES_XLSX_PATH\"])\n",
    "if vars_path.exists():\n",
    "    var_dict = pd.read_excel(vars_path, sheet_name=0)\n",
    "    var_dict.columns = [c.strip() for c in var_dict.columns]\n",
    "    print(f\"Loaded variable dictionary with {len(var_dict)} rows from: {vars_path}\")\n",
    "    display(var_dict.head(90))\n",
    "else:\n",
    "    var_dict = pd.DataFrame(columns=[\"Variable\",\"Two-word Description\",\"Category\"])\n",
    "    print(f\"WARNING: variable dictionary not found at {vars_path}. Continuing without it.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: variable dictionary not found at Variables.xlsx. Continuing without it.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "6c475cbd",
   "metadata": {},
   "source": [
    "### 2.2 Load raw data (no imputation or transformations)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e907e85a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T16:59:34.863514Z",
     "start_time": "2026-01-08T16:59:34.552311Z"
    }
   },
   "source": [
    "data_path = Path(CONFIG[\"DATA_PATH\"])\n",
    "df_raw = pd.read_csv(data_path, low_memory=False)\n",
    "print(f\"Loaded data from {data_path} with shape {df_raw.shape}\")\n",
    "\n",
    "display(df_raw.head())\n"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m data_path = Path(CONFIG[\u001B[33m\"\u001B[39m\u001B[33mDATA_PATH\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m df_raw = pd.read_csv(data_path, low_memory=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mLoaded data from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m with shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdf_raw.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      5\u001B[39m display(df_raw.head())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001B[39m, in \u001B[36mread_csv\u001B[39m\u001B[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[39m\n\u001B[32m   1013\u001B[39m kwds_defaults = _refine_defaults_read(\n\u001B[32m   1014\u001B[39m     dialect,\n\u001B[32m   1015\u001B[39m     delimiter,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1022\u001B[39m     dtype_backend=dtype_backend,\n\u001B[32m   1023\u001B[39m )\n\u001B[32m   1024\u001B[39m kwds.update(kwds_defaults)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001B[39m, in \u001B[36m_read\u001B[39m\u001B[34m(filepath_or_buffer, kwds)\u001B[39m\n\u001B[32m    617\u001B[39m _validate_names(kwds.get(\u001B[33m\"\u001B[39m\u001B[33mnames\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[32m    619\u001B[39m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m parser = TextFileReader(filepath_or_buffer, **kwds)\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[32m    623\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001B[39m, in \u001B[36mTextFileReader.__init__\u001B[39m\u001B[34m(self, f, engine, **kwds)\u001B[39m\n\u001B[32m   1617\u001B[39m     \u001B[38;5;28mself\u001B[39m.options[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m] = kwds[\u001B[33m\"\u001B[39m\u001B[33mhas_index_names\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1619\u001B[39m \u001B[38;5;28mself\u001B[39m.handles: IOHandles | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1620\u001B[39m \u001B[38;5;28mself\u001B[39m._engine = \u001B[38;5;28mself\u001B[39m._make_engine(f, \u001B[38;5;28mself\u001B[39m.engine)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001B[39m, in \u001B[36mTextFileReader._make_engine\u001B[39m\u001B[34m(self, f, engine)\u001B[39m\n\u001B[32m   1878\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[32m   1879\u001B[39m         mode += \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1880\u001B[39m \u001B[38;5;28mself\u001B[39m.handles = get_handle(\n\u001B[32m   1881\u001B[39m     f,\n\u001B[32m   1882\u001B[39m     mode,\n\u001B[32m   1883\u001B[39m     encoding=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m   1884\u001B[39m     compression=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mcompression\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m   1885\u001B[39m     memory_map=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mmemory_map\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[32m   1886\u001B[39m     is_text=is_text,\n\u001B[32m   1887\u001B[39m     errors=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mencoding_errors\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstrict\u001B[39m\u001B[33m\"\u001B[39m),\n\u001B[32m   1888\u001B[39m     storage_options=\u001B[38;5;28mself\u001B[39m.options.get(\u001B[33m\"\u001B[39m\u001B[33mstorage_options\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[32m   1889\u001B[39m )\n\u001B[32m   1890\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1891\u001B[39m f = \u001B[38;5;28mself\u001B[39m.handles.handle\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/io/common.py:873\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    868\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    869\u001B[39m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[32m    870\u001B[39m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[32m    871\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ioargs.encoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs.mode:\n\u001B[32m    872\u001B[39m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m873\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(\n\u001B[32m    874\u001B[39m             handle,\n\u001B[32m    875\u001B[39m             ioargs.mode,\n\u001B[32m    876\u001B[39m             encoding=ioargs.encoding,\n\u001B[32m    877\u001B[39m             errors=errors,\n\u001B[32m    878\u001B[39m             newline=\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    879\u001B[39m         )\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m    882\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(handle, ioargs.mode)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "27300e16",
   "metadata": {},
   "source": [
    "### 2.3 Enforce panel identifiers, types, sorting, and deduplication"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbe7fdf3",
   "metadata": {},
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# Stable firm identifier\n",
    "if \"gvkey\" not in df.columns:\n",
    "    raise ValueError(\"Required identifier column `gvkey` not found in the dataset.\")\n",
    "df[\"firm_id\"] = df[\"gvkey\"].astype(str)\n",
    "\n",
    "# Fiscal year\n",
    "if \"fyear\" not in df.columns:\n",
    "    raise ValueError(\"Required time column `fyear` not found in the dataset.\")\n",
    "df[\"fyear\"] = pd.to_numeric(df[\"fyear\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Optional datadate parsing (kept as metadata; not used for splitting)\n",
    "if \"datadate\" in df.columns:\n",
    "    df[\"datadate\"] = pd.to_datetime(df[\"datadate\"], errors=\"coerce\")\n",
    "\n",
    "# Remove firm-year duplicates (keep-last rule, audit count)\n",
    "pre_n = len(df)\n",
    "dup_mask = df.duplicated(subset=[\"firm_id\",\"fyear\"], keep=False)\n",
    "n_dups = int(dup_mask.sum())\n",
    "if n_dups > 0:\n",
    "    print(f\"Found {n_dups} duplicated firm-year rows. Applying keep-last rule.\")\n",
    "    df = df.sort_values([\"firm_id\",\"fyear\",\"datadate\"] if \"datadate\" in df.columns else [\"firm_id\",\"fyear\"])\n",
    "    df = df.drop_duplicates(subset=[\"firm_id\",\"fyear\"], keep=\"last\")\n",
    "post_n = len(df)\n",
    "\n",
    "# Enforce sort order for lag/lead safety\n",
    "df = df.sort_values([\"firm_id\",\"fyear\"]).reset_index(drop=True)\n",
    "\n",
    "# Integrity checks\n",
    "assert df[[\"firm_id\",\"fyear\"]].isna().sum().sum() == 0, \"Missing firm_id or fyear after typing.\"\n",
    "assert df.duplicated(subset=[\"firm_id\",\"fyear\"]).sum() == 0, \"Duplicate firm-year keys remain after dedup.\"\n",
    "\n",
    "print(f\"Rows: {pre_n:,} -> {post_n:,} after deduplication.\")\n",
    "print(\"Unique firms:\", df[\"firm_id\"].nunique())\n",
    "print(\"Year range:\", int(df[\"fyear\"].min()), \"to\", int(df[\"fyear\"].max()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "990db334",
   "metadata": {},
   "source": [
    "### 2.4 Raw sample composition (no transformations)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0e2e3c5",
   "metadata": {},
   "source": [
    "# Minimal sample composition diagnostics (kept lightweight for large panels)\n",
    "\n",
    "by_year = df.groupby(\"fyear\").agg(\n",
    "    n_obs=(\"firm_id\",\"size\"),\n",
    "    n_firms=(\"firm_id\",\"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "display(by_year.tail(12))\n",
    "\n",
    "# Optional: industry composition if SIC exists\n",
    "if \"sic\" in df.columns:\n",
    "    df[\"sic2\"] = pd.to_numeric(df[\"sic\"], errors=\"coerce\").astype(\"Int64\") // 100\n",
    "    by_sic2 = df.groupby(\"sic2\").size().sort_values(ascending=False).head(15).rename(\"n_obs\").reset_index()\n",
    "    display(by_sic2)\n",
    "else:\n",
    "    print(\"Note: `sic` not present; skipping industry composition.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbd16501",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Missingness Handling (leakage-aware)\n",
    "\n",
    "### 3.1 Non-imputable identifiers and label-year setup\n",
    "\n",
    "We drop observations missing non-imputable identifiers (firm, year).  \n",
    "We also define `label_year = fyear + 1` as the *outcome year* used for forecasting splits."
   ]
  },
  {
   "cell_type": "code",
   "id": "31e1404a",
   "metadata": {},
   "source": [
    "# Drop rows with missing key identifiers (already asserted, but keep explicit)\n",
    "df = df.dropna(subset=[\"firm_id\",\"fyear\"]).copy()\n",
    "\n",
    "# label_year defines the year of the t+1 distress label\n",
    "df[\"label_year\"] = (df[\"fyear\"] + 1).astype(\"Int64\")\n",
    "\n",
    "# Split masks (defined early; used for leakage-safe preprocessing throughout)\n",
    "train_pool_mask = df[\"label_year\"] <= CONFIG[\"TRAIN_CUTOFF_LABEL_YEAR\"]\n",
    "train_pool_years = sorted(df.loc[train_pool_mask, \"label_year\"].dropna().unique().tolist())\n",
    "if len(train_pool_years) < (CONFIG[\"VAL_YEARS\"] + 1):\n",
    "    raise ValueError(\"Not enough label years in train pool to allocate validation years. Adjust TRAIN_CUTOFF_LABEL_YEAR or VAL_YEARS.\")\n",
    "\n",
    "val_years = train_pool_years[-CONFIG[\"VAL_YEARS\"]:]\n",
    "val_mask = df[\"label_year\"].isin(val_years)\n",
    "train_mask = train_pool_mask & (~val_mask)\n",
    "test_mask = df[\"label_year\"] > CONFIG[\"TRAIN_CUTOFF_LABEL_YEAR\"]\n",
    "\n",
    "df[\"split\"] = np.where(test_mask, \"test\", np.where(val_mask, \"val\", \"train\"))\n",
    "\n",
    "print(\"Split counts:\")\n",
    "display(df[\"split\"].value_counts(dropna=False).to_frame(\"n_obs\"))\n",
    "print(\"Validation label_year(s):\", val_years)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "caf030bc",
   "metadata": {},
   "source": [
    "### 3.2 Missingness audit before intervention"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2941f55",
   "metadata": {},
   "source": [
    "# Identify numeric columns eligible for imputation (exclude identifiers)\n",
    "id_cols = {\"gvkey\",\"firm_id\",\"fyear\",\"label_year\",\"datadate\",\"split\"}\n",
    "numeric_cols = [c for c in df.columns if c not in id_cols and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "missing_tbl = (df[numeric_cols].isna().mean().sort_values(ascending=False) * 100).rename(\"missing_%\").to_frame()\n",
    "missing_tbl[\"n_missing\"] = df[numeric_cols].isna().sum().astype(int)\n",
    "missing_tbl[\"dtype\"] = [str(df[c].dtype) for c in missing_tbl.index]\n",
    "\n",
    "display(missing_tbl.head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "314eca9a",
   "metadata": {},
   "source": [
    "### 3.3 Create missingness indicators (informative signals)"
   ]
  },
  {
   "cell_type": "code",
   "id": "caf47442",
   "metadata": {},
   "source": [
    "# Choose a focused set of inputs used for core ratios/events.\n",
    "REQUIRED_RAW = [\n",
    "    \"at\",\"dlc\",\"dltt\",\"seq\",\"mibt\",\"niadj\",\n",
    "    \"oibdp\",\"oancf\",\"xint\",\n",
    "    \"act\",\"lct\",\"che\",\"rect\",\"invt\",\n",
    "    # dividend-related (we will auto-detect among these later)\n",
    "    \"dv\",\"dvc\",\"dvt\",\"dvp\",\n",
    "]\n",
    "available_required = [c for c in REQUIRED_RAW if c in df.columns]\n",
    "\n",
    "# Hard requirement for the distress proxy; fail if absent (unless synthetic mode)\n",
    "HARD_REQUIRED = [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"niadj\",\"oancf\"]\n",
    "missing_hard = [c for c in HARD_REQUIRED if c not in df.columns]\n",
    "if missing_hard and not USING_SYNTHETIC_DATA:\n",
    "    raise ValueError(f\"Missing required columns for distress proxy construction: {missing_hard}\")\n",
    "\n",
    "for c in available_required:\n",
    "    df[f\"fmiss_{c}\"] = df[c].isna().astype(\"Int8\")\n",
    "\n",
    "print(\"Created missingness flags for:\", available_required)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1862160b",
   "metadata": {},
   "source": [
    "### 3.4 Training-derived size deciles (used for peer imputation groups)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7933cb0a",
   "metadata": {},
   "source": [
    "# Size is based on log(assets) from TRAIN only, to avoid leakage.\n",
    "at_train = pd.to_numeric(df.loc[train_mask, \"at\"], errors=\"coerce\")\n",
    "log_at_train = np.log(at_train.where(at_train > 0)).dropna()\n",
    "\n",
    "if len(log_at_train) < 50:\n",
    "    print(\"WARNING: too few non-missing training `at` values for stable size deciles. Using a single size bin.\")\n",
    "    df[\"size_decile\"] = 5  # arbitrary mid-bin\n",
    "    size_edges = None\n",
    "else:\n",
    "    # Use quantile cutpoints computed on training only\n",
    "    qs = np.linspace(0, 1, 11)\n",
    "    size_edges = log_at_train.quantile(qs).values\n",
    "    size_edges[0] = -np.inf\n",
    "    size_edges[-1] = np.inf\n",
    "\n",
    "    log_at_all = np.log(pd.to_numeric(df[\"at\"], errors=\"coerce\").where(lambda s: s > 0))\n",
    "    df[\"size_decile\"] = pd.cut(log_at_all, bins=size_edges, labels=False, include_lowest=True).astype(\"Float64\")\n",
    "\n",
    "# Fill NA size_decile with training median decile for downstream stability\n",
    "sd_med = float(pd.to_numeric(df.loc[train_mask, \"size_decile\"], errors=\"coerce\").median())\n",
    "df[\"size_decile\"] = pd.to_numeric(df[\"size_decile\"], errors=\"coerce\").fillna(sd_med).astype(int)\n",
    "\n",
    "print(\"Size decile distribution (train):\")\n",
    "display(df.loc[train_mask, \"size_decile\"].value_counts().sort_index().to_frame(\"n_obs\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.5 Imputation Pipeline",
   "id": "4be186dd4fa5a9a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Snapshot before any imputation\n",
    "df_pre_impute_snapshot = df.copy(deep=True)"
   ],
   "id": "da85e3d73736a4b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.5.1 KNN imputation on core structural items (train-fit; signed-log transform)\n",
    "\n",
    "We use KNN for core balance sheet and income statement aggregates. These variables have strong multivariate dependencies (e.g., Total Assets ≈ Total Liabilities + Equity). KNN captures these relationships, allowing the imputation to respect the specific \"profile\" of a company."
   ],
   "id": "c6bdf404d9e0d89b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Core structural variables for KNN\n",
    "knn_cols = [\n",
    "    \"at\", \"act\", \"lct\", \"che\", \"rect\", \"invt\", \"dlc\", \"dltt\", \n",
    "    \"seq\", \"ceq\", \"lt\", \"ppent\", \"intan\", \"oibdp\", \"niadj\", \n",
    "    \"oancf\", \"xint\", \"dp\", \"re\", \"capx\"\n",
    "]\n",
    "knn_cols = [c for c in knn_cols if c in df.columns]\n",
    "\n",
    "if len(knn_cols) >= 3:\n",
    "    Z = df[knn_cols + [\"fyear\",\"size_decile\"]].copy()\n",
    "    # Transform magnitudes for distance stability\n",
    "    for c in knn_cols:\n",
    "        Z[c] = signed_log1p(Z[c])\n",
    "    # Standardize fyear and size_decile to prevent distance domination by year scale (Issue 1)\n",
    "    for c in [\"fyear\", \"size_decile\"]:\n",
    "        Z[c] = pd.to_numeric(Z[c], errors=\"coerce\")\n",
    "        mu = Z.loc[train_mask, c].mean()\n",
    "        sigma = Z.loc[train_mask, c].std()\n",
    "        if sigma > 0:\n",
    "            Z[c] = (Z[c] - mu) / sigma\n",
    "\n",
    "    # --- KNN Imputation using training data ---\n",
    "    imputer = KNNImputer(n_neighbors=CONFIG[\"KNN_K\"], weights=\"distance\")\n",
    "    imputer.fit(Z.loc[train_mask, :])\n",
    "\n",
    "    Z_imp = pd.DataFrame(imputer.transform(Z), columns=Z.columns, index=Z.index)\n",
    "\n",
    "    # Invert signed-log transform back for magnitudes\n",
    "    for c in knn_cols:\n",
    "        # inverse of signed_log1p: sign(z)*(exp(|z|)-1)\n",
    "        z = pd.to_numeric(Z_imp[c], errors=\"coerce\")\n",
    "        df[c] = np.sign(z) * (np.expm1(np.abs(z)))\n",
    "else:\n",
    "    print(\"Skipping KNN imputation: insufficient columns available.\")"
   ],
   "id": "6e6db926a02307a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.5.2 KNN Parameter Selection Audit\n",
    "\n",
    "We evaluate the reconstruction quality for different values of $K$ to justify the choice of `KNN_K=25`. We use a subset of fully observed training data and artificially introduce missingness to measure RMSE."
   ],
   "id": "874a9cc64bda1318"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_knn_k(Z_train, k_list, mask_fraction=0.1, seed=42):\n",
    "    # Subset to fully observed rows for ground truth\n",
    "    ground_truth_full = Z_train.dropna()\n",
    "    if len(ground_truth_full) < 100:\n",
    "        return None\n",
    "    \n",
    "    # Sample if too large for speed\n",
    "    if len(ground_truth_full) > 2000:\n",
    "        ground_truth = ground_truth_full.sample(n=2000, random_state=seed)\n",
    "    else:\n",
    "        ground_truth = ground_truth_full\n",
    "        \n",
    "    # Create masked version\n",
    "    rng = np.random.default_rng(seed)\n",
    "    masked_data = ground_truth.copy()\n",
    "    \n",
    "    # Only mask the core numeric columns (knn_cols)\n",
    "    cols_to_mask = [c for c in ground_truth.columns if c not in [\"fyear\", \"size_decile\"]]\n",
    "    \n",
    "    for col in cols_to_mask:\n",
    "        mask = rng.random(len(masked_data)) < mask_fraction\n",
    "        masked_data.loc[mask, col] = np.nan\n",
    "        \n",
    "    results = []\n",
    "    for k in k_list:\n",
    "        imputer_test = KNNImputer(n_neighbors=k, weights=\"distance\")\n",
    "        # Fit on the original (possibly missing) training data\n",
    "        imputer_test.fit(Z_train) \n",
    "        # Transform the artificially masked data\n",
    "        imputed_data = imputer_test.transform(masked_data)\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=ground_truth.columns, index=ground_truth.index)\n",
    "        \n",
    "        # Calculate RMSE only on the values we masked\n",
    "        mse = 0\n",
    "        count = 0\n",
    "        for col in cols_to_mask:\n",
    "            actual_mask = masked_data[col].isna()\n",
    "            if actual_mask.any():\n",
    "                mse += mean_squared_error(ground_truth.loc[actual_mask, col], imputed_df.loc[actual_mask, col]) * actual_mask.sum()\n",
    "                count += actual_mask.sum()\n",
    "        \n",
    "        rmse = np.sqrt(mse / count) if count > 0 else np.nan\n",
    "        results.append({\"K\": k, \"RMSE\": rmse})\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if 'knn_cols' in locals() and len(knn_cols) >= 3:\n",
    "    print(\"Evaluating KNN imputation performance (reconstruction RMSE)...\")\n",
    "    k_options = [5, 10, 25, 50, 100]\n",
    "    knn_audit_df = evaluate_knn_k(Z.loc[train_mask, :], k_options)\n",
    "    \n",
    "    if knn_audit_df is not None:\n",
    "        display(knn_audit_df.style.highlight_min(subset=\"RMSE\", color=\"lightgreen\"))\n",
    "        \n",
    "        k25_rmse = knn_audit_df.loc[knn_audit_df[\"K\"] == 25, \"RMSE\"].values[0]\n",
    "        best_k = knn_audit_df.loc[knn_audit_df[\"RMSE\"].idxmin(), \"K\"]\n",
    "        print(f\"\\nKNN K=25 RMSE: {k25_rmse:.4f}\")\n",
    "        if best_k == 25:\n",
    "            print(\"K=25 is the optimal parameter among tested values.\")\n",
    "        else:\n",
    "            print(f\"Optimal K among tested is {best_k}. K=25 is used as a balanced choice.\")\n",
    "    else:\n",
    "        print(\"Insufficient fully observed data for KNN audit.\")"
   ],
   "id": "8078342dea980b68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.6 Train-only peer-median imputation (fyear × size_decile)\n",
    "\n",
    "We use year-size median imputation for secondary items, \"other\" categories, and sparse flow variables (e.g., dividends, acquisitions). These variables are often missing, zero, or highly idiosyncratic. Using a multivariate model like KNN on them might introduce noise or over-impute non-zero values for sparse events. A year-size median provides a robust \"typical\" value for companies of similar scale in the same year, which is a safer conservative estimate for these items."
   ],
   "id": "79965ecc92898ccd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Secondary/incidental variables for Peer Median\n",
    "peer_impute_candidates = [\n",
    "    \"aco\", \"lco\", \"recch\", \"invch\", \"txp\", \"txditc\", \n",
    "    \"caps\", \"mibt\", \"aqc\", \"prstkc\",\n",
    "    \"dv\", \"dvc\", \"dvt\", \"dvp\"\n",
    "]\n",
    "peer_impute_cols = [c for c in peer_impute_candidates if c in df.columns]\n",
    "\n",
    "group_cols = [\"fyear\",\"size_decile\"]\n",
    "\n",
    "def peer_median_impute(df_in: pd.DataFrame, cols: list[str], train_mask: pd.Series, group_cols: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Impute NaNs using TRAIN-only medians by group_cols, with TRAIN (size_decile) then global median fallback.\"\"\"\n",
    "    df_out = df_in.copy()\n",
    "    train = df_out.loc[train_mask, group_cols + cols].copy()\n",
    "    group_meds = train.groupby(group_cols)[cols].median()\n",
    "    global_meds = train[cols].median()\n",
    "\n",
    "    # Intermediate fallback for unseen (fyear, size_decile): use TRAIN size_decile medians\n",
    "    size_meds = train.groupby([\"size_decile\"])[cols].median()\n",
    "    tmp_size = df_out[[\"size_decile\"]].merge(size_meds.reset_index(), on=\"size_decile\", how=\"left\")\n",
    "\n",
    "    # Join group medians (wide) to all rows\n",
    "    tmp = df_out[group_cols].merge(group_meds.reset_index(), on=group_cols, how=\"left\", suffixes=(\"\", \"_peer\"))\n",
    "    # tmp currently contains the group median columns with original names\n",
    "    for c in cols:\n",
    "        peer_med = tmp[c]\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), peer_med)\n",
    "        size_med = tmp_size[c]\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), size_med)\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), global_meds[c])\n",
    "    impact = pd.DataFrame({\n",
    "        \"col\": cols,\n",
    "        \"n_imputed\": [int(df_in[c].isna().sum() - df_out[c].isna().sum()) for c in cols],\n",
    "        \"train_global_median\": [float(global_meds[c]) if pd.notna(global_meds[c]) else np.nan for c in cols],\n",
    "    })\n",
    "    return df_out, impact\n",
    "\n",
    "df, peer_impact = peer_median_impute(df, peer_impute_cols, train_mask, group_cols)\n",
    "\n",
    "display(peer_impact.sort_values(\"n_imputed\", ascending=False).head(15))"
   ],
   "id": "fd7f2bcc553da3f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.7 Guardrail capping of imputed magnitudes (train quantile bands)",
   "id": "b36405bf9b40affc"
  },
  {
   "cell_type": "code",
   "id": "f6c81343",
   "metadata": {},
   "source": [
    "# Apply capping to all columns that underwent imputation (KNN and Peer Median)\n",
    "cap_cols = list(set(knn_cols + peer_impute_cols))\n",
    "bounds = {}\n",
    "\n",
    "for c in cap_cols:\n",
    "    lo, hi = winsorize_train_bounds(df_pre_impute_snapshot.loc[train_mask, c], CONFIG[\"IMPUTE_LO_Q\"], CONFIG[\"IMPUTE_HI_Q\"])\n",
    "    bounds[c] = {\"lo\": lo, \"hi\": hi}\n",
    "    df[c] = apply_bounds(df[c], lo, hi)\n",
    "\n",
    "bounds_df = pd.DataFrame({c: (v[\"lo\"], v[\"hi\"]) for c,v in bounds.items()}, index=[\"lo\",\"hi\"]).T\n",
    "bounds_df.index.name = \"col\"\n",
    "display(bounds_df.head(15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a0d12d1",
   "metadata": {},
   "source": [
    "### 3.8 Imputation impact audit (pre vs post)"
   ]
  },
  {
   "cell_type": "code",
   "id": "779518ce",
   "metadata": {},
   "source": [
    "audit_cols = [c for c in [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"oancf\",\"act\",\"lct\"] if c in df.columns]\n",
    "\n",
    "def dist_summary(x: pd.Series) -> dict:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return {\n",
    "        \"n\": int(x.notna().sum()),\n",
    "        \"mean\": float(x.mean()) if x.notna().any() else np.nan,\n",
    "        \"p50\": float(x.median()) if x.notna().any() else np.nan,\n",
    "        \"p10\": float(x.quantile(0.10)) if x.notna().any() else np.nan,\n",
    "        \"p90\": float(x.quantile(0.90)) if x.notna().any() else np.nan,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for c in audit_cols:\n",
    "    pre = dist_summary(df_pre_impute_snapshot[c])\n",
    "    post = dist_summary(df[c])\n",
    "    rows.append({\n",
    "        \"col\": c,\n",
    "        \"n_pre\": pre[\"n\"],\n",
    "        \"n_post\": post[\"n\"],\n",
    "        \"mean_pre\": pre[\"mean\"],\n",
    "        \"mean_post\": post[\"mean\"],\n",
    "        \"p50_pre\": pre[\"p50\"],\n",
    "        \"p50_post\": post[\"p50\"],\n",
    "    })\n",
    "impact_tbl = pd.DataFrame(rows).sort_values(\"col\")\n",
    "display(impact_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5cff47ca",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA focuses on **signal strength and data quality**, not exhaustive plotting.  \n",
    "At this stage we describe the imputed-but-not-modeled input space, by split.\n",
    "\n",
    "### 4.1 Summary statistics by split (key magnitudes)"
   ]
  },
  {
   "cell_type": "code",
   "id": "df1d3718",
   "metadata": {},
   "source": [
    "eda_cols = [c for c in [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"oancf\",\"xint\"] if c in df.columns]\n",
    "\n",
    "def split_describe(df_in: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for sp in [\"train\",\"val\",\"test\"]:\n",
    "        d = df_in.loc[df_in[\"split\"]==sp, cols].describe(percentiles=[0.01,0.1,0.5,0.9,0.99]).T\n",
    "        d.insert(0, \"split\", sp)\n",
    "        d.insert(1, \"col\", d.index)\n",
    "        out.append(d.reset_index(drop=True))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "desc_tbl = split_describe(df, eda_cols)\n",
    "display(desc_tbl.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e05b4c3b",
   "metadata": {},
   "source": [
    "### 4.2 Missingness rates by split (key inputs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e8ad60dd",
   "metadata": {},
   "source": [
    "miss_cols = [c for c in available_required if f\"fmiss_{c}\" in df.columns]\n",
    "miss_by_split = (\n",
    "    df.groupby(\"split\")[ [f\"fmiss_{c}\" for c in available_required if f\"fmiss_{c}\" in df.columns] ]\n",
    "      .mean()\n",
    "      .T\n",
    ")\n",
    "miss_by_split.index = [i.replace(\"fmiss_\",\"\") for i in miss_by_split.index]\n",
    "miss_by_split = (miss_by_split * 100).round(2)\n",
    "display(miss_by_split)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa2a8235",
   "metadata": {},
   "source": [
    "### 4.3 Visual sanity-check plots (train vs test distributions)"
   ]
  },
  {
   "cell_type": "code",
   "id": "41b9931c",
   "metadata": {},
   "source": [
    "# Lightweight plots to spot gross drift / outliers.\n",
    "plot_cols = [c for c in [\"at\",\"dltt\",\"dlc\",\"oibdp\",\"oancf\"] if c in df.columns]\n",
    "\n",
    "for c in plot_cols[:3]:\n",
    "    a = pd.to_numeric(df.loc[df[\"split\"]==\"train\", c], errors=\"coerce\")\n",
    "    b = pd.to_numeric(df.loc[df[\"split\"]==\"test\", c], errors=\"coerce\")\n",
    "    plt.figure()\n",
    "    plt.hist(np.log1p(a.dropna()), bins=60, alpha=0.5, label=\"train\")\n",
    "    plt.hist(np.log1p(b.dropna()), bins=60, alpha=0.5, label=\"test\")\n",
    "    plt.title(f\"log1p({c}) distribution: train vs test\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"eda_log1p_{c}_train_vs_test.png\", dpi=140)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Feature Engineering & Target Construction\n",
    "\n",
    "This section constructs **all derived features explicitly** from Compustat-style raw items, including:\n",
    "- debt aggregates and leverage ratios,\n",
    "- cash-flow-to-debt ratios,\n",
    "- log size and log market value,\n",
    "- the NA-aware distress proxy and the next-year label.\n",
    "\n",
    "Design choice: ratios with non-positive denominators are treated as **extreme tail states** (encoded via `+∞` then converted to `NaN` before modeling), rather than silently set to zero.\n",
    "\n",
    "### 5.1 Feature list definitions (V1, V2, V3)"
   ],
   "id": "600ce0bf223cb84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FEATURES_V1 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \"aco_act\", \n",
    "    \"lco_lct\", \"rect_act\", \"invt_act\", \"recch_act\", \"invch_act\", \n",
    "    \"txp_lct\", \"txditc_at\", \"lt_at\", \"dlc_at\", \"dltt_at\", \n",
    "    \"debt_at\", \"st_debt_share\", \"ebitda_at\", \"dp_at\", \n",
    "    \"xint_at\", \"interest_coverage\", \"debt_to_ebitda\", \"ebit_to_capital\", \"capx_at\"\n",
    "]\n",
    "\n",
    "FEATURES_V2 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \"aco_act\", \n",
    "    \"lco_lct\", \"rect_act\", \"invt_act\", \"ppent_at\", \"intan_at\", \n",
    "    \"txp_lct\", \"txditc_at\", \"lt_at\", \"debt_at\", \"st_debt_share\", \n",
    "    \"ebitda_at\", \"xint_at\", \"interest_coverage\", \"debt_to_ebitda\", \n",
    "    \"ebit_to_capital\", \"ocf_to_debt\", \"fcf_to_debt\", \"capx_at\", \"re_at\"\n",
    "]\n",
    "\n",
    "FEATURES_V3 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \"aco_act\", \n",
    "    \"lco_lct\", \"rect_act\", \"invt_act\", \"recch_act\", \"invch_act\", \n",
    "    \"txp_lct\", \"txditc_at\", \"lt_at\", \"ceq_at\", \"re_at\", \n",
    "    \"caps_at\", \"mibt_at\", \"dp_at\", \"niadj_at\", \"loss_indicator\", \n",
    "    \"xint_at\", \"xint_lct\", \"capx_at\", \"aqc_at\", \"prstkc_at\"\n",
    "]"
   ],
   "id": "d0e137d18843d373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Debt, capital, and operating aggregates",
   "id": "14e07ab621282e57"
  },
  {
   "cell_type": "code",
   "id": "3be8ff9f",
   "metadata": {},
   "source": [
    "# Ensure all required raw items are numeric for safe arithmetic\n",
    "raw_items = [\n",
    "    \"at\", \"che\", \"act\", \"lct\", \"aco\", \"lco\", \"rect\", \"invt\", \"recch\", \"invch\",\n",
    "    \"txp\", \"txditc\", \"lt\", \"dlc\", \"dltt\", \"oibdp\", \"dp\", \"xint\", \"ceq\", \"capx\",\n",
    "    \"ppent\", \"intan\", \"oancf\", \"re\", \"caps\", \"mibt\", \"niadj\", \"aqc\", \"prstkc\", \"seq\"\n",
    "]\n",
    "for c in raw_items:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Debt aggregate\n",
    "df[\"total_debt\"] = df[[\"dlc\",\"dltt\"]].sum(axis=1, min_count=1)\n",
    "\n",
    "# Equity plus minority interest (if available)\n",
    "if \"mibt\" in df.columns:\n",
    "    df[\"equity_plus_mi\"] = df[[\"seq\",\"mibt\"]].sum(axis=1, min_count=1)\n",
    "else:\n",
    "    df[\"equity_plus_mi\"] = df[\"seq\"]\n",
    "\n",
    "# Total capital and a non-positive capital flag\n",
    "df[\"total_capital\"] = df[[\"total_debt\",\"equity_plus_mi\"]].sum(axis=1, min_count=1)\n",
    "df[\"cap_nonpos_flag\"] = (df[\"total_capital\"] <= 0).astype(\"Int8\")\n",
    "\n",
    "# EBITDA proxy\n",
    "df[\"ebitda_proxy\"] = df[\"oibdp\"]\n",
    "df[\"ebitda_nonpos_flag\"] = (df[\"ebitda_proxy\"] <= 0).astype(\"Int8\")\n",
    "\n",
    "# Log transforms\n",
    "df[\"ln_at\"] = np.log(df[\"at\"].where(lambda s: s > 0))\n",
    "# Legacy name if needed elsewhere\n",
    "df[\"log_at\"] = df[\"ln_at\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Leverage, coverage, and cash-flow ratios (V1, V2, V3 features)",
   "id": "8398da80f9dc0939"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- V1/V2/V3 Shared & Specific Features ---\n",
    "# (Using safe_divide which handles division by zero and returns NaN for extreme states)\n",
    "\n",
    "# Basic Ratios\n",
    "df[\"cash_at\"] = safe_divide(df[\"che\"], df[\"at\"])\n",
    "df[\"current_ratio\"] = safe_divide(df[\"act\"], df[\"lct\"])\n",
    "df[\"nwc_at\"] = safe_divide(df[\"act\"] - df[\"lct\"], df[\"at\"])\n",
    "df[\"aco_act\"] = safe_divide(df[\"aco\"], df[\"act\"])\n",
    "df[\"lco_lct\"] = safe_divide(df[\"lco\"], df[\"lct\"])\n",
    "df[\"rect_act\"] = safe_divide(df[\"rect\"], df[\"act\"])\n",
    "df[\"invt_act\"] = safe_divide(df[\"invt\"], df[\"act\"])\n",
    "df[\"recch_act\"] = safe_divide(df[\"recch\"], df[\"act\"])\n",
    "df[\"invch_act\"] = safe_divide(df[\"invch\"], df[\"act\"])\n",
    "df[\"txp_lct\"] = safe_divide(df[\"txp\"], df[\"lct\"])\n",
    "df[\"txditc_at\"] = safe_divide(df[\"txditc\"], df[\"at\"])\n",
    "df[\"lt_at\"] = safe_divide(df[\"lt\"], df[\"at\"])\n",
    "df[\"dlc_at\"] = safe_divide(df[\"dlc\"], df[\"at\"])\n",
    "df[\"dltt_at\"] = safe_divide(df[\"dltt\"], df[\"at\"])\n",
    "df[\"debt_at\"] = safe_divide(df[\"total_debt\"], df[\"at\"])\n",
    "df[\"st_debt_share\"] = safe_divide(df[\"dlc\"], df[\"total_debt\"])\n",
    "df[\"ebitda_at\"] = safe_divide(df[\"oibdp\"], df[\"at\"])\n",
    "df[\"dp_at\"] = safe_divide(df[\"dp\"], df[\"at\"])\n",
    "df[\"xint_at\"] = safe_divide(df[\"xint\"], df[\"at\"])\n",
    "df[\"interest_coverage\"] = safe_divide(df[\"oibdp\"], df[\"xint\"])\n",
    "df[\"debt_to_ebitda\"] = safe_divide(df[\"total_debt\"], df[\"oibdp\"])\n",
    "df[\"ebit_to_capital\"] = safe_divide(df[\"oibdp\"] - df[\"dp\"], df[\"total_debt\"] + df[\"ceq\"])\n",
    "df[\"capx_at\"] = safe_divide(df[\"capx\"], df[\"at\"])\n",
    "\n",
    "# V2 extras\n",
    "df[\"ppent_at\"] = safe_divide(df[\"ppent\"], df[\"at\"])\n",
    "df[\"intan_at\"] = safe_divide(df[\"intan\"], df[\"at\"])\n",
    "df[\"ocf_to_debt\"] = safe_divide(df[\"oancf\"], df[\"total_debt\"])\n",
    "df[\"fcf_to_debt\"] = safe_divide(df[\"oancf\"] - df[\"capx\"], df[\"total_debt\"])\n",
    "df[\"re_at\"] = safe_divide(df[\"re\"], df[\"at\"])\n",
    "\n",
    "# V3 extras\n",
    "df[\"ceq_at\"] = safe_divide(df[\"ceq\"], df[\"at\"])\n",
    "df[\"caps_at\"] = safe_divide(df[\"caps\"], df[\"at\"])\n",
    "df[\"mibt_at\"] = safe_divide(df[\"mibt\"], df[\"at\"])\n",
    "df[\"niadj_at\"] = safe_divide(df[\"niadj\"], df[\"at\"])\n",
    "df[\"loss_indicator\"] = (df[\"niadj\"] < 0).astype(float)\n",
    "df[\"xint_lct\"] = safe_divide(df[\"xint\"], df[\"lct\"])\n",
    "df[\"aqc_at\"] = safe_divide(df[\"aqc\"], df[\"at\"])\n",
    "df[\"prstkc_at\"] = safe_divide(df[\"prstkc\"], df[\"at\"])\n",
    "\n",
    "# --- Legacy mappings for distress proxy definitions (Section 5.4) ---\n",
    "# (Keeping sp_ prefix for variables used in distress proxy definition rules)\n",
    "ffo_proxy = df[\"oancf\"] + df[\"xint\"]\n",
    "if \"txp\" in df.columns:\n",
    "    ffo_proxy = ffo_proxy - df[\"txp\"]\n",
    "df[\"sp_ffo_to_debt\"] = safe_divide(ffo_proxy, df[\"total_debt\"])\n",
    "df[\"sp_debt_to_capital\"] = safe_divide(df[\"total_debt\"], df[\"total_capital\"])\n",
    "df[\"sp_debt_to_ebitda\"] = df[\"debt_to_ebitda\"]\n",
    "df[\"sp_interest_coverage\"] = df[\"interest_coverage\"].clip(lower=-50, upper=50)\n",
    "\n",
    "# Identify remaining +/-inf (though safe_divide already handles most)\n",
    "ratio_cols = [\"sp_debt_to_capital\",\"sp_debt_to_ebitda\",\"sp_ffo_to_debt\",\"sp_interest_coverage\"]\n",
    "for c in ratio_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].replace([np.inf, -np.inf], np.nan)"
   ],
   "id": "7e74c9720be0b0c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.4 Multiple Distress Proxies (fiscal year t) and next-year supervised labels (t+1)",
   "id": "b0fb583df65bc4b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distress proxy thresholds (frozen and documented)\n",
    "DISTRESS_RULE = {\n",
    "    \"FFO_TO_DEBT_LT\": 0.15,\n",
    "    \"DEBT_TO_CAPITAL_GT\": 0.55,\n",
    "    \"DEBT_TO_EBITDA_GT\": 4.5,\n",
    "    \"NEG_EQUITY_SEQ_LE\": 0.0,\n",
    "}\n",
    "\n",
    "# --- Target construction from raw (non-imputed) data ---\n",
    "# We compute distress proxies from the raw snapshot (df_pre_impute_snapshot) \n",
    "# to ensure that target labels are not contaminated by the imputation process.\n",
    "# Imputation is strictly reserved for predictive features.\n",
    "\n",
    "raw_niadj = ensure_nullable_float(df_pre_impute_snapshot[\"niadj\"])\n",
    "raw_oancf = ensure_nullable_float(df_pre_impute_snapshot[\"oancf\"])\n",
    "raw_seq = ensure_nullable_float(df_pre_impute_snapshot[\"seq\"])\n",
    "\n",
    "# S&P components from raw items (propagate missingness - Issue 3)\n",
    "raw_dlc = ensure_nullable_float(df_pre_impute_snapshot[\"dlc\"])\n",
    "raw_dltt = ensure_nullable_float(df_pre_impute_snapshot[\"dltt\"])\n",
    "raw_total_debt = raw_dlc + raw_dltt\n",
    "\n",
    "raw_oibdp = ensure_nullable_float(df_pre_impute_snapshot[\"oibdp\"])\n",
    "raw_xint = ensure_nullable_float(df_pre_impute_snapshot[\"xint\"])\n",
    "raw_txp = ensure_nullable_float(df_pre_impute_snapshot[\"txp\"]) if \"txp\" in df_pre_impute_snapshot.columns else 0\n",
    "\n",
    "raw_ffo = raw_oancf + raw_xint - raw_txp\n",
    "raw_ffo_to_debt = safe_divide(raw_ffo, raw_total_debt)\n",
    "\n",
    "raw_mibt = ensure_nullable_float(df_pre_impute_snapshot[\"mibt\"]) if \"mibt\" in df_pre_impute_snapshot.columns else pd.Series(np.nan, index=df_pre_impute_snapshot.index)\n",
    "raw_equity = ensure_nullable_float(df_pre_impute_snapshot[[\"seq\",\"mibt\"]].sum(axis=1, min_count=1)) if \"mibt\" in df_pre_impute_snapshot.columns else raw_seq\n",
    "raw_total_capital = raw_total_debt + raw_equity\n",
    "\n",
    "raw_debt_to_cap = safe_divide(raw_total_debt, raw_total_capital)\n",
    "raw_debt_to_ebitda = safe_divide(raw_total_debt, raw_oibdp)\n",
    "\n",
    "# V1: Loss + NegCFO (Accounting-based)\n",
    "# Beaver (1966), Ohlson (1980) logic: niadj < 0 and oancf < 0\n",
    "df[\"distress_v1_t\"] = (raw_niadj < 0) & (raw_oancf < 0)\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_niadj.isna() | raw_oancf.isna(), \"distress_v1_t\"] = pd.NA\n",
    "\n",
    "# V2: Negative Equity\n",
    "df[\"distress_v2_t\"] = raw_seq <= DISTRESS_RULE[\"NEG_EQUITY_SEQ_LE\"]\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_seq.isna(), \"distress_v2_t\"] = pd.NA\n",
    "\n",
    "# V3: S&P High Leverage Solely (without conditioning on negative equity)\n",
    "cond_ffo = raw_ffo_to_debt < DISTRESS_RULE[\"FFO_TO_DEBT_LT\"]\n",
    "cond_cap = raw_debt_to_cap > DISTRESS_RULE[\"DEBT_TO_CAPITAL_GT\"]\n",
    "cond_ebitda = raw_debt_to_ebitda > DISTRESS_RULE[\"DEBT_TO_EBITDA_GT\"]\n",
    "df[\"distress_v3_t\"] = cond_ffo & cond_cap & cond_ebitda\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_ffo_to_debt.isna() | raw_debt_to_cap.isna() | raw_debt_to_ebitda.isna(), \"distress_v3_t\"] = pd.NA\n",
    "\n",
    "# Next-year targets: lead of proxies within firm\n",
    "# Fix: Robust adjacency check (exactly fyear + 1) to avoid mislabeling gaps (Issue 1)\n",
    "next_fyear = df.groupby(\"firm_id\")[\"fyear\"].shift(-1)\n",
    "is_adjacent = (next_fyear == (df[\"fyear\"] + 1))\n",
    "\n",
    "df[\"target_next_v1\"] = df.groupby(\"firm_id\")[\"distress_v1_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v1\"] = pd.NA\n",
    "df[\"target_next_v1\"] = df[\"target_next_v1\"].astype(\"Int8\")\n",
    "\n",
    "df[\"target_next_v2\"] = df.groupby(\"firm_id\")[\"distress_v2_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v2\"] = pd.NA\n",
    "df[\"target_next_v2\"] = df[\"target_next_v2\"].astype(\"Int8\")\n",
    "\n",
    "df[\"target_next_v3\"] = df.groupby(\"firm_id\")[\"distress_v3_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v3\"] = pd.NA\n",
    "df[\"target_next_v3\"] = df[\"target_next_v3\"].astype(\"Int8\")\n",
    "\n",
    "# Note: We keep v1, v2, v3 separate as requested and do not combine them.\n",
    "# v2/target_next_v2 is used as the primary modeling proxy/target in the subsequent sections.\n",
    "PROXY_NAME = \"distress_v3_t\"\n",
    "TARGET_NAME = \"target_next_v3\"\n",
    "\n",
    "# Label availability / attrition (fixed to check adjacency)\n",
    "df[\"has_next_year_obs\"] = is_adjacent.fillna(False).astype(\"Int8\")\n",
    "\n",
    "target_cols = [\"target_next_v1\", \"target_next_v2\", \"target_next_v3\"]\n",
    "print(\"Distress prevalence (by split) — multiple targets:\")\n",
    "display(df.groupby(\"split\")[target_cols].mean())\n",
    "\n",
    "print(\"Share of observations with next-year observation (attrition diagnostic):\")\n",
    "display(df.groupby(\"split\")[\"has_next_year_obs\"].mean().rename(\"has_next_rate\").to_frame())"
   ],
   "id": "374270afcbf5bd23",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76baf30e",
   "metadata": {},
   "source": "### 5.5 Target prevalence and attrition diagnostics (by year and size)"
  },
  {
   "cell_type": "code",
   "id": "4fa023a7",
   "metadata": {},
   "source": [
    "# Target prevalence by label year\n",
    "target_cols = [\"target_next_v1\", \"target_next_v2\", \"target_next_v3\"]\n",
    "agg_dict = {\n",
    "    \"n_obs\": (\"firm_id\", \"size\"),\n",
    "    \"has_next_rate\": (\"has_next_year_obs\", \"mean\"),\n",
    "}\n",
    "for c in target_cols:\n",
    "    agg_dict[f\"{c}_rate\"] = (c, \"mean\")\n",
    "\n",
    "by_label_year = df.groupby([\"label_year\",\"split\"]).agg(**agg_dict).reset_index()\n",
    "\n",
    "display(by_label_year.tail(15))\n",
    "\n",
    "# By size decile (train pool), to assess composition effects\n",
    "agg_dict_size = {\"n_obs\": (\"firm_id\", \"size\")}\n",
    "for c in target_cols:\n",
    "    agg_dict_size[f\"{c}_rate\"] = (c, \"mean\")\n",
    "\n",
    "by_size = df.groupby([\"size_decile\",\"split\"]).agg(**agg_dict_size).reset_index()\n",
    "\n",
    "display(by_size.sort_values([\"split\",\"size_decile\"]).head(30))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8843b675",
   "metadata": {},
   "source": [
    "### 5.6 Event indicators (evt_*) for decision support\n",
    "\n",
    "Events are discrete, interpretable signals designed for operational triage.  \n",
    "They are calibrated **using training data only** (when thresholds are estimated), and we explicitly **exclude** events mechanically tied to the distress-definition ratios (leverage/coverage) from the predictive feature set.\n",
    "\n",
    "Events implemented here (subject to data availability):\n",
    "- Dividend cut / suspension / initiation\n",
    "- Liquidity squeeze (current ratio < 1.0) and quick-ratio squeeze (< 0.8)\n",
    "- EBITDA drop (vs. t-1) and CFO drop (vs. t-1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "973f6172",
   "metadata": {},
   "source": [
    "# Ensure sorting already enforced\n",
    "assert df.index.is_monotonic_increasing\n",
    "\n",
    "# Lag helpers\n",
    "def lag(df_in: pd.DataFrame, col: str, n: int = 1) -> pd.Series:\n",
    "    \"\"\"Robust firm-level lag that enforces year adjacency (Issue 1).\"\"\"\n",
    "    val = df_in.groupby(\"firm_id\")[col].shift(n)\n",
    "    year_lag = df_in.groupby(\"firm_id\")[\"fyear\"].shift(n)\n",
    "    is_adjacent = (year_lag == (df_in[\"fyear\"] - n))\n",
    "    return val.where(is_adjacent.fillna(False), np.nan)\n",
    "\n",
    "# Identify dividend column (prefer dvc if present; else dv / dvt / dvp)\n",
    "dividend_candidates = [\"dvc\",\"dv\",\"dvt\",\"dvp\"]\n",
    "div_col = next((c for c in dividend_candidates if c in df.columns), None)\n",
    "\n",
    "if div_col is None:\n",
    "    print(\"Dividend column not found (looked for dvc/dv/dvt/dvp). Dividend events will be NaN.\")\n",
    "    df[\"evt_divcut\"] = np.nan\n",
    "    df[\"evt_divsusp\"] = np.nan\n",
    "    df[\"evt_divinit\"] = np.nan\n",
    "else:\n",
    "    # Use absolute value (guard against sign conventions)\n",
    "    df[\"dv_obs\"] = pd.to_numeric(df[div_col], errors=\"coerce\").abs()\n",
    "    df[\"dv_obs_l1\"] = lag(df, \"dv_obs\", 1)\n",
    "\n",
    "# Liquidity ratios\n",
    "if \"act\" in df.columns and \"lct\" in df.columns:\n",
    "    df[\"current_ratio\"] = safe_divide(df[\"act\"], df[\"lct\"], denom_floor=1e-6)\n",
    "else:\n",
    "    df[\"current_ratio\"] = np.nan\n",
    "\n",
    "if \"act\" in df.columns and \"lct\" in df.columns:\n",
    "    if \"invt\" in df.columns:\n",
    "        df[\"quick_ratio\"] = safe_divide(pd.to_numeric(df[\"act\"], errors=\"coerce\") - pd.to_numeric(df[\"invt\"], errors=\"coerce\"),\n",
    "                                        df[\"lct\"], denom_floor=1e-6)\n",
    "    elif \"che\" in df.columns and \"rect\" in df.columns:\n",
    "        df[\"quick_ratio\"] = safe_divide(pd.to_numeric(df[\"che\"], errors=\"coerce\") + pd.to_numeric(df[\"rect\"], errors=\"coerce\"),\n",
    "                                        df[\"lct\"], denom_floor=1e-6)\n",
    "    else:\n",
    "        df[\"quick_ratio\"] = df[\"current_ratio\"]\n",
    "else:\n",
    "    df[\"quick_ratio\"] = np.nan\n",
    "\n",
    "# EBITDA and CFO lags for deterioration events\n",
    "if \"ebitda_proxy\" in df.columns:\n",
    "    df[\"ebitda_l1\"] = lag(df, \"ebitda_proxy\", 1)\n",
    "if \"oancf\" in df.columns:\n",
    "    df[\"cfo_l1\"] = lag(df, \"oancf\", 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a512a90",
   "metadata": {},
   "source": [
    "#### 5.5.1 Dividend policy events (training-calibrated cut threshold)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f257c30f",
   "metadata": {},
   "source": [
    "event_params = {}\n",
    "\n",
    "if div_col is None:\n",
    "    pass\n",
    "else:\n",
    "    # YoY % change among observed payers with meaningful baseline\n",
    "    dv_l1 = pd.to_numeric(df[\"dv_obs_l1\"], errors=\"coerce\")\n",
    "    dv = pd.to_numeric(df[\"dv_obs\"], errors=\"coerce\")\n",
    "    df[\"div_pct_change\"] = np.where(dv_l1 > 1e-2, (dv - dv_l1) / dv_l1, np.nan)\n",
    "\n",
    "    payer_train = train_mask & (dv_l1 > 0) & pd.notna(df[\"div_pct_change\"])\n",
    "    if payer_train.sum() >= 50:\n",
    "        cut_thr = float(np.nanpercentile(df.loc[payer_train, \"div_pct_change\"], 10))\n",
    "    else:\n",
    "        cut_thr = -0.25\n",
    "\n",
    "    # Bound cut threshold to avoid pathological values\n",
    "    cut_thr = float(np.clip(cut_thr, -0.50, -0.10))\n",
    "    event_params[\"DIV_CUT_THR_P10_BOUNDED\"] = cut_thr\n",
    "\n",
    "    # Dividend cut: large negative YoY change among payers\n",
    "    df[\"evt_divcut\"] = (df[\"div_pct_change\"] <= cut_thr).astype(\"Int8\")\n",
    "    df.loc[df[\"div_pct_change\"].isna(), \"evt_divcut\"] = pd.NA\n",
    "\n",
    "    # Suspension: payer last year, ~zero dividend now\n",
    "    df[\"evt_divsusp\"] = ((dv_l1 > 0) & (dv.fillna(0) <= 1e-4)).astype(\"Int8\")\n",
    "    df.loc[dv_l1.isna() | dv.isna(), \"evt_divsusp\"] = pd.NA\n",
    "\n",
    "    # Initiation: ~zero last year, dividend now positive\n",
    "    df[\"evt_divinit\"] = ((dv_l1.fillna(0) <= 1e-4) & (dv > 1e-4)).astype(\"Int8\")\n",
    "    df.loc[dv_l1.isna() | dv.isna(), \"evt_divinit\"] = pd.NA\n",
    "\n",
    "    print(f\"Dividend cut threshold (train P10 bounded): {cut_thr:.3f}\")\n",
    "    display(df[[\"dv_obs\",\"dv_obs_l1\",\"div_pct_change\",\"evt_divcut\",\"evt_divsusp\",\"evt_divinit\"]].head(8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ada601d",
   "metadata": {},
   "source": [
    "#### 5.5.2 Liquidity squeeze events"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3735439",
   "metadata": {},
   "source": [
    "cr = pd.to_numeric(df[\"current_ratio\"], errors=\"coerce\")\n",
    "df[\"evt_liq_squeeze\"] = (cr < 1.0).astype(\"Int8\")\n",
    "df.loc[cr.isna(), \"evt_liq_squeeze\"] = pd.NA\n",
    "\n",
    "qr = pd.to_numeric(df[\"quick_ratio\"], errors=\"coerce\")\n",
    "df[\"evt_quick_squeeze\"] = (qr < 0.8).astype(\"Int8\")\n",
    "df.loc[qr.isna(), \"evt_quick_squeeze\"] = pd.NA\n",
    "\n",
    "display(df[[\"current_ratio\",\"quick_ratio\",\"evt_liq_squeeze\",\"evt_quick_squeeze\"]].head(8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d21d0b2",
   "metadata": {},
   "source": [
    "#### 5.5.3 Operating deterioration events (vs. t-1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8da494b5",
   "metadata": {},
   "source": [
    "# EBITDA drop: requires lagged EBITDA observed and positive\n",
    "if \"ebitda_proxy\" in df.columns:\n",
    "    e = pd.to_numeric(df[\"ebitda_proxy\"], errors=\"coerce\")\n",
    "    e_l1 = pd.to_numeric(df[\"ebitda_l1\"], errors=\"coerce\")\n",
    "    ratio = e / e_l1\n",
    "    evt = ((e_l1 > 0) & ((ratio < 0.5) | (e <= 0))).astype(\"Int8\")\n",
    "    evt = evt.where(pd.notna(e_l1) & pd.notna(e), other=pd.NA).astype(\"Int8\")\n",
    "    df[\"evt_ebitdadrop\"] = evt\n",
    "else:\n",
    "    df[\"evt_ebitdadrop\"] = pd.NA\n",
    "\n",
    "# CFO drop: requires lagged CFO observed and positive\n",
    "if \"oancf\" in df.columns:\n",
    "    c = pd.to_numeric(df[\"oancf\"], errors=\"coerce\")\n",
    "    c_l1 = pd.to_numeric(df[\"cfo_l1\"], errors=\"coerce\")\n",
    "    ratio = c / c_l1\n",
    "    evt = ((c_l1 > 0) & ((ratio < 0.5) | (c <= 0))).astype(\"Int8\")\n",
    "    evt = evt.where(pd.notna(c_l1) & pd.notna(c), other=pd.NA).astype(\"Int8\")\n",
    "    df[\"evt_cfdrop\"] = evt\n",
    "else:\n",
    "    df[\"evt_cfdrop\"] = pd.NA\n",
    "\n",
    "display(df[[\"ebitda_proxy\",\"ebitda_l1\",\"evt_ebitdadrop\",\"oancf\",\"cfo_l1\",\"evt_cfdrop\"]].head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "185e58df",
   "metadata": {},
   "source": [
    "#### 5.5.4 Event dictionary (appendix-ready)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cfa35a4",
   "metadata": {},
   "source": [
    "event_dict_rows = [\n",
    "    {\"event\":\"evt_divcut\", \"definition\":\"Dividend YoY % change <= training P10 threshold (bounded [-0.50,-0.10])\", \"inputs\":div_col or \"N/A\", \"calibration\":\"train-only\"},\n",
    "    {\"event\":\"evt_divsusp\", \"definition\":\"Dividend >0 at t-1 and ~0 at t\", \"inputs\":div_col or \"N/A\", \"calibration\":\"none\"},\n",
    "    {\"event\":\"evt_divinit\", \"definition\":\"Dividend ~0 at t-1 and >0 at t\", \"inputs\":div_col or \"N/A\", \"calibration\":\"none\"},\n",
    "    {\"event\":\"evt_liq_squeeze\", \"definition\":\"Current ratio < 1.0\", \"inputs\":\"act,lct\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_quick_squeeze\", \"definition\":\"Quick ratio < 0.8\", \"inputs\":\"act,lct,invt (or che+rect)\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_ebitdadrop\", \"definition\":\"EBITDA <=0 OR EBITDA/EBITDA_{t-1}<0.5 (requires EBITDA_{t-1}>0)\", \"inputs\":\"oibdp\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_cfdrop\", \"definition\":\"CFO <=0 OR CFO/CFO_{t-1}<0.5 (requires CFO_{t-1}>0)\", \"inputs\":\"oancf\", \"calibration\":\"fixed threshold\"},\n",
    "]\n",
    "event_dict = pd.DataFrame(event_dict_rows)\n",
    "event_dict[\"parameter\"] = event_dict[\"event\"].map(lambda e: json.dumps({k:v for k,v in event_params.items()}) if e==\"evt_divcut\" else \"\")\n",
    "display(event_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8efbebce",
   "metadata": {},
   "source": [
    "## 6. Preprocessing for Modeling (train-only fitting)\n",
    "\n",
    "Preprocessing design principles:\n",
    "- **Train-only fitting:** imputation (if needed), winsorization bounds, and scaling are all fit on *train* only.\n",
    "- **Binary events stay in levels** (0/1) to preserve interpretability and prevalence.\n",
    "- **Leakage audit:** variables that mechanically define the distress proxy are excluded from `MODEL_FEATS`.\n",
    "\n",
    "### 6.1 Feature set definition and leakage audit"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b379b8c",
   "metadata": {},
   "source": [
    "# Features that participate in the distress proxy definition (must be excluded from predictors)\n",
    "# We use a dynamic set based on the chosen target to avoid definitional leakage (Issue 2).\n",
    "if TARGET_NAME == \"target_next_v1\":\n",
    "    # v1 uses niadj and oancf\n",
    "    DISTRESS_DEFINITION_VARS = {\"niadj\", \"oancf\", \"niadj_at\", \"loss_indicator\", \"ocf_to_debt\", \"fcf_to_debt\"}\n",
    "elif TARGET_NAME == \"target_next_v2\":\n",
    "    # v2 uses seq\n",
    "    DISTRESS_DEFINITION_VARS = {\"seq\"}\n",
    "elif TARGET_NAME == \"target_next_v3\":\n",
    "    # v3 uses ffo (oancf, xint, txp), debt (dlc, dltt), and equity (seq, mibt)\n",
    "    DISTRESS_DEFINITION_VARS = {\n",
    "        \"sp_ffo_to_debt\", \"sp_debt_to_capital\", \"sp_debt_to_ebitda\",\n",
    "        \"oancf\", \"xint\", \"txp\", \"dlc\", \"dltt\", \"seq\", \"mibt\", \"oibdp\",\n",
    "        \"ocf_to_debt\", \"fcf_to_debt\", \"debt_to_ebitda\", \"interest_coverage\"\n",
    "    }\n",
    "else:\n",
    "    DISTRESS_DEFINITION_VARS = set()\n",
    "\n",
    "# Candidate continuous predictors (selected based on TARGET_NAME)\n",
    "if TARGET_NAME == \"target_next_v1\":\n",
    "    continuous_feats_raw = [c for c in FEATURES_V1]\n",
    "    event_feats = []\n",
    "elif TARGET_NAME == \"target_next_v2\":\n",
    "    continuous_feats_raw = [c for c in FEATURES_V2]\n",
    "    event_feats = []\n",
    "elif TARGET_NAME == \"target_next_v3\":\n",
    "    # loss_indicator is binary, treat as event feature to avoid z-scoring\n",
    "    continuous_feats_raw = [c for c in FEATURES_V3 if c != \"loss_indicator\"]\n",
    "    event_feats = [\"loss_indicator\"]\n",
    "else:\n",
    "    continuous_feats_raw = [c for c in FEATURES_V2]\n",
    "    event_feats = []\n",
    "\n",
    "continuous_feats_raw = [c for c in continuous_feats_raw if c in df.columns]\n",
    "event_feats = [c for c in event_feats if c in df.columns]\n",
    "\n",
    "# Final model feature list (events in levels; continuous will be z-scored with z_ prefix)\n",
    "MODEL_FEATS = [f\"z_{c}\" for c in continuous_feats_raw] + event_feats\n",
    "\n",
    "# Leakage audit: ensure no distress-definition variables are included (raw or scaled variants)\n",
    "leakage_hits = []\n",
    "for v in DISTRESS_DEFINITION_VARS:\n",
    "    if v in continuous_feats_raw or v in event_feats or f\"z_{v}\" in MODEL_FEATS:\n",
    "        leakage_hits.append(v)\n",
    "\n",
    "if leakage_hits:\n",
    "    raise ValueError(f\"Leakage audit failed: distress-definition variables present in feature set: {leakage_hits}\")\n",
    "\n",
    "print(\"Continuous (to be scaled):\", continuous_feats_raw)\n",
    "print(\"Events (kept in levels):\", event_feats)\n",
    "print(\"MODEL_FEATS (post-scaling names):\", MODEL_FEATS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "944e6d68",
   "metadata": {},
   "source": [
    "### 6.2 Modeling sample and target availability"
   ]
  },
  {
   "cell_type": "code",
   "id": "54b0ebd7",
   "metadata": {},
   "source": [
    "# Modeling requires a defined next-year label\n",
    "model_mask = df[TARGET_NAME].notna()\n",
    "df_model = df.loc[model_mask].copy()\n",
    "\n",
    "print(\"Modeling sample size:\", df_model.shape[0])\n",
    "display(df_model[\"split\"].value_counts().to_frame(\"n_obs\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad654f30",
   "metadata": {},
   "source": [
    "### 6.3 Replace infinities and set up train-only median imputation for remaining NaNs"
   ]
  },
  {
   "cell_type": "code",
   "id": "34293218",
   "metadata": {},
   "source": [
    "# Replace inf with NaN for preprocessing\n",
    "for c in continuous_feats_raw:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Train-only medians for remaining NaNs (after earlier imputation steps)\n",
    "train_medians = df_model.loc[df_model[\"split\"]==\"train\", continuous_feats_raw].median()\n",
    "\n",
    "for c in continuous_feats_raw:\n",
    "    df_model[c] = df_model[c].fillna(train_medians[c])\n",
    "\n",
    "# Event features: coerce to Int8 with missing -> 0 (conservative) but preserve missingness flags separately if desired\n",
    "for c in event_feats:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").fillna(0).astype(\"Int8\")\n",
    "\n",
    "assert df_model[continuous_feats_raw].isna().sum().sum() == 0, \"NaNs remain in continuous features after train-median fill.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea8146d5",
   "metadata": {},
   "source": [
    "### 6.4 Winsorize continuous features (train quantile bounds)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ac086d4",
   "metadata": {},
   "source": [
    "winsor_bounds = {}\n",
    "for c in continuous_feats_raw:\n",
    "    lo, hi = winsorize_train_bounds(df_model.loc[df_model[\"split\"]==\"train\", c], CONFIG[\"WINSOR_LO_Q\"], CONFIG[\"WINSOR_HI_Q\"])\n",
    "    winsor_bounds[c] = (lo, hi)\n",
    "    df_model[c] = apply_bounds(df_model[c], lo, hi)\n",
    "\n",
    "winsor_tbl = pd.DataFrame(\n",
    "    [{\"feature\": c, \"lo\": winsor_bounds[c][0], \"hi\": winsor_bounds[c][1]} for c in continuous_feats_raw]\n",
    ")\n",
    "display(winsor_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d779925e",
   "metadata": {},
   "source": [
    "### 6.5 Standardize continuous features (train-fit scaler; z_ prefix)"
   ]
  },
  {
   "cell_type": "code",
   "id": "64b21d21",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize continuous features (fit on TRAIN only)\n",
    "scaler = StandardScaler()\n",
    "df_model[continuous_feats_raw] = df_model[continuous_feats_raw].apply(lambda s: pd.to_numeric(s, errors=\"coerce\"))\n",
    "\n",
    "train_cont = df_model.loc[df_model[\"split\"] == \"train\", continuous_feats_raw].astype(float)\n",
    "scaler.fit(train_cont)\n",
    "\n",
    "Z_all = scaler.transform(df_model[continuous_feats_raw].astype(float))\n",
    "for j, c in enumerate(continuous_feats_raw):\n",
    "    df_model[f\"z_{c}\"] = Z_all[:, j].astype(float)\n",
    "\n",
    "# Final modeling matrix (events forced to clean 0/1 ints)\n",
    "z_cols = [f\"z_{c}\" for c in continuous_feats_raw]\n",
    "X = df_model[z_cols + event_feats].copy()\n",
    "\n",
    "for c in event_feats:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "    X[c] = X[c].fillna(0).astype(\"int8\")\n",
    "    assert set(X[c].unique()).issubset({0, 1}), f\"{c} not binary after coercion: {sorted(X[c].unique())}\"\n",
    "\n",
    "y = df_model[TARGET_NAME].astype(int)\n",
    "\n",
    "# Split views\n",
    "splits = {}\n",
    "for sp in [\"train\", \"val\", \"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    splits[sp] = {\"X\": X.loc[mask, :], \"y\": y.loc[mask], \"df\": df_model.loc[mask, :]}\n",
    "\n",
    "print({sp: (v[\"X\"].shape[0], v[\"X\"].shape[1]) for sp, v in splits.items()})\n",
    "\n",
    "# Numeric-safe finiteness check\n",
    "assert np.isfinite(X.astype(\"float64\").to_numpy()).all(), \"Non-finite values in modeling matrix.\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6734f55",
   "metadata": {},
   "source": [
    "## 7. Model Selection & Training\n",
    "\n",
    "### 7A. Logit model (primary baseline: calibrated PD with interpretable coefficients)\n",
    "\n",
    "#### 7A.1 Hyperparameter tuning on out-of-time validation year"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2ef67f2",
   "metadata": {},
   "source": [
    "train_X, train_y = splits[\"train\"][\"X\"], splits[\"train\"][\"y\"]\n",
    "val_X, val_y = splits[\"val\"][\"X\"], splits[\"val\"][\"y\"]\n",
    "\n",
    "results = []\n",
    "for C in CONFIG[\"LOGIT_C_GRID\"]:\n",
    "    mdl = LogisticRegression(C=C, solver=\"lbfgs\", max_iter=2000, random_state=SEED)\n",
    "    mdl.fit(train_X, train_y)\n",
    "    val_proba = mdl.predict_proba(val_X)[:, 1]\n",
    "    results.append({\n",
    "        \"C\": C,\n",
    "        \"val_roc_auc\": roc_auc_score(val_y, val_proba),\n",
    "        \"val_pr_auc\": average_precision_score(val_y, val_proba),\n",
    "        \"val_brier\": brier_score_loss(val_y, val_proba),\n",
    "    })\n",
    "\n",
    "tune_tbl = pd.DataFrame(results).sort_values(\"val_roc_auc\", ascending=False)\n",
    "display(tune_tbl)\n",
    "\n",
    "best_C = float(tune_tbl.iloc[0][\"C\"])\n",
    "print(\"Selected C:\", best_C)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7A.2 Fit Logit models and generate PDs",
   "id": "6bd079298ae30c36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainval_mask = df_model[\"split\"].isin([\"train\",\"val\"])\n",
    "X_trainval = X.loc[trainval_mask, :]\n",
    "y_trainval = y.loc[trainval_mask]\n",
    "\n",
    "# To ensure 'val' metrics are honest out-of-sample estimates, we use the model \n",
    "# trained on 'train' only for the validation split. \n",
    "# For the final 'test' performance, we use the model trained on 'train+val'.\n",
    "\n",
    "# Model trained on 'train' ONLY (for honest 'val' evaluation)\n",
    "logit_train_only = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=3000, random_state=SEED)\n",
    "logit_train_only.fit(train_X, train_y)\n",
    "\n",
    "# Model trained on 'train+val' (for final 'test' evaluation)\n",
    "logit_trainval = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=3000, random_state=SEED)\n",
    "logit_trainval.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Assign predictions\n",
    "df_model[\"pd_logit\"] = np.nan\n",
    "# val gets predictions from train-only model (honest out-of-sample)\n",
    "df_model.loc[df_model[\"split\"]==\"val\", \"pd_logit\"] = logit_train_only.predict_proba(val_X)[:, 1]\n",
    "# test gets predictions from train+val model\n",
    "df_model.loc[df_model[\"split\"]==\"test\", \"pd_logit\"] = logit_trainval.predict_proba(splits[\"test\"][\"X\"])[:, 1]\n",
    "# train gets predictions from train+val model (in-sample)\n",
    "df_model.loc[df_model[\"split\"]==\"train\", \"pd_logit\"] = logit_trainval.predict_proba(train_X)[:, 1]\n",
    "\n",
    "# For legacy compatibility in reporting\n",
    "df_model[\"pd_logit_val\"] = np.where(df_model[\"split\"]==\"val\", df_model[\"pd_logit\"], np.nan)\n",
    "df_model[\"pd_logit_test\"] = np.where(df_model[\"split\"]==\"test\", df_model[\"pd_logit\"], np.nan)\n",
    "\n",
    "# Keep logit_clf as the final model for downstream use\n",
    "logit_clf = logit_trainval\n",
    "\n",
    "print(\"Example PDs (Logit):\")\n",
    "display(df_model[[\"firm_id\",\"fyear\",\"label_year\",\"split\",TARGET_NAME,\"pd_logit\"]].head(10))"
   ],
   "id": "ce3526c900d40cfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a94a27e",
   "metadata": {},
   "source": [
    "#### 7A.3 Inference audit (statsmodels Logit; clustered standard errors)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c743275",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\n",
    "# Statsmodels requires numpy arrays; keep column names for tables.\n",
    "X_sm = sm.add_constant(X_trainval, has_constant=\"add\")\n",
    "y_sm = y_trainval.astype(float)\n",
    "\n",
    "logit_sm = sm.Logit(y_sm, X_sm)\n",
    "res_sm = logit_sm.fit(disp=False, maxiter=200)\n",
    "\n",
    "# --- Firm cluster (numeric codes to avoid dtype issues) ---\n",
    "firm_raw = df_model.loc[trainval_mask, \"firm_id\"]\n",
    "firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\n",
    "\n",
    "cov_firm = cov_cluster(res_sm, firm_codes)\n",
    "se_firm = np.sqrt(np.diag(cov_firm))\n",
    "\n",
    "# --- Two-way cluster (firm + year), with feasibility + shape guards ---\n",
    "year_raw = df_model.loc[trainval_mask, \"label_year\"]\n",
    "firm_raw = df_model.loc[trainval_mask, \"firm_id\"]\n",
    "\n",
    "firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\n",
    "year_codes = pd.factorize(year_raw, sort=True)[0].astype(np.int64)\n",
    "\n",
    "if (np.unique(firm_codes).size < 2) or (np.unique(year_codes).size < 2):\n",
    "    # Not enough clusters in one dimension -> two-way clustering not identified\n",
    "    se_2 = se_firm.copy()\n",
    "else:\n",
    "    cov_2 = cov_cluster_2groups(res_sm, firm_codes, year_codes)\n",
    "    cov_2 = np.asarray(cov_2)\n",
    "\n",
    "    k = len(res_sm.params)\n",
    "    if cov_2.ndim == 2 and cov_2.shape == (k, k):\n",
    "        se_2 = np.sqrt(np.diag(cov_2))\n",
    "    elif cov_2.ndim == 1 and cov_2.size == k:\n",
    "        # Some statsmodels versions may return only the diagonal variances\n",
    "        se_2 = np.sqrt(cov_2)\n",
    "    else:\n",
    "        # Unexpected shape -> fall back (safer than crashing)\n",
    "        se_2 = se_firm.copy()\n",
    "\n",
    "coef = res_sm.params\n",
    "p_firm = 2 * (1 - stats.norm.cdf(np.abs(coef / se_firm)))\n",
    "p_2 = 2 * (1 - stats.norm.cdf(np.abs(coef / se_2)))\n",
    "\n",
    "infer_tbl = pd.DataFrame({\n",
    "    \"coef_logodds\": coef,\n",
    "    \"se_firm\": se_firm,\n",
    "    \"p_firm\": p_firm,\n",
    "    \"se_firm_year\": se_2,\n",
    "    \"p_firm_year\": p_2,\n",
    "    \"odds_ratio\": np.exp(coef),\n",
    "})\n",
    "infer_tbl.index.name = \"feature\"\n",
    "display(infer_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a69777d6",
   "metadata": {},
   "source": [
    "#### 7A.4 Economic magnitude: MEM marginal effects and IQR-scaled effects"
   ]
  },
  {
   "cell_type": "code",
   "id": "f27addce",
   "metadata": {},
   "source": [
    "# MEM marginal effects using statsmodels (on train+val)\n",
    "try:\n",
    "    me = res_sm.get_margeff(at=\"mean\")\n",
    "    me_tbl = me.summary_frame()\n",
    "    # Align to inference table index (margeff typically excludes const)\n",
    "    me_tbl = me_tbl.reindex(infer_tbl.index)\n",
    "    display(me_tbl)\n",
    "except Exception as e:\n",
    "    print(\"Marginal effects computation failed:\", e)\n",
    "    me_tbl = None\n",
    "\n",
    "# IQR-scaled effects for continuous features (using TRAIN distribution, mapped into z-space)\n",
    "train_df = df_model.loc[df_model[\"split\"]==\"train\", :].copy()\n",
    "\n",
    "iqr_rows = []\n",
    "for j, raw_c in enumerate(continuous_feats_raw):\n",
    "    q25 = float(train_df[raw_c].quantile(0.25))\n",
    "    q75 = float(train_df[raw_c].quantile(0.75))\n",
    "    iqr = q75 - q25\n",
    "    sd = float(scaler.scale_[j]) if scaler.scale_[j] > 0 else np.nan\n",
    "    delta_z = iqr / sd if sd and not np.isnan(sd) else np.nan\n",
    "    beta = float(infer_tbl.loc[f\"z_{raw_c}\", \"coef_logodds\"]) if f\"z_{raw_c}\" in infer_tbl.index else np.nan\n",
    "    logodds_delta = beta * delta_z if not np.isnan(beta) and not np.isnan(delta_z) else np.nan\n",
    "    iqr_rows.append({\n",
    "        \"raw_feature\": raw_c,\n",
    "        \"IQR_raw\": iqr,\n",
    "        \"delta_z_equiv\": delta_z,\n",
    "        \"logodds_change_IQR\": logodds_delta,\n",
    "        \"odds_ratio_IQR\": float(np.exp(logodds_delta)) if not np.isnan(logodds_delta) else np.nan,\n",
    "    })\n",
    "\n",
    "iqr_tbl = pd.DataFrame(iqr_rows)\n",
    "display(iqr_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7A.5 Average Partial Effects (APEs) in probability units with cluster-robust uncertainty\n"
   ],
   "id": "2e05569f33d2eab7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# APEs (Average Partial Effects) for logit model, using delta-method SEs with cluster-robust covariances\n",
    "# Notes:\n",
    "# - For logit, dP/dx_j = p*(1-p)*beta_j. The APE is the sample average of this derivative.\n",
    "# - We compute APEs on the TRAIN+VAL estimation sample used in statsmodels (X_sm, res_sm).\n",
    "# - SEs use the same cluster-robust covariance matrices already computed above (cov_firm and cov_2).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "def _coerce_cov(V, names):\n",
    "    \"\"\"Return numeric (k x k) covariance aligned to names. Fallback logic handles common statsmodels outputs.\"\"\"\n",
    "    k = len(names)\n",
    "\n",
    "    if isinstance(V, pd.DataFrame):\n",
    "        V = V.reindex(index=names, columns=names).to_numpy(dtype=float)\n",
    "        return V\n",
    "\n",
    "    V = np.asarray(V)\n",
    "    V = np.squeeze(V)\n",
    "\n",
    "    # Handle 3D objects (e.g., (3,k,k) or (k,k,3)): take first covariance slice\n",
    "    if V.ndim == 3:\n",
    "        if V.shape[1:] == (k, k):\n",
    "            V = V[0]\n",
    "        elif V.shape[:2] == (k, k):\n",
    "            V = V[:, :, 0]\n",
    "        else:\n",
    "            V = V.reshape(-1, k, k)[0]\n",
    "\n",
    "    # Handle diagonal-only variances\n",
    "    if V.ndim == 1:\n",
    "        if V.size != k:\n",
    "            raise ValueError(f\"Unexpected 1D covariance length: {V.size} (expected {k})\")\n",
    "        V = np.diag(V.astype(float))\n",
    "\n",
    "    if V.ndim != 2 or V.shape != (k, k):\n",
    "        raise ValueError(f\"Unexpected covariance shape: {V.shape} (expected {(k, k)})\")\n",
    "\n",
    "    V = V.astype(float)\n",
    "    V[~np.isfinite(V)] = 0.0\n",
    "    return V\n",
    "\n",
    "# ---- Align design matrix to params order ----\n",
    "X_df = X_sm if isinstance(X_sm, pd.DataFrame) else pd.DataFrame(X_sm)\n",
    "b_ser = res_sm.params\n",
    "\n",
    "names = list(b_ser.index)\n",
    "X_df = X_df.loc[:, names]                 # enforce same column order\n",
    "X_audit_np = X_df.to_numpy(dtype=float)\n",
    "\n",
    "b = b_ser.to_numpy(dtype=float)\n",
    "k = len(names)\n",
    "\n",
    "# Predicted probabilities on estimation sample\n",
    "eta = X_audit_np @ b\n",
    "p = 1.0 / (1.0 + np.exp(-eta))\n",
    "w = p * (1.0 - p)\n",
    "mw = float(np.mean(w))\n",
    "\n",
    "# APE_j = beta_j * mean(w)\n",
    "ape = b * mw\n",
    "if \"const\" in names:\n",
    "    ape[names.index(\"const\")] = np.nan\n",
    "\n",
    "# Delta-method gradient\n",
    "t = (w * (1.0 - 2.0 * p))[:, None] * X_audit_np\n",
    "dmw_db = np.mean(t, axis=0)\n",
    "\n",
    "G = np.full((k, k), np.nan, dtype=float)\n",
    "for j in range(k):\n",
    "    if names[j] == \"const\":\n",
    "        continue\n",
    "    g = dmw_db * b[j]\n",
    "    g[j] += mw\n",
    "    G[j, :] = g\n",
    "\n",
    "# Covariances (coerce 2-way; fallback to firm)\n",
    "V_firm = _coerce_cov(cov_firm, names)\n",
    "if \"cov_2\" in globals():\n",
    "    try:\n",
    "        V_2 = _coerce_cov(cov_2, names)\n",
    "    except Exception:\n",
    "        V_2 = V_firm\n",
    "else:\n",
    "    V_2 = V_firm\n",
    "\n",
    "def _se_from_V(V):\n",
    "    se = np.full(k, np.nan, dtype=float)\n",
    "    for j in range(k):\n",
    "        if not np.all(np.isfinite(G[j, :])):\n",
    "            continue\n",
    "        g = G[j, :].astype(float)\n",
    "        v = (g @ V @ g).item()  # scalar quadratic form\n",
    "        se[j] = np.sqrt(v) if v >= 0 else np.nan\n",
    "    return se\n",
    "\n",
    "se_ape_firm = _se_from_V(V_firm)\n",
    "se_ape_2 = _se_from_V(V_2)\n",
    "\n",
    "# p-values (normal approximation)\n",
    "z_firm = ape / se_ape_firm\n",
    "p_ape_firm = 2 * (1 - stats.norm.cdf(np.abs(z_firm)))\n",
    "\n",
    "z_2 = ape / se_ape_2\n",
    "p_ape_2 = 2 * (1 - stats.norm.cdf(np.abs(z_2)))\n",
    "\n",
    "ape_tbl = pd.DataFrame({\n",
    "    \"APE\": ape,\n",
    "    \"se_APE_firm\": se_ape_firm,\n",
    "    \"p_APE_firm\": p_ape_firm,\n",
    "    \"se_APE_firm_year\": se_ape_2,\n",
    "    \"p_APE_firm_year\": p_ape_2,\n",
    "}, index=pd.Index(names, name=\"feature\"))\n",
    "\n",
    "display(ape_tbl)\n",
    "\n",
    "infer_tbl_with_ape = infer_tbl.join(ape_tbl, how=\"left\")\n",
    "display(infer_tbl_with_ape)\n"
   ],
   "id": "c05ca6e8e5396cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de67ec61",
   "metadata": {},
   "source": [
    "#### 7A.5 Walk-forward validation (expanding window)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae44dc91",
   "metadata": {},
   "source": [
    "trainpool_df = df_model.loc[df_model[\"split\"].isin([\"train\",\"val\"]), :].copy()\n",
    "years = sorted(trainpool_df[\"label_year\"].unique().tolist())\n",
    "years = [int(y) for y in years if pd.notna(y)]\n",
    "\n",
    "N_SPLITS = 4\n",
    "if len(years) < (N_SPLITS + 2):\n",
    "    print(\"Not enough years for walk-forward validation; skipping.\")\n",
    "    wf_tbl = pd.DataFrame()\n",
    "else:\n",
    "    # Choose split points evenly across the year range (excluding last year to keep a holdout)\n",
    "    split_idx = np.linspace(2, len(years)-1, N_SPLITS, dtype=int)\n",
    "    wf_rows = []\n",
    "    for k in split_idx:\n",
    "        train_years = years[:k]\n",
    "        val_year = years[k]\n",
    "        tr = trainpool_df[\"label_year\"].isin(train_years)\n",
    "        va = trainpool_df[\"label_year\"].isin([val_year])\n",
    "\n",
    "        X_tr = trainpool_df.loc[tr, [f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "        y_tr = trainpool_df.loc[tr, TARGET_NAME].astype(int)\n",
    "        X_va = trainpool_df.loc[va, [f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "        y_va = trainpool_df.loc[va, TARGET_NAME].astype(int)\n",
    "\n",
    "        mdl = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=2000, random_state=SEED)\n",
    "        mdl.fit(X_tr, y_tr)\n",
    "        p_va = mdl.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        wf_rows.append({\n",
    "            \"train_years_min\": min(train_years),\n",
    "            \"train_years_max\": max(train_years),\n",
    "            \"val_year\": val_year,\n",
    "            \"n_train\": int(len(y_tr)),\n",
    "            \"n_val\": int(len(y_va)),\n",
    "            \"roc_auc\": roc_auc_score(y_va, p_va),\n",
    "            \"pr_auc\": average_precision_score(y_va, p_va),\n",
    "            \"brier\": brier_score_loss(y_va, p_va),\n",
    "        })\n",
    "    wf_tbl = pd.DataFrame(wf_rows)\n",
    "    display(wf_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0b34ac3",
   "metadata": {},
   "source": [
    "\n",
    "### 7B. Tree-based model (XGBoost; nonlinear )\n",
    "Tree models capture interactions and nonlinearities that logit cannot, but they require stronger regularization and calibration discipline.\n",
    "\n",
    "Implementation details:\n",
    "- Early stopping on **PR-AUC** using validation split.\n",
    "- Conservative depth and regularization parameters.\n",
    "- Cost-sensitive weighting to reflect class imbalance and FN/FP asymmetry.\n",
    "- **Isotonic calibration** fit on validation predictions (train-only model remains unchanged).\n",
    "\n",
    "#### 7B.1 Train XGBoost with early stopping (validation PR-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8810a478",
   "metadata": {},
   "source": [
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 0) Pull split matrices\n",
    "# ---------------------------------------------------------------------\n",
    "X_tr = splits[\"train\"][\"X\"]\n",
    "y_tr = splits[\"train\"][\"y\"].astype(int)\n",
    "\n",
    "X_va = splits[\"val\"][\"X\"]\n",
    "y_va = splits[\"val\"][\"y\"].astype(int)\n",
    "\n",
    "X_te = splits[\"test\"][\"X\"]\n",
    "y_te = splits[\"test\"][\"y\"].astype(int)\n",
    "\n",
    "# Optional: a dedicated calibration split (preferred)\n",
    "HAS_CALIB = \"calib\" in splits\n",
    "if HAS_CALIB:\n",
    "    X_ca = splits[\"calib\"][\"X\"]\n",
    "    y_ca = splits[\"calib\"][\"y\"].astype(int)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1) Class imbalance summary\n",
    "# ---------------------------------------------------------------------\n",
    "n_pos = int(y_tr.sum())\n",
    "n_neg = int((y_tr == 0).sum())\n",
    "imbalance = n_neg / max(n_pos, 1)\n",
    "base_rate = n_pos / max((n_pos + n_neg), 1)\n",
    "\n",
    "print(f\"[Train] n={n_pos+n_neg:,}  pos={n_pos:,}  neg={n_neg:,}  base_rate={base_rate:.4f}  imbalance={imbalance:.2f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2) TRAINING WEIGHTS (choose ONE philosophy)\n",
    "# ---------------------------------------------------------------------\n",
    "# Philosophy A (recommended): handle imbalance in training; handle costs at decision time\n",
    "#   -> stable ranking; cost sensitivity handled by threshold/capacity policy later.\n",
    "USE_COSTS_IN_TRAINING = False\n",
    "\n",
    "if USE_COSTS_IN_TRAINING:\n",
    "    # Philosophy B: cost-sensitive training only (do NOT also multiply by imbalance)\n",
    "    w_pos = float(CONFIG[\"COST_FN\"])\n",
    "    w_neg = float(CONFIG[\"COST_FP\"])\n",
    "    w_tr = np.where(y_tr.values == 1, w_pos, w_neg).astype(float)\n",
    "    print(f\"[Weights] cost-only: w_pos={w_pos:.3f} w_neg={w_neg:.3f} ratio={w_pos/max(w_neg,1e-12):.1f}\")\n",
    "else:\n",
    "    # Imbalance-only weighting\n",
    "    w_pos = float(imbalance)\n",
    "    w_neg = 1.0\n",
    "    w_tr = np.where(y_tr.values == 1, w_pos, w_neg).astype(float)\n",
    "    print(f\"[Weights] imbalance-only: w_pos={w_pos:.3f} w_neg={w_neg:.3f} ratio={w_pos/max(w_neg,1e-12):.1f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Build DMatrices\n",
    "#    - Train has weights (optional)\n",
    "#    - Validation has NO weights (recommended) to keep early stopping honest/stable\n",
    "# ---------------------------------------------------------------------\n",
    "feature_names = X_tr.columns.tolist()\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr, feature_names=feature_names)\n",
    "dval   = xgb.DMatrix(X_va, label=y_va, feature_names=feature_names)\n",
    "dtest  = xgb.DMatrix(X_te, label=y_te, feature_names=feature_names)\n",
    "\n",
    "# \"All rows\" for producing PDs in df_model\n",
    "# Ensure X and y exist in your notebook scope\n",
    "dall = xgb.DMatrix(X, label=y.astype(int), feature_names=feature_names)\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Train XGBoost with early stopping on val\n",
    "# ---------------------------------------------------------------------\n",
    "xgb_model = xgb.train(\n",
    "    params=CONFIG[\"XGB_PARAMS\"],\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=CONFIG[\"XGB_NUM_BOOST_ROUND\"],\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=CONFIG[\"XGB_EARLY_STOPPING\"],\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "best_iter = int(getattr(xgb_model, \"best_iteration\", 0))\n",
    "print(\"Best iteration:\", best_iter)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6a23d75",
   "metadata": {},
   "source": [
    "#### 7B.2 Isotonic calibration on validation set (probability calibration)"
   ]
  },
  {
   "cell_type": "code",
   "id": "86dbd5a4",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5) Predict raw probabilities\n",
    "# ---------------------------------------------------------------------\n",
    "p_val_raw  = xgb_model.predict(dval)\n",
    "p_test_raw = xgb_model.predict(dtest)\n",
    "p_all_raw  = xgb_model.predict(dall)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) Calibration\n",
    "#    Preferred: fit isotonic on a dedicated calibration split (not used for early stopping)\n",
    "#    Fallback: fit on val (but note this \"double uses\" val)\n",
    "# ---------------------------------------------------------------------\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "\n",
    "if HAS_CALIB:\n",
    "    dcalib = xgb.DMatrix(X_ca, label=y_ca, feature_names=feature_names)\n",
    "    p_calib_raw = xgb_model.predict(dcalib)\n",
    "    iso.fit(p_calib_raw, y_ca.values.astype(int))\n",
    "    print(\"Calibration fitted on separate calibration split (recommended).\")\n",
    "else:\n",
    "    iso.fit(p_val_raw, y_va.values.astype(int))\n",
    "    print(\"Calibration fitted on validation (fallback; val is reused).\")\n",
    "\n",
    "# Calibrated PDs for all observations in df_model\n",
    "df_model[\"pd_tree\"] = iso.transform(p_all_raw)\n",
    "\n",
    "# Optional diagnostics: split means (not a calibration metric, but a quick sanity check)\n",
    "print(\"Mean calibrated PD by split:\")\n",
    "display(df_model.groupby(\"split\")[\"pd_tree\"].mean().to_frame(\"mean_pd_tree\"))\n",
    "\n",
    "# Optional: store raw PD too for debugging / plots\n",
    "df_model[\"pd_tree_raw\"] = p_all_raw"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fdd237e",
   "metadata": {},
   "source": [
    "#### 7B.3 Feature importance and SHAP (optional explainability)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5a56f06",
   "metadata": {},
   "source": [
    "# Gain-based feature importance\n",
    "importance = xgb_model.get_score(importance_type=\"gain\")\n",
    "imp_tbl = (pd.DataFrame({\"feature\": list(importance.keys()), \"gain\": list(importance.values())})\n",
    "             .sort_values(\"gain\", ascending=False))\n",
    "display(imp_tbl.head(20))\n",
    "\n",
    "# Optional: SHAP summary for a subsample (can be expensive on large panels)\n",
    "try:\n",
    "    import shap\n",
    "    shap.initjs()\n",
    "    sample_n = min(5000, X_tr.shape[0])\n",
    "    X_sample = X_tr.sample(sample_n, random_state=SEED)\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_sample, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"shap_summary_tree.png\", dpi=160)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped:\", e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ffaf2ac",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation & Diagnostic Monitoring\n",
    "\n",
    "All evaluation in this section treats the **test split as untouchable**: no tuning based on test results.\n",
    "\n",
    "**Clean Evaluation Protocol Note:**\n",
    "- For **Logit**: The validation (`val`) performance reported below is an honest out-of-sample estimate because it uses a model trained on `train` only. The test performance uses a model trained on `train+val`.\n",
    "- For **Tree (XGBoost)**: The validation (`val`) performance is **in-sample** relative to early stopping and isotonic calibration, both of which use the validation set. Therefore, `val` performance for trees will appear optimistic.\n",
    "- **Unbiased Performance**: The **test split** results are the only strictly unbiased final performance metrics.\n",
    "\n",
    "We report:\n",
    "- ROC-AUC, PR-AUC, Brier score,\n",
    "- calibration curve and calibration slope (reliability),\n",
    "- persistence benchmark,\n",
    "- collinearity and drift diagnostics.\n",
    "\n",
    "### 8.1 Out-of-sample metrics (val and test) + persistence benchmark"
   ]
  },
  {
   "cell_type": "code",
   "id": "29873ad3",
   "metadata": {},
   "source": [
    "def eval_metrics(y_true: pd.Series, p: np.ndarray) -> dict:\n",
    "    y_true = y_true.astype(int).values\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc_score(y_true, p),\n",
    "        \"pr_auc\": average_precision_score(y_true, p),\n",
    "        \"brier\": brier_score_loss(y_true, p),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"event_rate\": float(np.mean(y_true)),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for sp in [\"val\",\"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    y_sp = df_model.loc[mask, TARGET_NAME].astype(int)\n",
    "\n",
    "    rows.append({\"split\": sp, \"model\":\"logit\", **eval_metrics(y_sp, df_model.loc[mask, \"pd_logit\"].values)})\n",
    "    rows.append({\"split\": sp, \"model\":\"tree_calibrated\", **eval_metrics(y_sp, df_model.loc[mask, \"pd_tree\"].values)})\n",
    "\n",
    "    # Persistence benchmark: predict next-year distress = current-year PROXY_NAME\n",
    "    pers = pd.to_numeric(df_model.loc[mask, PROXY_NAME], errors=\"coerce\").fillna(0).astype(int).values\n",
    "    rows.append({\"split\": sp, \"model\":\"persistence\", **eval_metrics(y_sp, pers)})\n",
    "\n",
    "metrics_tbl = pd.DataFrame(rows).sort_values([\"split\",\"model\"])\n",
    "display(metrics_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1b Early-warning vs Surveillance decomposition (state-conditional evaluation)\n"
   ],
   "id": "51c21d935f978c85"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Early-warning vs surveillance evaluation:\n",
    "#   - Early warning: subset with PROXY_NAME == 0 (not currently distressed)\n",
    "#   - Surveillance: subset with PROXY_NAME == 1 (currently distressed)\n",
    "# Also add a state-only baseline: predict next-year distress using current state only.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_eval_metrics(y_true: pd.Series, p: np.ndarray) -> dict:\n",
    "    y = y_true.astype(int).values\n",
    "    out = {\n",
    "        \"roc_auc\": np.nan,\n",
    "        \"pr_auc\": np.nan,\n",
    "        \"brier\": brier_score_loss(y, p),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"event_rate\": float(np.mean(y)),\n",
    "        \"n\": int(len(y)),\n",
    "    }\n",
    "    if np.unique(y).size >= 2:\n",
    "        out[\"roc_auc\"] = roc_auc_score(y, p)\n",
    "        out[\"pr_auc\"] = average_precision_score(y, p)\n",
    "    return out\n",
    "\n",
    "def eval_segment(df_seg: pd.DataFrame, split_name: str, segment_name: str) -> list:\n",
    "    rows = []\n",
    "    if df_seg.empty:\n",
    "        return rows\n",
    "\n",
    "    y = df_seg[TARGET_NAME].astype(int)\n",
    "\n",
    "    # State-only baseline (uses current distress state only)\n",
    "    state = pd.to_numeric(df_seg[PROXY_NAME], errors=\"coerce\").fillna(0).astype(int).values\n",
    "    base = safe_eval_metrics(y, state)\n",
    "\n",
    "    # Models\n",
    "    for col, mdl in [(\"pd_logit\",\"logit\"),\n",
    "                     (\"pd_tree\",\"tree_calibrated\")]:\n",
    "        met = safe_eval_metrics(y, df_seg[col].values)\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"segment\": segment_name,\n",
    "            \"model\": mdl,\n",
    "            **met,\n",
    "            \"baseline_roc_auc\": base[\"roc_auc\"],\n",
    "            \"baseline_pr_auc\": base[\"pr_auc\"],\n",
    "            \"baseline_brier\": base[\"brier\"],\n",
    "            \"delta_roc_auc\": (met[\"roc_auc\"] - base[\"roc_auc\"]) if (met[\"roc_auc\"]==met[\"roc_auc\"] and base[\"roc_auc\"]==base[\"roc_auc\"]) else np.nan,\n",
    "            \"delta_pr_auc\": (met[\"pr_auc\"] - base[\"pr_auc\"]) if (met[\"pr_auc\"]==met[\"pr_auc\"] and base[\"pr_auc\"]==base[\"pr_auc\"]) else np.nan,\n",
    "            \"delta_brier\": met[\"brier\"] - base[\"brier\"],  # negative is improvement\n",
    "        })\n",
    "\n",
    "    # Add baseline as a row for reference\n",
    "    rows.append({\n",
    "        \"split\": split_name,\n",
    "        \"segment\": segment_name,\n",
    "        \"model\": \"state_only\",\n",
    "        **base,\n",
    "        \"baseline_roc_auc\": np.nan,\n",
    "        \"baseline_pr_auc\": np.nan,\n",
    "        \"baseline_brier\": np.nan,\n",
    "        \"delta_roc_auc\": 0.0,\n",
    "        \"delta_pr_auc\": 0.0,\n",
    "        \"delta_brier\": 0.0,\n",
    "    })\n",
    "    return rows\n",
    "\n",
    "seg_rows = []\n",
    "for sp in [\"val\", \"test\"]:\n",
    "    df_sp = df_model.loc[df_model[\"split\"]==sp, :].copy()\n",
    "\n",
    "    # Only evaluate segments where current distress state is observed.\n",
    "    dcur = pd.to_numeric(df_sp[PROXY_NAME], errors=\"coerce\")\n",
    "    df_sp = df_sp.loc[dcur.notna(), :].copy()\n",
    "    df_sp[\"distress_t_int\"] = dcur.loc[dcur.notna()].astype(int)\n",
    "\n",
    "    seg_rows += eval_segment(df_sp.loc[df_sp[\"distress_t_int\"]==0, :], sp, f\"early_warning ({PROXY_NAME}=0)\")\n",
    "    seg_rows += eval_segment(df_sp.loc[df_sp[\"distress_t_int\"]==1, :], sp, f\"surveillance ({PROXY_NAME}=1)\")\n",
    "\n",
    "seg_metrics_tbl = pd.DataFrame(seg_rows)\n",
    "\n",
    "if not seg_metrics_tbl.empty:\n",
    "    seg_metrics_tbl = seg_metrics_tbl.sort_values([\"split\",\"segment\",\"model\"])\n",
    "    display(seg_metrics_tbl)\n",
    "else:\n",
    "    print(\"No segment metrics computed (empty segments).\")\n"
   ],
   "id": "ff41db2c85a96e38",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14804efc",
   "metadata": {},
   "source": [
    "### 8.2 Calibration diagnostics (curve + calibration-in-the-large + slope)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac2c963a",
   "metadata": {},
   "source": [
    "def calibration_slope_intercept(y_true: np.ndarray, p: np.ndarray) -> tuple[float,float]:\n",
    "    z = logit(p)\n",
    "    Xc = sm.add_constant(z, has_constant=\"add\")\n",
    "    mdl = sm.GLM(y_true, Xc, family=sm.families.Binomial())\n",
    "    res = mdl.fit()\n",
    "    intercept, slope = res.params[0], res.params[1]\n",
    "    return float(intercept), float(slope)\n",
    "\n",
    "def plot_calibration(y_true: np.ndarray, p: np.ndarray, title: str, fname: str):\n",
    "    frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=10, strategy=\"quantile\")\n",
    "    plt.figure()\n",
    "    plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"Mean predicted probability\")\n",
    "    plt.ylabel(\"Fraction of positives\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / fname, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "for sp in [\"val\",\"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    y_sp = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "    for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "        p = df_model.loc[mask, pcol].values\n",
    "        icpt, slope = calibration_slope_intercept(y_sp, p)\n",
    "        print(f\"{sp} | {model_name}: calibration intercept={icpt:.3f}, slope={slope:.3f}\")\n",
    "        plot_calibration(y_sp, p, f\"Calibration curve — {model_name} ({sp})\", f\"cal_curve_{model_name}_{sp}.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dae2a433",
   "metadata": {},
   "source": [
    "### 8.3 Temporal stability (walk-forward fold metrics)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0c531ed",
   "metadata": {},
   "source": [
    "if 'wf_tbl' in globals() and len(wf_tbl) > 0:\n",
    "    display(wf_tbl)\n",
    "    plt.figure()\n",
    "    plt.plot(wf_tbl[\"val_year\"], wf_tbl[\"roc_auc\"], marker=\"o\", label=\"ROC-AUC\")\n",
    "    plt.plot(wf_tbl[\"val_year\"], wf_tbl[\"pr_auc\"], marker=\"o\", label=\"PR-AUC\")\n",
    "    plt.title(\"Walk-forward validation metrics (logit)\")\n",
    "    plt.xlabel(\"Validation label_year\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"walkforward_metrics_logit.png\", dpi=160)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e114cc8",
   "metadata": {},
   "source": [
    "### 8.4 Collinearity checks (VIF + high-correlation pairs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a73fa727",
   "metadata": {},
   "source": [
    "# VIF on continuous z-features (train only)\n",
    "X_vif = splits[\"train\"][\"X\"][[f\"z_{c}\" for c in continuous_feats_raw]].copy()\n",
    "X_vif = sm.add_constant(X_vif, has_constant=\"add\")\n",
    "\n",
    "vif_rows = []\n",
    "for i, col in enumerate(X_vif.columns):\n",
    "    if col == \"const\":\n",
    "        continue\n",
    "    vif_rows.append({\"feature\": col, \"VIF\": float(variance_inflation_factor(X_vif.values, i))})\n",
    "\n",
    "vif_tbl = pd.DataFrame(vif_rows).sort_values(\"VIF\", ascending=False)\n",
    "display(vif_tbl)\n",
    "\n",
    "# Correlation screen (continuous only)\n",
    "corr = splits[\"train\"][\"X\"][[f\"z_{c}\" for c in continuous_feats_raw]].corr()\n",
    "high_pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        v = corr.iloc[i,j]\n",
    "        if abs(v) >= 0.85:\n",
    "            high_pairs.append((corr.columns[i], corr.columns[j], float(v)))\n",
    "high_pairs_tbl = pd.DataFrame(high_pairs, columns=[\"feat1\",\"feat2\",\"corr\"]).sort_values(\"corr\", key=np.abs, ascending=False)\n",
    "display(high_pairs_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a8305ac",
   "metadata": {},
   "source": [
    "### 8.5 Drift diagnostics (standardized mean difference: train vs test)"
   ]
  },
  {
   "cell_type": "code",
   "id": "82250df7",
   "metadata": {},
   "source": [
    "feat_cols = [f\"z_{c}\" for c in continuous_feats_raw] + event_feats\n",
    "drift_rows = []\n",
    "for c in feat_cols:\n",
    "    smd = compute_smd(df_model.loc[df_model[\"split\"]==\"train\", c], df_model.loc[df_model[\"split\"]==\"test\", c])\n",
    "    drift_rows.append({\"feature\": c, \"SMD_train_vs_test\": smd})\n",
    "drift_tbl = pd.DataFrame(drift_rows).sort_values(\"SMD_train_vs_test\", key=lambda s: s.abs(), ascending=False)\n",
    "display(drift_tbl.head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "03071f10",
   "metadata": {},
   "source": [
    "### 8.6 Probability distributions by class (test split)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce4a5617",
   "metadata": {},
   "source": [
    "mask = df_model[\"split\"]==\"test\"\n",
    "y_true = df_model.loc[mask, TARGET_NAME].astype(int)\n",
    "\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol]\n",
    "    plt.figure()\n",
    "    plt.hist(p[y_true==0], bins=50, alpha=0.6, label=\"y=0\")\n",
    "    plt.hist(p[y_true==1], bins=50, alpha=0.6, label=\"y=1\")\n",
    "    plt.title(f\"Test PD histogram by class — {model_name}\")\n",
    "    plt.xlabel(\"Predicted PD\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"pd_hist_{model_name}_test.png\", dpi=160)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50013862",
   "metadata": {},
   "source": [
    "## 9. Operational Risk Management Layer (Events + PDs)\n",
    "This section uses a **two-layer** design:\n",
    "\n",
    "- **Model layer (prediction):** calibrated probability of next-year distress (**PD**) from accounting ratios and structural predictors.\n",
    "- **Indicator layer (events):** discrete `evt_*` early-warning indicators **not used as predictors**. They serve governance, monitoring, and decision support.\n",
    "\n",
    "This structure matches four operational functions commonly discussed in risk-management systems:\n",
    "\n",
    "1. **Risk awareness:** documented prior knowledge of which indicators flag trouble (event dictionary + empirical lift).\n",
    "2. **Monitoring and warning:** continuous tracking of event activation/persistence and PD levels over the panel.\n",
    "3. **Communication:** translating signals into decision-maker-friendly views (risk tiers/deciles, transitions, reason codes).\n",
    "4. **Response capability:** predefined action rules (screen / monitor / no action) based on PDs and events under explicit costs and capacity constraints.\n",
    "\n",
    "### 9.1 Risk awareness — event dictionary and conditional risk (lift)"
   ]
  },
  {
   "cell_type": "code",
   "id": "94c3906b",
   "metadata": {},
   "source": [
    "EVT_COLS = event_dict[\"event\"].tolist()\n",
    "print(\"Decision-support events:\", EVT_COLS)\n",
    "\n",
    "# Optional: enrich the event dictionary with a simple mechanism taxonomy (appendix-ready)\n",
    "event_dict_enriched = event_dict.copy()\n",
    "mech_map = {\n",
    "    \"evt_divcut\": \"Payout policy\",\n",
    "    \"evt_divsusp\": \"Payout policy\",\n",
    "    \"evt_divinit\": \"Payout policy\",\n",
    "    \"evt_liq_squeeze\": \"Liquidity\",\n",
    "    \"evt_quick_squeeze\": \"Liquidity\",\n",
    "    \"evt_ebitdadrop\": \"Operating deterioration\",\n",
    "    \"evt_cfdrop\": \"Operating deterioration\",\n",
    "}\n",
    "event_dict_enriched[\"mechanism\"] = event_dict_enriched[\"event\"].map(mech_map).fillna(\"Other/unspecified\")\n",
    "display(event_dict_enriched)\n",
    "\n",
    "def event_lift_table(df_in: pd.DataFrame, events: list[str], y_col: str) -> pd.DataFrame:\n",
    "    # Event lift with explicit missingness handling.\n",
    "    # - prevalence_obs: among observations where the event is observed (not NA)\n",
    "    # - missing_rate: definitional missingness (insufficient inputs)\n",
    "    # - cond_distress_rate: P(y=1 | evt=1, evt observed)\n",
    "\n",
    "    base = df_in[y_col].astype(float).mean()\n",
    "    rows = []\n",
    "    for e in events:\n",
    "        if e not in df_in.columns:\n",
    "            continue\n",
    "\n",
    "        s = pd.to_numeric(df_in[e], errors=\"coerce\")  # may contain NA by construction\n",
    "        miss = float(s.isna().mean())\n",
    "        obs = s.notna()\n",
    "        if obs.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        s_obs = s[obs].astype(int)\n",
    "        n_event = int((s_obs == 1).sum())\n",
    "        if n_event == 0:\n",
    "            continue\n",
    "\n",
    "        rate = df_in.loc[obs & (s == 1), y_col].astype(float).mean()\n",
    "        prev = float((s_obs == 1).mean())\n",
    "\n",
    "        rows.append({\n",
    "            \"event\": e,\n",
    "            \"mechanism\": mech_map.get(e, \"Other/unspecified\"),\n",
    "            \"n_obs_event\": int(obs.sum()),\n",
    "            \"n_event\": n_event,\n",
    "            \"missing_rate\": miss,\n",
    "            \"prevalence_obs\": prev,\n",
    "            \"cond_distress_rate\": float(rate),\n",
    "            \"base_rate\": float(base),\n",
    "            \"lift_vs_base\": float(rate/base) if base > 0 else np.nan,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    if not out.empty:\n",
    "        out = out.sort_values([\"lift_vs_base\", \"n_event\"], ascending=[False, False])\n",
    "    return out\n",
    "\n",
    "for sp in [\"train\", \"test\"]:\n",
    "    df_sp = df_model.loc[df_model[\"split\"] == sp, :].copy()\n",
    "    print(f\"\\nEvent lift (labels: {TARGET_NAME}) — {sp}\")\n",
    "    display(event_lift_table(df_sp, EVT_COLS, TARGET_NAME).head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35162ffd",
   "metadata": {},
   "source": [
    "### 9.2 Monitoring and warning — event dynamics, persistence, and PD×event risk grids\n",
    "\n",
    "Monitoring should reflect (i) **activation** (0→1), (ii) **persistence** (1→1), and (iii) how event regimes interact with PDs.\n",
    "We treat events as *operational indicators* (not predictors) and monitor them jointly with calibrated PDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "aaa8fd1b",
   "metadata": {},
   "source": [
    "# --- 9.2A Event activation and persistence (adjacency-safe) ---\n",
    "def transition_stats(df_in: pd.DataFrame, event: str) -> dict:\n",
    "    # Robust transition stats that enforce year adjacency and handle NaNs.\n",
    "    s = pd.to_numeric(df_in[event], errors=\"coerce\")\n",
    "    s_l1 = lag(df_in, event, 1)\n",
    "\n",
    "    valid = s.notna() & s_l1.notna()\n",
    "    if valid.sum() == 0:\n",
    "        return {\"event\": event, \"activation_01_rate\": np.nan, \"persistence_11_rate\": np.nan, \"n_transitions\": 0}\n",
    "\n",
    "    s0 = s_l1[valid].astype(int)\n",
    "    s1 = s[valid].astype(int)\n",
    "\n",
    "    act_01 = ((s0 == 0) & (s1 == 1)).mean()\n",
    "    pers_11 = ((s0 == 1) & (s1 == 1)).mean()\n",
    "    return {\n",
    "        \"event\": event,\n",
    "        \"activation_01_rate\": float(act_01),\n",
    "        \"persistence_11_rate\": float(pers_11),\n",
    "        \"n_transitions\": int(valid.sum()),\n",
    "    }\n",
    "\n",
    "rows = [transition_stats(df_model, e) for e in EVT_COLS]\n",
    "trans_tbl = pd.DataFrame(rows)\n",
    "if not trans_tbl.empty:\n",
    "    trans_tbl = trans_tbl.sort_values(\"activation_01_rate\", ascending=False)\n",
    "display(trans_tbl)\n",
    "\n",
    "# --- 9.2B Monitoring summary by fiscal year (panel-level tracking) ---\n",
    "def monitoring_by_year(df_in: pd.DataFrame, p_col: str, y_col: str, evt_cols: list[str]) -> pd.DataFrame:\n",
    "    d = df_in[[\"fyear\", \"split\", p_col, y_col] + evt_cols].copy()\n",
    "\n",
    "    # Event aggregation: triggered count; missingness summarized separately.\n",
    "    evt_mat = d[evt_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    d[\"evt_missing_rate_mean\"] = evt_mat.isna().mean(axis=1)\n",
    "    d[\"evt_count\"] = (evt_mat.fillna(0) == 1).sum(axis=1)\n",
    "    d[\"evt_any\"] = (d[\"evt_count\"] > 0).astype(int)\n",
    "\n",
    "    out = (d.groupby([\"split\", \"fyear\"])\n",
    "             .agg(\n",
    "                 n=(\"fyear\",\"size\"),\n",
    "                 mean_pd=(p_col,\"mean\"),\n",
    "                 realized_rate=(y_col,\"mean\"),\n",
    "                 evt_any_rate=(\"evt_any\",\"mean\"),\n",
    "                 mean_evt_count=(\"evt_count\",\"mean\"),\n",
    "                 mean_evt_missing=(\"evt_missing_rate_mean\",\"mean\"),\n",
    "             )\n",
    "             .reset_index()\n",
    "             .sort_values([\"split\",\"fyear\"]))\n",
    "    return out\n",
    "\n",
    "print(\"\\nMonitoring by year — calibrated tree PD (pd_tree)\")\n",
    "display(monitoring_by_year(df_model, \"pd_tree\", TARGET_NAME, EVT_COLS).head(40))\n",
    "\n",
    "# --- 9.2C PD × Event risk grid (operational triangulation) ---\n",
    "def pd_event_grid(df_in: pd.DataFrame, p_col: str, y_col: str, evt_cols: list[str], n_bins: int = 10) -> pd.DataFrame:\n",
    "    d = df_in[[p_col, y_col] + evt_cols].dropna(subset=[p_col, y_col]).copy()\n",
    "    evt_mat = d[evt_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    d[\"evt_count\"] = (evt_mat.fillna(0) == 1).sum(axis=1)\n",
    "\n",
    "    d[\"evt_bucket\"] = pd.cut(d[\"evt_count\"], bins=[-0.1, 0.5, 1.5, 10**6], labels=[\"0\", \"1\", \"2+\"])\n",
    "    d[\"pd_decile\"] = pd.qcut(d[p_col], q=n_bins, labels=False, duplicates=\"drop\") + 1\n",
    "\n",
    "    g = (d.groupby([\"pd_decile\",\"evt_bucket\"])\n",
    "           .agg(\n",
    "               n=(\"pd_decile\",\"size\"),\n",
    "               mean_pd=(p_col,\"mean\"),\n",
    "               realized_rate=(y_col,\"mean\"),\n",
    "           )\n",
    "           .reset_index())\n",
    "    return g.sort_values([\"pd_decile\",\"evt_bucket\"])\n",
    "\n",
    "print(\"\\nTest split PD × Events grid — calibrated tree\")\n",
    "display(pd_event_grid(df_model.loc[df_model[\"split\"]==\"test\", :], \"pd_tree\", TARGET_NAME, EVT_COLS, n_bins=10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89c18d2c",
   "metadata": {},
   "source": [
    "### 9.3 Communication — risk tiers, transitions, and reason codes\n",
    "\n",
    "Communication should translate model outputs and indicator triggers into decision-maker-friendly artifacts:\n",
    "\n",
    "- **Risk tiers/deciles:** expected vs realized risk by PD bucket.\n",
    "- **Transitions:** PD movements and event activations/persistence.\n",
    "- **Reason codes:** simple, interpretable attributions for material PD jumps (based on newly triggered events).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "48e1cb6a",
   "metadata": {},
   "source": [
    "def decile_table(df_in: pd.DataFrame, p_col: str, y_col: str) -> pd.DataFrame:\n",
    "    d = df_in[[p_col, y_col]].dropna().copy()\n",
    "    d[\"decile\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\"drop\") + 1\n",
    "    out = d.groupby(\"decile\").agg(\n",
    "        n=(\"decile\",\"size\"),\n",
    "        mean_pd=(p_col,\"mean\"),\n",
    "        realized_rate=(y_col,\"mean\"),\n",
    "    ).reset_index()\n",
    "    out[\"calibration_gap\"] = out[\"realized_rate\"] - out[\"mean_pd\"]\n",
    "    return out\n",
    "\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    print(f\"\\nTest deciles — {model_name}\")\n",
    "    dt = decile_table(df_model.loc[df_model[\"split\"]==\"test\", :], pcol, TARGET_NAME)\n",
    "    display(dt)\n",
    "    # --- 9.3A Reason codes for large PD jumps (event-based) ---\n",
    "# When PD decile increases materially year-over-year, summarize which events newly activated.\n",
    "\n",
    "def reason_codes_for_pd_jumps(df_in: pd.DataFrame, p_col: str, evt_cols: list[str], min_decile_jump: int = 3, split: str = \"test\") -> pd.DataFrame:\n",
    "    d = df_in.loc[df_in[\"split\"] == split, [\"firm_id\",\"fyear\", p_col] + evt_cols].copy()\n",
    "    d = d.sort_values([\"firm_id\",\"fyear\"])\n",
    "\n",
    "    # PD deciles within the split (communication tiering)\n",
    "    d[\"pd_decile\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\"drop\") + 1\n",
    "    d[\"pd_decile_l1\"] = lag(d, \"pd_decile\", 1)\n",
    "    d[\"decile_jump\"] = d[\"pd_decile\"] - d[\"pd_decile_l1\"]\n",
    "\n",
    "    jump_mask = d[\"decile_jump\"].notna() & (d[\"decile_jump\"] >= min_decile_jump)\n",
    "    if int(jump_mask.sum()) == 0:\n",
    "        return pd.DataFrame(columns=[\"event\",\"n_new_activation_in_jumps\",\"share_of_jumps\"])\n",
    "\n",
    "    n_jumps = int(jump_mask.sum())\n",
    "    rows = []\n",
    "    for e in evt_cols:\n",
    "        s = pd.to_numeric(d[e], errors=\"coerce\")\n",
    "        s_l1 = lag(d, e, 1)\n",
    "        valid = jump_mask & s.notna() & s_l1.notna()\n",
    "        if int(valid.sum()) == 0:\n",
    "            continue\n",
    "        new_act = int(((s_l1[valid].astype(int) == 0) & (s[valid].astype(int) == 1)).sum())\n",
    "        if new_act > 0:\n",
    "            rows.append({\n",
    "                \"event\": e,\n",
    "                \"n_new_activation_in_jumps\": new_act,\n",
    "                \"share_of_jumps\": float(new_act / n_jumps),\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"n_new_activation_in_jumps\", ascending=False)\n",
    "    return out\n",
    "\n",
    "print(\"\\nReason codes — events newly activating during large PD jumps (test split)\")\n",
    "display(reason_codes_for_pd_jumps(df_model, \"pd_tree\", EVT_COLS, min_decile_jump=3, split=\"test\").head(20))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fc0a52a",
   "metadata": {},
   "source": [
    "### 9.4 Response capability — predefined action rules under costs and capacity\n",
    "\n",
    "We translate PDs and `evt_*` indicators into an operational policy with three actions:\n",
    "\n",
    "- **Screen / Review** (capacity-limited): highest-risk firms warrant immediate attention.\n",
    "- **Monitor more closely**: elevated risk, but not high enough for immediate screening.\n",
    "- **No action**: routine monitoring only.\n",
    "\n",
    "We compare:\n",
    "- **PD-only policy** (threshold on PD),\n",
    "- **Hybrid policy** (PD + event burden) that can prioritize “indicator-led” cases without retraining the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "66ca9b6f",
   "metadata": {},
   "source": [
    "COST_FN = float(CONFIG[\"COST_FN\"])\n",
    "COST_FP = float(CONFIG[\"COST_FP\"])\n",
    "CAPACITY_PCT = float(CONFIG[\"CAPACITY_PCT\"])\n",
    "MONITOR_PCT = float(CONFIG.get(\"MONITOR_PCT\", min(0.20, 2*CAPACITY_PCT)))  # fallback: monitor top 20% or 2x capacity\n",
    "\n",
    "def expected_cost(y_true: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    return COST_FN*fn + COST_FP*fp\n",
    "\n",
    "def apply_pd_only_policy(p: np.ndarray, thr_screen: float, thr_monitor: float) -> dict:\n",
    "    screen = (p >= thr_screen).astype(int)\n",
    "    monitor = ((p >= thr_monitor) & (p < thr_screen)).astype(int)\n",
    "    return {\"screen\": screen, \"monitor\": monitor}\n",
    "\n",
    "def apply_hybrid_policy(p: np.ndarray, evt_count: np.ndarray, alpha: float = 0.05, beta: float = 0.10) -> dict:\n",
    "    \"\"\"Hybrid prioritization score:\n",
    "      score = p + alpha*1{evt_any} + beta*1{evt_count>=2}\n",
    "    Screening/monitoring are then capacity-based on the score.\"\"\"\n",
    "    evt_any = (evt_count > 0).astype(int)\n",
    "    score = p + alpha*evt_any + beta*(evt_count >= 2).astype(int)\n",
    "    thr_score_screen = float(np.quantile(score, 1-CAPACITY_PCT))\n",
    "    thr_score_monitor = float(np.quantile(score, 1-MONITOR_PCT))\n",
    "    screen = (score >= thr_score_screen).astype(int)\n",
    "    monitor = ((score >= thr_score_monitor) & (score < thr_score_screen)).astype(int)\n",
    "    return {\"screen\": screen, \"monitor\": monitor, \"score\": score, \"thr_score_screen\": thr_score_screen, \"thr_score_monitor\": thr_score_monitor}\n",
    "\n",
    "def build_evt_count(df_in: pd.DataFrame, evt_cols: list[str]) -> np.ndarray:\n",
    "    evt_mat = df_in[evt_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return (evt_mat.fillna(0) == 1).sum(axis=1).values\n",
    "\n",
    "# --- Threshold selection (validation only) for PD-only policy ---\n",
    "grid = np.linspace(0.01, 0.99, 99)\n",
    "mask_val = df_model[\"split\"] == \"val\"\n",
    "y_val = df_model.loc[mask_val, TARGET_NAME].astype(int).values\n",
    "\n",
    "thr_tbls = {}\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p_val = df_model.loc[mask_val, pcol].values\n",
    "\n",
    "    # Cost-opt threshold\n",
    "    costs = []\n",
    "    for thr in grid:\n",
    "        costs.append(expected_cost(y_val, (p_val >= thr).astype(int)))\n",
    "    thr_cost_opt = float(grid[int(np.argmin(costs))])\n",
    "\n",
    "    # Capacity and monitoring thresholds (operational)\n",
    "    thr_capacity = float(np.quantile(p_val, 1-CAPACITY_PCT))\n",
    "    thr_monitor = float(np.quantile(p_val, 1-MONITOR_PCT))\n",
    "\n",
    "    thr_tbls[model_name] = {\"thr_cost_opt\": thr_cost_opt, \"thr_capacity\": thr_capacity, \"thr_monitor\": thr_monitor}\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(grid, costs)\n",
    "    plt.title(f\"Validation expected cost vs PD threshold — {model_name}\")\n",
    "    plt.xlabel(\"PD threshold\")\n",
    "    plt.ylabel(\"Expected misclassification cost\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"cost_curve_{model_name}_val.png\", dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "display(pd.DataFrame(thr_tbls).T)\n",
    "\n",
    "# --- Policy comparison on TEST: PD-only vs Hybrid (PD + events) ---\n",
    "mask_test = df_model[\"split\"] == \"test\"\n",
    "y_test = df_model.loc[mask_test, TARGET_NAME].astype(int).values\n",
    "evt_count_test = build_evt_count(df_model.loc[mask_test, :], EVT_COLS)\n",
    "\n",
    "rows = []\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p_test = df_model.loc[mask_test, pcol].values\n",
    "\n",
    "    thr_screen = thr_tbls[model_name][\"thr_capacity\"]\n",
    "    thr_monitor = thr_tbls[model_name][\"thr_monitor\"]\n",
    "\n",
    "    # PD-only (screen decision)\n",
    "    polA = apply_pd_only_policy(p_test, thr_screen, thr_monitor)\n",
    "    costA = expected_cost(y_test, polA[\"screen\"])\n",
    "    capA = float(polA[\"screen\"].mean())\n",
    "    tprA = float(((polA[\"screen\"]==1) & (y_test==1)).sum() / max(1, (y_test==1).sum()))\n",
    "    ppvA = float(((polA[\"screen\"]==1) & (y_test==1)).sum() / max(1, (polA[\"screen\"]==1).sum()))\n",
    "\n",
    "    # Hybrid (screen decision derived from capacity on composite score)\n",
    "    polB = apply_hybrid_policy(p_test, evt_count_test, alpha=0.05, beta=0.10)\n",
    "    costB = expected_cost(y_test, polB[\"screen\"])\n",
    "    capB = float(polB[\"screen\"].mean())\n",
    "    tprB = float(((polB[\"screen\"]==1) & (y_test==1)).sum() / max(1, (y_test==1).sum()))\n",
    "    ppvB = float(((polB[\"screen\"]==1) & (y_test==1)).sum() / max(1, (polB[\"screen\"]==1).sum()))\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"policy\": \"PD-only\",\n",
    "        \"screen_rate\": capA,\n",
    "        \"monitor_rate\": float(polA[\"monitor\"].mean()),\n",
    "        \"tpr_screen\": tprA,\n",
    "        \"ppv_screen\": ppvA,\n",
    "        \"expected_cost\": costA,\n",
    "        \"thr_screen_pd\": thr_screen,\n",
    "        \"thr_monitor_pd\": thr_monitor,\n",
    "    })\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"policy\": \"Hybrid (PD + events)\",\n",
    "        \"screen_rate\": capB,\n",
    "        \"monitor_rate\": float(polB[\"monitor\"].mean()),\n",
    "        \"tpr_screen\": tprB,\n",
    "        \"ppv_screen\": ppvB,\n",
    "        \"expected_cost\": costB,\n",
    "        \"thr_screen_score\": polB[\"thr_score_screen\"],\n",
    "        \"thr_monitor_score\": polB[\"thr_score_monitor\"],\n",
    "        \"alpha_evt_any\": 0.05,\n",
    "        \"beta_evt_2plus\": 0.10,\n",
    "    })\n",
    "\n",
    "policy_cmp = pd.DataFrame(rows).sort_values([\"model\",\"policy\"])\n",
    "print(\"\\nPolicy comparison on TEST (screen decision):\")\n",
    "display(policy_cmp)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e71b677",
   "metadata": {},
   "source": [
    "### 9.4.1 Decision curve analysis (net benefit)\n",
    "\n",
    "Decision curves provide an alternative view of “response capability”: the net benefit of acting at different PD thresholds (treat-all vs treat-none baselines)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fce9eda2",
   "metadata": {},
   "source": [
    "def net_benefit(y_true: np.ndarray, p: np.ndarray, pt: float) -> float:\n",
    "    y_hat = (p >= pt).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    n = len(y_true)\n",
    "    w = pt/(1-pt)\n",
    "    return (tp/n) - (fp/n)*w\n",
    "\n",
    "mask = df_model[\"split\"]==\"test\"\n",
    "y_test_np = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "pts = np.linspace(0.01, 0.50, 50)\n",
    "plt.figure()\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol].values\n",
    "    nb = [net_benefit(y_test_np, p, pt) for pt in pts]\n",
    "    plt.plot(pts, nb, label=model_name)\n",
    "\n",
    "# Treat-all and treat-none baselines\n",
    "event_rate = y_test_np.mean()\n",
    "nb_all = [event_rate - (1-event_rate)*(pt/(1-pt)) for pt in pts]\n",
    "nb_none = [0 for _ in pts]\n",
    "plt.plot(pts, nb_all, linestyle=\"--\", label=\"treat-all\")\n",
    "plt.plot(pts, nb_none, linestyle=\"--\", label=\"treat-none\")\n",
    "\n",
    "plt.title(\"Decision curves (test split): net benefit vs threshold probability\")\n",
    "plt.xlabel(\"Threshold probability (pt)\")\n",
    "plt.ylabel(\"Net benefit\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"decision_curves_test.png\", dpi=160)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11412605",
   "metadata": {},
   "source": [
    "### 9.5 Scenario analysis (accounting-consistent pro-forma adjustments; illustrative)\n",
    "\n",
    "Scenario analysis is a **communication and response** aid: it shows how the PD changes under internally consistent accounting adjustments (illustrative; not causal)."
   ]
  },
  {
   "cell_type": "code",
   "id": "350a73f0",
   "metadata": {},
   "source": [
    "# Scenario engine: recompute a single-row feature vector using the same rules as the main pipeline.\n",
    "\n",
    "def build_model_features_from_row(row: pd.Series) -> pd.DataFrame:\n",
    "    # --- Helper for safe ratios in single row ---\n",
    "    def safe_div(n, d):\n",
    "        try:\n",
    "            n_f = float(n)\n",
    "            d_f = float(d)\n",
    "            if pd.isna(n_f) or pd.isna(d_f) or d_f == 0:\n",
    "                return np.nan\n",
    "            return n_f / d_f\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # Raw items from row\n",
    "    at = row.get(\"at\", np.nan)\n",
    "    che = row.get(\"che\", np.nan)\n",
    "    act = row.get(\"act\", np.nan)\n",
    "    lct = row.get(\"lct\", np.nan)\n",
    "    aco = row.get(\"aco\", np.nan)\n",
    "    lco = row.get(\"lco\", np.nan)\n",
    "    rect = row.get(\"rect\", np.nan)\n",
    "    invt = row.get(\"invt\", np.nan)\n",
    "    recch = row.get(\"recch\", np.nan)\n",
    "    invch = row.get(\"invch\", np.nan)\n",
    "    txp = row.get(\"txp\", np.nan)\n",
    "    txditc = row.get(\"txditc\", np.nan)\n",
    "    lt = row.get(\"lt\", np.nan)\n",
    "    dlc = row.get(\"dlc\", np.nan)\n",
    "    dltt = row.get(\"dltt\", np.nan)\n",
    "    oibdp = row.get(\"oibdp\", np.nan)\n",
    "    dp = row.get(\"dp\", np.nan)\n",
    "    xint = row.get(\"xint\", np.nan)\n",
    "    ceq = row.get(\"ceq\", np.nan)\n",
    "    capx = row.get(\"capx\", np.nan)\n",
    "    ppent = row.get(\"ppent\", np.nan)\n",
    "    intan = row.get(\"intan\", np.nan)\n",
    "    oancf = row.get(\"oancf\", np.nan)\n",
    "    re = row.get(\"re\", np.nan)\n",
    "    caps = row.get(\"caps\", np.nan)\n",
    "    mibt = row.get(\"mibt\", np.nan)\n",
    "    niadj = row.get(\"niadj\", np.nan)\n",
    "    aqc = row.get(\"aqc\", np.nan)\n",
    "    prstkc = row.get(\"prstkc\", np.nan)\n",
    "\n",
    "    # Debt aggregate matching df logic\n",
    "    d_vals = [v for v in [dlc, dltt] if pd.notna(v)]\n",
    "    total_debt = sum(d_vals) if d_vals else np.nan\n",
    "\n",
    "    # Map of all potential continuous features\n",
    "    feat_map = {}\n",
    "    feat_map[\"ln_at\"] = np.log(at) if pd.notna(at) and at > 0 else np.nan\n",
    "    feat_map[\"cash_at\"] = safe_div(che, at)\n",
    "    feat_map[\"current_ratio\"] = safe_div(act, lct)\n",
    "    feat_map[\"nwc_at\"] = safe_div(act - lct, at)\n",
    "    feat_map[\"aco_act\"] = safe_div(aco, act)\n",
    "    feat_map[\"lco_lct\"] = safe_div(lco, lct)\n",
    "    feat_map[\"rect_act\"] = safe_div(rect, act)\n",
    "    feat_map[\"invt_act\"] = safe_div(invt, act)\n",
    "    feat_map[\"recch_act\"] = safe_div(recch, act)\n",
    "    feat_map[\"invch_act\"] = safe_div(invch, act)\n",
    "    feat_map[\"txp_lct\"] = safe_div(txp, lct)\n",
    "    feat_map[\"txditc_at\"] = safe_div(txditc, at)\n",
    "    feat_map[\"lt_at\"] = safe_div(lt, at)\n",
    "    feat_map[\"dlc_at\"] = safe_div(dlc, at)\n",
    "    feat_map[\"dltt_at\"] = safe_div(dltt, at)\n",
    "    feat_map[\"debt_at\"] = safe_div(total_debt, at)\n",
    "    feat_map[\"st_debt_share\"] = safe_div(dlc, total_debt)\n",
    "    feat_map[\"ebitda_at\"] = safe_div(oibdp, at)\n",
    "    feat_map[\"dp_at\"] = safe_div(dp, at)\n",
    "    feat_map[\"xint_at\"] = safe_div(xint, at)\n",
    "    feat_map[\"interest_coverage\"] = safe_div(oibdp, xint)\n",
    "    feat_map[\"debt_to_ebitda\"] = safe_div(total_debt, oibdp)\n",
    "    feat_map[\"ebit_to_capital\"] = safe_div(oibdp - dp, total_debt + ceq)\n",
    "    feat_map[\"capx_at\"] = safe_div(capx, at)\n",
    "\n",
    "    # V2 extras\n",
    "    feat_map[\"ppent_at\"] = safe_div(ppent, at)\n",
    "    feat_map[\"intan_at\"] = safe_div(intan, at)\n",
    "    feat_map[\"ocf_to_debt\"] = safe_div(oancf, total_debt)\n",
    "    feat_map[\"fcf_to_debt\"] = safe_div(oancf - capx, total_debt)\n",
    "    feat_map[\"re_at\"] = safe_div(re, at)\n",
    "\n",
    "    # V3 extras\n",
    "    feat_map[\"ceq_at\"] = safe_div(ceq, at)\n",
    "    feat_map[\"caps_at\"] = safe_div(caps, at)\n",
    "    feat_map[\"mibt_at\"] = safe_div(mibt, at)\n",
    "    feat_map[\"niadj_at\"] = safe_div(niadj, at)\n",
    "    feat_map[\"xint_lct\"] = safe_div(xint, lct)\n",
    "    feat_map[\"aqc_at\"] = safe_div(aqc, at)\n",
    "    feat_map[\"prstkc_at\"] = safe_div(prstkc, at)\n",
    "\n",
    "    # Event map\n",
    "    event_map = {}\n",
    "    event_map[\"loss_indicator\"] = 1.0 if pd.notna(niadj) and niadj < 0 else 0.0\n",
    "\n",
    "    # Assemble raw feature vector\n",
    "    out_dict = {}\n",
    "    for c in continuous_feats_raw:\n",
    "        out_dict[c] = feat_map.get(c, np.nan)\n",
    "    for e in event_feats:\n",
    "        out_dict[e] = event_map.get(e, 0)\n",
    "\n",
    "    out = pd.DataFrame([out_dict])\n",
    "\n",
    "    # Preprocessing: train medians, winsor, scaler -> z_\n",
    "    for c in continuous_feats_raw:\n",
    "        v = out[c].replace([np.inf, -np.inf], np.nan)\n",
    "        v = v.fillna(train_medians[c])\n",
    "        lo, hi = winsor_bounds[c]\n",
    "        v = apply_bounds(v, lo, hi)\n",
    "        out[c] = v\n",
    "\n",
    "    Z = scaler.transform(out[continuous_feats_raw].astype(float))\n",
    "    for j, c in enumerate(continuous_feats_raw):\n",
    "        out[f\"z_{c}\"] = Z[:, j]\n",
    "\n",
    "    # Final feature vector in MODEL_FEATS order\n",
    "    return out[[f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "\n",
    "def predict_pd_from_features(X_row: pd.DataFrame) -> dict:\n",
    "    pd_logit = float(logit_clf.predict_proba(X_row)[:, 1][0])\n",
    "    drow = xgb.DMatrix(X_row, feature_names=X_row.columns.tolist())\n",
    "    pd_tree_raw = float(xgb_model.predict(drow)[0])\n",
    "    pd_tree = float(iso.transform([pd_tree_raw])[0])\n",
    "    return {\"pd_logit\": pd_logit, \"pd_tree\": pd_tree}\n",
    "\n",
    "# Select a representative high-risk test observation\n",
    "test_df = df_model.loc[df_model[\"split\"]==\"test\", :].copy()\n",
    "rep_idx = test_df[\"pd_logit\"].idxmax()\n",
    "row0 = df.loc[rep_idx, :]  # use df (feature-engineered, imputed), not df_model\n",
    "base_X = build_model_features_from_row(row0)\n",
    "base_pd = predict_pd_from_features(base_X)\n",
    "\n",
    "print(\"Representative observation (highest logit PD in test):\")\n",
    "display(df_model.loc[rep_idx, [\"firm_id\",\"fyear\",\"label_year\",\"pd_logit\",\"pd_tree\",\"target_next_v1\",\"target_next_v2\",\"target_next_v3\"]])\n",
    "print(\"Base PDs:\", base_pd)\n",
    "\n",
    "# Scenario 1: Liquidity buffer to current ratio = 1.2 (increase current assets; illustrative)\n",
    "row1 = row0.copy()\n",
    "if \"act\" in row1.index and \"lct\" in row1.index and pd.notna(row1[\"act\"]) and pd.notna(row1[\"lct\"]) and row1[\"lct\"] > 0:\n",
    "    target_cr = 1.2\n",
    "    add_act = max(0.0, target_cr*row1[\"lct\"] - row1[\"act\"])\n",
    "    row1[\"act\"] = row1[\"act\"] + add_act\n",
    "    if \"che\" in row1.index and pd.notna(row1.get(\"che\", np.nan)):\n",
    "        row1[\"che\"] = row1[\"che\"] + add_act  # assume added liquidity goes to cash\n",
    "X1 = build_model_features_from_row(row1)\n",
    "pd1 = predict_pd_from_features(X1)\n",
    "\n",
    "# Scenario 2: CFO improvement of +10% of assets (accounting-consistent in the short-run is debatable; treat as stress-test)\n",
    "row2 = row0.copy()\n",
    "if \"oancf\" in row2.index and \"at\" in row2.index and pd.notna(row2[\"at\"]):\n",
    "    delta = 0.10 * row2[\"at\"]\n",
    "    row2[\"oancf\"] = (row2[\"oancf\"] if pd.notna(row2.get(\"oancf\", np.nan)) else 0.0) + delta\n",
    "X2 = build_model_features_from_row(row2)\n",
    "pd2 = predict_pd_from_features(X2)\n",
    "\n",
    "scenario_tbl = pd.DataFrame([\n",
    "    {\"scenario\":\"base\", **base_pd},\n",
    "    {\"scenario\":\"liquidity_buffer_CR_1.2\", **pd1},\n",
    "    {\"scenario\":\"CFO_plus_10pct_assets\", **pd2},\n",
    "])\n",
    "display(scenario_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "757172aa",
   "metadata": {},
   "source": [
    "## 10. Results Summary & Interpretation Guardrails\n",
    "\n",
    "### 10.1 Interpretation guardrails (publication-ready language)\n",
    "\n",
    "- The label is a **constructed proxy** for balance-sheet/coverage stress; it is not a legal default outcome.\n",
    "- Coefficients and SHAP values are **associational and predictive**, not causal effects.\n",
    "- Even with leakage controls, residual mechanical endogeneity may remain because accounting choices jointly affect both predictors and the proxy label.\n",
    "- Attrition (missing next-year observations) can create sample-selection distortions; diagnostics are reported via `has_next_year_obs`.\n",
    "\n",
    "### 10.2 Replication artifacts\n",
    "\n",
    "The following tables/exports are written to `outputs/` for downstream paper workflow:\n",
    "- `config_summary.json`\n",
    "- `distress_rule.json`\n",
    "- `event_dictionary.csv`\n",
    "- `logit_inference_table.csv`\n",
    "- `metrics_table.csv`\n",
    "- `predictions.csv`\n",
    "\n",
    "### 10.3 Export tables, thresholds, and predictions"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9838ad0",
   "metadata": {},
   "source": [
    "out_dir = Path(CONFIG[\"OUTPUT_DIR\"])\n",
    "\n",
    "# Config + distress rule\n",
    "(out_dir / \"config_summary.json\").write_text(json.dumps(CONFIG, indent=2))\n",
    "(out_dir / \"distress_rule.json\").write_text(json.dumps(DISTRESS_RULE, indent=2))\n",
    "\n",
    "# Event dictionary\n",
    "event_dict.to_csv(out_dir / \"event_dictionary.csv\", index=False)\n",
    "\n",
    "# Logit inference table\n",
    "infer_tbl.reset_index().to_csv(out_dir / \"logit_inference_table.csv\", index=False)\n",
    "\n",
    "# Metrics table\n",
    "metrics_tbl.to_csv(out_dir / \"metrics_table.csv\", index=False)\n",
    "\n",
    "# Predictions export (replication-friendly)\n",
    "export_cols = [\"firm_id\",\"gvkey\",\"fyear\",\"label_year\",\"split\",\"target_next_v1\",\"target_next_v2\",\"target_next_v3\",\"pd_logit\",\"pd_tree\"]\n",
    "export_cols = [c for c in export_cols if c in df_model.columns]\n",
    "export_cols += [c for c in event_feats if c in df_model.columns]\n",
    "pred_export = df_model[export_cols].copy()\n",
    "pred_export.to_csv(out_dir / \"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Wrote artifacts to:\", out_dir.resolve())\n",
    "print_df(pred_export, n=10, name=\"predictions.csv preview\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50eece1d",
   "metadata": {},
   "source": [
    "### 10.4 Deployment and maintenance (future work)\n",
    "\n",
    "This notebook produces a research-grade replication pipeline. For production use (not required for journal replication), a minimal MLOps extension would include:\n",
    "- scheduled re-scoring and monitoring for drift in feature distributions and target prevalence,\n",
    "- retraining triggers and versioned model registry,\n",
    "- data validation contracts (schema + unit tests) for the upstream Compustat extraction process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
