{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ad9bfb",
   "metadata": {},
   "source": [
    "# Next-Year Financial Distress Prediction (Compustat Annual Panel) — Reproducible ML Pipeline\n",
    "\n",
    "**Goal.** Predict the probability that a firm is in *financial distress* in fiscal year **t+1** using accounting (and permitted market) information available at fiscal year **t**.\n",
    "\n",
    "**Important scope note.** The outcome is an **engineered distress proxy** (high leverage / balance-sheet stress), not a realized legal default or bankruptcy. The notebook is therefore a **predictive measurement and decision-support pipeline**, not a causal identification design.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook structure (Data Science Lifecycle — 10 phases)\n",
    "\n",
    "1. Problem Definition & Setup  \n",
    "2. Data Collection & Panel Integrity  \n",
    "3. Data Cleaning & Missingness Handling (leakage-aware)  \n",
    "4. Exploratory Data Analysis (EDA)  \n",
    "5. Feature Engineering & Target Construction  \n",
    "6. Preprocessing for Modeling (train-only fitting)  \n",
    "7. Model Selection & Training (7A Logit; 7B Trees)  \n",
    "8. Model Evaluation & Diagnostic Monitoring  \n",
    "9. Decision Support Layer (events, lift, scenarios, cost/decision curves)  \n",
    "10. Results Summary, Guardrails, and Replication Artifacts\n",
    "\n",
    "> This organization mirrors the course lifecycle guidance and the project's technical review action items (see provided PDF and technical report).\n",
    "\n",
    "## How to run (replication package convention)\n",
    "\n",
    "1. Place `data.csv` in the project root (or update `CONFIG[\"DATA_PATH\"]` in Section 1).\n",
    "2. Keep `Variables.xlsx` (variable dictionary) alongside the notebook for automatic documentation.\n",
    "3. Run **Kernel → Restart & Run All**.\n",
    "\n",
    "The notebook creates an `outputs/` folder containing:\n",
    "- a predictions export (`predictions.csv`),\n",
    "- configuration and threshold tables,\n",
    "- model summary tables suitable for an appendix,\n",
    "- figures saved as PNG for paper workflow.\n",
    "\n",
    "## 1. Problem Definition & Setup\n",
    "\n",
    "### 1.1 Prediction target, success metrics, and decision objective\n",
    "\n",
    "- **Target (supervised label):** `target_next_v1`, `target_next_v2`, or `target_next_v3` (separate distress proxies). Downstream modeling uses `target_next_v2` by default.  \n",
    "- **Primary performance metrics (out-of-sample):**\n",
    "  - ROC-AUC (ranking quality),\n",
    "  - PR-AUC (class imbalance),\n",
    "  - Brier score (probability accuracy / calibration).\n",
    "- **Decision objective (screening):** convert predicted PDs into a review policy using:\n",
    "  - **misclassification costs** (`COST_FN`, `COST_FP`) and\n",
    "  - **capacity constraints** (screen top `CAPACITY_PCT` percent of firms).\n",
    "\n",
    "This is a *risk scoring* workflow: calibrated probabilities and operational interpretability matter more than headline accuracy.\n",
    "\n",
    "### 1.2 Configuration, determinism, and library versions"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f7594c2",
   "metadata": {},
   "source": [
    "# Core numerics\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML / metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Stats / inference\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\n",
    "from scipy import stats\n",
    "\n",
    "# Trees / explainability\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# Determinism\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "USING_SYNTHETIC_DATA = False # Global flag for data mode\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration (edit here)\n",
    "# ----------------------------\n",
    "CONFIG = {\n",
    "    # Data inputs\n",
    "    \"DATA_PATH\": \"data.csv\",\n",
    "    \"VARIABLES_XLSX_PATH\": \"Variables.xlsx\",\n",
    "\n",
    "    # Temporal splitting via label_year = fyear + 1\n",
    "    \"TRAIN_CUTOFF_LABEL_YEAR\": 2022,   # label_year <= cutoff -> train/val pool; later -> test\n",
    "    \"VAL_YEARS\": 1,                    # number of last label years inside the train pool used as validation\n",
    "\n",
    "    # Missingness / imputation\n",
    "    \"KNN_K\": 25,\n",
    "    \"IMPUTE_LO_Q\": 0.01,\n",
    "    \"IMPUTE_HI_Q\": 0.99,\n",
    "\n",
    "    # Preprocessing\n",
    "    \"WINSOR_LO_Q\": 0.01,\n",
    "    \"WINSOR_HI_Q\": 0.99,\n",
    "\n",
    "    # Logit hyperparameter search\n",
    "    \"LOGIT_C_GRID\": [0.01, 0.1, 1.0, 10.0],\n",
    "\n",
    "    # Tree model (XGBoost) parameters (conservative / regularized)\n",
    "    \"XGB_PARAMS\": {\n",
    "        \"max_depth\": 4,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"eta\": 0.05,\n",
    "        \"reg_lambda\": 10.0,\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": SEED,\n",
    "    },\n",
    "    \"XGB_NUM_BOOST_ROUND\": 5000,\n",
    "    \"XGB_EARLY_STOPPING\": 100,\n",
    "\n",
    "    # Decision policy parameters (costs + capacity)\n",
    "    \"COST_FN\": 10.0,\n",
    "    \"COST_FP\": 1.0,\n",
    "    \"CAPACITY_PCT\": 0.20,  # screen top 20% by PD as a capacity policy\n",
    "\n",
    "    # Outputs\n",
    "    \"OUTPUT_DIR\": \"outputs\",\n",
    "    \"FIG_DIR\": \"figures\",\n",
    "}\n",
    "\n",
    "Path(CONFIG[\"OUTPUT_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(CONFIG[\"FIG_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CONFIG (key parameters):\")\n",
    "for k in [\"DATA_PATH\",\"TRAIN_CUTOFF_LABEL_YEAR\",\"VAL_YEARS\",\"KNN_K\",\"WINSOR_LO_Q\",\"WINSOR_HI_Q\",\"COST_FN\",\"COST_FP\",\"CAPACITY_PCT\"]:\n",
    "    print(f\"  {k}: {CONFIG[k]}\")\n",
    "print(\"\\nPython:\", sys.version.split()[0])\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b26c8dff",
   "metadata": {},
   "source": [
    "### 1.3 Helper utilities (robust ratios, transforms, and reporting)"
   ]
  },
  {
   "cell_type": "code",
   "id": "76a360d9",
   "metadata": {},
   "source": [
    "def signed_log1p(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Signed log1p transform: sign(x) * log1p(|x|). Preserves zero and sign, stabilizes tails.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "def safe_divide(numer: pd.Series, denom: pd.Series, denom_floor: float = None) -> pd.Series:\n",
    "    \"\"\"Safe divide with optional denominator floor for stability. Returns float with NaN where undefined.\"\"\"\n",
    "    numer = pd.to_numeric(numer, errors=\"coerce\")\n",
    "    denom = pd.to_numeric(denom, errors=\"coerce\")\n",
    "    if denom_floor is not None:\n",
    "        denom = denom.where(denom.abs() >= denom_floor, other=np.sign(denom).replace(0, 1) * denom_floor)\n",
    "    out = numer / denom\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    return out\n",
    "\n",
    "def ensure_nullable_float(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert to pandas nullable Float64 to enable NA-aware comparisons (returns <NA> instead of False).\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "def winsorize_train_bounds(x: pd.Series, lo: float, hi: float) -> tuple[float, float]:\n",
    "    \"\"\"Return winsorization bounds computed on *training* observed values.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    x_obs = x.dropna()\n",
    "    if len(x_obs) == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (float(x_obs.quantile(lo)), float(x_obs.quantile(hi)))\n",
    "\n",
    "def apply_bounds(x: pd.Series, lo: float, hi: float) -> pd.Series:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if np.isnan(lo) or np.isnan(hi):\n",
    "        return x\n",
    "    return x.clip(lower=lo, upper=hi)\n",
    "\n",
    "def compute_smd(train: pd.Series, test: pd.Series) -> float:\n",
    "    \"\"\"Standardized mean difference (SMD): (mu_train - mu_test)/pooled_sd.\"\"\"\n",
    "    a = pd.to_numeric(train, errors=\"coerce\").dropna()\n",
    "    b = pd.to_numeric(test, errors=\"coerce\").dropna()\n",
    "    if len(a) < 2 or len(b) < 2:\n",
    "        return np.nan\n",
    "    mu_a, mu_b = a.mean(), b.mean()\n",
    "    sd_a, sd_b = a.std(ddof=1), b.std(ddof=1)\n",
    "    pooled = np.sqrt(0.5*(sd_a**2 + sd_b**2))\n",
    "    return float((mu_a - mu_b) / pooled) if pooled > 0 else np.nan\n",
    "\n",
    "def logit(p: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def print_df(df: pd.DataFrame, n: int = 10, name: str = None):\n",
    "    if name:\n",
    "        print(f\"\\n{name} (top {n} rows):\")\n",
    "    display(df.head(n))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cde14739",
   "metadata": {},
   "source": [
    "## 2. Data Collection & Panel Integrity\n",
    "\n",
    "### 2.1 Load variable dictionary (for documentation)\n",
    "\n",
    "We load the provided variable dictionary (`Variables.xlsx`) to:\n",
    "- validate required Compustat mnemonics exist in the data file,\n",
    "- generate appendix-ready variable tables.\n",
    "\n",
    "This step **does not** transform the modeling data."
   ]
  },
  {
   "cell_type": "code",
   "id": "70e93db7",
   "metadata": {},
   "source": [
    "vars_path = Path(CONFIG[\"VARIABLES_XLSX_PATH\"])\n",
    "if vars_path.exists():\n",
    "    var_dict = pd.read_excel(vars_path, sheet_name=0)\n",
    "    var_dict.columns = [c.strip() for c in var_dict.columns]\n",
    "    print(f\"Loaded variable dictionary with {len(var_dict)} rows from: {vars_path}\")\n",
    "    display(var_dict.head(90))\n",
    "else:\n",
    "    var_dict = pd.DataFrame(columns=[\"Variable\",\"Two-word Description\",\"Category\"])\n",
    "    print(f\"WARNING: variable dictionary not found at {vars_path}. Continuing without it.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6c475cbd",
   "metadata": {},
   "source": [
    "### 2.2 Load raw data (no imputation or transformations)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e907e85a",
   "metadata": {},
   "source": [
    "data_path = Path(CONFIG[\"DATA_PATH\"])\n",
    "df_raw = pd.read_csv(data_path, low_memory=False)\n",
    "print(f\"Loaded data from {data_path} with shape {df_raw.shape}\")\n",
    "\n",
    "display(df_raw.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27300e16",
   "metadata": {},
   "source": [
    "### 2.3 Enforce panel identifiers, types, sorting, and deduplication"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbe7fdf3",
   "metadata": {},
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# Stable firm identifier\n",
    "if \"gvkey\" not in df.columns:\n",
    "    raise ValueError(\"Required identifier column `gvkey` not found in the dataset.\")\n",
    "df[\"firm_id\"] = df[\"gvkey\"].astype(str)\n",
    "\n",
    "# Fiscal year\n",
    "if \"fyear\" not in df.columns:\n",
    "    raise ValueError(\"Required time column `fyear` not found in the dataset.\")\n",
    "df[\"fyear\"] = pd.to_numeric(df[\"fyear\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Optional datadate parsing (kept as metadata; not used for splitting)\n",
    "if \"datadate\" in df.columns:\n",
    "    df[\"datadate\"] = pd.to_datetime(df[\"datadate\"], errors=\"coerce\")\n",
    "\n",
    "# Remove firm-year duplicates (keep-last rule, audit count)\n",
    "pre_n = len(df)\n",
    "dup_mask = df.duplicated(subset=[\"firm_id\",\"fyear\"], keep=False)\n",
    "n_dups = int(dup_mask.sum())\n",
    "if n_dups > 0:\n",
    "    print(f\"Found {n_dups} duplicated firm-year rows. Applying keep-last rule.\")\n",
    "    df = df.sort_values([\"firm_id\",\"fyear\",\"datadate\"] if \"datadate\" in df.columns else [\"firm_id\",\"fyear\"])\n",
    "    df = df.drop_duplicates(subset=[\"firm_id\",\"fyear\"], keep=\"last\")\n",
    "post_n = len(df)\n",
    "\n",
    "# Enforce sort order for lag/lead safety\n",
    "df = df.sort_values([\"firm_id\",\"fyear\"]).reset_index(drop=True)\n",
    "\n",
    "# Integrity checks\n",
    "assert df[[\"firm_id\",\"fyear\"]].isna().sum().sum() == 0, \"Missing firm_id or fyear after typing.\"\n",
    "assert df.duplicated(subset=[\"firm_id\",\"fyear\"]).sum() == 0, \"Duplicate firm-year keys remain after dedup.\"\n",
    "\n",
    "print(f\"Rows: {pre_n:,} -> {post_n:,} after deduplication.\")\n",
    "print(\"Unique firms:\", df[\"firm_id\"].nunique())\n",
    "print(\"Year range:\", int(df[\"fyear\"].min()), \"to\", int(df[\"fyear\"].max()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "990db334",
   "metadata": {},
   "source": [
    "### 2.4 Raw sample composition (no transformations)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0e2e3c5",
   "metadata": {},
   "source": [
    "# Minimal sample composition diagnostics (kept lightweight for large panels)\n",
    "\n",
    "by_year = df.groupby(\"fyear\").agg(\n",
    "    n_obs=(\"firm_id\",\"size\"),\n",
    "    n_firms=(\"firm_id\",\"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "display(by_year.tail(12))\n",
    "\n",
    "# Optional: industry composition if SIC exists\n",
    "if \"sic\" in df.columns:\n",
    "    df[\"sic2\"] = pd.to_numeric(df[\"sic\"], errors=\"coerce\").astype(\"Int64\") // 100\n",
    "    by_sic2 = df.groupby(\"sic2\").size().sort_values(ascending=False).head(15).rename(\"n_obs\").reset_index()\n",
    "    display(by_sic2)\n",
    "else:\n",
    "    print(\"Note: `sic` not present; skipping industry composition.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbd16501",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Missingness Handling (leakage-aware)\n",
    "\n",
    "### 3.1 Non-imputable identifiers and label-year setup\n",
    "\n",
    "We drop observations missing non-imputable identifiers (firm, year).  \n",
    "We also define `label_year = fyear + 1` as the *outcome year* used for forecasting splits."
   ]
  },
  {
   "cell_type": "code",
   "id": "31e1404a",
   "metadata": {},
   "source": [
    "# Drop rows with missing key identifiers (already asserted, but keep explicit)\n",
    "df = df.dropna(subset=[\"firm_id\",\"fyear\"]).copy()\n",
    "\n",
    "# label_year defines the year of the t+1 distress label\n",
    "df[\"label_year\"] = (df[\"fyear\"] + 1).astype(\"Int64\")\n",
    "\n",
    "# Split masks (defined early; used for leakage-safe preprocessing throughout)\n",
    "train_pool_mask = df[\"label_year\"] <= CONFIG[\"TRAIN_CUTOFF_LABEL_YEAR\"]\n",
    "train_pool_years = sorted(df.loc[train_pool_mask, \"label_year\"].dropna().unique().tolist())\n",
    "if len(train_pool_years) < (CONFIG[\"VAL_YEARS\"] + 1):\n",
    "    raise ValueError(\"Not enough label years in train pool to allocate validation years. Adjust TRAIN_CUTOFF_LABEL_YEAR or VAL_YEARS.\")\n",
    "\n",
    "val_years = train_pool_years[-CONFIG[\"VAL_YEARS\"]:]\n",
    "val_mask = df[\"label_year\"].isin(val_years)\n",
    "train_mask = train_pool_mask & (~val_mask)\n",
    "test_mask = df[\"label_year\"] > CONFIG[\"TRAIN_CUTOFF_LABEL_YEAR\"]\n",
    "\n",
    "df[\"split\"] = np.where(test_mask, \"test\", np.where(val_mask, \"val\", \"train\"))\n",
    "\n",
    "print(\"Split counts:\")\n",
    "display(df[\"split\"].value_counts(dropna=False).to_frame(\"n_obs\"))\n",
    "print(\"Validation label_year(s):\", val_years)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "caf030bc",
   "metadata": {},
   "source": [
    "### 3.2 Missingness audit before intervention"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2941f55",
   "metadata": {},
   "source": [
    "# Identify numeric columns eligible for imputation (exclude identifiers)\n",
    "id_cols = {\"gvkey\",\"firm_id\",\"fyear\",\"label_year\",\"datadate\",\"split\"}\n",
    "numeric_cols = [c for c in df.columns if c not in id_cols and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "missing_tbl = (df[numeric_cols].isna().mean().sort_values(ascending=False) * 100).rename(\"missing_%\").to_frame()\n",
    "missing_tbl[\"n_missing\"] = df[numeric_cols].isna().sum().astype(int)\n",
    "missing_tbl[\"dtype\"] = [str(df[c].dtype) for c in missing_tbl.index]\n",
    "\n",
    "display(missing_tbl.head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "314eca9a",
   "metadata": {},
   "source": [
    "### 3.3 Create missingness indicators (informative signals)"
   ]
  },
  {
   "cell_type": "code",
   "id": "caf47442",
   "metadata": {},
   "source": [
    "# Choose a focused set of inputs used for core ratios/events.\n",
    "REQUIRED_RAW = [\n",
    "    \"at\",\"dlc\",\"dltt\",\"seq\",\"mibt\",\"niadj\",\n",
    "    \"oibdp\",\"oancf\",\"xint\",\n",
    "    \"act\",\"lct\",\"che\",\"rect\",\"invt\",\n",
    "    # dividend-related (we will auto-detect among these later)\n",
    "    \"dv\",\"dvc\",\"dvt\",\"dvp\",\n",
    "]\n",
    "available_required = [c for c in REQUIRED_RAW if c in df.columns]\n",
    "\n",
    "# Hard requirement for the distress proxy; fail if absent (unless synthetic mode)\n",
    "HARD_REQUIRED = [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"niadj\",\"oancf\"]\n",
    "missing_hard = [c for c in HARD_REQUIRED if c not in df.columns]\n",
    "if missing_hard and not USING_SYNTHETIC_DATA:\n",
    "    raise ValueError(f\"Missing required columns for distress proxy construction: {missing_hard}\")\n",
    "\n",
    "for c in available_required:\n",
    "    df[f\"fmiss_{c}\"] = df[c].isna().astype(\"Int8\")\n",
    "\n",
    "print(\"Created missingness flags for:\", available_required)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1862160b",
   "metadata": {},
   "source": [
    "### 3.4 Training-derived size deciles (used for peer imputation groups)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7933cb0a",
   "metadata": {},
   "source": [
    "# Size is based on log(assets) from TRAIN only, to avoid leakage.\n",
    "at_train = pd.to_numeric(df.loc[train_mask, \"at\"], errors=\"coerce\")\n",
    "log_at_train = np.log(at_train.where(at_train > 0)).dropna()\n",
    "\n",
    "if len(log_at_train) < 50:\n",
    "    print(\"WARNING: too few non-missing training `at` values for stable size deciles. Using a single size bin.\")\n",
    "    df[\"size_decile\"] = 5  # arbitrary mid-bin\n",
    "    size_edges = None\n",
    "else:\n",
    "    # Use quantile cutpoints computed on training only\n",
    "    qs = np.linspace(0, 1, 11)\n",
    "    size_edges = log_at_train.quantile(qs).values\n",
    "    size_edges[0] = -np.inf\n",
    "    size_edges[-1] = np.inf\n",
    "\n",
    "    log_at_all = np.log(pd.to_numeric(df[\"at\"], errors=\"coerce\").where(lambda s: s > 0))\n",
    "    df[\"size_decile\"] = pd.cut(log_at_all, bins=size_edges, labels=False, include_lowest=True).astype(\"Float64\")\n",
    "\n",
    "# Fill NA size_decile with training median decile for downstream stability\n",
    "sd_med = float(pd.to_numeric(df.loc[train_mask, \"size_decile\"], errors=\"coerce\").median())\n",
    "df[\"size_decile\"] = pd.to_numeric(df[\"size_decile\"], errors=\"coerce\").fillna(sd_med).astype(int)\n",
    "\n",
    "print(\"Size decile distribution (train):\")\n",
    "display(df.loc[train_mask, \"size_decile\"].value_counts().sort_index().to_frame(\"n_obs\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.5 Imputation Pipeline",
   "id": "4be186dd4fa5a9a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Snapshot before any imputation\n",
    "df_pre_impute_snapshot = df.copy(deep=True)"
   ],
   "id": "da85e3d73736a4b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.5.1 KNN imputation on core structural items (train-fit; signed-log transform)\n",
    "\n",
    "We use KNN for core balance sheet and income statement aggregates. These variables have strong multivariate dependencies (e.g., Total Assets ≈ Total Liabilities + Equity). KNN captures these relationships, allowing the imputation to respect the specific \"profile\" of a company."
   ],
   "id": "c6bdf404d9e0d89b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Core structural variables for KNN\n",
    "knn_cols = [\n",
    "    \"at\", \"act\", \"lct\", \"che\", \"rect\", \"invt\", \"dlc\", \"dltt\", \n",
    "    \"seq\", \"ceq\", \"lt\", \"ppent\", \"intan\", \"oibdp\", \"niadj\", \n",
    "    \"oancf\", \"xint\", \"dp\", \"re\", \"capx\"\n",
    "]\n",
    "knn_cols = [c for c in knn_cols if c in df.columns]\n",
    "\n",
    "if len(knn_cols) >= 3:\n",
    "    Z = df[knn_cols + [\"fyear\",\"size_decile\"]].copy()\n",
    "    # Transform magnitudes for distance stability\n",
    "    for c in knn_cols:\n",
    "        Z[c] = signed_log1p(Z[c])\n",
    "    # Standardize fyear and size_decile to prevent distance domination by year scale (Issue 1)\n",
    "    for c in [\"fyear\", \"size_decile\"]:\n",
    "        Z[c] = pd.to_numeric(Z[c], errors=\"coerce\")\n",
    "        mu = Z.loc[train_mask, c].mean()\n",
    "        sigma = Z.loc[train_mask, c].std()\n",
    "        if sigma > 0:\n",
    "            Z[c] = (Z[c] - mu) / sigma\n",
    "\n",
    "    # --- KNN Imputation using training data ---\n",
    "    imputer = KNNImputer(n_neighbors=CONFIG[\"KNN_K\"], weights=\"distance\")\n",
    "    imputer.fit(Z.loc[train_mask, :])\n",
    "\n",
    "    Z_imp = pd.DataFrame(imputer.transform(Z), columns=Z.columns, index=Z.index)\n",
    "\n",
    "    # Invert signed-log transform back for magnitudes\n",
    "    for c in knn_cols:\n",
    "        # inverse of signed_log1p: sign(z)*(exp(|z|)-1)\n",
    "        z = pd.to_numeric(Z_imp[c], errors=\"coerce\")\n",
    "        df[c] = np.sign(z) * (np.expm1(np.abs(z)))\n",
    "else:\n",
    "    print(\"Skipping KNN imputation: insufficient columns available.\")"
   ],
   "id": "6e6db926a02307a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.5.2 KNN Parameter Selection Audit\n",
    "\n",
    "We evaluate the reconstruction quality for different values of $K$ to justify the choice of `KNN_K=25`. We use a subset of fully observed training data and artificially introduce missingness to measure RMSE."
   ],
   "id": "874a9cc64bda1318"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_knn_k(Z_train, k_list, mask_fraction=0.1, seed=42):\n",
    "    # Subset to fully observed rows for ground truth\n",
    "    ground_truth_full = Z_train.dropna()\n",
    "    if len(ground_truth_full) < 100:\n",
    "        return None\n",
    "    \n",
    "    # Sample if too large for speed\n",
    "    if len(ground_truth_full) > 2000:\n",
    "        ground_truth = ground_truth_full.sample(n=2000, random_state=seed)\n",
    "    else:\n",
    "        ground_truth = ground_truth_full\n",
    "        \n",
    "    # Create masked version\n",
    "    rng = np.random.default_rng(seed)\n",
    "    masked_data = ground_truth.copy()\n",
    "    \n",
    "    # Only mask the core numeric columns (knn_cols)\n",
    "    cols_to_mask = [c for c in ground_truth.columns if c not in [\"fyear\", \"size_decile\"]]\n",
    "    \n",
    "    for col in cols_to_mask:\n",
    "        mask = rng.random(len(masked_data)) < mask_fraction\n",
    "        masked_data.loc[mask, col] = np.nan\n",
    "        \n",
    "    results = []\n",
    "    for k in k_list:\n",
    "        imputer_test = KNNImputer(n_neighbors=k, weights=\"distance\")\n",
    "        # Fit on the original (possibly missing) training data\n",
    "        imputer_test.fit(Z_train) \n",
    "        # Transform the artificially masked data\n",
    "        imputed_data = imputer_test.transform(masked_data)\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=ground_truth.columns, index=ground_truth.index)\n",
    "        \n",
    "        # Calculate RMSE only on the values we masked\n",
    "        mse = 0\n",
    "        count = 0\n",
    "        for col in cols_to_mask:\n",
    "            actual_mask = masked_data[col].isna()\n",
    "            if actual_mask.any():\n",
    "                mse += mean_squared_error(ground_truth.loc[actual_mask, col], imputed_df.loc[actual_mask, col]) * actual_mask.sum()\n",
    "                count += actual_mask.sum()\n",
    "        \n",
    "        rmse = np.sqrt(mse / count) if count > 0 else np.nan\n",
    "        results.append({\"K\": k, \"RMSE\": rmse})\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if 'knn_cols' in locals() and len(knn_cols) >= 3:\n",
    "    print(\"Evaluating KNN imputation performance (reconstruction RMSE)...\")\n",
    "    k_options = [5, 10, 25, 50, 100]\n",
    "    knn_audit_df = evaluate_knn_k(Z.loc[train_mask, :], k_options)\n",
    "    \n",
    "    if knn_audit_df is not None:\n",
    "        display(knn_audit_df.style.highlight_min(subset=\"RMSE\", color=\"lightgreen\"))\n",
    "        \n",
    "        k25_rmse = knn_audit_df.loc[knn_audit_df[\"K\"] == 25, \"RMSE\"].values[0]\n",
    "        best_k = knn_audit_df.loc[knn_audit_df[\"RMSE\"].idxmin(), \"K\"]\n",
    "        print(f\"\\nKNN K=25 RMSE: {k25_rmse:.4f}\")\n",
    "        if best_k == 25:\n",
    "            print(\"K=25 is the optimal parameter among tested values.\")\n",
    "        else:\n",
    "            print(f\"Optimal K among tested is {best_k}. K=25 is used as a balanced choice.\")\n",
    "    else:\n",
    "        print(\"Insufficient fully observed data for KNN audit.\")"
   ],
   "id": "8078342dea980b68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.6 Train-only peer-median imputation (fyear × size_decile)\n",
    "\n",
    "We use year-size median imputation for secondary items, \"other\" categories, and sparse flow variables (e.g., dividends, acquisitions). These variables are often missing, zero, or highly idiosyncratic. Using a multivariate model like KNN on them might introduce noise or over-impute non-zero values for sparse events. A year-size median provides a robust \"typical\" value for companies of similar scale in the same year, which is a safer conservative estimate for these items."
   ],
   "id": "79965ecc92898ccd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Secondary/incidental variables for Peer Median\n",
    "peer_impute_candidates = [\n",
    "    \"aco\", \"lco\", \"recch\", \"invch\", \"txp\", \"txditc\", \n",
    "    \"caps\", \"mibt\", \"aqc\", \"prstkc\",\n",
    "    \"dv\", \"dvc\", \"dvt\", \"dvp\"\n",
    "]\n",
    "peer_impute_cols = [c for c in peer_impute_candidates if c in df.columns]\n",
    "\n",
    "group_cols = [\"fyear\",\"size_decile\"]\n",
    "\n",
    "def peer_median_impute(df_in: pd.DataFrame, cols: list[str], train_mask: pd.Series, group_cols: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Impute NaNs using TRAIN-only medians by group_cols, with TRAIN (size_decile) then global median fallback.\"\"\"\n",
    "    df_out = df_in.copy()\n",
    "    train = df_out.loc[train_mask, group_cols + cols].copy()\n",
    "    group_meds = train.groupby(group_cols)[cols].median()\n",
    "    global_meds = train[cols].median()\n",
    "\n",
    "    # Intermediate fallback for unseen (fyear, size_decile): use TRAIN size_decile medians\n",
    "    size_meds = train.groupby([\"size_decile\"])[cols].median()\n",
    "    tmp_size = df_out[[\"size_decile\"]].merge(size_meds.reset_index(), on=\"size_decile\", how=\"left\")\n",
    "\n",
    "    # Join group medians (wide) to all rows\n",
    "    tmp = df_out[group_cols].merge(group_meds.reset_index(), on=group_cols, how=\"left\", suffixes=(\"\", \"_peer\"))\n",
    "    # tmp currently contains the group median columns with original names\n",
    "    for c in cols:\n",
    "        peer_med = tmp[c]\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), peer_med)\n",
    "        size_med = tmp_size[c]\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), size_med)\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), global_meds[c])\n",
    "    impact = pd.DataFrame({\n",
    "        \"col\": cols,\n",
    "        \"n_imputed\": [int(df_in[c].isna().sum() - df_out[c].isna().sum()) for c in cols],\n",
    "        \"train_global_median\": [float(global_meds[c]) if pd.notna(global_meds[c]) else np.nan for c in cols],\n",
    "    })\n",
    "    return df_out, impact\n",
    "\n",
    "df, peer_impact = peer_median_impute(df, peer_impute_cols, train_mask, group_cols)\n",
    "\n",
    "display(peer_impact.sort_values(\"n_imputed\", ascending=False).head(15))"
   ],
   "id": "fd7f2bcc553da3f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.7 Guardrail capping of imputed magnitudes (train quantile bands)",
   "id": "b36405bf9b40affc"
  },
  {
   "cell_type": "code",
   "id": "f6c81343",
   "metadata": {},
   "source": [
    "# Apply capping to all columns that underwent imputation (KNN and Peer Median)\n",
    "cap_cols = list(set(knn_cols + peer_impute_cols))\n",
    "bounds = {}\n",
    "\n",
    "for c in cap_cols:\n",
    "    lo, hi = winsorize_train_bounds(df_pre_impute_snapshot.loc[train_mask, c], CONFIG[\"IMPUTE_LO_Q\"], CONFIG[\"IMPUTE_HI_Q\"])\n",
    "    bounds[c] = {\"lo\": lo, \"hi\": hi}\n",
    "    df[c] = apply_bounds(df[c], lo, hi)\n",
    "\n",
    "bounds_df = pd.DataFrame({c: (v[\"lo\"], v[\"hi\"]) for c,v in bounds.items()}, index=[\"lo\",\"hi\"]).T\n",
    "bounds_df.index.name = \"col\"\n",
    "display(bounds_df.head(15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a0d12d1",
   "metadata": {},
   "source": [
    "### 3.8 Imputation impact audit (pre vs post)"
   ]
  },
  {
   "cell_type": "code",
   "id": "779518ce",
   "metadata": {},
   "source": [
    "audit_cols = [c for c in [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"oancf\",\"act\",\"lct\"] if c in df.columns]\n",
    "\n",
    "def dist_summary(x: pd.Series) -> dict:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return {\n",
    "        \"n\": int(x.notna().sum()),\n",
    "        \"mean\": float(x.mean()) if x.notna().any() else np.nan,\n",
    "        \"p50\": float(x.median()) if x.notna().any() else np.nan,\n",
    "        \"p10\": float(x.quantile(0.10)) if x.notna().any() else np.nan,\n",
    "        \"p90\": float(x.quantile(0.90)) if x.notna().any() else np.nan,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for c in audit_cols:\n",
    "    pre = dist_summary(df_pre_impute_snapshot[c])\n",
    "    post = dist_summary(df[c])\n",
    "    rows.append({\n",
    "        \"col\": c,\n",
    "        \"n_pre\": pre[\"n\"],\n",
    "        \"n_post\": post[\"n\"],\n",
    "        \"mean_pre\": pre[\"mean\"],\n",
    "        \"mean_post\": post[\"mean\"],\n",
    "        \"p50_pre\": pre[\"p50\"],\n",
    "        \"p50_post\": post[\"p50\"],\n",
    "    })\n",
    "impact_tbl = pd.DataFrame(rows).sort_values(\"col\")\n",
    "display(impact_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5cff47ca",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA focuses on **signal strength and data quality**, not exhaustive plotting.  \n",
    "At this stage we describe the imputed-but-not-modeled input space, by split.\n",
    "\n",
    "### 4.1 Summary statistics by split (key magnitudes)"
   ]
  },
  {
   "cell_type": "code",
   "id": "df1d3718",
   "metadata": {},
   "source": [
    "eda_cols = [c for c in [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"oancf\",\"xint\"] if c in df.columns]\n",
    "\n",
    "def split_describe(df_in: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for sp in [\"train\",\"val\",\"test\"]:\n",
    "        d = df_in.loc[df_in[\"split\"]==sp, cols].describe(percentiles=[0.01,0.1,0.5,0.9,0.99]).T\n",
    "        d.insert(0, \"split\", sp)\n",
    "        d.insert(1, \"col\", d.index)\n",
    "        out.append(d.reset_index(drop=True))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "desc_tbl = split_describe(df, eda_cols)\n",
    "display(desc_tbl.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e05b4c3b",
   "metadata": {},
   "source": [
    "### 4.2 Missingness rates by split (key inputs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e8ad60dd",
   "metadata": {},
   "source": [
    "miss_cols = [c for c in available_required if f\"fmiss_{c}\" in df.columns]\n",
    "miss_by_split = (\n",
    "    df.groupby(\"split\")[ [f\"fmiss_{c}\" for c in available_required if f\"fmiss_{c}\" in df.columns] ]\n",
    "      .mean()\n",
    "      .T\n",
    ")\n",
    "miss_by_split.index = [i.replace(\"fmiss_\",\"\") for i in miss_by_split.index]\n",
    "miss_by_split = (miss_by_split * 100).round(2)\n",
    "display(miss_by_split)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa2a8235",
   "metadata": {},
   "source": [
    "### 4.3 Visual sanity-check plots (train vs test distributions)"
   ]
  },
  {
   "cell_type": "code",
   "id": "41b9931c",
   "metadata": {},
   "source": [
    "# Lightweight plots to spot gross drift / outliers.\n",
    "plot_cols = [c for c in [\"at\",\"dltt\",\"dlc\",\"oibdp\",\"oancf\"] if c in df.columns]\n",
    "\n",
    "for c in plot_cols[:3]:\n",
    "    a = pd.to_numeric(df.loc[df[\"split\"]==\"train\", c], errors=\"coerce\")\n",
    "    b = pd.to_numeric(df.loc[df[\"split\"]==\"test\", c], errors=\"coerce\")\n",
    "    plt.figure()\n",
    "    plt.hist(np.log1p(a.dropna()), bins=60, alpha=0.5, label=\"train\")\n",
    "    plt.hist(np.log1p(b.dropna()), bins=60, alpha=0.5, label=\"test\")\n",
    "    plt.title(f\"log1p({c}) distribution: train vs test\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"eda_log1p_{c}_train_vs_test.png\", dpi=140)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Feature Engineering & Target Construction\n",
    "\n",
    "This section constructs **all derived features explicitly** from Compustat-style raw items, including:\n",
    "- debt aggregates and leverage ratios,\n",
    "- cash-flow-to-debt ratios,\n",
    "- log size and log market value,\n",
    "- the NA-aware distress proxy and the next-year label.\n",
    "\n",
    "Design choice: ratios with non-positive denominators are treated as **extreme tail states** (encoded via `+∞` then converted to `NaN` before modeling), rather than silently set to zero.\n",
    "\n",
    "### 5.1 Feature list definitions (V1, V2, V3)"
   ],
   "id": "600ce0bf223cb84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "FEATURES_V1 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \"aco_act\", \n",
    "    \"lco_lct\", \"rect_act\", \"invt_act\", \"recch_act\", \"invch_act\", \n",
    "    \"txp_lct\", \"txditc_at\", \"lt_at\", \"dlc_at\", \"dltt_at\", \n",
    "    \"debt_at\", \"st_debt_share\", \"ebitda_at\", \"dp_at\", \n",
    "    \"xint_at\", \"interest_coverage\", \"debt_to_ebitda\", \"ebit_to_capital\", \"capx_at\"\n",
    "]\n",
    "\n",
    "FEATURES_V2 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \"aco_act\", \n",
    "    \"lco_lct\", \"rect_act\", \"invt_act\", \"ppent_at\", \"intan_at\", \n",
    "    \"txp_lct\", \"txditc_at\", \"lt_at\", \"debt_at\", \"st_debt_share\", \n",
    "    \"ebitda_at\", \"xint_at\", \"interest_coverage\", \"debt_to_ebitda\", \n",
    "    \"ebit_to_capital\", \"ocf_to_debt\", \"fcf_to_debt\", \"capx_at\", \"re_at\"\n",
    "]\n",
    "\n",
    "FEATURES_V3 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \"aco_act\", \n",
    "    \"lco_lct\", \"rect_act\", \"invt_act\", \"recch_act\", \"invch_act\", \n",
    "    \"txp_lct\", \"txditc_at\", \"lt_at\", \"ceq_at\", \"re_at\", \n",
    "    \"caps_at\", \"mibt_at\", \"dp_at\", \"niadj_at\", \"loss_indicator\", \n",
    "    \"xint_at\", \"xint_lct\", \"capx_at\", \"aqc_at\", \"prstkc_at\"\n",
    "]"
   ],
   "id": "d0e137d18843d373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2 Debt, capital, and operating aggregates",
   "id": "14e07ab621282e57"
  },
  {
   "cell_type": "code",
   "id": "3be8ff9f",
   "metadata": {},
   "source": [
    "# Ensure all required raw items are numeric for safe arithmetic\n",
    "raw_items = [\n",
    "    \"at\", \"che\", \"act\", \"lct\", \"aco\", \"lco\", \"rect\", \"invt\", \"recch\", \"invch\",\n",
    "    \"txp\", \"txditc\", \"lt\", \"dlc\", \"dltt\", \"oibdp\", \"dp\", \"xint\", \"ceq\", \"capx\",\n",
    "    \"ppent\", \"intan\", \"oancf\", \"re\", \"caps\", \"mibt\", \"niadj\", \"aqc\", \"prstkc\", \"seq\"\n",
    "]\n",
    "for c in raw_items:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Debt aggregate\n",
    "df[\"total_debt\"] = df[[\"dlc\",\"dltt\"]].sum(axis=1, min_count=1)\n",
    "\n",
    "# Equity plus minority interest (if available)\n",
    "if \"mibt\" in df.columns:\n",
    "    df[\"equity_plus_mi\"] = df[[\"seq\",\"mibt\"]].sum(axis=1, min_count=1)\n",
    "else:\n",
    "    df[\"equity_plus_mi\"] = df[\"seq\"]\n",
    "\n",
    "# Total capital and a non-positive capital flag\n",
    "df[\"total_capital\"] = df[[\"total_debt\",\"equity_plus_mi\"]].sum(axis=1, min_count=1)\n",
    "df[\"cap_nonpos_flag\"] = (df[\"total_capital\"] <= 0).astype(\"Int8\")\n",
    "\n",
    "# EBITDA proxy\n",
    "df[\"ebitda_proxy\"] = df[\"oibdp\"]\n",
    "df[\"ebitda_nonpos_flag\"] = (df[\"ebitda_proxy\"] <= 0).astype(\"Int8\")\n",
    "\n",
    "# Log transforms\n",
    "df[\"ln_at\"] = np.log(df[\"at\"].where(lambda s: s > 0))\n",
    "# Legacy name if needed elsewhere\n",
    "df[\"log_at\"] = df[\"ln_at\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3 Leverage, coverage, and cash-flow ratios (V1, V2, V3 features)",
   "id": "8398da80f9dc0939"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- V1/V2/V3 Shared & Specific Features ---\n",
    "# (Using safe_divide which handles division by zero and returns NaN for extreme states)\n",
    "\n",
    "# Basic Ratios\n",
    "df[\"cash_at\"] = safe_divide(df[\"che\"], df[\"at\"])\n",
    "df[\"current_ratio\"] = safe_divide(df[\"act\"], df[\"lct\"])\n",
    "df[\"nwc_at\"] = safe_divide(df[\"act\"] - df[\"lct\"], df[\"at\"])\n",
    "df[\"aco_act\"] = safe_divide(df[\"aco\"], df[\"act\"])\n",
    "df[\"lco_lct\"] = safe_divide(df[\"lco\"], df[\"lct\"])\n",
    "df[\"rect_act\"] = safe_divide(df[\"rect\"], df[\"act\"])\n",
    "df[\"invt_act\"] = safe_divide(df[\"invt\"], df[\"act\"])\n",
    "df[\"recch_act\"] = safe_divide(df[\"recch\"], df[\"act\"])\n",
    "df[\"invch_act\"] = safe_divide(df[\"invch\"], df[\"act\"])\n",
    "df[\"txp_lct\"] = safe_divide(df[\"txp\"], df[\"lct\"])\n",
    "df[\"txditc_at\"] = safe_divide(df[\"txditc\"], df[\"at\"])\n",
    "df[\"lt_at\"] = safe_divide(df[\"lt\"], df[\"at\"])\n",
    "df[\"dlc_at\"] = safe_divide(df[\"dlc\"], df[\"at\"])\n",
    "df[\"dltt_at\"] = safe_divide(df[\"dltt\"], df[\"at\"])\n",
    "df[\"debt_at\"] = safe_divide(df[\"total_debt\"], df[\"at\"])\n",
    "df[\"st_debt_share\"] = safe_divide(df[\"dlc\"], df[\"total_debt\"])\n",
    "df[\"ebitda_at\"] = safe_divide(df[\"oibdp\"], df[\"at\"])\n",
    "df[\"dp_at\"] = safe_divide(df[\"dp\"], df[\"at\"])\n",
    "df[\"xint_at\"] = safe_divide(df[\"xint\"], df[\"at\"])\n",
    "df[\"interest_coverage\"] = safe_divide(df[\"oibdp\"], df[\"xint\"])\n",
    "df[\"debt_to_ebitda\"] = safe_divide(df[\"total_debt\"], df[\"oibdp\"])\n",
    "df[\"ebit_to_capital\"] = safe_divide(df[\"oibdp\"] - df[\"dp\"], df[\"total_debt\"] + df[\"ceq\"])\n",
    "df[\"capx_at\"] = safe_divide(df[\"capx\"], df[\"at\"])\n",
    "\n",
    "# V2 extras\n",
    "df[\"ppent_at\"] = safe_divide(df[\"ppent\"], df[\"at\"])\n",
    "df[\"intan_at\"] = safe_divide(df[\"intan\"], df[\"at\"])\n",
    "df[\"ocf_to_debt\"] = safe_divide(df[\"oancf\"], df[\"total_debt\"])\n",
    "df[\"fcf_to_debt\"] = safe_divide(df[\"oancf\"] - df[\"capx\"], df[\"total_debt\"])\n",
    "df[\"re_at\"] = safe_divide(df[\"re\"], df[\"at\"])\n",
    "\n",
    "# V3 extras\n",
    "df[\"ceq_at\"] = safe_divide(df[\"ceq\"], df[\"at\"])\n",
    "df[\"caps_at\"] = safe_divide(df[\"caps\"], df[\"at\"])\n",
    "df[\"mibt_at\"] = safe_divide(df[\"mibt\"], df[\"at\"])\n",
    "df[\"niadj_at\"] = safe_divide(df[\"niadj\"], df[\"at\"])\n",
    "df[\"loss_indicator\"] = (df[\"niadj\"] < 0).astype(float)\n",
    "df[\"xint_lct\"] = safe_divide(df[\"xint\"], df[\"lct\"])\n",
    "df[\"aqc_at\"] = safe_divide(df[\"aqc\"], df[\"at\"])\n",
    "df[\"prstkc_at\"] = safe_divide(df[\"prstkc\"], df[\"at\"])\n",
    "\n",
    "# --- Legacy mappings for distress proxy definitions (Section 5.4) ---\n",
    "# (Keeping sp_ prefix for variables used in distress proxy definition rules)\n",
    "ffo_proxy = df[\"oancf\"] + df[\"xint\"]\n",
    "if \"txp\" in df.columns:\n",
    "    ffo_proxy = ffo_proxy - df[\"txp\"]\n",
    "df[\"sp_ffo_to_debt\"] = safe_divide(ffo_proxy, df[\"total_debt\"])\n",
    "df[\"sp_debt_to_capital\"] = safe_divide(df[\"total_debt\"], df[\"total_capital\"])\n",
    "df[\"sp_debt_to_ebitda\"] = df[\"debt_to_ebitda\"]\n",
    "df[\"sp_interest_coverage\"] = df[\"interest_coverage\"].clip(lower=-50, upper=50)\n",
    "\n",
    "# Identify remaining +/-inf (though safe_divide already handles most)\n",
    "ratio_cols = [\"sp_debt_to_capital\",\"sp_debt_to_ebitda\",\"sp_ffo_to_debt\",\"sp_interest_coverage\"]\n",
    "for c in ratio_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].replace([np.inf, -np.inf], np.nan)"
   ],
   "id": "7e74c9720be0b0c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.4 Multiple Distress Proxies (fiscal year t) and next-year supervised labels (t+1)",
   "id": "b0fb583df65bc4b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distress proxy thresholds (frozen and documented)\n",
    "DISTRESS_RULE = {\n",
    "    \"FFO_TO_DEBT_LT\": 0.15,\n",
    "    \"DEBT_TO_CAPITAL_GT\": 0.55,\n",
    "    \"DEBT_TO_EBITDA_GT\": 4.5,\n",
    "    \"NEG_EQUITY_SEQ_LE\": 0.0,\n",
    "}\n",
    "\n",
    "# --- Target construction from raw (non-imputed) data ---\n",
    "# We compute distress proxies from the raw snapshot (df_pre_impute_snapshot) \n",
    "# to ensure that target labels are not contaminated by the imputation process.\n",
    "# Imputation is strictly reserved for predictive features.\n",
    "\n",
    "raw_niadj = ensure_nullable_float(df_pre_impute_snapshot[\"niadj\"])\n",
    "raw_oancf = ensure_nullable_float(df_pre_impute_snapshot[\"oancf\"])\n",
    "raw_seq = ensure_nullable_float(df_pre_impute_snapshot[\"seq\"])\n",
    "\n",
    "# S&P components from raw items (propagate missingness - Issue 3)\n",
    "raw_dlc = ensure_nullable_float(df_pre_impute_snapshot[\"dlc\"])\n",
    "raw_dltt = ensure_nullable_float(df_pre_impute_snapshot[\"dltt\"])\n",
    "raw_total_debt = raw_dlc + raw_dltt\n",
    "\n",
    "raw_oibdp = ensure_nullable_float(df_pre_impute_snapshot[\"oibdp\"])\n",
    "raw_xint = ensure_nullable_float(df_pre_impute_snapshot[\"xint\"])\n",
    "raw_txp = ensure_nullable_float(df_pre_impute_snapshot[\"txp\"]) if \"txp\" in df_pre_impute_snapshot.columns else 0\n",
    "\n",
    "raw_ffo = raw_oancf + raw_xint - raw_txp\n",
    "raw_ffo_to_debt = safe_divide(raw_ffo, raw_total_debt)\n",
    "\n",
    "raw_mibt = ensure_nullable_float(df_pre_impute_snapshot[\"mibt\"]) if \"mibt\" in df_pre_impute_snapshot.columns else pd.Series(np.nan, index=df_pre_impute_snapshot.index)\n",
    "raw_equity = ensure_nullable_float(df_pre_impute_snapshot[[\"seq\",\"mibt\"]].sum(axis=1, min_count=1)) if \"mibt\" in df_pre_impute_snapshot.columns else raw_seq\n",
    "raw_total_capital = raw_total_debt + raw_equity\n",
    "\n",
    "raw_debt_to_cap = safe_divide(raw_total_debt, raw_total_capital)\n",
    "raw_debt_to_ebitda = safe_divide(raw_total_debt, raw_oibdp)\n",
    "\n",
    "# V1: Loss + NegCFO (Accounting-based)\n",
    "# Beaver (1966), Ohlson (1980) logic: niadj < 0 and oancf < 0\n",
    "df[\"distress_v1_t\"] = (raw_niadj < 0) & (raw_oancf < 0)\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_niadj.isna() | raw_oancf.isna(), \"distress_v1_t\"] = pd.NA\n",
    "\n",
    "# V2: Negative Equity\n",
    "df[\"distress_v2_t\"] = raw_seq <= DISTRESS_RULE[\"NEG_EQUITY_SEQ_LE\"]\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_seq.isna(), \"distress_v2_t\"] = pd.NA\n",
    "\n",
    "# V3: S&P High Leverage Solely (without conditioning on negative equity)\n",
    "cond_ffo = raw_ffo_to_debt < DISTRESS_RULE[\"FFO_TO_DEBT_LT\"]\n",
    "cond_cap = raw_debt_to_cap > DISTRESS_RULE[\"DEBT_TO_CAPITAL_GT\"]\n",
    "cond_ebitda = raw_debt_to_ebitda > DISTRESS_RULE[\"DEBT_TO_EBITDA_GT\"]\n",
    "df[\"distress_v3_t\"] = cond_ffo & cond_cap & cond_ebitda\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_ffo_to_debt.isna() | raw_debt_to_cap.isna() | raw_debt_to_ebitda.isna(), \"distress_v3_t\"] = pd.NA\n",
    "\n",
    "# Next-year targets: lead of proxies within firm\n",
    "# Fix: Robust adjacency check (exactly fyear + 1) to avoid mislabeling gaps (Issue 1)\n",
    "next_fyear = df.groupby(\"firm_id\")[\"fyear\"].shift(-1)\n",
    "is_adjacent = (next_fyear == (df[\"fyear\"] + 1))\n",
    "\n",
    "df[\"target_next_v1\"] = df.groupby(\"firm_id\")[\"distress_v1_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v1\"] = pd.NA\n",
    "df[\"target_next_v1\"] = df[\"target_next_v1\"].astype(\"Int8\")\n",
    "\n",
    "df[\"target_next_v2\"] = df.groupby(\"firm_id\")[\"distress_v2_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v2\"] = pd.NA\n",
    "df[\"target_next_v2\"] = df[\"target_next_v2\"].astype(\"Int8\")\n",
    "\n",
    "df[\"target_next_v3\"] = df.groupby(\"firm_id\")[\"distress_v3_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v3\"] = pd.NA\n",
    "df[\"target_next_v3\"] = df[\"target_next_v3\"].astype(\"Int8\")\n",
    "\n",
    "# Note: We keep v1, v2, v3 separate as requested and do not combine them.\n",
    "# v2/target_next_v2 is used as the primary modeling proxy/target in the subsequent sections.\n",
    "PROXY_NAME = \"distress_v2_t\"\n",
    "TARGET_NAME = \"target_next_v2\"\n",
    "\n",
    "# Label availability / attrition (fixed to check adjacency)\n",
    "df[\"has_next_year_obs\"] = is_adjacent.fillna(False).astype(\"Int8\")\n",
    "\n",
    "target_cols = [\"target_next_v1\", \"target_next_v2\", \"target_next_v3\"]\n",
    "print(\"Distress prevalence (by split) — multiple targets:\")\n",
    "display(df.groupby(\"split\")[target_cols].mean())\n",
    "\n",
    "print(\"Share of observations with next-year observation (attrition diagnostic):\")\n",
    "display(df.groupby(\"split\")[\"has_next_year_obs\"].mean().rename(\"has_next_rate\").to_frame())"
   ],
   "id": "374270afcbf5bd23",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76baf30e",
   "metadata": {},
   "source": "### 5.5 Target prevalence and attrition diagnostics (by year and size)"
  },
  {
   "cell_type": "code",
   "id": "4fa023a7",
   "metadata": {},
   "source": [
    "# Target prevalence by label year\n",
    "target_cols = [\"target_next_v1\", \"target_next_v2\", \"target_next_v3\"]\n",
    "agg_dict = {\n",
    "    \"n_obs\": (\"firm_id\", \"size\"),\n",
    "    \"has_next_rate\": (\"has_next_year_obs\", \"mean\"),\n",
    "}\n",
    "for c in target_cols:\n",
    "    agg_dict[f\"{c}_rate\"] = (c, \"mean\")\n",
    "\n",
    "by_label_year = df.groupby([\"label_year\",\"split\"]).agg(**agg_dict).reset_index()\n",
    "\n",
    "display(by_label_year.tail(15))\n",
    "\n",
    "# By size decile (train pool), to assess composition effects\n",
    "agg_dict_size = {\"n_obs\": (\"firm_id\", \"size\")}\n",
    "for c in target_cols:\n",
    "    agg_dict_size[f\"{c}_rate\"] = (c, \"mean\")\n",
    "\n",
    "by_size = df.groupby([\"size_decile\",\"split\"]).agg(**agg_dict_size).reset_index()\n",
    "\n",
    "display(by_size.sort_values([\"split\",\"size_decile\"]).head(30))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8843b675",
   "metadata": {},
   "source": [
    "### 5.6 Event indicators (evt_*) for decision support\n",
    "\n",
    "Events are discrete, interpretable signals designed for operational triage.  \n",
    "They are calibrated **using training data only** (when thresholds are estimated), and we explicitly **exclude** events mechanically tied to the distress-definition ratios (leverage/coverage) from the predictive feature set.\n",
    "\n",
    "Events implemented here (subject to data availability):\n",
    "- Dividend cut / suspension / initiation\n",
    "- Liquidity squeeze (current ratio < 1.0) and quick-ratio squeeze (< 0.8)\n",
    "- EBITDA drop (vs. t-1) and CFO drop (vs. t-1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "973f6172",
   "metadata": {},
   "source": [
    "# Ensure sorting already enforced\n",
    "assert df.index.is_monotonic_increasing\n",
    "\n",
    "# Lag helpers\n",
    "def lag(df_in: pd.DataFrame, col: str, n: int = 1) -> pd.Series:\n",
    "    \"\"\"Robust firm-level lag that enforces year adjacency (Issue 1).\"\"\"\n",
    "    val = df_in.groupby(\"firm_id\")[col].shift(n)\n",
    "    year_lag = df_in.groupby(\"firm_id\")[\"fyear\"].shift(n)\n",
    "    is_adjacent = (year_lag == (df_in[\"fyear\"] - n))\n",
    "    return val.where(is_adjacent.fillna(False), np.nan)\n",
    "\n",
    "# Identify dividend column (prefer dvc if present; else dv / dvt / dvp)\n",
    "dividend_candidates = [\"dvc\",\"dv\",\"dvt\",\"dvp\"]\n",
    "div_col = next((c for c in dividend_candidates if c in df.columns), None)\n",
    "\n",
    "if div_col is None:\n",
    "    print(\"Dividend column not found (looked for dvc/dv/dvt/dvp). Dividend events will be NaN.\")\n",
    "    df[\"evt_divcut\"] = np.nan\n",
    "    df[\"evt_divsusp\"] = np.nan\n",
    "    df[\"evt_divinit\"] = np.nan\n",
    "else:\n",
    "    # Use absolute value (guard against sign conventions)\n",
    "    df[\"dv_obs\"] = pd.to_numeric(df[div_col], errors=\"coerce\").abs()\n",
    "    df[\"dv_obs_l1\"] = lag(df, \"dv_obs\", 1)\n",
    "\n",
    "# Liquidity ratios\n",
    "if \"act\" in df.columns and \"lct\" in df.columns:\n",
    "    df[\"current_ratio\"] = safe_divide(df[\"act\"], df[\"lct\"], denom_floor=1e-6)\n",
    "else:\n",
    "    df[\"current_ratio\"] = np.nan\n",
    "\n",
    "if \"act\" in df.columns and \"lct\" in df.columns:\n",
    "    if \"invt\" in df.columns:\n",
    "        df[\"quick_ratio\"] = safe_divide(pd.to_numeric(df[\"act\"], errors=\"coerce\") - pd.to_numeric(df[\"invt\"], errors=\"coerce\"),\n",
    "                                        df[\"lct\"], denom_floor=1e-6)\n",
    "    elif \"che\" in df.columns and \"rect\" in df.columns:\n",
    "        df[\"quick_ratio\"] = safe_divide(pd.to_numeric(df[\"che\"], errors=\"coerce\") + pd.to_numeric(df[\"rect\"], errors=\"coerce\"),\n",
    "                                        df[\"lct\"], denom_floor=1e-6)\n",
    "    else:\n",
    "        df[\"quick_ratio\"] = df[\"current_ratio\"]\n",
    "else:\n",
    "    df[\"quick_ratio\"] = np.nan\n",
    "\n",
    "# EBITDA and CFO lags for deterioration events\n",
    "if \"ebitda_proxy\" in df.columns:\n",
    "    df[\"ebitda_l1\"] = lag(df, \"ebitda_proxy\", 1)\n",
    "if \"oancf\" in df.columns:\n",
    "    df[\"cfo_l1\"] = lag(df, \"oancf\", 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a512a90",
   "metadata": {},
   "source": [
    "#### 5.5.1 Dividend policy events (training-calibrated cut threshold)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f257c30f",
   "metadata": {},
   "source": [
    "event_params = {}\n",
    "\n",
    "if div_col is None:\n",
    "    pass\n",
    "else:\n",
    "    # YoY % change among observed payers with meaningful baseline\n",
    "    dv_l1 = pd.to_numeric(df[\"dv_obs_l1\"], errors=\"coerce\")\n",
    "    dv = pd.to_numeric(df[\"dv_obs\"], errors=\"coerce\")\n",
    "    df[\"div_pct_change\"] = np.where(dv_l1 > 1e-2, (dv - dv_l1) / dv_l1, np.nan)\n",
    "\n",
    "    payer_train = train_mask & (dv_l1 > 0) & pd.notna(df[\"div_pct_change\"])\n",
    "    if payer_train.sum() >= 50:\n",
    "        cut_thr = float(np.nanpercentile(df.loc[payer_train, \"div_pct_change\"], 10))\n",
    "    else:\n",
    "        cut_thr = -0.25\n",
    "\n",
    "    # Bound cut threshold to avoid pathological values\n",
    "    cut_thr = float(np.clip(cut_thr, -0.50, -0.10))\n",
    "    event_params[\"DIV_CUT_THR_P10_BOUNDED\"] = cut_thr\n",
    "\n",
    "    # Dividend cut: large negative YoY change among payers\n",
    "    df[\"evt_divcut\"] = (df[\"div_pct_change\"] <= cut_thr).astype(\"Int8\")\n",
    "    df.loc[df[\"div_pct_change\"].isna(), \"evt_divcut\"] = pd.NA\n",
    "\n",
    "    # Suspension: payer last year, ~zero dividend now\n",
    "    df[\"evt_divsusp\"] = ((dv_l1 > 0) & (dv.fillna(0) <= 1e-4)).astype(\"Int8\")\n",
    "    df.loc[dv_l1.isna() | dv.isna(), \"evt_divsusp\"] = pd.NA\n",
    "\n",
    "    # Initiation: ~zero last year, dividend now positive\n",
    "    df[\"evt_divinit\"] = ((dv_l1.fillna(0) <= 1e-4) & (dv > 1e-4)).astype(\"Int8\")\n",
    "    df.loc[dv_l1.isna() | dv.isna(), \"evt_divinit\"] = pd.NA\n",
    "\n",
    "    print(f\"Dividend cut threshold (train P10 bounded): {cut_thr:.3f}\")\n",
    "    display(df[[\"dv_obs\",\"dv_obs_l1\",\"div_pct_change\",\"evt_divcut\",\"evt_divsusp\",\"evt_divinit\"]].head(8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ada601d",
   "metadata": {},
   "source": [
    "#### 5.5.2 Liquidity squeeze events"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3735439",
   "metadata": {},
   "source": [
    "cr = pd.to_numeric(df[\"current_ratio\"], errors=\"coerce\")\n",
    "df[\"evt_liq_squeeze\"] = (cr < 1.0).astype(\"Int8\")\n",
    "df.loc[cr.isna(), \"evt_liq_squeeze\"] = pd.NA\n",
    "\n",
    "qr = pd.to_numeric(df[\"quick_ratio\"], errors=\"coerce\")\n",
    "df[\"evt_quick_squeeze\"] = (qr < 0.8).astype(\"Int8\")\n",
    "df.loc[qr.isna(), \"evt_quick_squeeze\"] = pd.NA\n",
    "\n",
    "display(df[[\"current_ratio\",\"quick_ratio\",\"evt_liq_squeeze\",\"evt_quick_squeeze\"]].head(8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d21d0b2",
   "metadata": {},
   "source": [
    "#### 5.5.3 Operating deterioration events (vs. t-1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8da494b5",
   "metadata": {},
   "source": [
    "# EBITDA drop: requires lagged EBITDA observed and positive\n",
    "if \"ebitda_proxy\" in df.columns:\n",
    "    e = pd.to_numeric(df[\"ebitda_proxy\"], errors=\"coerce\")\n",
    "    e_l1 = pd.to_numeric(df[\"ebitda_l1\"], errors=\"coerce\")\n",
    "    ratio = e / e_l1\n",
    "    evt = ((e_l1 > 0) & ((ratio < 0.5) | (e <= 0))).astype(\"Int8\")\n",
    "    evt = evt.where(pd.notna(e_l1) & pd.notna(e), other=pd.NA).astype(\"Int8\")\n",
    "    df[\"evt_ebitdadrop\"] = evt\n",
    "else:\n",
    "    df[\"evt_ebitdadrop\"] = pd.NA\n",
    "\n",
    "# CFO drop: requires lagged CFO observed and positive\n",
    "if \"oancf\" in df.columns:\n",
    "    c = pd.to_numeric(df[\"oancf\"], errors=\"coerce\")\n",
    "    c_l1 = pd.to_numeric(df[\"cfo_l1\"], errors=\"coerce\")\n",
    "    ratio = c / c_l1\n",
    "    evt = ((c_l1 > 0) & ((ratio < 0.5) | (c <= 0))).astype(\"Int8\")\n",
    "    evt = evt.where(pd.notna(c_l1) & pd.notna(c), other=pd.NA).astype(\"Int8\")\n",
    "    df[\"evt_cfdrop\"] = evt\n",
    "else:\n",
    "    df[\"evt_cfdrop\"] = pd.NA\n",
    "\n",
    "display(df[[\"ebitda_proxy\",\"ebitda_l1\",\"evt_ebitdadrop\",\"oancf\",\"cfo_l1\",\"evt_cfdrop\"]].head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "185e58df",
   "metadata": {},
   "source": [
    "#### 5.5.4 Event dictionary (appendix-ready)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cfa35a4",
   "metadata": {},
   "source": [
    "event_dict_rows = [\n",
    "    {\"event\":\"evt_divcut\", \"definition\":\"Dividend YoY % change <= training P10 threshold (bounded [-0.50,-0.10])\", \"inputs\":div_col or \"N/A\", \"calibration\":\"train-only\"},\n",
    "    {\"event\":\"evt_divsusp\", \"definition\":\"Dividend >0 at t-1 and ~0 at t\", \"inputs\":div_col or \"N/A\", \"calibration\":\"none\"},\n",
    "    {\"event\":\"evt_divinit\", \"definition\":\"Dividend ~0 at t-1 and >0 at t\", \"inputs\":div_col or \"N/A\", \"calibration\":\"none\"},\n",
    "    {\"event\":\"evt_liq_squeeze\", \"definition\":\"Current ratio < 1.0\", \"inputs\":\"act,lct\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_quick_squeeze\", \"definition\":\"Quick ratio < 0.8\", \"inputs\":\"act,lct,invt (or che+rect)\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_ebitdadrop\", \"definition\":\"EBITDA <=0 OR EBITDA/EBITDA_{t-1}<0.5 (requires EBITDA_{t-1}>0)\", \"inputs\":\"oibdp\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_cfdrop\", \"definition\":\"CFO <=0 OR CFO/CFO_{t-1}<0.5 (requires CFO_{t-1}>0)\", \"inputs\":\"oancf\", \"calibration\":\"fixed threshold\"},\n",
    "]\n",
    "event_dict = pd.DataFrame(event_dict_rows)\n",
    "event_dict[\"parameter\"] = event_dict[\"event\"].map(lambda e: json.dumps({k:v for k,v in event_params.items()}) if e==\"evt_divcut\" else \"\")\n",
    "display(event_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8efbebce",
   "metadata": {},
   "source": [
    "## 6. Preprocessing for Modeling (train-only fitting)\n",
    "\n",
    "Preprocessing design principles:\n",
    "- **Train-only fitting:** imputation (if needed), winsorization bounds, and scaling are all fit on *train* only.\n",
    "- **Binary events stay in levels** (0/1) to preserve interpretability and prevalence.\n",
    "- **Leakage audit:** variables that mechanically define the distress proxy are excluded from `MODEL_FEATS`.\n",
    "\n",
    "### 6.1 Feature set definition and leakage audit"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b379b8c",
   "metadata": {},
   "source": [
    "# Features that participate in the distress proxy definition (must be excluded from predictors)\n",
    "# We use a dynamic set based on the chosen target to avoid definitional leakage (Issue 2).\n",
    "if TARGET_NAME == \"target_next_v1\":\n",
    "    # v1 uses niadj and oancf\n",
    "    DISTRESS_DEFINITION_VARS = {\"niadj\", \"oancf\", \"niadj_at\", \"loss_indicator\", \"ocf_to_debt\", \"fcf_to_debt\"}\n",
    "elif TARGET_NAME == \"target_next_v2\":\n",
    "    # v2 uses seq\n",
    "    DISTRESS_DEFINITION_VARS = {\"seq\"}\n",
    "elif TARGET_NAME == \"target_next_v3\":\n",
    "    # v3 uses ffo (oancf, xint, txp), debt (dlc, dltt), and equity (seq, mibt)\n",
    "    DISTRESS_DEFINITION_VARS = {\n",
    "        \"sp_ffo_to_debt\", \"sp_debt_to_capital\", \"sp_debt_to_ebitda\",\n",
    "        \"oancf\", \"xint\", \"txp\", \"dlc\", \"dltt\", \"seq\", \"mibt\", \"oibdp\",\n",
    "        \"ocf_to_debt\", \"fcf_to_debt\", \"debt_to_ebitda\", \"interest_coverage\"\n",
    "    }\n",
    "else:\n",
    "    DISTRESS_DEFINITION_VARS = set()\n",
    "\n",
    "# Candidate continuous predictors (selected based on TARGET_NAME)\n",
    "if TARGET_NAME == \"target_next_v1\":\n",
    "    continuous_feats_raw = [c for c in FEATURES_V1]\n",
    "    event_feats = []\n",
    "elif TARGET_NAME == \"target_next_v2\":\n",
    "    continuous_feats_raw = [c for c in FEATURES_V2]\n",
    "    event_feats = []\n",
    "elif TARGET_NAME == \"target_next_v3\":\n",
    "    # loss_indicator is binary, treat as event feature to avoid z-scoring\n",
    "    continuous_feats_raw = [c for c in FEATURES_V3 if c != \"loss_indicator\"]\n",
    "    event_feats = [\"loss_indicator\"]\n",
    "else:\n",
    "    continuous_feats_raw = [c for c in FEATURES_V2]\n",
    "    event_feats = []\n",
    "\n",
    "continuous_feats_raw = [c for c in continuous_feats_raw if c in df.columns]\n",
    "event_feats = [c for c in event_feats if c in df.columns]\n",
    "\n",
    "# Final model feature list (events in levels; continuous will be z-scored with z_ prefix)\n",
    "MODEL_FEATS = [f\"z_{c}\" for c in continuous_feats_raw] + event_feats\n",
    "\n",
    "# Leakage audit: ensure no distress-definition variables are included (raw or scaled variants)\n",
    "leakage_hits = []\n",
    "for v in DISTRESS_DEFINITION_VARS:\n",
    "    if v in continuous_feats_raw or v in event_feats or f\"z_{v}\" in MODEL_FEATS:\n",
    "        leakage_hits.append(v)\n",
    "\n",
    "if leakage_hits:\n",
    "    raise ValueError(f\"Leakage audit failed: distress-definition variables present in feature set: {leakage_hits}\")\n",
    "\n",
    "print(\"Continuous (to be scaled):\", continuous_feats_raw)\n",
    "print(\"Events (kept in levels):\", event_feats)\n",
    "print(\"MODEL_FEATS (post-scaling names):\", MODEL_FEATS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "944e6d68",
   "metadata": {},
   "source": [
    "### 6.2 Modeling sample and target availability"
   ]
  },
  {
   "cell_type": "code",
   "id": "54b0ebd7",
   "metadata": {},
   "source": [
    "# Modeling requires a defined next-year label\n",
    "model_mask = df[TARGET_NAME].notna()\n",
    "df_model = df.loc[model_mask].copy()\n",
    "\n",
    "print(\"Modeling sample size:\", df_model.shape[0])\n",
    "display(df_model[\"split\"].value_counts().to_frame(\"n_obs\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad654f30",
   "metadata": {},
   "source": [
    "### 6.3 Replace infinities and set up train-only median imputation for remaining NaNs"
   ]
  },
  {
   "cell_type": "code",
   "id": "34293218",
   "metadata": {},
   "source": [
    "# Replace inf with NaN for preprocessing\n",
    "for c in continuous_feats_raw:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Train-only medians for remaining NaNs (after earlier imputation steps)\n",
    "train_medians = df_model.loc[df_model[\"split\"]==\"train\", continuous_feats_raw].median()\n",
    "\n",
    "for c in continuous_feats_raw:\n",
    "    df_model[c] = df_model[c].fillna(train_medians[c])\n",
    "\n",
    "# Event features: coerce to Int8 with missing -> 0 (conservative) but preserve missingness flags separately if desired\n",
    "for c in event_feats:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").fillna(0).astype(\"Int8\")\n",
    "\n",
    "assert df_model[continuous_feats_raw].isna().sum().sum() == 0, \"NaNs remain in continuous features after train-median fill.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea8146d5",
   "metadata": {},
   "source": [
    "### 6.4 Winsorize continuous features (train quantile bounds)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ac086d4",
   "metadata": {},
   "source": [
    "winsor_bounds = {}\n",
    "for c in continuous_feats_raw:\n",
    "    lo, hi = winsorize_train_bounds(df_model.loc[df_model[\"split\"]==\"train\", c], CONFIG[\"WINSOR_LO_Q\"], CONFIG[\"WINSOR_HI_Q\"])\n",
    "    winsor_bounds[c] = (lo, hi)\n",
    "    df_model[c] = apply_bounds(df_model[c], lo, hi)\n",
    "\n",
    "winsor_tbl = pd.DataFrame(\n",
    "    [{\"feature\": c, \"lo\": winsor_bounds[c][0], \"hi\": winsor_bounds[c][1]} for c in continuous_feats_raw]\n",
    ")\n",
    "display(winsor_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d779925e",
   "metadata": {},
   "source": [
    "### 6.5 Standardize continuous features (train-fit scaler; z_ prefix)"
   ]
  },
  {
   "cell_type": "code",
   "id": "64b21d21",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize continuous features (fit on TRAIN only)\n",
    "scaler = StandardScaler()\n",
    "df_model[continuous_feats_raw] = df_model[continuous_feats_raw].apply(lambda s: pd.to_numeric(s, errors=\"coerce\"))\n",
    "\n",
    "train_cont = df_model.loc[df_model[\"split\"] == \"train\", continuous_feats_raw].astype(float)\n",
    "scaler.fit(train_cont)\n",
    "\n",
    "Z_all = scaler.transform(df_model[continuous_feats_raw].astype(float))\n",
    "for j, c in enumerate(continuous_feats_raw):\n",
    "    df_model[f\"z_{c}\"] = Z_all[:, j].astype(float)\n",
    "\n",
    "# Final modeling matrix (events forced to clean 0/1 ints)\n",
    "z_cols = [f\"z_{c}\" for c in continuous_feats_raw]\n",
    "X = df_model[z_cols + event_feats].copy()\n",
    "\n",
    "for c in event_feats:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "    X[c] = X[c].fillna(0).astype(\"int8\")\n",
    "    assert set(X[c].unique()).issubset({0, 1}), f\"{c} not binary after coercion: {sorted(X[c].unique())}\"\n",
    "\n",
    "y = df_model[TARGET_NAME].astype(int)\n",
    "\n",
    "# Split views\n",
    "splits = {}\n",
    "for sp in [\"train\", \"val\", \"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    splits[sp] = {\"X\": X.loc[mask, :], \"y\": y.loc[mask], \"df\": df_model.loc[mask, :]}\n",
    "\n",
    "print({sp: (v[\"X\"].shape[0], v[\"X\"].shape[1]) for sp, v in splits.items()})\n",
    "\n",
    "# Numeric-safe finiteness check\n",
    "assert np.isfinite(X.astype(\"float64\").to_numpy()).all(), \"Non-finite values in modeling matrix.\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6734f55",
   "metadata": {},
   "source": [
    "## 7. Model Selection & Training\n",
    "\n",
    "### 7A. Logit model (primary baseline: calibrated PD with interpretable coefficients)\n",
    "\n",
    "#### 7A.1 Hyperparameter tuning on out-of-time validation year"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2ef67f2",
   "metadata": {},
   "source": [
    "train_X, train_y = splits[\"train\"][\"X\"], splits[\"train\"][\"y\"]\n",
    "val_X, val_y = splits[\"val\"][\"X\"], splits[\"val\"][\"y\"]\n",
    "\n",
    "results = []\n",
    "for C in CONFIG[\"LOGIT_C_GRID\"]:\n",
    "    mdl = LogisticRegression(C=C, solver=\"lbfgs\", max_iter=2000, random_state=SEED)\n",
    "    mdl.fit(train_X, train_y)\n",
    "    val_proba = mdl.predict_proba(val_X)[:, 1]\n",
    "    results.append({\n",
    "        \"C\": C,\n",
    "        \"val_roc_auc\": roc_auc_score(val_y, val_proba),\n",
    "        \"val_pr_auc\": average_precision_score(val_y, val_proba),\n",
    "        \"val_brier\": brier_score_loss(val_y, val_proba),\n",
    "    })\n",
    "\n",
    "tune_tbl = pd.DataFrame(results).sort_values(\"val_roc_auc\", ascending=False)\n",
    "display(tune_tbl)\n",
    "\n",
    "best_C = float(tune_tbl.iloc[0][\"C\"])\n",
    "print(\"Selected C:\", best_C)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7A.2 Fit Logit models and generate PDs",
   "id": "6bd079298ae30c36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainval_mask = df_model[\"split\"].isin([\"train\",\"val\"])\n",
    "X_trainval = X.loc[trainval_mask, :]\n",
    "y_trainval = y.loc[trainval_mask]\n",
    "\n",
    "# To ensure 'val' metrics are honest out-of-sample estimates, we use the model \n",
    "# trained on 'train' only for the validation split. \n",
    "# For the final 'test' performance, we use the model trained on 'train+val'.\n",
    "\n",
    "# Model trained on 'train' ONLY (for honest 'val' evaluation)\n",
    "logit_train_only = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=3000, random_state=SEED)\n",
    "logit_train_only.fit(train_X, train_y)\n",
    "\n",
    "# Model trained on 'train+val' (for final 'test' evaluation)\n",
    "logit_trainval = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=3000, random_state=SEED)\n",
    "logit_trainval.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Assign predictions\n",
    "df_model[\"pd_logit\"] = np.nan\n",
    "# val gets predictions from train-only model (honest out-of-sample)\n",
    "df_model.loc[df_model[\"split\"]==\"val\", \"pd_logit\"] = logit_train_only.predict_proba(val_X)[:, 1]\n",
    "# test gets predictions from train+val model\n",
    "df_model.loc[df_model[\"split\"]==\"test\", \"pd_logit\"] = logit_trainval.predict_proba(splits[\"test\"][\"X\"])[:, 1]\n",
    "# train gets predictions from train+val model (in-sample)\n",
    "df_model.loc[df_model[\"split\"]==\"train\", \"pd_logit\"] = logit_trainval.predict_proba(train_X)[:, 1]\n",
    "\n",
    "# For legacy compatibility in reporting\n",
    "df_model[\"pd_logit_val\"] = np.where(df_model[\"split\"]==\"val\", df_model[\"pd_logit\"], np.nan)\n",
    "df_model[\"pd_logit_test\"] = np.where(df_model[\"split\"]==\"test\", df_model[\"pd_logit\"], np.nan)\n",
    "\n",
    "# Keep logit_clf as the final model for downstream use\n",
    "logit_clf = logit_trainval\n",
    "\n",
    "print(\"Example PDs (Logit):\")\n",
    "display(df_model[[\"firm_id\",\"fyear\",\"label_year\",\"split\",TARGET_NAME,\"pd_logit\"]].head(10))"
   ],
   "id": "ce3526c900d40cfd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a94a27e",
   "metadata": {},
   "source": [
    "#### 7A.3 Inference audit (statsmodels Logit; clustered standard errors)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c743275",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\n",
    "# Statsmodels requires numpy arrays; keep column names for tables.\n",
    "X_sm = sm.add_constant(X_trainval, has_constant=\"add\")\n",
    "y_sm = y_trainval.astype(float)\n",
    "\n",
    "logit_sm = sm.Logit(y_sm, X_sm)\n",
    "res_sm = logit_sm.fit(disp=False, maxiter=200)\n",
    "\n",
    "# --- Firm cluster (numeric codes to avoid dtype issues) ---\n",
    "firm_raw = df_model.loc[trainval_mask, \"firm_id\"]\n",
    "firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\n",
    "\n",
    "cov_firm = cov_cluster(res_sm, firm_codes)\n",
    "se_firm = np.sqrt(np.diag(cov_firm))\n",
    "\n",
    "# --- Two-way cluster (firm + year), with feasibility + shape guards ---\n",
    "year_raw = df_model.loc[trainval_mask, \"label_year\"]\n",
    "firm_raw = df_model.loc[trainval_mask, \"firm_id\"]\n",
    "\n",
    "firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\n",
    "year_codes = pd.factorize(year_raw, sort=True)[0].astype(np.int64)\n",
    "\n",
    "if (np.unique(firm_codes).size < 2) or (np.unique(year_codes).size < 2):\n",
    "    # Not enough clusters in one dimension -> two-way clustering not identified\n",
    "    se_2 = se_firm.copy()\n",
    "else:\n",
    "    cov_2 = cov_cluster_2groups(res_sm, firm_codes, year_codes)\n",
    "    cov_2 = np.asarray(cov_2)\n",
    "\n",
    "    k = len(res_sm.params)\n",
    "    if cov_2.ndim == 2 and cov_2.shape == (k, k):\n",
    "        se_2 = np.sqrt(np.diag(cov_2))\n",
    "    elif cov_2.ndim == 1 and cov_2.size == k:\n",
    "        # Some statsmodels versions may return only the diagonal variances\n",
    "        se_2 = np.sqrt(cov_2)\n",
    "    else:\n",
    "        # Unexpected shape -> fall back (safer than crashing)\n",
    "        se_2 = se_firm.copy()\n",
    "\n",
    "coef = res_sm.params\n",
    "p_firm = 2 * (1 - stats.norm.cdf(np.abs(coef / se_firm)))\n",
    "p_2 = 2 * (1 - stats.norm.cdf(np.abs(coef / se_2)))\n",
    "\n",
    "infer_tbl = pd.DataFrame({\n",
    "    \"coef_logodds\": coef,\n",
    "    \"se_firm\": se_firm,\n",
    "    \"p_firm\": p_firm,\n",
    "    \"se_firm_year\": se_2,\n",
    "    \"p_firm_year\": p_2,\n",
    "    \"odds_ratio\": np.exp(coef),\n",
    "})\n",
    "infer_tbl.index.name = \"feature\"\n",
    "display(infer_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a69777d6",
   "metadata": {},
   "source": [
    "#### 7A.4 Economic magnitude: MEM marginal effects and IQR-scaled effects"
   ]
  },
  {
   "cell_type": "code",
   "id": "f27addce",
   "metadata": {},
   "source": [
    "# MEM marginal effects using statsmodels (on train+val)\n",
    "try:\n",
    "    me = res_sm.get_margeff(at=\"mean\")\n",
    "    me_tbl = me.summary_frame()\n",
    "    # Align to inference table index (margeff typically excludes const)\n",
    "    me_tbl = me_tbl.reindex(infer_tbl.index)\n",
    "    display(me_tbl)\n",
    "except Exception as e:\n",
    "    print(\"Marginal effects computation failed:\", e)\n",
    "    me_tbl = None\n",
    "\n",
    "# IQR-scaled effects for continuous features (using TRAIN distribution, mapped into z-space)\n",
    "train_df = df_model.loc[df_model[\"split\"]==\"train\", :].copy()\n",
    "\n",
    "iqr_rows = []\n",
    "for j, raw_c in enumerate(continuous_feats_raw):\n",
    "    q25 = float(train_df[raw_c].quantile(0.25))\n",
    "    q75 = float(train_df[raw_c].quantile(0.75))\n",
    "    iqr = q75 - q25\n",
    "    sd = float(scaler.scale_[j]) if scaler.scale_[j] > 0 else np.nan\n",
    "    delta_z = iqr / sd if sd and not np.isnan(sd) else np.nan\n",
    "    beta = float(infer_tbl.loc[f\"z_{raw_c}\", \"coef_logodds\"]) if f\"z_{raw_c}\" in infer_tbl.index else np.nan\n",
    "    logodds_delta = beta * delta_z if not np.isnan(beta) and not np.isnan(delta_z) else np.nan\n",
    "    iqr_rows.append({\n",
    "        \"raw_feature\": raw_c,\n",
    "        \"IQR_raw\": iqr,\n",
    "        \"delta_z_equiv\": delta_z,\n",
    "        \"logodds_change_IQR\": logodds_delta,\n",
    "        \"odds_ratio_IQR\": float(np.exp(logodds_delta)) if not np.isnan(logodds_delta) else np.nan,\n",
    "    })\n",
    "\n",
    "iqr_tbl = pd.DataFrame(iqr_rows)\n",
    "display(iqr_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7A.5 Average Partial Effects (APEs) in probability units with cluster-robust uncertainty\n"
   ],
   "id": "2e05569f33d2eab7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# APEs (Average Partial Effects) for logit model, using delta-method SEs with cluster-robust covariances\n",
    "# Notes:\n",
    "# - For logit, dP/dx_j = p*(1-p)*beta_j. The APE is the sample average of this derivative.\n",
    "# - We compute APEs on the TRAIN+VAL estimation sample used in statsmodels (X_sm, res_sm).\n",
    "# - SEs use the same cluster-robust covariance matrices already computed above (cov_firm and cov_2).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "def _coerce_cov(V, names):\n",
    "    \"\"\"Return numeric (k x k) covariance aligned to names. Fallback logic handles common statsmodels outputs.\"\"\"\n",
    "    k = len(names)\n",
    "\n",
    "    if isinstance(V, pd.DataFrame):\n",
    "        V = V.reindex(index=names, columns=names).to_numpy(dtype=float)\n",
    "        return V\n",
    "\n",
    "    V = np.asarray(V)\n",
    "    V = np.squeeze(V)\n",
    "\n",
    "    # Handle 3D objects (e.g., (3,k,k) or (k,k,3)): take first covariance slice\n",
    "    if V.ndim == 3:\n",
    "        if V.shape[1:] == (k, k):\n",
    "            V = V[0]\n",
    "        elif V.shape[:2] == (k, k):\n",
    "            V = V[:, :, 0]\n",
    "        else:\n",
    "            V = V.reshape(-1, k, k)[0]\n",
    "\n",
    "    # Handle diagonal-only variances\n",
    "    if V.ndim == 1:\n",
    "        if V.size != k:\n",
    "            raise ValueError(f\"Unexpected 1D covariance length: {V.size} (expected {k})\")\n",
    "        V = np.diag(V.astype(float))\n",
    "\n",
    "    if V.ndim != 2 or V.shape != (k, k):\n",
    "        raise ValueError(f\"Unexpected covariance shape: {V.shape} (expected {(k, k)})\")\n",
    "\n",
    "    V = V.astype(float)\n",
    "    V[~np.isfinite(V)] = 0.0\n",
    "    return V\n",
    "\n",
    "# ---- Align design matrix to params order ----\n",
    "X_df = X_sm if isinstance(X_sm, pd.DataFrame) else pd.DataFrame(X_sm)\n",
    "b_ser = res_sm.params\n",
    "\n",
    "names = list(b_ser.index)\n",
    "X_df = X_df.loc[:, names]                 # enforce same column order\n",
    "X_audit_np = X_df.to_numpy(dtype=float)\n",
    "\n",
    "b = b_ser.to_numpy(dtype=float)\n",
    "k = len(names)\n",
    "\n",
    "# Predicted probabilities on estimation sample\n",
    "eta = X_audit_np @ b\n",
    "p = 1.0 / (1.0 + np.exp(-eta))\n",
    "w = p * (1.0 - p)\n",
    "mw = float(np.mean(w))\n",
    "\n",
    "# APE_j = beta_j * mean(w)\n",
    "ape = b * mw\n",
    "if \"const\" in names:\n",
    "    ape[names.index(\"const\")] = np.nan\n",
    "\n",
    "# Delta-method gradient\n",
    "t = (w * (1.0 - 2.0 * p))[:, None] * X_audit_np\n",
    "dmw_db = np.mean(t, axis=0)\n",
    "\n",
    "G = np.full((k, k), np.nan, dtype=float)\n",
    "for j in range(k):\n",
    "    if names[j] == \"const\":\n",
    "        continue\n",
    "    g = dmw_db * b[j]\n",
    "    g[j] += mw\n",
    "    G[j, :] = g\n",
    "\n",
    "# Covariances (coerce 2-way; fallback to firm)\n",
    "V_firm = _coerce_cov(cov_firm, names)\n",
    "if \"cov_2\" in globals():\n",
    "    try:\n",
    "        V_2 = _coerce_cov(cov_2, names)\n",
    "    except Exception:\n",
    "        V_2 = V_firm\n",
    "else:\n",
    "    V_2 = V_firm\n",
    "\n",
    "def _se_from_V(V):\n",
    "    se = np.full(k, np.nan, dtype=float)\n",
    "    for j in range(k):\n",
    "        if not np.all(np.isfinite(G[j, :])):\n",
    "            continue\n",
    "        g = G[j, :].astype(float)\n",
    "        v = (g @ V @ g).item()  # scalar quadratic form\n",
    "        se[j] = np.sqrt(v) if v >= 0 else np.nan\n",
    "    return se\n",
    "\n",
    "se_ape_firm = _se_from_V(V_firm)\n",
    "se_ape_2 = _se_from_V(V_2)\n",
    "\n",
    "# p-values (normal approximation)\n",
    "z_firm = ape / se_ape_firm\n",
    "p_ape_firm = 2 * (1 - stats.norm.cdf(np.abs(z_firm)))\n",
    "\n",
    "z_2 = ape / se_ape_2\n",
    "p_ape_2 = 2 * (1 - stats.norm.cdf(np.abs(z_2)))\n",
    "\n",
    "ape_tbl = pd.DataFrame({\n",
    "    \"APE\": ape,\n",
    "    \"se_APE_firm\": se_ape_firm,\n",
    "    \"p_APE_firm\": p_ape_firm,\n",
    "    \"se_APE_firm_year\": se_ape_2,\n",
    "    \"p_APE_firm_year\": p_ape_2,\n",
    "}, index=pd.Index(names, name=\"feature\"))\n",
    "\n",
    "display(ape_tbl)\n",
    "\n",
    "infer_tbl_with_ape = infer_tbl.join(ape_tbl, how=\"left\")\n",
    "display(infer_tbl_with_ape)\n"
   ],
   "id": "c05ca6e8e5396cbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "de67ec61",
   "metadata": {},
   "source": [
    "#### 7A.5 Walk-forward validation (expanding window)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae44dc91",
   "metadata": {},
   "source": [
    "trainpool_df = df_model.loc[df_model[\"split\"].isin([\"train\",\"val\"]), :].copy()\n",
    "years = sorted(trainpool_df[\"label_year\"].unique().tolist())\n",
    "years = [int(y) for y in years if pd.notna(y)]\n",
    "\n",
    "N_SPLITS = 4\n",
    "if len(years) < (N_SPLITS + 2):\n",
    "    print(\"Not enough years for walk-forward validation; skipping.\")\n",
    "    wf_tbl = pd.DataFrame()\n",
    "else:\n",
    "    # Choose split points evenly across the year range (excluding last year to keep a holdout)\n",
    "    split_idx = np.linspace(2, len(years)-1, N_SPLITS, dtype=int)\n",
    "    wf_rows = []\n",
    "    for k in split_idx:\n",
    "        train_years = years[:k]\n",
    "        val_year = years[k]\n",
    "        tr = trainpool_df[\"label_year\"].isin(train_years)\n",
    "        va = trainpool_df[\"label_year\"].isin([val_year])\n",
    "\n",
    "        X_tr = trainpool_df.loc[tr, [f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "        y_tr = trainpool_df.loc[tr, TARGET_NAME].astype(int)\n",
    "        X_va = trainpool_df.loc[va, [f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "        y_va = trainpool_df.loc[va, TARGET_NAME].astype(int)\n",
    "\n",
    "        mdl = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=2000, random_state=SEED)\n",
    "        mdl.fit(X_tr, y_tr)\n",
    "        p_va = mdl.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        wf_rows.append({\n",
    "            \"train_years_min\": min(train_years),\n",
    "            \"train_years_max\": max(train_years),\n",
    "            \"val_year\": val_year,\n",
    "            \"n_train\": int(len(y_tr)),\n",
    "            \"n_val\": int(len(y_va)),\n",
    "            \"roc_auc\": roc_auc_score(y_va, p_va),\n",
    "            \"pr_auc\": average_precision_score(y_va, p_va),\n",
    "            \"brier\": brier_score_loss(y_va, p_va),\n",
    "        })\n",
    "    wf_tbl = pd.DataFrame(wf_rows)\n",
    "    display(wf_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0b34ac3",
   "metadata": {},
   "source": [
    "### 7B. Tree-based model (XGBoost; nonlinear )\n",
    "\n",
    "Tree models capture interactions and nonlinearities that logit cannot, but they require stronger regularization and calibration discipline.\n",
    "\n",
    "Implementation details:\n",
    "- Early stopping on **PR-AUC** using validation split.\n",
    "- Conservative depth and regularization parameters.\n",
    "- Cost-sensitive weighting to reflect class imbalance and FN/FP asymmetry.\n",
    "- **Isotonic calibration** fit on validation predictions (train-only model remains unchanged).\n",
    "\n",
    "#### 7B.1 Train XGBoost with early stopping (validation PR-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8810a478",
   "metadata": {},
   "source": [
    "# Build DMatrix objects\n",
    "X_tr = splits[\"train\"][\"X\"]\n",
    "y_tr = splits[\"train\"][\"y\"].astype(int)\n",
    "X_va = splits[\"val\"][\"X\"]\n",
    "y_va = splits[\"val\"][\"y\"].astype(int)\n",
    "X_te = splits[\"test\"][\"X\"]\n",
    "y_te = splits[\"test\"][\"y\"].astype(int)\n",
    "\n",
    "n_pos = int(y_tr.sum())\n",
    "n_neg = int((y_tr==0).sum())\n",
    "imbalance = (n_neg / max(n_pos, 1))\n",
    "\n",
    "w_pos = CONFIG[\"COST_FN\"] * imbalance\n",
    "w_neg = CONFIG[\"COST_FP\"]\n",
    "\n",
    "w_tr = np.where(y_tr.values==1, w_pos, w_neg).astype(float)\n",
    "w_va = np.where(y_va.values==1, w_pos, w_neg).astype(float)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr, feature_names=X_tr.columns.tolist())\n",
    "dval   = xgb.DMatrix(X_va, label=y_va, weight=w_va, feature_names=X_tr.columns.tolist())\n",
    "dall   = xgb.DMatrix(X, label=y.astype(int), feature_names=X_tr.columns.tolist())\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    params=CONFIG[\"XGB_PARAMS\"],\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=CONFIG[\"XGB_NUM_BOOST_ROUND\"],\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=CONFIG[\"XGB_EARLY_STOPPING\"],\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "print(\"Best iteration:\", xgb_model.best_iteration)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6a23d75",
   "metadata": {},
   "source": [
    "#### 7B.2 Isotonic calibration on validation set (probability calibration)"
   ]
  },
  {
   "cell_type": "code",
   "id": "86dbd5a4",
   "metadata": {},
   "source": [
    "# Raw probabilities (uncalibrated)\n",
    "p_val_raw = xgb_model.predict(dval)\n",
    "p_all_raw = xgb_model.predict(dall)\n",
    "\n",
    "# Fit isotonic on validation only\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso.fit(p_val_raw, y_va.values.astype(int))\n",
    "\n",
    "df_model[\"pd_tree\"] = iso.transform(p_all_raw)\n",
    "\n",
    "print(\"Calibration fitted on validation only.\")\n",
    "display(df_model[[\"split\",\"pd_tree\"]].groupby(\"split\").mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fdd237e",
   "metadata": {},
   "source": [
    "#### 7B.3 Feature importance and SHAP (optional explainability)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5a56f06",
   "metadata": {},
   "source": [
    "# Gain-based feature importance\n",
    "importance = xgb_model.get_score(importance_type=\"gain\")\n",
    "imp_tbl = (pd.DataFrame({\"feature\": list(importance.keys()), \"gain\": list(importance.values())})\n",
    "             .sort_values(\"gain\", ascending=False))\n",
    "display(imp_tbl.head(20))\n",
    "\n",
    "# Optional: SHAP summary for a subsample (can be expensive on large panels)\n",
    "try:\n",
    "    import shap\n",
    "    shap.initjs()\n",
    "    sample_n = min(5000, X_tr.shape[0])\n",
    "    X_sample = X_tr.sample(sample_n, random_state=SEED)\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_sample, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"shap_summary_tree.png\", dpi=160)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped:\", e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ffaf2ac",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation & Diagnostic Monitoring\n",
    "\n",
    "All evaluation in this section treats the **test split as untouchable**: no tuning based on test results.\n",
    "\n",
    "**Clean Evaluation Protocol Note:**\n",
    "- For **Logit**: The validation (`val`) performance reported below is an honest out-of-sample estimate because it uses a model trained on `train` only. The test performance uses a model trained on `train+val`.\n",
    "- For **Tree (XGBoost)**: The validation (`val`) performance is **in-sample** relative to early stopping and isotonic calibration, both of which use the validation set. Therefore, `val` performance for trees will appear optimistic.\n",
    "- **Unbiased Performance**: The **test split** results are the only strictly unbiased final performance metrics.\n",
    "\n",
    "We report:\n",
    "- ROC-AUC, PR-AUC, Brier score,\n",
    "- calibration curve and calibration slope (reliability),\n",
    "- persistence benchmark,\n",
    "- collinearity and drift diagnostics.\n",
    "\n",
    "### 8.1 Out-of-sample metrics (val and test) + persistence benchmark"
   ]
  },
  {
   "cell_type": "code",
   "id": "29873ad3",
   "metadata": {},
   "source": [
    "def eval_metrics(y_true: pd.Series, p: np.ndarray) -> dict:\n",
    "    y_true = y_true.astype(int).values\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc_score(y_true, p),\n",
    "        \"pr_auc\": average_precision_score(y_true, p),\n",
    "        \"brier\": brier_score_loss(y_true, p),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"event_rate\": float(np.mean(y_true)),\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for sp in [\"val\",\"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    y_sp = df_model.loc[mask, TARGET_NAME].astype(int)\n",
    "\n",
    "    rows.append({\"split\": sp, \"model\":\"logit\", **eval_metrics(y_sp, df_model.loc[mask, \"pd_logit\"].values)})\n",
    "    rows.append({\"split\": sp, \"model\":\"tree_calibrated\", **eval_metrics(y_sp, df_model.loc[mask, \"pd_tree\"].values)})\n",
    "\n",
    "    # Persistence benchmark: predict next-year distress = current-year PROXY_NAME\n",
    "    pers = pd.to_numeric(df_model.loc[mask, PROXY_NAME], errors=\"coerce\").fillna(0).astype(int).values\n",
    "    rows.append({\"split\": sp, \"model\":\"persistence\", **eval_metrics(y_sp, pers)})\n",
    "\n",
    "metrics_tbl = pd.DataFrame(rows).sort_values([\"split\",\"model\"])\n",
    "display(metrics_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1b Early-warning vs Surveillance decomposition (state-conditional evaluation)\n"
   ],
   "id": "51c21d935f978c85"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Early-warning vs surveillance evaluation:\n",
    "#   - Early warning: subset with PROXY_NAME == 0 (not currently distressed)\n",
    "#   - Surveillance: subset with PROXY_NAME == 1 (currently distressed)\n",
    "# Also add a state-only baseline: predict next-year distress using current state only.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def safe_eval_metrics(y_true: pd.Series, p: np.ndarray) -> dict:\n",
    "    y = y_true.astype(int).values\n",
    "    out = {\n",
    "        \"roc_auc\": np.nan,\n",
    "        \"pr_auc\": np.nan,\n",
    "        \"brier\": brier_score_loss(y, p),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"event_rate\": float(np.mean(y)),\n",
    "        \"n\": int(len(y)),\n",
    "    }\n",
    "    if np.unique(y).size >= 2:\n",
    "        out[\"roc_auc\"] = roc_auc_score(y, p)\n",
    "        out[\"pr_auc\"] = average_precision_score(y, p)\n",
    "    return out\n",
    "\n",
    "def eval_segment(df_seg: pd.DataFrame, split_name: str, segment_name: str) -> list:\n",
    "    rows = []\n",
    "    if df_seg.empty:\n",
    "        return rows\n",
    "\n",
    "    y = df_seg[TARGET_NAME].astype(int)\n",
    "\n",
    "    # State-only baseline (uses current distress state only)\n",
    "    state = pd.to_numeric(df_seg[PROXY_NAME], errors=\"coerce\").fillna(0).astype(int).values\n",
    "    base = safe_eval_metrics(y, state)\n",
    "\n",
    "    # Models\n",
    "    for col, mdl in [(\"pd_logit\",\"logit\"),\n",
    "                     (\"pd_tree\",\"tree_calibrated\")]:\n",
    "        met = safe_eval_metrics(y, df_seg[col].values)\n",
    "\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"segment\": segment_name,\n",
    "            \"model\": mdl,\n",
    "            **met,\n",
    "            \"baseline_roc_auc\": base[\"roc_auc\"],\n",
    "            \"baseline_pr_auc\": base[\"pr_auc\"],\n",
    "            \"baseline_brier\": base[\"brier\"],\n",
    "            \"delta_roc_auc\": (met[\"roc_auc\"] - base[\"roc_auc\"]) if (met[\"roc_auc\"]==met[\"roc_auc\"] and base[\"roc_auc\"]==base[\"roc_auc\"]) else np.nan,\n",
    "            \"delta_pr_auc\": (met[\"pr_auc\"] - base[\"pr_auc\"]) if (met[\"pr_auc\"]==met[\"pr_auc\"] and base[\"pr_auc\"]==base[\"pr_auc\"]) else np.nan,\n",
    "            \"delta_brier\": met[\"brier\"] - base[\"brier\"],  # negative is improvement\n",
    "        })\n",
    "\n",
    "    # Add baseline as a row for reference\n",
    "    rows.append({\n",
    "        \"split\": split_name,\n",
    "        \"segment\": segment_name,\n",
    "        \"model\": \"state_only\",\n",
    "        **base,\n",
    "        \"baseline_roc_auc\": np.nan,\n",
    "        \"baseline_pr_auc\": np.nan,\n",
    "        \"baseline_brier\": np.nan,\n",
    "        \"delta_roc_auc\": 0.0,\n",
    "        \"delta_pr_auc\": 0.0,\n",
    "        \"delta_brier\": 0.0,\n",
    "    })\n",
    "    return rows\n",
    "\n",
    "seg_rows = []\n",
    "for sp in [\"val\", \"test\"]:\n",
    "    df_sp = df_model.loc[df_model[\"split\"]==sp, :].copy()\n",
    "\n",
    "    # Only evaluate segments where current distress state is observed.\n",
    "    dcur = pd.to_numeric(df_sp[PROXY_NAME], errors=\"coerce\")\n",
    "    df_sp = df_sp.loc[dcur.notna(), :].copy()\n",
    "    df_sp[\"distress_t_int\"] = dcur.loc[dcur.notna()].astype(int)\n",
    "\n",
    "    seg_rows += eval_segment(df_sp.loc[df_sp[\"distress_t_int\"]==0, :], sp, f\"early_warning ({PROXY_NAME}=0)\")\n",
    "    seg_rows += eval_segment(df_sp.loc[df_sp[\"distress_t_int\"]==1, :], sp, f\"surveillance ({PROXY_NAME}=1)\")\n",
    "\n",
    "seg_metrics_tbl = pd.DataFrame(seg_rows)\n",
    "\n",
    "if not seg_metrics_tbl.empty:\n",
    "    seg_metrics_tbl = seg_metrics_tbl.sort_values([\"split\",\"segment\",\"model\"])\n",
    "    display(seg_metrics_tbl)\n",
    "else:\n",
    "    print(\"No segment metrics computed (empty segments).\")\n"
   ],
   "id": "ff41db2c85a96e38",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14804efc",
   "metadata": {},
   "source": [
    "### 8.2 Calibration diagnostics (curve + calibration-in-the-large + slope)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac2c963a",
   "metadata": {},
   "source": [
    "def calibration_slope_intercept(y_true: np.ndarray, p: np.ndarray) -> tuple[float,float]:\n",
    "    z = logit(p)\n",
    "    Xc = sm.add_constant(z, has_constant=\"add\")\n",
    "    mdl = sm.GLM(y_true, Xc, family=sm.families.Binomial())\n",
    "    res = mdl.fit()\n",
    "    intercept, slope = res.params[0], res.params[1]\n",
    "    return float(intercept), float(slope)\n",
    "\n",
    "def plot_calibration(y_true: np.ndarray, p: np.ndarray, title: str, fname: str):\n",
    "    frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=10, strategy=\"quantile\")\n",
    "    plt.figure()\n",
    "    plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"Mean predicted probability\")\n",
    "    plt.ylabel(\"Fraction of positives\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / fname, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "for sp in [\"val\",\"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    y_sp = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "    for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "        p = df_model.loc[mask, pcol].values\n",
    "        icpt, slope = calibration_slope_intercept(y_sp, p)\n",
    "        print(f\"{sp} | {model_name}: calibration intercept={icpt:.3f}, slope={slope:.3f}\")\n",
    "        plot_calibration(y_sp, p, f\"Calibration curve — {model_name} ({sp})\", f\"cal_curve_{model_name}_{sp}.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dae2a433",
   "metadata": {},
   "source": [
    "### 8.3 Temporal stability (walk-forward fold metrics)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0c531ed",
   "metadata": {},
   "source": [
    "if 'wf_tbl' in globals() and len(wf_tbl) > 0:\n",
    "    display(wf_tbl)\n",
    "    plt.figure()\n",
    "    plt.plot(wf_tbl[\"val_year\"], wf_tbl[\"roc_auc\"], marker=\"o\", label=\"ROC-AUC\")\n",
    "    plt.plot(wf_tbl[\"val_year\"], wf_tbl[\"pr_auc\"], marker=\"o\", label=\"PR-AUC\")\n",
    "    plt.title(\"Walk-forward validation metrics (logit)\")\n",
    "    plt.xlabel(\"Validation label_year\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"walkforward_metrics_logit.png\", dpi=160)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e114cc8",
   "metadata": {},
   "source": [
    "### 8.4 Collinearity checks (VIF + high-correlation pairs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a73fa727",
   "metadata": {},
   "source": [
    "# VIF on continuous z-features (train only)\n",
    "X_vif = splits[\"train\"][\"X\"][[f\"z_{c}\" for c in continuous_feats_raw]].copy()\n",
    "X_vif = sm.add_constant(X_vif, has_constant=\"add\")\n",
    "\n",
    "vif_rows = []\n",
    "for i, col in enumerate(X_vif.columns):\n",
    "    if col == \"const\":\n",
    "        continue\n",
    "    vif_rows.append({\"feature\": col, \"VIF\": float(variance_inflation_factor(X_vif.values, i))})\n",
    "\n",
    "vif_tbl = pd.DataFrame(vif_rows).sort_values(\"VIF\", ascending=False)\n",
    "display(vif_tbl)\n",
    "\n",
    "# Correlation screen (continuous only)\n",
    "corr = splits[\"train\"][\"X\"][[f\"z_{c}\" for c in continuous_feats_raw]].corr()\n",
    "high_pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        v = corr.iloc[i,j]\n",
    "        if abs(v) >= 0.85:\n",
    "            high_pairs.append((corr.columns[i], corr.columns[j], float(v)))\n",
    "high_pairs_tbl = pd.DataFrame(high_pairs, columns=[\"feat1\",\"feat2\",\"corr\"]).sort_values(\"corr\", key=np.abs, ascending=False)\n",
    "display(high_pairs_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a8305ac",
   "metadata": {},
   "source": [
    "### 8.5 Drift diagnostics (standardized mean difference: train vs test)"
   ]
  },
  {
   "cell_type": "code",
   "id": "82250df7",
   "metadata": {},
   "source": [
    "feat_cols = [f\"z_{c}\" for c in continuous_feats_raw] + event_feats\n",
    "drift_rows = []\n",
    "for c in feat_cols:\n",
    "    smd = compute_smd(df_model.loc[df_model[\"split\"]==\"train\", c], df_model.loc[df_model[\"split\"]==\"test\", c])\n",
    "    drift_rows.append({\"feature\": c, \"SMD_train_vs_test\": smd})\n",
    "drift_tbl = pd.DataFrame(drift_rows).sort_values(\"SMD_train_vs_test\", key=lambda s: s.abs(), ascending=False)\n",
    "display(drift_tbl.head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "03071f10",
   "metadata": {},
   "source": [
    "### 8.6 Probability distributions by class (test split)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce4a5617",
   "metadata": {},
   "source": [
    "mask = df_model[\"split\"]==\"test\"\n",
    "y_true = df_model.loc[mask, TARGET_NAME].astype(int)\n",
    "\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol]\n",
    "    plt.figure()\n",
    "    plt.hist(p[y_true==0], bins=50, alpha=0.6, label=\"y=0\")\n",
    "    plt.hist(p[y_true==1], bins=50, alpha=0.6, label=\"y=1\")\n",
    "    plt.title(f\"Test PD histogram by class — {model_name}\")\n",
    "    plt.xlabel(\"Predicted PD\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"pd_hist_{model_name}_test.png\", dpi=160)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50013862",
   "metadata": {},
   "source": [
    "## 9. Decision Support Layer\n",
    "\n",
    "This section operationalizes predicted probabilities into interpretable risk signals and policies:\n",
    "- **Event lift tables:** how discrete events shift conditional distress risk.\n",
    "- **Risk deciles:** realized risk by predicted PD decile (reliability in operational tiers).\n",
    "- **Cost curves & capacity rules:** choose thresholds under explicit misclassification costs and screening capacity.\n",
    "- **Pro-forma scenarios:** sensitivity of PD to accounting-consistent adjustments (illustrative; not causal).\n",
    "\n",
    "### 9.1 Event lift tables (prevalence, conditional risk, lift)"
   ]
  },
  {
   "cell_type": "code",
   "id": "94c3906b",
   "metadata": {},
   "source": [
    "def event_lift_table(df_in: pd.DataFrame, events: list[str], y_col: str) -> pd.DataFrame:\n",
    "    base = df_in[y_col].astype(float).mean()\n",
    "    rows=[]\n",
    "    for e in events:\n",
    "        if e not in df_in.columns:\n",
    "            continue\n",
    "        s = pd.to_numeric(df_in[e], errors=\"coerce\").fillna(0).astype(int)\n",
    "        if s.sum() == 0:\n",
    "            continue\n",
    "        rate = df_in.loc[s==1, y_col].astype(float).mean()\n",
    "        prev = s.mean()\n",
    "        rows.append({\n",
    "            \"event\": e,\n",
    "            \"prevalence\": prev,\n",
    "            \"cond_distress_rate\": rate,\n",
    "            \"lift_vs_base\": rate/base if base>0 else np.nan,\n",
    "            \"base_rate\": base,\n",
    "            \"n_event\": int(s.sum()),\n",
    "        })\n",
    "    out = pd.DataFrame(rows)\n",
    "    if not out.empty:\n",
    "        out = out.sort_values(\"lift_vs_base\", ascending=False)\n",
    "    return out\n",
    "\n",
    "for sp in [\"train\",\"test\"]:\n",
    "    df_sp = df_model.loc[df_model[\"split\"]==sp, :]\n",
    "    print(f\"\\nEvent lift — {sp}\")\n",
    "    display(event_lift_table(df_sp, event_feats, TARGET_NAME).head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35162ffd",
   "metadata": {},
   "source": [
    "### 9.2 Event transitions (0→1 activation; 1→1 persistence)"
   ]
  },
  {
   "cell_type": "code",
   "id": "aaa8fd1b",
   "metadata": {},
   "source": [
    "def transition_stats(df_in: pd.DataFrame, event: str) -> dict:\n",
    "    \"\"\"Robust transition stats that enforce year adjacency (Issue 1) and handle NaNs (Issue 2).\"\"\"\n",
    "    s = pd.to_numeric(df_in[event], errors=\"coerce\")\n",
    "    s_l1 = lag(df_in, event, 1)\n",
    "    \n",
    "    # Valid transitions require both observed and adjacent years\n",
    "    valid = s.notna() & s_l1.notna()\n",
    "    s_valid = s[valid].astype(int)\n",
    "    s_l1_valid = s_l1[valid].astype(int)\n",
    "    \n",
    "    if len(s_valid) == 0:\n",
    "         return {\"event\": event, \"activation_01_rate\": np.nan, \"persistence_11_rate\": np.nan}\n",
    "\n",
    "    act_01 = ((s_l1_valid==0) & (s_valid==1)).mean()\n",
    "    pers_11 = ((s_l1_valid==1) & (s_valid==1)).mean()\n",
    "    return {\"event\": event, \"activation_01_rate\": float(act_01), \"persistence_11_rate\": float(pers_11)}\n",
    "\n",
    "rows=[]\n",
    "for e in event_feats:\n",
    "    rows.append(transition_stats(df_model, e))\n",
    "trans_tbl = pd.DataFrame(rows)\n",
    "if not trans_tbl.empty:\n",
    "    trans_tbl = trans_tbl.sort_values(\"activation_01_rate\", ascending=False)\n",
    "display(trans_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89c18d2c",
   "metadata": {},
   "source": [
    "### 9.3 Risk deciles (expected vs realized distress by PD tier)"
   ]
  },
  {
   "cell_type": "code",
   "id": "48e1cb6a",
   "metadata": {},
   "source": [
    "def decile_table(df_in: pd.DataFrame, p_col: str, y_col: str) -> pd.DataFrame:\n",
    "    d = df_in[[p_col, y_col]].dropna().copy()\n",
    "    d[\"decile\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\"drop\") + 1\n",
    "    out = d.groupby(\"decile\").agg(\n",
    "        n=(\"decile\",\"size\"),\n",
    "        mean_pd=(p_col,\"mean\"),\n",
    "        realized_rate=(y_col,\"mean\"),\n",
    "    ).reset_index()\n",
    "    out[\"calibration_gap\"] = out[\"realized_rate\"] - out[\"mean_pd\"]\n",
    "    return out\n",
    "\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    print(f\"\\nTest deciles — {model_name}\")\n",
    "    dt = decile_table(df_model.loc[df_model[\"split\"]==\"test\", :], pcol, TARGET_NAME)\n",
    "    display(dt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fc0a52a",
   "metadata": {},
   "source": [
    "### 9.4 Cost curves and threshold selection (validation-only)"
   ]
  },
  {
   "cell_type": "code",
   "id": "66ca9b6f",
   "metadata": {},
   "source": [
    "COST_FN = float(CONFIG[\"COST_FN\"])\n",
    "COST_FP = float(CONFIG[\"COST_FP\"])\n",
    "CAPACITY_PCT = float(CONFIG[\"CAPACITY_PCT\"])\n",
    "\n",
    "def expected_cost(y_true: np.ndarray, p: np.ndarray, thr: float) -> float:\n",
    "    y_hat = (p >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    return COST_FN*fn + COST_FP*fp\n",
    "\n",
    "def cost_curve(y_true: np.ndarray, p: np.ndarray, grid: np.ndarray) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for thr in grid:\n",
    "        y_hat = (p >= thr).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "        rows.append({\n",
    "            \"thr\": float(thr),\n",
    "            \"TP\": int(tp), \"FP\": int(fp), \"TN\": int(tn), \"FN\": int(fn),\n",
    "            \"cost\": float(COST_FN*fn + COST_FP*fp),\n",
    "            \"tpr\": float(tp/(tp+fn)) if (tp+fn)>0 else np.nan,\n",
    "            \"fpr\": float(fp/(fp+tn)) if (fp+tn)>0 else np.nan,\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "grid = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "mask = df_model[\"split\"]==\"val\"\n",
    "y_val_np = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "thr_tbls = {}\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol].values\n",
    "    cc = cost_curve(y_val_np, p, grid)\n",
    "    thr_star = float(cc.loc[cc[\"cost\"].idxmin(), \"thr\"])\n",
    "    thr_capacity = float(np.quantile(p, 1-CAPACITY_PCT))\n",
    "    thr_tbls[model_name] = {\"thr_cost_opt\": thr_star, \"thr_capacity\": thr_capacity}\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(cc[\"thr\"], cc[\"cost\"])\n",
    "    plt.title(f\"Validation expected cost vs threshold — {model_name}\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Expected misclassification cost\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"cost_curve_{model_name}_val.png\", dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "    print(model_name, \"cost-opt thr=\", thr_star, \"capacity thr=\", thr_capacity)\n",
    "\n",
    "display(pd.DataFrame(thr_tbls).T)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e71b677",
   "metadata": {},
   "source": [
    "### 9.5 Decision curve analysis (net benefit)"
   ]
  },
  {
   "cell_type": "code",
   "id": "fce9eda2",
   "metadata": {},
   "source": [
    "def net_benefit(y_true: np.ndarray, p: np.ndarray, pt: float) -> float:\n",
    "    y_hat = (p >= pt).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    n = len(y_true)\n",
    "    w = pt/(1-pt)\n",
    "    return (tp/n) - (fp/n)*w\n",
    "\n",
    "mask = df_model[\"split\"]==\"test\"\n",
    "y_test_np = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "pts = np.linspace(0.01, 0.50, 50)\n",
    "plt.figure()\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol].values\n",
    "    nb = [net_benefit(y_test_np, p, pt) for pt in pts]\n",
    "    plt.plot(pts, nb, label=model_name)\n",
    "\n",
    "# Treat-all and treat-none baselines\n",
    "event_rate = y_test_np.mean()\n",
    "nb_all = [event_rate - (1-event_rate)*(pt/(1-pt)) for pt in pts]\n",
    "nb_none = [0 for _ in pts]\n",
    "plt.plot(pts, nb_all, linestyle=\"--\", label=\"treat-all\")\n",
    "plt.plot(pts, nb_none, linestyle=\"--\", label=\"treat-none\")\n",
    "\n",
    "plt.title(\"Decision curves (test split): net benefit vs threshold probability\")\n",
    "plt.xlabel(\"Threshold probability (pt)\")\n",
    "plt.ylabel(\"Net benefit\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"decision_curves_test.png\", dpi=160)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11412605",
   "metadata": {},
   "source": [
    "### 9.6 Scenario analysis (accounting-consistent pro-forma adjustments; illustrative)"
   ]
  },
  {
   "cell_type": "code",
   "id": "350a73f0",
   "metadata": {},
   "source": [
    "# Scenario engine: recompute a single-row feature vector using the same rules as the main pipeline.\n",
    "\n",
    "def build_model_features_from_row(row: pd.Series) -> pd.DataFrame:\n",
    "    # --- Helper for safe ratios in single row ---\n",
    "    def safe_div(n, d):\n",
    "        try:\n",
    "            n_f = float(n)\n",
    "            d_f = float(d)\n",
    "            if pd.isna(n_f) or pd.isna(d_f) or d_f == 0:\n",
    "                return np.nan\n",
    "            return n_f / d_f\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    # Raw items from row\n",
    "    at = row.get(\"at\", np.nan)\n",
    "    che = row.get(\"che\", np.nan)\n",
    "    act = row.get(\"act\", np.nan)\n",
    "    lct = row.get(\"lct\", np.nan)\n",
    "    aco = row.get(\"aco\", np.nan)\n",
    "    lco = row.get(\"lco\", np.nan)\n",
    "    rect = row.get(\"rect\", np.nan)\n",
    "    invt = row.get(\"invt\", np.nan)\n",
    "    recch = row.get(\"recch\", np.nan)\n",
    "    invch = row.get(\"invch\", np.nan)\n",
    "    txp = row.get(\"txp\", np.nan)\n",
    "    txditc = row.get(\"txditc\", np.nan)\n",
    "    lt = row.get(\"lt\", np.nan)\n",
    "    dlc = row.get(\"dlc\", np.nan)\n",
    "    dltt = row.get(\"dltt\", np.nan)\n",
    "    oibdp = row.get(\"oibdp\", np.nan)\n",
    "    dp = row.get(\"dp\", np.nan)\n",
    "    xint = row.get(\"xint\", np.nan)\n",
    "    ceq = row.get(\"ceq\", np.nan)\n",
    "    capx = row.get(\"capx\", np.nan)\n",
    "    ppent = row.get(\"ppent\", np.nan)\n",
    "    intan = row.get(\"intan\", np.nan)\n",
    "    oancf = row.get(\"oancf\", np.nan)\n",
    "    re = row.get(\"re\", np.nan)\n",
    "    caps = row.get(\"caps\", np.nan)\n",
    "    mibt = row.get(\"mibt\", np.nan)\n",
    "    niadj = row.get(\"niadj\", np.nan)\n",
    "    aqc = row.get(\"aqc\", np.nan)\n",
    "    prstkc = row.get(\"prstkc\", np.nan)\n",
    "\n",
    "    # Debt aggregate matching df logic\n",
    "    d_vals = [v for v in [dlc, dltt] if pd.notna(v)]\n",
    "    total_debt = sum(d_vals) if d_vals else np.nan\n",
    "\n",
    "    # Map of all potential continuous features\n",
    "    feat_map = {}\n",
    "    feat_map[\"ln_at\"] = np.log(at) if pd.notna(at) and at > 0 else np.nan\n",
    "    feat_map[\"cash_at\"] = safe_div(che, at)\n",
    "    feat_map[\"current_ratio\"] = safe_div(act, lct)\n",
    "    feat_map[\"nwc_at\"] = safe_div(act - lct, at)\n",
    "    feat_map[\"aco_act\"] = safe_div(aco, act)\n",
    "    feat_map[\"lco_lct\"] = safe_div(lco, lct)\n",
    "    feat_map[\"rect_act\"] = safe_div(rect, act)\n",
    "    feat_map[\"invt_act\"] = safe_div(invt, act)\n",
    "    feat_map[\"recch_act\"] = safe_div(recch, act)\n",
    "    feat_map[\"invch_act\"] = safe_div(invch, act)\n",
    "    feat_map[\"txp_lct\"] = safe_div(txp, lct)\n",
    "    feat_map[\"txditc_at\"] = safe_div(txditc, at)\n",
    "    feat_map[\"lt_at\"] = safe_div(lt, at)\n",
    "    feat_map[\"dlc_at\"] = safe_div(dlc, at)\n",
    "    feat_map[\"dltt_at\"] = safe_div(dltt, at)\n",
    "    feat_map[\"debt_at\"] = safe_div(total_debt, at)\n",
    "    feat_map[\"st_debt_share\"] = safe_div(dlc, total_debt)\n",
    "    feat_map[\"ebitda_at\"] = safe_div(oibdp, at)\n",
    "    feat_map[\"dp_at\"] = safe_div(dp, at)\n",
    "    feat_map[\"xint_at\"] = safe_div(xint, at)\n",
    "    feat_map[\"interest_coverage\"] = safe_div(oibdp, xint)\n",
    "    feat_map[\"debt_to_ebitda\"] = safe_div(total_debt, oibdp)\n",
    "    feat_map[\"ebit_to_capital\"] = safe_div(oibdp - dp, total_debt + ceq)\n",
    "    feat_map[\"capx_at\"] = safe_div(capx, at)\n",
    "    \n",
    "    # V2 extras\n",
    "    feat_map[\"ppent_at\"] = safe_div(ppent, at)\n",
    "    feat_map[\"intan_at\"] = safe_div(intan, at)\n",
    "    feat_map[\"ocf_to_debt\"] = safe_div(oancf, total_debt)\n",
    "    feat_map[\"fcf_to_debt\"] = safe_div(oancf - capx, total_debt)\n",
    "    feat_map[\"re_at\"] = safe_div(re, at)\n",
    "    \n",
    "    # V3 extras\n",
    "    feat_map[\"ceq_at\"] = safe_div(ceq, at)\n",
    "    feat_map[\"caps_at\"] = safe_div(caps, at)\n",
    "    feat_map[\"mibt_at\"] = safe_div(mibt, at)\n",
    "    feat_map[\"niadj_at\"] = safe_div(niadj, at)\n",
    "    feat_map[\"xint_lct\"] = safe_div(xint, lct)\n",
    "    feat_map[\"aqc_at\"] = safe_div(aqc, at)\n",
    "    feat_map[\"prstkc_at\"] = safe_div(prstkc, at)\n",
    "\n",
    "    # Event map\n",
    "    event_map = {}\n",
    "    event_map[\"loss_indicator\"] = 1.0 if pd.notna(niadj) and niadj < 0 else 0.0\n",
    "\n",
    "    # Assemble raw feature vector\n",
    "    out_dict = {}\n",
    "    for c in continuous_feats_raw:\n",
    "        out_dict[c] = feat_map.get(c, np.nan)\n",
    "    for e in event_feats:\n",
    "        out_dict[e] = event_map.get(e, 0)\n",
    "    \n",
    "    out = pd.DataFrame([out_dict])\n",
    "\n",
    "    # Preprocessing: train medians, winsor, scaler -> z_\n",
    "    for c in continuous_feats_raw:\n",
    "        v = out[c].replace([np.inf, -np.inf], np.nan)\n",
    "        v = v.fillna(train_medians[c])\n",
    "        lo, hi = winsor_bounds[c]\n",
    "        v = apply_bounds(v, lo, hi)\n",
    "        out[c] = v\n",
    "\n",
    "    Z = scaler.transform(out[continuous_feats_raw].astype(float))\n",
    "    for j, c in enumerate(continuous_feats_raw):\n",
    "        out[f\"z_{c}\"] = Z[:, j]\n",
    "\n",
    "    # Final feature vector in MODEL_FEATS order\n",
    "    return out[[f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "\n",
    "def predict_pd_from_features(X_row: pd.DataFrame) -> dict:\n",
    "    pd_logit = float(logit_clf.predict_proba(X_row)[:, 1][0])\n",
    "    drow = xgb.DMatrix(X_row, feature_names=X_row.columns.tolist())\n",
    "    pd_tree_raw = float(xgb_model.predict(drow)[0])\n",
    "    pd_tree = float(iso.transform([pd_tree_raw])[0])\n",
    "    return {\"pd_logit\": pd_logit, \"pd_tree\": pd_tree}\n",
    "\n",
    "# Select a representative high-risk test observation\n",
    "test_df = df_model.loc[df_model[\"split\"]==\"test\", :].copy()\n",
    "rep_idx = test_df[\"pd_logit\"].idxmax()\n",
    "row0 = df.loc[rep_idx, :]  # use df (feature-engineered, imputed), not df_model\n",
    "base_X = build_model_features_from_row(row0)\n",
    "base_pd = predict_pd_from_features(base_X)\n",
    "\n",
    "print(\"Representative observation (highest logit PD in test):\")\n",
    "display(df_model.loc[rep_idx, [\"firm_id\",\"fyear\",\"label_year\",\"pd_logit\",\"pd_tree\",\"target_next_v1\",\"target_next_v2\",\"target_next_v3\"]])\n",
    "print(\"Base PDs:\", base_pd)\n",
    "\n",
    "# Scenario 1: Liquidity buffer to current ratio = 1.2 (increase current assets; illustrative)\n",
    "row1 = row0.copy()\n",
    "if \"act\" in row1.index and \"lct\" in row1.index and pd.notna(row1[\"act\"]) and pd.notna(row1[\"lct\"]) and row1[\"lct\"] > 0:\n",
    "    target_cr = 1.2\n",
    "    add_act = max(0.0, target_cr*row1[\"lct\"] - row1[\"act\"])\n",
    "    row1[\"act\"] = row1[\"act\"] + add_act\n",
    "    if \"che\" in row1.index and pd.notna(row1.get(\"che\", np.nan)):\n",
    "        row1[\"che\"] = row1[\"che\"] + add_act  # assume added liquidity goes to cash\n",
    "X1 = build_model_features_from_row(row1)\n",
    "pd1 = predict_pd_from_features(X1)\n",
    "\n",
    "# Scenario 2: CFO improvement of +10% of assets (accounting-consistent in the short-run is debatable; treat as stress-test)\n",
    "row2 = row0.copy()\n",
    "if \"oancf\" in row2.index and \"at\" in row2.index and pd.notna(row2[\"at\"]):\n",
    "    delta = 0.10 * row2[\"at\"]\n",
    "    row2[\"oancf\"] = (row2[\"oancf\"] if pd.notna(row2.get(\"oancf\", np.nan)) else 0.0) + delta\n",
    "X2 = build_model_features_from_row(row2)\n",
    "pd2 = predict_pd_from_features(X2)\n",
    "\n",
    "scenario_tbl = pd.DataFrame([\n",
    "    {\"scenario\":\"base\", **base_pd},\n",
    "    {\"scenario\":\"liquidity_buffer_CR_1.2\", **pd1},\n",
    "    {\"scenario\":\"CFO_plus_10pct_assets\", **pd2},\n",
    "])\n",
    "display(scenario_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "757172aa",
   "metadata": {},
   "source": [
    "## 10. Results Summary & Interpretation Guardrails\n",
    "\n",
    "### 10.1 Interpretation guardrails (publication-ready language)\n",
    "\n",
    "- The label is a **constructed proxy** for balance-sheet/coverage stress; it is not a legal default outcome.\n",
    "- Coefficients and SHAP values are **associational and predictive**, not causal effects.\n",
    "- Even with leakage controls, residual mechanical endogeneity may remain because accounting choices jointly affect both predictors and the proxy label.\n",
    "- Attrition (missing next-year observations) can create sample-selection distortions; diagnostics are reported via `has_next_year_obs`.\n",
    "\n",
    "### 10.2 Replication artifacts\n",
    "\n",
    "The following tables/exports are written to `outputs/` for downstream paper workflow:\n",
    "- `config_summary.json`\n",
    "- `distress_rule.json`\n",
    "- `event_dictionary.csv`\n",
    "- `logit_inference_table.csv`\n",
    "- `metrics_table.csv`\n",
    "- `predictions.csv`\n",
    "\n",
    "### 10.3 Export tables, thresholds, and predictions"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9838ad0",
   "metadata": {},
   "source": [
    "out_dir = Path(CONFIG[\"OUTPUT_DIR\"])\n",
    "\n",
    "# Config + distress rule\n",
    "(out_dir / \"config_summary.json\").write_text(json.dumps(CONFIG, indent=2))\n",
    "(out_dir / \"distress_rule.json\").write_text(json.dumps(DISTRESS_RULE, indent=2))\n",
    "\n",
    "# Event dictionary\n",
    "event_dict.to_csv(out_dir / \"event_dictionary.csv\", index=False)\n",
    "\n",
    "# Logit inference table\n",
    "infer_tbl.reset_index().to_csv(out_dir / \"logit_inference_table.csv\", index=False)\n",
    "\n",
    "# Metrics table\n",
    "metrics_tbl.to_csv(out_dir / \"metrics_table.csv\", index=False)\n",
    "\n",
    "# Predictions export (replication-friendly)\n",
    "export_cols = [\"firm_id\",\"gvkey\",\"fyear\",\"label_year\",\"split\",\"target_next_v1\",\"target_next_v2\",\"target_next_v3\",\"pd_logit\",\"pd_tree\"]\n",
    "export_cols = [c for c in export_cols if c in df_model.columns]\n",
    "export_cols += [c for c in event_feats if c in df_model.columns]\n",
    "pred_export = df_model[export_cols].copy()\n",
    "pred_export.to_csv(out_dir / \"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Wrote artifacts to:\", out_dir.resolve())\n",
    "print_df(pred_export, n=10, name=\"predictions.csv preview\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50eece1d",
   "metadata": {},
   "source": [
    "### 10.4 Deployment and maintenance (future work)\n",
    "\n",
    "This notebook produces a research-grade replication pipeline. For production use (not required for journal replication), a minimal MLOps extension would include:\n",
    "- scheduled re-scoring and monitoring for drift in feature distributions and target prevalence,\n",
    "- retraining triggers and versioned model registry,\n",
    "- data validation contracts (schema + unit tests) for the upstream Compustat extraction process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
