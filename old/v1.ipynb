{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# 0. CONFIGURATION\n",
    "# =============================================================================\n",
    "# Define the temporal split cut-off\n",
    "TRAIN_CUTOFF_YEAR = 2022  # Training: <= 2022, Testing: > 2022\n",
    "FILE_NAME = \"data.csv\"    # Replace with your actual file name\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD & TYPE CONVERSION\n",
    "# =============================================================================\n",
    "df = pd.read_csv(FILE_NAME, low_memory=False)\n",
    "\n",
    "# 1.1 Datetime conversion\n",
    "if 'datadate' in df.columns:\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'], errors='coerce')\n",
    "\n",
    "# 1.2 Numeric conversion\n",
    "numeric_cols = ['prcc_c', 'prcc_f', 'gvkey', 'fyear', 'ismod',\n",
    "                'ib', 'at', 'dltt', 'dlc', 'che', 're', 'seq',\n",
    "                'xrd', 'dv', 'ni', 'act', 'lct', 'oancf', 'ivncf', 'fincf',\n",
    "                'oibdp', 'xint', 'mkvalt', 'capx']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Ensure key columns exist\n",
    "required_keys = ['gvkey', 'fyear']\n",
    "missing_keys = [c for c in required_keys if c not in df.columns]\n",
    "if missing_keys:\n",
    "    raise KeyError(f\"Missing required column(s): {missing_keys}. Check your CSV schema.\")\n",
    "\n",
    "# 1.3 Create firm_id and Sort\n",
    "df['firm_id'] = df['gvkey']  # Keep gvkey as ID\n",
    "df = df.sort_values(['firm_id', 'fyear']).reset_index(drop=True)\n",
    "\n",
    "# Prefer panel-unique duplicates removal if possible\n",
    "df = df.drop_duplicates(subset=['firm_id', 'fyear'], keep='last').reset_index(drop=True)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. FEATURE ENGINEERING (RAW)\n",
    "# =============================================================================\n",
    "# We construct raw ratios BEFORE scaling/winsorizing to preserve economic meaning.\n",
    "# However, we must handle division by zero.\n",
    "\n",
    "eps = 1e-6\n",
    "\n",
    "# 2.1 Distress Label Construction (Target Variable: t+1)\n",
    "# ------------------------------------------------------\n",
    "# Definition: Distress = 1 if (Interest Coverage < 1) OR (Negative Equity)\n",
    "# Note: This checks distress in the CURRENT year. We will shift it later for prediction.\n",
    "\n",
    "# Interest Coverage: EBIT / Interest Expense\n",
    "df['interest_coverage'] = np.nan\n",
    "if all(c in df.columns for c in ['oibdp', 'xint']):\n",
    "    df['interest_coverage'] = df['oibdp'] / (df['xint'] + eps)\n",
    "\n",
    "# Binary Distress Indicator\n",
    "cond_coverage = (df['interest_coverage'] < 1.0)\n",
    "cond_insolvency = pd.Series(False, index=df.index)\n",
    "if 'seq' in df.columns:\n",
    "    cond_insolvency = (df['seq'] < 0)\n",
    "\n",
    "df['distress_dummy'] = (cond_coverage.fillna(False) | cond_insolvency.fillna(False)).astype(int)\n",
    "\n",
    "# 2.2 Financial Ratios\n",
    "# -------------------------------------------\n",
    "df['roa'] = np.nan\n",
    "df['cf_roa'] = np.nan\n",
    "if all(c in df.columns for c in ['ib', 'at']):\n",
    "    df['roa'] = df['ib'] / (df['at'] + eps)\n",
    "if all(c in df.columns for c in ['oancf', 'at']):\n",
    "    df['cf_roa'] = df['oancf'] / (df['at'] + eps)\n",
    "\n",
    "# Leverage\n",
    "df['total_debt'] = np.nan\n",
    "df['leverage'] = np.nan\n",
    "df['debt_to_equity'] = np.nan\n",
    "if 'dltt' in df.columns or 'dlc' in df.columns:\n",
    "    dltt = df['dltt'] if 'dltt' in df.columns else 0\n",
    "    dlc = df['dlc'] if 'dlc' in df.columns else 0\n",
    "    df['total_debt'] = pd.to_numeric(dltt, errors='coerce').fillna(0) + pd.to_numeric(dlc, errors='coerce').fillna(0)\n",
    "\n",
    "if 'total_debt' in df.columns and 'at' in df.columns:\n",
    "    df['leverage'] = df['total_debt'] / (df['at'] + eps)\n",
    "if 'total_debt' in df.columns and 'seq' in df.columns:\n",
    "    df['debt_to_equity'] = df['total_debt'] / (df['seq'] + eps)\n",
    "\n",
    "# Liquidity\n",
    "df['current_ratio'] = np.nan\n",
    "df['cash_ratio'] = np.nan\n",
    "if all(c in df.columns for c in ['act', 'lct']):\n",
    "    df['current_ratio'] = df['act'] / (df['lct'] + eps)\n",
    "if all(c in df.columns for c in ['che', 'lct']):\n",
    "    df['cash_ratio'] = df['che'] / (df['lct'] + eps)\n",
    "\n",
    "# Solvency / Altman-style\n",
    "df['re_to_assets'] = np.nan\n",
    "df['mkt_to_book'] = np.nan\n",
    "if all(c in df.columns for c in ['re', 'at']):\n",
    "    df['re_to_assets'] = df['re'] / (df['at'] + eps)\n",
    "if all(c in df.columns for c in ['mkvalt', 'seq']):\n",
    "    df['mkt_to_book'] = df['mkvalt'] / (df['seq'] + eps)\n",
    "\n",
    "# Investment\n",
    "df['capex_ratio'] = np.nan\n",
    "if all(c in df.columns for c in ['capx', 'at']):\n",
    "    df['capex_ratio'] = df['capx'] / (df['at'] + eps)\n",
    "\n",
    "# 2.3 Lagging (Predicting t+1 using t)\n",
    "# ------------------------------------\n",
    "df['target_next_year_distress'] = df.groupby('firm_id')['distress_dummy'].shift(-1)\n",
    "\n",
    "# Drop rows where target is NaN (usually the last year for each firm)\n",
    "df = df.dropna(subset=['target_next_year_distress']).reset_index(drop=True)"
   ],
   "id": "923e4b641cf0939f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "547cafbfbcec3f3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# 3. SPLIT TRAIN AND TEST (Temporal)\n",
    "# =============================================================================\n",
    "print(f\"Splitting data at year {TRAIN_CUTOFF_YEAR}...\")\n",
    "\n",
    "train_mask = df['fyear'] <= TRAIN_CUTOFF_YEAR\n",
    "test_mask = df['fyear'] > TRAIN_CUTOFF_YEAR\n",
    "\n",
    "train = df[train_mask].copy()\n",
    "test = df[test_mask].copy()\n",
    "\n",
    "print(f\"Train samples: {len(train)}\")\n",
    "print(f\"Test samples:  {len(test)}\")"
   ],
   "id": "ec063ffbdc970cec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. WINSORIZATION (Fit on Train, Apply to Test)\n",
    "# =============================================================================\n",
    "winsor_cols = ['roa', 'cf_roa', 'leverage', 'debt_to_equity', 'current_ratio',\n",
    "               'cash_ratio', 're_to_assets', 'mkt_to_book', 'capex_ratio',\n",
    "               'interest_coverage']\n",
    "\n",
    "winsor_cols = [c for c in winsor_cols if c in train.columns and c in test.columns]\n",
    "\n",
    "winsor_stats = {}\n",
    "\n",
    "for col in winsor_cols:\n",
    "    train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "    # Fit bounds on Train (guard against all-NaN columns)\n",
    "    if train[col].notna().sum() == 0:\n",
    "        winsor_stats[col] = (np.nan, np.nan)\n",
    "        continue\n",
    "\n",
    "    lower = train[col].quantile(0.01)\n",
    "    upper = train[col].quantile(0.99)\n",
    "    winsor_stats[col] = (lower, upper)\n",
    "\n",
    "    train[col] = train[col].clip(lower=lower, upper=upper)\n",
    "    test[col] = test[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "print(\"Winsorization complete (Bounds derived from Train set).\")"
   ],
   "id": "777e33600b24a782",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 5. STANDARDIZATION (Fit on Train, Apply to Test)\n",
    "# =============================================================================\n",
    "# Z-score = (x - mean_train) / std_train\n",
    "\n",
    "# Log-transform size variables if present\n",
    "for df_split in [train, test]:\n",
    "    for col in ['at', 'mkvalt']:\n",
    "        if col in df_split.columns:\n",
    "            df_split[col] = pd.to_numeric(df_split[col], errors='coerce')\n",
    "            df_split[f'log_{col}'] = np.log1p(df_split[col].clip(lower=0))\n",
    "\n",
    "final_features = winsor_cols + [c for c in ['log_at', 'log_mkvalt'] if c in train.columns and c in test.columns]\n",
    "\n",
    "scaling_stats = {}\n",
    "\n",
    "for col in final_features:\n",
    "    train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "    mu = train[col].mean()\n",
    "    sigma = train[col].std()\n",
    "    scaling_stats[col] = (mu, sigma)\n",
    "\n",
    "    train[f'z_{col}'] = (train[col] - mu) / (sigma + 1e-8)\n",
    "    test[f'z_{col}'] = (test[col] - mu) / (sigma + 1e-8)\n",
    "\n",
    "print(\"Standardization complete (Stats derived from Train set).\")\n"
   ],
   "id": "a4077a79ad14f506",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "############################################################\n",
    "# 3. Feature Selection Prep (Chapter 2: Feature Selection)\n",
    "# ----------------------------------------------------------\n",
    "# Filter methods:\n",
    "#   - Correlation analysis for numeric features vs target\n",
    "#   - VIF for multicollinearity diagnostics\n",
    "############################################################\n",
    "\n",
    "# Use features that were defined and standardized\n",
    "feature_vars = [\n",
    "    'roa', 'cf_roa', 'leverage', 'debt_to_equity', 'current_ratio',\n",
    "    'cash_ratio', 're_to_assets', 'mkt_to_book', 'capex_ratio',\n",
    "    'interest_coverage', 'log_at', 'log_mkvalt'\n",
    "]\n",
    "\n",
    "# Retain only those that exist in train\n",
    "feature_vars = [v for v in feature_vars if v in train.columns]\n",
    "\n",
    "# Use train data for feature selection to avoid look-ahead bias\n",
    "target_col = 'target_next_year_distress'\n",
    "\n",
    "# 3.1 Correlation with target variable\n",
    "# ------------------------------------\n",
    "print(\"----- Correlation of Features with Target Variable -----\")\n",
    "corr_matrix = train[[target_col] + feature_vars].corr()\n",
    "\n",
    "for var in feature_vars:\n",
    "    r = corr_matrix.loc[target_col, var]\n",
    "    print(f\"{var:<20} r = {r: .4f}\")\n",
    "\n",
    "# 3.2 VIF (Variance Inflation Factor)\n",
    "# ------------------------------------\n",
    "vif_vars = feature_vars\n",
    "X_df = train[vif_vars].dropna()\n",
    "X = X_df.values\n",
    "var_names = list(vif_vars)\n",
    "\n",
    "print(\"\\n----- VIF for selected features -----\")\n",
    "\n",
    "def compute_vif(X, j):\n",
    "    y = X[:, j]\n",
    "    X_other = np.delete(X, j, axis=1)\n",
    "    X_other_const = np.column_stack([np.ones(X_other.shape[0]), X_other])\n",
    "    beta, _, _, _ = np.linalg.lstsq(X_other_const, y, rcond=None)\n",
    "    y_pred = X_other_const @ beta\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - y.mean()) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "    return np.inf if r2 >= 1 else 1.0 / (1.0 - r2)\n",
    "\n",
    "for j, name in enumerate(var_names):\n",
    "    vif_val = compute_vif(X, j)\n",
    "    print(f\"{name:<20} VIF = {vif_val: .4f}\")\n",
    "\n",
    "# 3.3 Variability checks (IQR & Std. Dev.)\n",
    "# ----------------------------------------\n",
    "print(\"\\n----- Variability Checks (IQR & Std. Dev.) -----\")\n",
    "for var in feature_vars:\n",
    "    series = train[var].dropna()\n",
    "    if series.empty:\n",
    "        print(f\"{var:<20} IQR: NA, Std. Dev.: NA\")\n",
    "        continue\n",
    "    q25 = series.quantile(0.25)\n",
    "    q75 = series.quantile(0.75)\n",
    "    iqr = q75 - q25\n",
    "    std = series.std(ddof=1)\n",
    "    print(f\"{var:<20} IQR: {iqr:.6f}, Std. Dev.: {std:.6f}\")\n",
    "\n",
    "\n"
   ],
   "id": "9e9d7be4145e50",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T15:52:45.597226Z",
     "start_time": "2025-12-19T15:52:45.530248Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f958f1c1a4499d6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating boxplots for winsorized features...\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
