{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ad9bfb",
   "metadata": {},
   "source": [
    "# Next-Year Financial Distress Early-Warning (Transition) & Surveillance (Compustat Annual Panel) — Reproducible ML Pipeline\n",
    "\n",
    "**Goal.** Predict the probability that a firm is in *financial distress* in fiscal year **t+1** using accounting (and permitted market) information available at fiscal year **t**.\n",
    "\n",
    "**Important scope note.** The outcome is an **engineered distress proxy** (high leverage / balance-sheet stress), not a realized legal default or bankruptcy. The notebook is therefore a **predictive measurement and decision-support pipeline**, not a causal identification design.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook structure (Data Science Lifecycle — 10 phases)\n",
    "\n",
    "1. Problem Definition & Setup  \n",
    "2. Data Collection & Panel Integrity  \n",
    "3. Data Cleaning & Missingness Handling (leakage-aware)  \n",
    "4. Exploratory Data Analysis (EDA)  \n",
    "5. Feature Engineering & Target Construction  \n",
    "6. Preprocessing for Modeling (train-only fitting)  \n",
    "7. Model Selection & Training (7A Logit; 7B Trees)  \n",
    "8. Model Evaluation & Diagnostic Monitoring  \n",
    "9. Operational Risk Management Layer (Events + PDs)\n",
    "10. Results Summary, Guardrails, and Replication Artifacts\n",
    "\n",
    "> This organization mirrors the course lifecycle guidance and the project's technical review action items (see provided PDF and technical report).\n",
    "\n",
    "## How to run (replication package convention)\n",
    "\n",
    "1. Place `data.csv` in the project root (or update `CONFIG[\"DATA_PATH\"]` in Section 1).\n",
    "2. Keep `Variables.xlsx` (variable dictionary) alongside the notebook for automatic documentation.\n",
    "3. Run **Kernel → Restart & Run All**.\n",
    "\n",
    "The notebook creates an `outputs/` folder containing:\n",
    "- a predictions export (`predictions.csv`),\n",
    "- configuration and threshold tables,\n",
    "- model summary tables suitable for an appendix,\n",
    "- figures saved as PNG for paper workflow.\n",
    "\n",
    "## 1. Problem Definition & Setup\n",
    "\n",
    "### 1.1 Prediction target, success metrics, and decision objective\n",
    "\n",
    "- **Target (supervised label):** `target_next_v1`, `target_next_v2`, or `target_next_v3` (separate distress proxies). Downstream modeling uses `target_next_v2` by default.  \n",
    "- **Primary performance metrics (out-of-sample):**\n",
    "  - ROC-AUC (ranking quality),\n",
    "  - PR-AUC (class imbalance),\n",
    "  - Brier score (probability accuracy / calibration).\n",
    "- **Decision objective (screening):** convert predicted PDs into a review policy using:\n",
    "  - **misclassification costs** (`COST_FN`, `COST_FP`) and\n",
    "  - **capacity constraints** (screen top `CAPACITY_PCT` percent of firms).\n",
    "\n",
    "This is a *risk scoring* workflow: calibrated probabilities and operational interpretability matter more than headline accuracy.\n",
    "\n",
    "### 1.2 Configuration, determinism, and library versions\n",
    "\n",
    "**Objective options:**\n",
    "- **Transition (early-warning):** predict *healthy at t → distressed at t+1*.\n",
    "- **State (surveillance):** predict *distress state at t+1* (includes persistence).\n",
    "\n",
    "The notebook preserves proxy selection (V1/V2/V3); set `PROXY_VERSION` and `OBJECTIVE` in Section 4 (Targets).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3f7594c2",
   "metadata": {},
   "source": [
    "# Core numerics\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML / metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Stats / inference\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\n",
    "from scipy import stats\n",
    "\n",
    "# Trees / explainability\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# Determinism\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "USING_SYNTHETIC_DATA = False # Global flag for data mode\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration (edit here)\n",
    "# ----------------------------\n",
    "CONFIG = {\n",
    "    # Data inputs\n",
    "    \"DATA_PATH\": \"data.csv\",\n",
    "    \"VARIABLES_XLSX_PATH\": \"Variables.xlsx\",\n",
    "\n",
    "    # Temporal splitting via label_year = fyear + 1\n",
    "    \"TRAIN_CUTOFF_LABEL_YEAR\": 2022,   # label_year <= cutoff -> train/val pool; later -> test\n",
    "    \"VAL_YEARS\": 1,                    # number of last label years inside the train pool used as validation\n",
    "\n",
    "    # Missingness / imputation\n",
    "    \"KNN_K\": 5,\n",
    "    \"IMPUTE_LO_Q\": 0.01,\n",
    "    \"IMPUTE_HI_Q\": 0.99,\n",
    "\n",
    "    # Preprocessing\n",
    "    \"WINSOR_LO_Q\": 0.01,\n",
    "    \"WINSOR_HI_Q\": 0.99,\n",
    "\n",
    "    # Logit hyperparameter search\n",
    "    \"LOGIT_C_GRID\": [0.01, 0.1, 1.0, 10.0],\n",
    "\n",
    "    # Tree model (XGBoost) parameters (conservative / regularized)\n",
    "    \"XGB_PARAMS\": {\n",
    "        \"max_depth\": 4,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"eta\": 0.05,\n",
    "        \"reg_lambda\": 10.0,\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": SEED,\n",
    "    },\n",
    "    \"XGB_NUM_BOOST_ROUND\": 5000,\n",
    "    \"XGB_EARLY_STOPPING\": 200,\n",
    "\n",
    "    # Decision policy parameters (costs + capacity)\n",
    "    \"COST_FN\": 50.0,\n",
    "    \"COST_FP\": 1.0,\n",
    "    \"CAPACITY_PCT\": 0.20,  # screen top 20% by PD as a capacity policy\n",
    "\n",
    "    # Outputs\n",
    "    \"OUTPUT_DIR\": \"outputs\",\n",
    "    \"FIG_DIR\": \"figures\",\n",
    "}\n",
    "\n",
    "Path(CONFIG[\"OUTPUT_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(CONFIG[\"FIG_DIR\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CONFIG (key parameters):\")\n",
    "for k in [\"DATA_PATH\",\"TRAIN_CUTOFF_LABEL_YEAR\",\"VAL_YEARS\",\"KNN_K\",\"WINSOR_LO_Q\",\"WINSOR_HI_Q\",\"COST_FN\",\"COST_FP\",\"CAPACITY_PCT\"]:\n",
    "    print(f\"  {k}: {CONFIG[k]}\")\n",
    "print(\"\\nPython:\", sys.version.split()[0])\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b26c8dff",
   "metadata": {},
   "source": [
    "### 1.3 Helper utilities (robust ratios, transforms, and reporting)"
   ]
  },
  {
   "cell_type": "code",
   "id": "76a360d9",
   "metadata": {},
   "source": [
    "def signed_log1p(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Signed log1p transform: sign(x) * log1p(|x|). Preserves zero and sign, stabilizes tails.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "def safe_divide(numer: pd.Series, denom: pd.Series, denom_floor: float = None) -> pd.Series:\n",
    "    \"\"\"Safe divide with optional denominator floor for stability. Returns float with NaN where undefined.\"\"\"\n",
    "    numer = pd.to_numeric(numer, errors=\"coerce\")\n",
    "    denom = pd.to_numeric(denom, errors=\"coerce\")\n",
    "    if denom_floor is not None:\n",
    "        denom = denom.where(denom.abs() >= denom_floor, other=np.sign(denom).replace(0, 1) * denom_floor)\n",
    "    out = numer / denom\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    return out\n",
    "\n",
    "def ensure_nullable_float(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert to pandas nullable Float64 to enable NA-aware comparisons (returns <NA> instead of False).\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(\"Float64\")\n",
    "\n",
    "def winsorize_train_bounds(x: pd.Series, lo: float, hi: float) -> tuple[float, float]:\n",
    "    \"\"\"Return winsorization bounds computed on *training* observed values.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    x_obs = x.dropna()\n",
    "    if len(x_obs) == 0:\n",
    "        return (np.nan, np.nan)\n",
    "    return (float(x_obs.quantile(lo)), float(x_obs.quantile(hi)))\n",
    "\n",
    "def apply_bounds(x: pd.Series, lo: float, hi: float) -> pd.Series:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    if np.isnan(lo) or np.isnan(hi):\n",
    "        return x\n",
    "    return x.clip(lower=lo, upper=hi)\n",
    "\n",
    "def compute_smd(train: pd.Series, test: pd.Series) -> float:\n",
    "    \"\"\"Standardized mean difference (SMD): (mu_train - mu_test)/pooled_sd.\"\"\"\n",
    "    a = pd.to_numeric(train, errors=\"coerce\").dropna()\n",
    "    b = pd.to_numeric(test, errors=\"coerce\").dropna()\n",
    "    if len(a) < 2 or len(b) < 2:\n",
    "        return np.nan\n",
    "    mu_a, mu_b = a.mean(), b.mean()\n",
    "    sd_a, sd_b = a.std(ddof=1), b.std(ddof=1)\n",
    "    pooled = np.sqrt(0.5*(sd_a**2 + sd_b**2))\n",
    "    return float((mu_a - mu_b) / pooled) if pooled > 0 else np.nan\n",
    "\n",
    "def logit(p: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def print_df(df: pd.DataFrame, n: int = 10, name: str = None):\n",
    "    if name:\n",
    "        print(f\"\\n{name} (top {n} rows):\")\n",
    "    display(df.head(n))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cde14739",
   "metadata": {},
   "source": [
    "## 2. Data Collection & Panel Integrity\n",
    "\n",
    "### 2.1 Load variable dictionary (for documentation)\n",
    "\n",
    "We load the provided variable dictionary (`Variables.xlsx`) to:\n",
    "- validate required Compustat mnemonics exist in the data file,\n",
    "- generate appendix-ready variable tables.\n",
    "\n",
    "This step **does not** transform the modeling data."
   ]
  },
  {
   "cell_type": "code",
   "id": "70e93db7",
   "metadata": {},
   "source": [
    "vars_path = Path(CONFIG[\"VARIABLES_XLSX_PATH\"])\n",
    "if vars_path.exists():\n",
    "    var_dict = pd.read_excel(vars_path, sheet_name=0)\n",
    "    var_dict.columns = [c.strip() for c in var_dict.columns]\n",
    "    print(f\"Loaded variable dictionary with {len(var_dict)} rows from: {vars_path}\")\n",
    "    display(var_dict.head(90))\n",
    "else:\n",
    "    var_dict = pd.DataFrame(columns=[\"Variable\",\"Two-word Description\",\"Category\"])\n",
    "    print(f\"WARNING: variable dictionary not found at {vars_path}. Continuing without it.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6c475cbd",
   "metadata": {},
   "source": [
    "### 2.2 Load raw data (no imputation or transformations)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e907e85a",
   "metadata": {},
   "source": [
    "data_path = Path(CONFIG[\"DATA_PATH\"])\n",
    "df_raw = pd.read_csv(data_path, low_memory=False)\n",
    "print(f\"Loaded data from {data_path} with shape {df_raw.shape}\")\n",
    "\n",
    "display(df_raw.head())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "27300e16",
   "metadata": {},
   "source": [
    "### 2.3 Enforce panel identifiers, types, sorting, and deduplication"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbe7fdf3",
   "metadata": {},
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# Stable firm identifier\n",
    "if \"gvkey\" not in df.columns:\n",
    "    raise ValueError(\"Required identifier column `gvkey` not found in the dataset.\")\n",
    "df[\"firm_id\"] = df[\"gvkey\"].astype(str)\n",
    "\n",
    "# Fiscal year\n",
    "if \"fyear\" not in df.columns:\n",
    "    raise ValueError(\"Required time column `fyear` not found in the dataset.\")\n",
    "df[\"fyear\"] = pd.to_numeric(df[\"fyear\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Optional datadate parsing (kept as metadata; not used for splitting)\n",
    "if \"datadate\" in df.columns:\n",
    "    df[\"datadate\"] = pd.to_datetime(df[\"datadate\"], errors=\"coerce\")\n",
    "\n",
    "# Remove firm-year duplicates (keep-last rule, audit count)\n",
    "pre_n = len(df)\n",
    "dup_mask = df.duplicated(subset=[\"firm_id\",\"fyear\"], keep=False)\n",
    "n_dups = int(dup_mask.sum())\n",
    "if n_dups > 0:\n",
    "    print(f\"Found {n_dups} duplicated firm-year rows. Applying keep-last rule.\")\n",
    "    df = df.sort_values([\"firm_id\",\"fyear\",\"datadate\"] if \"datadate\" in df.columns else [\"firm_id\",\"fyear\"])\n",
    "    df = df.drop_duplicates(subset=[\"firm_id\",\"fyear\"], keep=\"last\")\n",
    "post_n = len(df)\n",
    "\n",
    "# Enforce sort order for lag/lead safety\n",
    "df = df.sort_values([\"firm_id\",\"fyear\"]).reset_index(drop=True)\n",
    "\n",
    "# Integrity checks\n",
    "assert df[[\"firm_id\",\"fyear\"]].isna().sum().sum() == 0, \"Missing firm_id or fyear after typing.\"\n",
    "assert df.duplicated(subset=[\"firm_id\",\"fyear\"]).sum() == 0, \"Duplicate firm-year keys remain after dedup.\"\n",
    "\n",
    "print(f\"Rows: {pre_n:,} -> {post_n:,} after deduplication.\")\n",
    "print(\"Unique firms:\", df[\"firm_id\"].nunique())\n",
    "print(\"Year range:\", int(df[\"fyear\"].min()), \"to\", int(df[\"fyear\"].max()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "990db334",
   "metadata": {},
   "source": [
    "### 2.4 Raw sample composition (no transformations)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0e2e3c5",
   "metadata": {},
   "source": [
    "# Minimal sample composition diagnostics (kept lightweight for large panels)\n",
    "\n",
    "by_year = df.groupby(\"fyear\").agg(\n",
    "    n_obs=(\"firm_id\",\"size\"),\n",
    "    n_firms=(\"firm_id\",\"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "display(by_year.tail(12))\n",
    "\n",
    "# Optional: industry composition if SIC exists\n",
    "if \"sic\" in df.columns:\n",
    "    df[\"sic2\"] = pd.to_numeric(df[\"sic\"], errors=\"coerce\").astype(\"Int64\") // 100\n",
    "    by_sic2 = df.groupby(\"sic2\").size().sort_values(ascending=False).head(15).rename(\"n_obs\").reset_index()\n",
    "    display(by_sic2)\n",
    "else:\n",
    "    print(\"Note: `sic` not present; skipping industry composition.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dbd16501",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Missingness Handling (leakage-aware)\n",
    "\n",
    "### 3.1 Non-imputable identifiers and label-year setup\n",
    "\n",
    "We drop observations missing non-imputable identifiers (firm, year).  \n",
    "We also define `label_year = fyear + 1` as the *outcome year* used for forecasting splits."
   ]
  },
  {
   "cell_type": "code",
   "id": "31e1404a",
   "metadata": {},
   "source": [
    "# Drop rows with missing key identifiers (already asserted, but keep explicit)\n",
    "df = df.dropna(subset=[\"firm_id\",\"fyear\"]).copy()\n",
    "\n",
    "# label_year defines the year of the t+1 distress label\n",
    "df[\"label_year\"] = (df[\"fyear\"] + 1).astype(\"Int64\")\n",
    "\n",
    "# Remove excluded variables from dataframe before split (global removal)\n",
    "EXCLUDED_VARS = [\n",
    "    \"aco_act\", \"aqc_at\", \"caps_at\", \"capx_at\", \"dp_at\",\n",
    "    \"invch_act\", \"lco_lct\", \"mibt_at\", \"recch_act\",\n",
    "    \"txditc_at\", \"txp_lct\", \"xint_lct\"\n",
    "]\n",
    "df = df.drop(columns=EXCLUDED_VARS, errors=\"ignore\")\n",
    "print(f\"Dropped excluded variables: {EXCLUDED_VARS}\")\n",
    "\n",
    "# Split masks (defined early; used for leakage-safe preprocessing throughout)\n",
    "train_pool_mask = df[\"label_year\"] <= CONFIG[\"TRAIN_CUTOFF_LABEL_YEAR\"]\n",
    "train_pool_years = sorted(df.loc[train_pool_mask, \"label_year\"].dropna().unique().tolist())\n",
    "if len(train_pool_years) < (CONFIG[\"VAL_YEARS\"] + 1):\n",
    "    raise ValueError(\"Not enough label years in train pool to allocate validation years. Adjust TRAIN_CUTOFF_LABEL_YEAR or VAL_YEARS.\")\n",
    "\n",
    "val_years = train_pool_years[-CONFIG[\"VAL_YEARS\"]:]\n",
    "val_mask = df[\"label_year\"].isin(val_years)\n",
    "train_mask = train_pool_mask & (~val_mask)\n",
    "test_mask = df[\"label_year\"] > CONFIG[\"TRAIN_CUTOFF_LABEL_YEAR\"]\n",
    "\n",
    "df[\"split\"] = np.where(test_mask, \"test\", np.where(val_mask, \"val\", \"train\"))\n",
    "\n",
    "print(\"Split counts:\")\n",
    "display(df[\"split\"].value_counts(dropna=False).to_frame(\"n_obs\"))\n",
    "print(\"Validation label_year(s):\", val_years)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "caf030bc",
   "metadata": {},
   "source": [
    "### 3.2 Missingness audit before intervention"
   ]
  },
  {
   "cell_type": "code",
   "id": "f2941f55",
   "metadata": {},
   "source": [
    "# Identify numeric columns eligible for imputation (exclude identifiers)\n",
    "id_cols = {\"gvkey\",\"firm_id\",\"fyear\",\"label_year\",\"datadate\",\"split\"}\n",
    "numeric_cols = [c for c in df.columns if c not in id_cols and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "missing_tbl = (df[numeric_cols].isna().mean().sort_values(ascending=False) * 100).rename(\"missing_%\").to_frame()\n",
    "missing_tbl[\"n_missing\"] = df[numeric_cols].isna().sum().astype(int)\n",
    "missing_tbl[\"dtype\"] = [str(df[c].dtype) for c in missing_tbl.index]\n",
    "\n",
    "display(missing_tbl.head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "314eca9a",
   "metadata": {},
   "source": [
    "### 3.3 Create missingness indicators (informative signals)"
   ]
  },
  {
   "cell_type": "code",
   "id": "caf47442",
   "metadata": {},
   "source": [
    "# Choose a focused set of inputs used for core ratios/events.\n",
    "REQUIRED_RAW = [\n",
    "    \"at\",\"dlc\",\"dltt\",\"seq\",\"mibt\",\"niadj\",\n",
    "    \"oibdp\",\"oancf\",\"xint\",\n",
    "    \"act\",\"lct\",\"che\",\"rect\",\"invt\",\n",
    "    # dividend-related (we will auto-detect among these later)\n",
    "    \"dv\",\"dvc\",\"dvt\",\"dvp\",\n",
    "]\n",
    "available_required = [c for c in REQUIRED_RAW if c in df.columns]\n",
    "\n",
    "# Hard requirement for the distress proxy; fail if absent (unless synthetic mode)\n",
    "HARD_REQUIRED = [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"niadj\",\"oancf\"]\n",
    "missing_hard = [c for c in HARD_REQUIRED if c not in df.columns]\n",
    "if missing_hard and not USING_SYNTHETIC_DATA:\n",
    "    raise ValueError(f\"Missing required columns for distress proxy construction: {missing_hard}\")\n",
    "\n",
    "for c in available_required:\n",
    "    df[f\"fmiss_{c}\"] = df[c].isna().astype(\"Int8\")\n",
    "\n",
    "print(\"Created missingness flags for:\", available_required)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1862160b",
   "metadata": {},
   "source": [
    "### 3.4 Training-derived size deciles (used for peer imputation groups)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7933cb0a",
   "metadata": {},
   "source": [
    "# Size is based on log(assets) from TRAIN only, to avoid leakage.\n",
    "at_train = pd.to_numeric(df.loc[train_mask, \"at\"], errors=\"coerce\")\n",
    "log_at_train = np.log(at_train.where(at_train > 0)).dropna()\n",
    "\n",
    "if len(log_at_train) < 50:\n",
    "    print(\"WARNING: too few non-missing training `at` values for stable size deciles. Using a single size bin.\")\n",
    "    df[\"size_decile\"] = 5  # arbitrary mid-bin\n",
    "    size_edges = None\n",
    "else:\n",
    "    # Use quantile cutpoints computed on training only\n",
    "    qs = np.linspace(0, 1, 11)\n",
    "    size_edges = log_at_train.quantile(qs).values\n",
    "    size_edges[0] = -np.inf\n",
    "    size_edges[-1] = np.inf\n",
    "\n",
    "    log_at_all = np.log(pd.to_numeric(df[\"at\"], errors=\"coerce\").where(lambda s: s > 0))\n",
    "    df[\"size_decile\"] = pd.cut(log_at_all, bins=size_edges, labels=False, include_lowest=True).astype(\"Float64\")\n",
    "\n",
    "# Fill NA size_decile with training median decile for downstream stability\n",
    "sd_med = float(pd.to_numeric(df.loc[train_mask, \"size_decile\"], errors=\"coerce\").median())\n",
    "df[\"size_decile\"] = pd.to_numeric(df[\"size_decile\"], errors=\"coerce\").fillna(sd_med).astype(int)\n",
    "\n",
    "print(\"Size decile distribution (train):\")\n",
    "display(df.loc[train_mask, \"size_decile\"].value_counts().sort_index().to_frame(\"n_obs\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4be186dd4fa5a9a9",
   "metadata": {},
   "source": [
    "### 3.5 Imputation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "id": "da85e3d73736a4b6",
   "metadata": {},
   "source": [
    "# Snapshot before any imputation\n",
    "df_pre_impute_snapshot = df.copy(deep=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6bdf404d9e0d89b",
   "metadata": {},
   "source": [
    "### 3.5.1 KNN imputation on core structural items (train-fit; signed-log transform)\n",
    "\n",
    "We use KNN for core balance sheet and income statement aggregates. These variables have strong multivariate dependencies (e.g., Total Assets ≈ Total Liabilities + Equity). KNN captures these relationships, allowing the imputation to respect the specific \"profile\" of a company.\n",
    "### 3.5.2 KNN Parameter Selection Audit\n",
    "\n",
    "We evaluate the reconstruction quality for different values of $K$ to justify the choice of `KNN_K=25`. We use a subset of fully observed training data and artificially introduce missingness to measure RMSE."
   ]
  },
  {
   "cell_type": "code",
   "id": "6e6db926a02307a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T12:58:02.963921Z",
     "start_time": "2026-01-15T12:57:28.008624Z"
    }
   },
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "# pyampute (audit missingness generation)\n",
    "try:\n",
    "    from pyampute.ampute import MultivariateAmputation\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"pyampute is required for the KNN audit. Install via: pip install pyampute\\n\"\n",
    "        f\"Import error: {e}\"\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Core structural variables for KNN (NO fyear / size_decile)\n",
    "# ---------------------------------------------------------------------\n",
    "knn_cols = [\n",
    "    \"at\", \"act\", \"lct\", \"che\", \"rect\", \"invt\", \"dlc\", \"dltt\",\n",
    "    \"seq\", \"ceq\", \"lt\", \"ppent\", \"intan\", \"oibdp\", \"niadj\",\n",
    "    \"oancf\", \"xint\", \"dp\", \"re\", \"capx\"\n",
    "]\n",
    "knn_cols = [c for c in knn_cols if c in df.columns]\n",
    "\n",
    "def signed_log1p(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "def inverse_signed_log1p(z):\n",
    "    z = pd.to_numeric(z, errors=\"coerce\")\n",
    "    return np.sign(z) * (np.expm1(np.abs(z)))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# pyampute-based audit: NRMSE on forced-missing cells (TRAIN only)\n",
    "# ---------------------------------------------------------------------\n",
    "def knn_audit_pyampute_train_only(\n",
    "    Z_train: pd.DataFrame,\n",
    "    knn_cols: list,\n",
    "    k_list=(5, 10, 25, 50, 100),\n",
    "    prop_rows_incomplete=0.50,\n",
    "    row_subsample=2000,\n",
    "    seed=42\n",
    "):\n",
    "    # complete TRAIN rows only (pyampute requirement)\n",
    "    Zc = Z_train.copy().apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "    if len(Zc) < 200:\n",
    "        print(f\"[KNN audit] Not enough complete TRAIN rows: n={len(Zc)}\")\n",
    "        return None\n",
    "\n",
    "    if len(Zc) > row_subsample:\n",
    "        Zc = Zc.sample(n=row_subsample, random_state=seed)\n",
    "\n",
    "    std = Zc[knn_cols].std(ddof=0).replace(0, np.nan)\n",
    "\n",
    "    # KEY FIX: one-variable patterns (so rows are not fully missing)\n",
    "    patterns = [\n",
    "        {\"incomplete_vars\": [c], \"mechanism\": \"MCAR\", \"freq\": 1.0/len(knn_cols)}\n",
    "        for c in knn_cols\n",
    "    ]\n",
    "\n",
    "    ma = MultivariateAmputation(\n",
    "        prop=float(prop_rows_incomplete),\n",
    "        patterns=patterns,\n",
    "        std=False,\n",
    "        seed=int(seed),\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    Za = ma.fit_transform(Zc)\n",
    "    Za = pd.DataFrame(Za, columns=Zc.columns, index=Zc.index)\n",
    "\n",
    "    introduced = Za[knn_cols].isna() & Zc[knn_cols].notna()\n",
    "    n_amputed = int(introduced.values.sum())\n",
    "    if n_amputed == 0:\n",
    "        print(\"[KNN audit] No cells amputated; increase prop_rows_incomplete.\")\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "    for k in k_list:\n",
    "        imp = KNNImputer(n_neighbors=int(k), weights=\"distance\")\n",
    "        imp.fit(Zc)\n",
    "        Zimp = pd.DataFrame(imp.transform(Za), columns=Za.columns, index=Za.index)\n",
    "\n",
    "        per = {}\n",
    "        sqerrs = []\n",
    "        var_w = []\n",
    "        cnt = 0\n",
    "\n",
    "        for c in knn_cols:\n",
    "            m = introduced[c].values\n",
    "            if m.sum() == 0 or pd.isna(std[c]) or std[c] <= 0:\n",
    "                continue\n",
    "            y_true = Zc[c].values[m]\n",
    "            y_pred = Zimp[c].values[m]\n",
    "            rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "            nrmse = float(rmse / std[c])\n",
    "            per[f\"NRMSE_{c}\"] = nrmse\n",
    "\n",
    "            sqerrs.append((y_true - y_pred) ** 2)\n",
    "            var_w.append((std[c] ** 2) * m.sum())\n",
    "            cnt += int(m.sum())\n",
    "\n",
    "        pooled_nrmse = np.nan\n",
    "        if cnt > 0 and sqerrs:\n",
    "            pooled_mse = float(np.mean(np.concatenate(sqerrs)))\n",
    "            pooled_rmse = float(np.sqrt(pooled_mse))\n",
    "            pooled_std = float(np.sqrt(np.sum(var_w) / cnt))\n",
    "            pooled_nrmse = float(pooled_rmse / pooled_std) if pooled_std > 0 else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"K\": int(k),\n",
    "            \"amputated_cells\": n_amputed,\n",
    "            \"pooled_NRMSE\": pooled_nrmse,\n",
    "            **per\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"K\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main: build Z (ONLY knn_cols), run audit (TRAIN only), then impute df\n",
    "# ---------------------------------------------------------------------\n",
    "if len(knn_cols) >= 3:\n",
    "    # Build Z (NO fyear / size_decile)\n",
    "    Z = df[knn_cols].copy()\n",
    "\n",
    "    # Transform magnitudes for distance stability\n",
    "    for c in knn_cols:\n",
    "        Z[c] = signed_log1p(Z[c])\n",
    "\n",
    "    # ---- pyampute audit (TRAIN only) ----\n",
    "    print(\"Auditing KNN imputation via pyampute (TRAIN only, forced-missing cells, NRMSE)...\")\n",
    "    k_options = [5, 10, 25, 50, 100]\n",
    "    audit_tbl = knn_audit_pyampute_train_only(\n",
    "        Z_train=Z.loc[train_mask, :],\n",
    "        knn_cols=knn_cols,\n",
    "        k_list=k_options,\n",
    "        row_subsample=2000,\n",
    "        seed=SEED if \"SEED\" in globals() else 42\n",
    "    )\n",
    "    if audit_tbl is not None:\n",
    "        display(audit_tbl)\n",
    "\n",
    "    # ---- Production imputation (train-fit) ----\n",
    "    imputer = KNNImputer(n_neighbors=CONFIG[\"KNN_K\"], weights=\"distance\")\n",
    "    imputer.fit(Z.loc[train_mask, :])\n",
    "\n",
    "    Z_imp = pd.DataFrame(imputer.transform(Z), columns=Z.columns, index=Z.index)\n",
    "\n",
    "    # Invert signed-log transform back for magnitudes and write into df\n",
    "    for c in knn_cols:\n",
    "        df[c] = inverse_signed_log1p(Z_imp[c])\n",
    "\n",
    "else:\n",
    "    print(\"Skipping KNN imputation: insufficient columns available.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 13:57:28,106 [WARNING] Failed to load lookup table for a prespecified score to probability function. It is possible data/shift_lookup.csv is missing, in the wrong location, or corrupted. Try rerunning scripts/generate_shift_lookup_table.py to regenerate the lookup table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auditing KNN imputation via pyampute (TRAIN only, forced-missing cells, NRMSE)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     K  amputated_cells  pooled_NRMSE      NRMSE_at     NRMSE_act  \\\n",
       "0    5              944  1.207035e-07  7.007066e-08  1.480826e-07   \n",
       "1   10              944  2.250771e-07  1.334529e-07  2.457306e-07   \n",
       "2   25              944  5.160216e-07  3.084376e-07  5.200988e-07   \n",
       "3   50              944  9.425254e-07  5.569693e-07  9.483978e-07   \n",
       "4  100              944  1.714867e-06  1.066645e-06  1.781404e-06   \n",
       "\n",
       "      NRMSE_lct     NRMSE_che    NRMSE_rect    NRMSE_invt     NRMSE_dlc  ...  \\\n",
       "0  1.406538e-07  4.542721e-07  1.457547e-07  1.706392e-07  9.026118e-08  ...   \n",
       "1  2.643682e-07  7.221956e-07  2.486175e-07  3.260323e-07  1.942205e-07  ...   \n",
       "2  6.225754e-07  1.435830e-06  5.326652e-07  7.195006e-07  4.451796e-07  ...   \n",
       "3  1.144297e-06  2.315298e-06  9.369103e-07  1.289121e-06  8.539351e-07  ...   \n",
       "4  2.112260e-06  3.603554e-06  1.656242e-06  2.330688e-06  1.617243e-06  ...   \n",
       "\n",
       "       NRMSE_lt   NRMSE_ppent   NRMSE_intan   NRMSE_oibdp   NRMSE_niadj  \\\n",
       "0  9.245894e-08  1.015310e-07  1.335480e-07  7.273422e-08  9.102323e-08   \n",
       "1  1.883268e-07  2.048680e-07  2.495337e-07  1.360155e-07  1.950973e-07   \n",
       "2  4.596244e-07  4.325985e-07  5.990090e-07  3.421695e-07  4.645668e-07   \n",
       "3  8.660616e-07  7.685585e-07  1.111734e-06  6.317788e-07  9.337970e-07   \n",
       "4  1.687262e-06  1.477766e-06  2.052450e-06  1.136871e-06  1.708383e-06   \n",
       "\n",
       "    NRMSE_oancf    NRMSE_xint      NRMSE_dp      NRMSE_re    NRMSE_capx  \n",
       "0  1.239416e-07  1.280428e-07  7.742707e-08  1.177202e-07  8.412832e-08  \n",
       "1  2.577585e-07  2.501765e-07  1.576672e-07  2.247726e-07  1.404975e-07  \n",
       "2  6.580518e-07  5.455789e-07  3.802396e-07  5.273627e-07  2.409636e-07  \n",
       "3  1.242691e-06  9.001676e-07  6.987450e-07  9.533459e-07  4.891670e-07  \n",
       "4  2.250079e-06  1.653501e-06  1.378933e-06  1.803477e-06  9.294310e-07  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>amputated_cells</th>\n",
       "      <th>pooled_NRMSE</th>\n",
       "      <th>NRMSE_at</th>\n",
       "      <th>NRMSE_act</th>\n",
       "      <th>NRMSE_lct</th>\n",
       "      <th>NRMSE_che</th>\n",
       "      <th>NRMSE_rect</th>\n",
       "      <th>NRMSE_invt</th>\n",
       "      <th>NRMSE_dlc</th>\n",
       "      <th>...</th>\n",
       "      <th>NRMSE_lt</th>\n",
       "      <th>NRMSE_ppent</th>\n",
       "      <th>NRMSE_intan</th>\n",
       "      <th>NRMSE_oibdp</th>\n",
       "      <th>NRMSE_niadj</th>\n",
       "      <th>NRMSE_oancf</th>\n",
       "      <th>NRMSE_xint</th>\n",
       "      <th>NRMSE_dp</th>\n",
       "      <th>NRMSE_re</th>\n",
       "      <th>NRMSE_capx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>944</td>\n",
       "      <td>1.207035e-07</td>\n",
       "      <td>7.007066e-08</td>\n",
       "      <td>1.480826e-07</td>\n",
       "      <td>1.406538e-07</td>\n",
       "      <td>4.542721e-07</td>\n",
       "      <td>1.457547e-07</td>\n",
       "      <td>1.706392e-07</td>\n",
       "      <td>9.026118e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.245894e-08</td>\n",
       "      <td>1.015310e-07</td>\n",
       "      <td>1.335480e-07</td>\n",
       "      <td>7.273422e-08</td>\n",
       "      <td>9.102323e-08</td>\n",
       "      <td>1.239416e-07</td>\n",
       "      <td>1.280428e-07</td>\n",
       "      <td>7.742707e-08</td>\n",
       "      <td>1.177202e-07</td>\n",
       "      <td>8.412832e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>944</td>\n",
       "      <td>2.250771e-07</td>\n",
       "      <td>1.334529e-07</td>\n",
       "      <td>2.457306e-07</td>\n",
       "      <td>2.643682e-07</td>\n",
       "      <td>7.221956e-07</td>\n",
       "      <td>2.486175e-07</td>\n",
       "      <td>3.260323e-07</td>\n",
       "      <td>1.942205e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.883268e-07</td>\n",
       "      <td>2.048680e-07</td>\n",
       "      <td>2.495337e-07</td>\n",
       "      <td>1.360155e-07</td>\n",
       "      <td>1.950973e-07</td>\n",
       "      <td>2.577585e-07</td>\n",
       "      <td>2.501765e-07</td>\n",
       "      <td>1.576672e-07</td>\n",
       "      <td>2.247726e-07</td>\n",
       "      <td>1.404975e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>944</td>\n",
       "      <td>5.160216e-07</td>\n",
       "      <td>3.084376e-07</td>\n",
       "      <td>5.200988e-07</td>\n",
       "      <td>6.225754e-07</td>\n",
       "      <td>1.435830e-06</td>\n",
       "      <td>5.326652e-07</td>\n",
       "      <td>7.195006e-07</td>\n",
       "      <td>4.451796e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.596244e-07</td>\n",
       "      <td>4.325985e-07</td>\n",
       "      <td>5.990090e-07</td>\n",
       "      <td>3.421695e-07</td>\n",
       "      <td>4.645668e-07</td>\n",
       "      <td>6.580518e-07</td>\n",
       "      <td>5.455789e-07</td>\n",
       "      <td>3.802396e-07</td>\n",
       "      <td>5.273627e-07</td>\n",
       "      <td>2.409636e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>944</td>\n",
       "      <td>9.425254e-07</td>\n",
       "      <td>5.569693e-07</td>\n",
       "      <td>9.483978e-07</td>\n",
       "      <td>1.144297e-06</td>\n",
       "      <td>2.315298e-06</td>\n",
       "      <td>9.369103e-07</td>\n",
       "      <td>1.289121e-06</td>\n",
       "      <td>8.539351e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660616e-07</td>\n",
       "      <td>7.685585e-07</td>\n",
       "      <td>1.111734e-06</td>\n",
       "      <td>6.317788e-07</td>\n",
       "      <td>9.337970e-07</td>\n",
       "      <td>1.242691e-06</td>\n",
       "      <td>9.001676e-07</td>\n",
       "      <td>6.987450e-07</td>\n",
       "      <td>9.533459e-07</td>\n",
       "      <td>4.891670e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>944</td>\n",
       "      <td>1.714867e-06</td>\n",
       "      <td>1.066645e-06</td>\n",
       "      <td>1.781404e-06</td>\n",
       "      <td>2.112260e-06</td>\n",
       "      <td>3.603554e-06</td>\n",
       "      <td>1.656242e-06</td>\n",
       "      <td>2.330688e-06</td>\n",
       "      <td>1.617243e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.687262e-06</td>\n",
       "      <td>1.477766e-06</td>\n",
       "      <td>2.052450e-06</td>\n",
       "      <td>1.136871e-06</td>\n",
       "      <td>1.708383e-06</td>\n",
       "      <td>2.250079e-06</td>\n",
       "      <td>1.653501e-06</td>\n",
       "      <td>1.378933e-06</td>\n",
       "      <td>1.803477e-06</td>\n",
       "      <td>9.294310e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[76]\u001B[39m\u001B[32m, line 146\u001B[39m\n\u001B[32m    143\u001B[39m imputer = KNNImputer(n_neighbors=CONFIG[\u001B[33m\"\u001B[39m\u001B[33mKNN_K\u001B[39m\u001B[33m\"\u001B[39m], weights=\u001B[33m\"\u001B[39m\u001B[33mdistance\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    144\u001B[39m imputer.fit(Z.loc[train_mask, :])\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m Z_imp = pd.DataFrame(imputer.transform(Z), columns=Z.columns, index=Z.index)\n\u001B[32m    148\u001B[39m \u001B[38;5;66;03m# Invert signed-log transform back for magnitudes and write into df\u001B[39;00m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m knn_cols:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m     data_to_wrap = f(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs)\n\u001B[32m    317\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    318\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    319\u001B[39m         return_tuple = (\n\u001B[32m    320\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    321\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    322\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/impute/_knn.py:376\u001B[39m, in \u001B[36mKNNImputer.transform\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    367\u001B[39m \u001B[38;5;66;03m# process in fixed-memory chunks\u001B[39;00m\n\u001B[32m    368\u001B[39m gen = pairwise_distances_chunked(\n\u001B[32m    369\u001B[39m     X[row_missing_idx, :],\n\u001B[32m    370\u001B[39m     \u001B[38;5;28mself\u001B[39m._fit_X,\n\u001B[32m   (...)\u001B[39m\u001B[32m    374\u001B[39m     reduce_func=process_chunk,\n\u001B[32m    375\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m376\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m gen:\n\u001B[32m    377\u001B[39m     \u001B[38;5;66;03m# process_chunk modifies X in place. No return value.\u001B[39;00m\n\u001B[32m    378\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    380\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.keep_empty_features:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:2240\u001B[39m, in \u001B[36mpairwise_distances_chunked\u001B[39m\u001B[34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001B[39m\n\u001B[32m   2238\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2239\u001B[39m     X_chunk = X[sl]\n\u001B[32m-> \u001B[39m\u001B[32m2240\u001B[39m D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)\n\u001B[32m   2241\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (X \u001B[38;5;129;01mis\u001B[39;00m Y \u001B[38;5;129;01mor\u001B[39;00m Y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001B[32m   2242\u001B[39m     metric, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2243\u001B[39m ) \u001B[38;5;129;01mis\u001B[39;00m euclidean_distances:\n\u001B[32m   2244\u001B[39m     \u001B[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001B[39;00m\n\u001B[32m   2245\u001B[39m     \u001B[38;5;66;03m# i.e. \"l2\"\u001B[39;00m\n\u001B[32m   2246\u001B[39m     D_chunk.flat[sl.start :: _num_samples(X) + \u001B[32m1\u001B[39m] = \u001B[32m0\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:2476\u001B[39m, in \u001B[36mpairwise_distances\u001B[39m\u001B[34m(X, Y, metric, n_jobs, force_all_finite, ensure_all_finite, **kwds)\u001B[39m\n\u001B[32m   2473\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m distance.squareform(distance.pdist(X, metric=metric, **kwds))\n\u001B[32m   2474\u001B[39m     func = partial(distance.cdist, metric=metric, **kwds)\n\u001B[32m-> \u001B[39m\u001B[32m2476\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:1960\u001B[39m, in \u001B[36m_parallel_pairwise\u001B[39m\u001B[34m(X, Y, func, n_jobs, **kwds)\u001B[39m\n\u001B[32m   1957\u001B[39m X, Y, dtype = _return_float_dtype(X, Y)\n\u001B[32m   1959\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m effective_n_jobs(n_jobs) == \u001B[32m1\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1960\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m func(X, Y, **kwds)\n\u001B[32m   1962\u001B[39m \u001B[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001B[39;00m\n\u001B[32m   1963\u001B[39m fd = delayed(_dist_wrapper)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:191\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    189\u001B[39m global_skip_validation = get_config()[\u001B[33m\"\u001B[39m\u001B[33mskip_parameter_validation\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    190\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[32m--> \u001B[39m\u001B[32m191\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    193\u001B[39m func_sig = signature(func)\n\u001B[32m    195\u001B[39m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:558\u001B[39m, in \u001B[36mnan_euclidean_distances\u001B[39m\u001B[34m(X, Y, squared, missing_values, copy)\u001B[39m\n\u001B[32m    556\u001B[39m YY = Y * Y\n\u001B[32m    557\u001B[39m distances -= np.dot(XX, missing_Y.T)\n\u001B[32m--> \u001B[39m\u001B[32m558\u001B[39m distances -= np.dot(missing_X, YY.T)\n\u001B[32m    560\u001B[39m np.clip(distances, \u001B[32m0\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m, out=distances)\n\u001B[32m    562\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m Y:\n\u001B[32m    563\u001B[39m     \u001B[38;5;66;03m# Ensure that distances between vectors and themselves are set to 0.0.\u001B[39;00m\n\u001B[32m    564\u001B[39m     \u001B[38;5;66;03m# This may not be the case due to floating point rounding errors.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/multiarray.py:761\u001B[39m, in \u001B[36mdot\u001B[39m\u001B[34m(a, b, out)\u001B[39m\n\u001B[32m    692\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    693\u001B[39m \u001B[33;03m    result_type(*arrays_and_dtypes)\u001B[39;00m\n\u001B[32m    694\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    756\u001B[39m \n\u001B[32m    757\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    758\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m arrays_and_dtypes\n\u001B[32m--> \u001B[39m\u001B[32m761\u001B[39m \u001B[38;5;129m@array_function_from_c_func_and_dispatcher\u001B[39m(_multiarray_umath.dot)\n\u001B[32m    762\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdot\u001B[39m(a, b, out=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    763\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    764\u001B[39m \u001B[33;03m    dot(a, b, out=None)\u001B[39;00m\n\u001B[32m    765\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    851\u001B[39m \n\u001B[32m    852\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    853\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, b, out)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "id": "79965ecc92898ccd",
   "metadata": {},
   "source": [
    "### 3.6 Train-only peer-median imputation (fyear × size_decile)\n",
    "\n",
    "We use year-size median imputation for secondary items, \"other\" categories, and sparse flow variables (e.g., dividends, acquisitions). These variables are often missing, zero, or highly idiosyncratic. Using a multivariate model like KNN on them might introduce noise or over-impute non-zero values for sparse events. A year-size median provides a robust \"typical\" value for companies of similar scale in the same year, which is a safer conservative estimate for these items."
   ]
  },
  {
   "cell_type": "code",
   "id": "fd7f2bcc553da3f4",
   "metadata": {},
   "source": [
    "# Secondary/incidental variables for Peer Median\n",
    "# Removed raw variables that create excluded ratios: aco, lco, recch, invch, txp, txditc, caps, mibt, aqc\n",
    "peer_impute_candidates = [\n",
    "    \"prstkc\",\n",
    "    \"dv\", \"dvc\", \"dvt\", \"dvp\"\n",
    "]\n",
    "peer_impute_cols = [c for c in peer_impute_candidates if c in df.columns]\n",
    "\n",
    "group_cols = [\"fyear\",\"size_decile\"]\n",
    "\n",
    "def peer_median_impute(df_in: pd.DataFrame, cols: list[str], train_mask: pd.Series, group_cols: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Impute NaNs using TRAIN-only medians by group_cols, with TRAIN (size_decile) then global median fallback.\"\"\"\n",
    "    df_out = df_in.copy()\n",
    "    train = df_out.loc[train_mask, group_cols + cols].copy()\n",
    "    group_meds = train.groupby(group_cols)[cols].median()\n",
    "    global_meds = train[cols].median()\n",
    "\n",
    "    # Intermediate fallback for unseen (fyear, size_decile): use TRAIN size_decile medians\n",
    "    size_meds = train.groupby([\"size_decile\"])[cols].median()\n",
    "    tmp_size = df_out[[\"size_decile\"]].merge(size_meds.reset_index(), on=\"size_decile\", how=\"left\")\n",
    "\n",
    "    # Join group medians (wide) to all rows\n",
    "    tmp = df_out[group_cols].merge(group_meds.reset_index(), on=group_cols, how=\"left\", suffixes=(\"\", \"_peer\"))\n",
    "    # tmp currently contains the group median columns with original names\n",
    "    for c in cols:\n",
    "        peer_med = tmp[c]\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), peer_med)\n",
    "        size_med = tmp_size[c]\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), size_med)\n",
    "        df_out[c] = df_out[c].where(df_out[c].notna(), global_meds[c])\n",
    "    impact = pd.DataFrame({\n",
    "        \"col\": cols,\n",
    "        \"n_imputed\": [int(df_in[c].isna().sum() - df_out[c].isna().sum()) for c in cols],\n",
    "        \"train_global_median\": [float(global_meds[c]) if pd.notna(global_meds[c]) else np.nan for c in cols],\n",
    "    })\n",
    "    return df_out, impact\n",
    "\n",
    "df, peer_impact = peer_median_impute(df, peer_impute_cols, train_mask, group_cols)\n",
    "\n",
    "display(peer_impact.sort_values(\"n_imputed\", ascending=False).head(15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b36405bf9b40affc",
   "metadata": {},
   "source": [
    "### 3.7 Guardrail capping of imputed magnitudes (train quantile bands)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6c81343",
   "metadata": {},
   "source": [
    "# Apply capping to all columns that underwent imputation (KNN and Peer Median)\n",
    "cap_cols = list(set(knn_cols + peer_impute_cols))\n",
    "bounds = {}\n",
    "\n",
    "for c in cap_cols:\n",
    "    lo, hi = winsorize_train_bounds(df_pre_impute_snapshot.loc[train_mask, c], CONFIG[\"IMPUTE_LO_Q\"], CONFIG[\"IMPUTE_HI_Q\"])\n",
    "    bounds[c] = {\"lo\": lo, \"hi\": hi}\n",
    "    df[c] = apply_bounds(df[c], lo, hi)\n",
    "\n",
    "bounds_df = pd.DataFrame({c: (v[\"lo\"], v[\"hi\"]) for c,v in bounds.items()}, index=[\"lo\",\"hi\"]).T\n",
    "bounds_df.index.name = \"col\"\n",
    "display(bounds_df.head(15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a0d12d1",
   "metadata": {},
   "source": [
    "### 3.8 Imputation impact audit (pre vs post)"
   ]
  },
  {
   "cell_type": "code",
   "id": "779518ce",
   "metadata": {},
   "source": [
    "audit_cols = [c for c in [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"oancf\",\"act\",\"lct\"] if c in df.columns]\n",
    "\n",
    "def dist_summary(x: pd.Series) -> dict:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return {\n",
    "        \"n\": int(x.notna().sum()),\n",
    "        \"mean\": float(x.mean()) if x.notna().any() else np.nan,\n",
    "        \"p50\": float(x.median()) if x.notna().any() else np.nan,\n",
    "        \"p10\": float(x.quantile(0.10)) if x.notna().any() else np.nan,\n",
    "        \"p90\": float(x.quantile(0.90)) if x.notna().any() else np.nan,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "for c in audit_cols:\n",
    "    pre = dist_summary(df_pre_impute_snapshot[c])\n",
    "    post = dist_summary(df[c])\n",
    "    rows.append({\n",
    "        \"col\": c,\n",
    "        \"n_pre\": pre[\"n\"],\n",
    "        \"n_post\": post[\"n\"],\n",
    "        \"mean_pre\": pre[\"mean\"],\n",
    "        \"mean_post\": post[\"mean\"],\n",
    "        \"p50_pre\": pre[\"p50\"],\n",
    "        \"p50_post\": post[\"p50\"],\n",
    "    })\n",
    "impact_tbl = pd.DataFrame(rows).sort_values(\"col\")\n",
    "display(impact_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5cff47ca",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA focuses on **signal strength and data quality**, not exhaustive plotting.  \n",
    "At this stage we describe the imputed-but-not-modeled input space, by split.\n",
    "\n",
    "### 4.1 Summary statistics by split (key magnitudes)"
   ]
  },
  {
   "cell_type": "code",
   "id": "df1d3718",
   "metadata": {},
   "source": [
    "eda_cols = [c for c in [\"at\",\"dlc\",\"dltt\",\"seq\",\"oibdp\",\"oancf\",\"xint\"] if c in df.columns]\n",
    "\n",
    "def split_describe(df_in: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for sp in [\"train\",\"val\",\"test\"]:\n",
    "        d = df_in.loc[df_in[\"split\"]==sp, cols].describe(percentiles=[0.01,0.1,0.5,0.9,0.99]).T\n",
    "        d.insert(0, \"split\", sp)\n",
    "        d.insert(1, \"col\", d.index)\n",
    "        out.append(d.reset_index(drop=True))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "desc_tbl = split_describe(df, eda_cols)\n",
    "display(desc_tbl.head(20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e05b4c3b",
   "metadata": {},
   "source": [
    "### 4.2 Missingness rates by split (key inputs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e8ad60dd",
   "metadata": {},
   "source": [
    "miss_cols = [c for c in available_required if f\"fmiss_{c}\" in df.columns]\n",
    "miss_by_split = (\n",
    "    df.groupby(\"split\")[ [f\"fmiss_{c}\" for c in available_required if f\"fmiss_{c}\" in df.columns] ]\n",
    "      .mean()\n",
    "      .T\n",
    ")\n",
    "miss_by_split.index = [i.replace(\"fmiss_\",\"\") for i in miss_by_split.index]\n",
    "miss_by_split = (miss_by_split * 100).round(2)\n",
    "display(miss_by_split)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aa2a8235",
   "metadata": {},
   "source": [
    "### 4.3 Visual sanity-check plots (train vs test distributions)"
   ]
  },
  {
   "cell_type": "code",
   "id": "41b9931c",
   "metadata": {},
   "source": [
    "# Lightweight plots to spot gross drift / outliers.\n",
    "plot_cols = [c for c in [\"at\",\"dltt\",\"dlc\",\"oibdp\",\"oancf\"] if c in df.columns]\n",
    "\n",
    "for c in plot_cols[:3]:\n",
    "    a = pd.to_numeric(df.loc[df[\"split\"]==\"train\", c], errors=\"coerce\")\n",
    "    b = pd.to_numeric(df.loc[df[\"split\"]==\"test\", c], errors=\"coerce\")\n",
    "    plt.figure()\n",
    "    plt.hist(np.log1p(a.dropna()), bins=60, alpha=0.5, label=\"train\")\n",
    "    plt.hist(np.log1p(b.dropna()), bins=60, alpha=0.5, label=\"test\")\n",
    "    plt.title(f\"log1p({c}) distribution: train vs test\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"eda_log1p_{c}_train_vs_test.png\", dpi=140)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "600ce0bf223cb84",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering & Target Construction\n",
    "\n",
    "This section constructs **all derived features explicitly** from Compustat-style raw items, including:\n",
    "- debt aggregates and leverage ratios,\n",
    "- cash-flow-to-debt ratios,\n",
    "- log size and log market value,\n",
    "- the NA-aware distress proxy and the next-year label.\n",
    "\n",
    "Design choice: ratios with non-positive denominators are treated as **extreme tail states** (encoded via `+∞` then converted to `NaN` before modeling), rather than silently set to zero.\n",
    "\n",
    "### 5.1 Feature list definitions (V1, V2, V3)"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0e137d18843d373",
   "metadata": {},
   "source": [
    "# Variables to exclude from modeling (removed per requirements)\n",
    "EXCLUDED_VARS = [\n",
    "    \"aco_act\", \"aqc_at\", \"caps_at\", \"capx_at\", \"dp_at\", \n",
    "    \"invch_act\", \"lco_lct\", \"mibt_at\", \"recch_act\", \n",
    "    \"txditc_at\", \"txp_lct\", \"xint_lct\"\n",
    "]\n",
    "\n",
    "FEATURES_V1 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \n",
    "    \"rect_act\", \"invt_act\", \n",
    "    \"lt_at\", \"dlc_at\", \"dltt_at\", \n",
    "    \"debt_at\", \"st_debt_share\", \"ebitda_at\", \n",
    "    \"xint_at\", \"interest_coverage\", \"debt_to_ebitda\", \"ebit_to_capital\"\n",
    "]\n",
    "\n",
    "FEATURES_V2 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \n",
    "    \"rect_act\", \"invt_act\", \"ppent_at\", \"intan_at\", \n",
    "    \"lt_at\", \"debt_at\", \"st_debt_share\", \n",
    "    \"ebitda_at\", \"xint_at\", \"interest_coverage\", \"debt_to_ebitda\", \n",
    "    \"ebit_to_capital\", \"ocf_to_debt\", \"fcf_to_debt\",\n",
    "]\n",
    "\n",
    "FEATURES_V3 = [\n",
    "    \"ln_at\", \"cash_at\", \"current_ratio\", \"nwc_at\", \n",
    "    \"rect_act\", \"invt_act\", \n",
    "    \"lt_at\", \"ceq_at\", \"re_at\", \n",
    "    \"niadj_at\", \"loss_indicator\", \n",
    "    \"xint_at\", \"prstkc_at\"\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14e07ab621282e57",
   "metadata": {},
   "source": [
    "### 5.2 Debt, capital, and operating aggregates"
   ]
  },
  {
   "cell_type": "code",
   "id": "3be8ff9f",
   "metadata": {},
   "source": [
    "# Ensure all required raw items are numeric for safe arithmetic\n",
    "raw_items = [\n",
    "    \"at\", \"che\", \"act\", \"lct\", \"aco\", \"lco\", \"rect\", \"invt\", \"recch\", \"invch\",\n",
    "    \"txp\", \"txditc\", \"lt\", \"dlc\", \"dltt\", \"oibdp\", \"dp\", \"xint\", \"ceq\", \"capx\",\n",
    "    \"ppent\", \"intan\", \"oancf\", \"re\", \"caps\", \"mibt\", \"niadj\", \"aqc\", \"prstkc\", \"seq\"\n",
    "]\n",
    "for c in raw_items:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Debt aggregate\n",
    "df[\"total_debt\"] = df[[\"dlc\",\"dltt\"]].sum(axis=1, min_count=1)\n",
    "\n",
    "# Equity plus minority interest (if available)\n",
    "if \"mibt\" in df.columns:\n",
    "    df[\"equity_plus_mi\"] = df[[\"seq\",\"mibt\"]].sum(axis=1, min_count=1)\n",
    "else:\n",
    "    df[\"equity_plus_mi\"] = df[\"seq\"]\n",
    "\n",
    "# Total capital and a non-positive capital flag\n",
    "df[\"total_capital\"] = df[[\"total_debt\",\"equity_plus_mi\"]].sum(axis=1, min_count=1)\n",
    "df[\"cap_nonpos_flag\"] = (df[\"total_capital\"] <= 0).astype(\"Int8\")\n",
    "\n",
    "# EBITDA proxy\n",
    "df[\"ebitda_proxy\"] = df[\"oibdp\"]\n",
    "df[\"ebitda_nonpos_flag\"] = (df[\"ebitda_proxy\"] <= 0).astype(\"Int8\")\n",
    "\n",
    "# Log transforms\n",
    "df[\"ln_at\"] = np.log(df[\"at\"].where(lambda s: s > 0))\n",
    "# Legacy name if needed elsewhere\n",
    "df[\"log_at\"] = df[\"ln_at\"]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8398da80f9dc0939",
   "metadata": {},
   "source": [
    "### 5.3 Leverage, coverage, and cash-flow ratios (V1, V2, V3 features)"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e74c9720be0b0c6",
   "metadata": {},
   "source": [
    "# --- V1/V2/V3 Shared & Specific Features ---\n",
    "# (Using safe_divide which handles division by zero and returns NaN for extreme states)\n",
    "\n",
    "# Basic Ratios\n",
    "df[\"cash_at\"] = safe_divide(df[\"che\"], df[\"at\"])\n",
    "df[\"current_ratio\"] = safe_divide(df[\"act\"], df[\"lct\"])\n",
    "df[\"nwc_at\"] = safe_divide(df[\"act\"] - df[\"lct\"], df[\"at\"])\n",
    "# Removed: aco_act, lco_lct (excluded variables)\n",
    "df[\"rect_act\"] = safe_divide(df[\"rect\"], df[\"act\"])\n",
    "df[\"invt_act\"] = safe_divide(df[\"invt\"], df[\"act\"])\n",
    "# Removed: recch_act, invch_act, txp_lct, txditc_at (excluded variables)\n",
    "df[\"lt_at\"] = safe_divide(df[\"lt\"], df[\"at\"])\n",
    "df[\"dlc_at\"] = safe_divide(df[\"dlc\"], df[\"at\"])\n",
    "df[\"dltt_at\"] = safe_divide(df[\"dltt\"], df[\"at\"])\n",
    "df[\"debt_at\"] = safe_divide(df[\"total_debt\"], df[\"at\"])\n",
    "df[\"st_debt_share\"] = safe_divide(df[\"dlc\"], df[\"total_debt\"])\n",
    "df[\"ebitda_at\"] = safe_divide(df[\"oibdp\"], df[\"at\"])\n",
    "# Removed: dp_at (excluded variable)\n",
    "df[\"xint_at\"] = safe_divide(df[\"xint\"], df[\"at\"])\n",
    "df[\"interest_coverage\"] = safe_divide(df[\"oibdp\"], df[\"xint\"])\n",
    "df[\"debt_to_ebitda\"] = safe_divide(df[\"total_debt\"], df[\"oibdp\"])\n",
    "df[\"ebit_to_capital\"] = safe_divide(df[\"oibdp\"] - df[\"dp\"], df[\"total_debt\"] + df[\"ceq\"])\n",
    "# Removed: capx_at (excluded variable)\n",
    "\n",
    "# V2 extras\n",
    "df[\"ppent_at\"] = safe_divide(df[\"ppent\"], df[\"at\"])\n",
    "df[\"intan_at\"] = safe_divide(df[\"intan\"], df[\"at\"])\n",
    "df[\"ocf_to_debt\"] = safe_divide(df[\"oancf\"], df[\"total_debt\"])\n",
    "df[\"fcf_to_debt\"] = safe_divide(df[\"oancf\"] - df[\"capx\"], df[\"total_debt\"])\n",
    "\n",
    "# V3 extras\n",
    "df[\"ceq_at\"] = safe_divide(df[\"ceq\"], df[\"at\"])\n",
    "# Removed: caps_at, mibt_at (excluded variables)\n",
    "df[\"niadj_at\"] = safe_divide(df[\"niadj\"], df[\"at\"])\n",
    "df[\"loss_indicator\"] = (df[\"niadj\"] < 0).astype(float)\n",
    "# Removed: xint_lct, aqc_at (excluded variables)\n",
    "df[\"prstkc_at\"] = safe_divide(df[\"prstkc\"], df[\"at\"])\n",
    "\n",
    "# --- Legacy mappings for distress proxy definitions (Section 5.4) ---\n",
    "# (Keeping sp_ prefix for variables used in distress proxy definition rules)\n",
    "ffo_proxy = df[\"oancf\"] + df[\"xint\"]\n",
    "if \"txp\" in df.columns:\n",
    "    ffo_proxy = ffo_proxy - df[\"txp\"]\n",
    "df[\"sp_ffo_to_debt\"] = safe_divide(ffo_proxy, df[\"total_debt\"])\n",
    "df[\"sp_debt_to_capital\"] = safe_divide(df[\"total_debt\"], df[\"total_capital\"])\n",
    "df[\"sp_debt_to_ebitda\"] = df[\"debt_to_ebitda\"]\n",
    "df[\"sp_interest_coverage\"] = df[\"interest_coverage\"].clip(lower=-50, upper=50)\n",
    "\n",
    "# Identify remaining +/-inf (though safe_divide already handles most)\n",
    "ratio_cols = [\"sp_debt_to_capital\",\"sp_debt_to_ebitda\",\"sp_ffo_to_debt\",\"sp_interest_coverage\"]\n",
    "for c in ratio_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].replace([np.inf, -np.inf], np.nan)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0fb583df65bc4b4",
   "metadata": {},
   "source": [
    "### 5.4 Multiple Distress Proxies (fiscal year t) and next-year supervised labels (t+1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "374270afcbf5bd23",
   "metadata": {},
   "source": [
    "# Distress proxy thresholds (frozen and documented)\n",
    "DISTRESS_RULE = {\n",
    "    \"FFO_TO_DEBT_LT\": 0.15,\n",
    "    \"DEBT_TO_CAPITAL_GT\": 0.55,\n",
    "    \"DEBT_TO_EBITDA_GT\": 4.5,\n",
    "    \"NEG_EQUITY_SEQ_LE\": 0.0,\n",
    "}\n",
    "\n",
    "# --- Target construction from raw (non-imputed) data ---\n",
    "# We compute distress proxies from the raw snapshot (df_pre_impute_snapshot) \n",
    "# to ensure that target labels are not contaminated by the imputation process.\n",
    "# Imputation is strictly reserved for predictive features.\n",
    "\n",
    "raw_niadj = ensure_nullable_float(df_pre_impute_snapshot[\"niadj\"])\n",
    "raw_oancf = ensure_nullable_float(df_pre_impute_snapshot[\"oancf\"])\n",
    "raw_seq = ensure_nullable_float(df_pre_impute_snapshot[\"seq\"])\n",
    "\n",
    "# S&P components from raw items (propagate missingness - Issue 3)\n",
    "raw_dlc = ensure_nullable_float(df_pre_impute_snapshot[\"dlc\"])\n",
    "raw_dltt = ensure_nullable_float(df_pre_impute_snapshot[\"dltt\"])\n",
    "raw_total_debt = raw_dlc + raw_dltt\n",
    "\n",
    "raw_oibdp = ensure_nullable_float(df_pre_impute_snapshot[\"oibdp\"])\n",
    "raw_xint = ensure_nullable_float(df_pre_impute_snapshot[\"xint\"])\n",
    "raw_txp = ensure_nullable_float(df_pre_impute_snapshot[\"txp\"]) if \"txp\" in df_pre_impute_snapshot.columns else 0\n",
    "\n",
    "raw_ffo = raw_oancf + raw_xint - raw_txp\n",
    "raw_ffo_to_debt = safe_divide(raw_ffo, raw_total_debt)\n",
    "\n",
    "raw_mibt = ensure_nullable_float(df_pre_impute_snapshot[\"mibt\"]) if \"mibt\" in df_pre_impute_snapshot.columns else pd.Series(np.nan, index=df_pre_impute_snapshot.index)\n",
    "raw_equity = ensure_nullable_float(df_pre_impute_snapshot[[\"seq\",\"mibt\"]].sum(axis=1, min_count=1)) if \"mibt\" in df_pre_impute_snapshot.columns else raw_seq\n",
    "raw_total_capital = raw_total_debt + raw_equity\n",
    "\n",
    "raw_debt_to_cap = safe_divide(raw_total_debt, raw_total_capital)\n",
    "raw_debt_to_ebitda = safe_divide(raw_total_debt, raw_oibdp)\n",
    "\n",
    "# V1: Loss + NegCFO (Accounting-based)\n",
    "# Beaver (1966), Ohlson (1980) logic: niadj < 0 and oancf < 0\n",
    "df[\"distress_v1_t\"] = (raw_niadj < 0) & (raw_oancf < 0)\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_niadj.isna() | raw_oancf.isna(), \"distress_v1_t\"] = pd.NA\n",
    "\n",
    "# V2: Negative Equity\n",
    "df[\"distress_v2_t\"] = raw_seq <= DISTRESS_RULE[\"NEG_EQUITY_SEQ_LE\"]\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_seq.isna(), \"distress_v2_t\"] = pd.NA\n",
    "\n",
    "# V3: S&P High Leverage Solely (without conditioning on negative equity)\n",
    "cond_ffo = raw_ffo_to_debt < DISTRESS_RULE[\"FFO_TO_DEBT_LT\"]\n",
    "cond_cap = raw_debt_to_cap > DISTRESS_RULE[\"DEBT_TO_CAPITAL_GT\"]\n",
    "cond_ebitda = raw_debt_to_ebitda > DISTRESS_RULE[\"DEBT_TO_EBITDA_GT\"]\n",
    "df[\"distress_v3_t\"] = cond_ffo & cond_cap & cond_ebitda\n",
    "# Fix: explicitly set to missing if inputs are missing\n",
    "df.loc[raw_ffo_to_debt.isna() | raw_debt_to_cap.isna() | raw_debt_to_ebitda.isna(), \"distress_v3_t\"] = pd.NA\n",
    "\n",
    "# Next-year targets: lead of proxies within firm\n",
    "# Fix: Robust adjacency check (exactly fyear + 1) to avoid mislabeling gaps (Issue 1)\n",
    "next_fyear = df.groupby(\"firm_id\")[\"fyear\"].shift(-1)\n",
    "is_adjacent = (next_fyear == (df[\"fyear\"] + 1))\n",
    "\n",
    "df[\"target_next_v1\"] = df.groupby(\"firm_id\")[\"distress_v1_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v1\"] = pd.NA\n",
    "df[\"target_next_v1\"] = df[\"target_next_v1\"].astype(\"Int8\")\n",
    "\n",
    "df[\"target_next_v2\"] = df.groupby(\"firm_id\")[\"distress_v2_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v2\"] = pd.NA\n",
    "df[\"target_next_v2\"] = df[\"target_next_v2\"].astype(\"Int8\")\n",
    "\n",
    "df[\"target_next_v3\"] = df.groupby(\"firm_id\")[\"distress_v3_t\"].shift(-1)\n",
    "df.loc[~is_adjacent, \"target_next_v3\"] = pd.NA\n",
    "df[\"target_next_v3\"] = df[\"target_next_v3\"].astype(\"Int8\")\n",
    "\n",
    "# Transition targets (early-warning): 1[distress_t==0 AND distress_{t+1}==1]\n",
    "# - Defined only for observations that are *healthy at t* (distress_t==0) and have an adjacent t+1.\n",
    "# - Rows with distress_t==1 are set to NA (they are not part of the early-warning risk set).\n",
    "for _v in [\"v1\", \"v2\", \"v3\"]:\n",
    "    _dcol = f\"distress_{_v}_t\"\n",
    "    _ncol = f\"target_next_{_v}\"\n",
    "    _tcol = f\"target_transition_{_v}\"\n",
    "\n",
    "    _dcur = pd.to_numeric(df[_dcol], errors=\"coerce\")  # {0,1} with NaNs\n",
    "    _ncur = pd.to_numeric(df[_ncol], errors=\"coerce\")\n",
    "\n",
    "    df[_tcol] = pd.NA\n",
    "    _ok = is_adjacent & _dcur.notna() & _ncur.notna()\n",
    "\n",
    "    _healthy = _ok & (_dcur == 0)\n",
    "    df.loc[_healthy, _tcol] = (_ncur.loc[_healthy] == 1).astype(\"Int8\")\n",
    "\n",
    "    df[_tcol] = df[_tcol].astype(\"Int8\")\n",
    "\n",
    "# -------------------------\n",
    "# Modeling objective + proxy selection\n",
    "# -------------------------\n",
    "# PROXY_VERSION: choose among {\"v1\",\"v2\",\"v3\"}.\n",
    "# OBJECTIVE:\n",
    "#   - \"transition\": early-warning (healthy at t -> distressed at t+1)   [recommended for claims of \"early warning\"]\n",
    "#   - \"state\":       surveillance of the t+1 distress state (includes persistence)\n",
    "PROXY_VERSION = \"v2\"\n",
    "OBJECTIVE = \"transition\"\n",
    "\n",
    "PROXY_NAME = f\"distress_{PROXY_VERSION}_t\"\n",
    "STATE_TARGET_NAME = f\"target_next_{PROXY_VERSION}\"\n",
    "TRANS_TARGET_NAME = f\"target_transition_{PROXY_VERSION}\"\n",
    "TARGET_NAME = TRANS_TARGET_NAME if OBJECTIVE.lower().startswith(\"trans\") else STATE_TARGET_NAME\n",
    "\n",
    "# Label availability / attrition (fixed to check adjacency)\n",
    "df[\"has_next_year_obs\"] = is_adjacent.fillna(False).astype(\"Int8\")\n",
    "\n",
    "target_cols = [\"target_next_v1\", \"target_next_v2\", \"target_next_v3\"]\n",
    "print(\"Distress prevalence (by split) — multiple targets:\")\n",
    "display(df.groupby(\"split\")[target_cols].mean())\n",
    "\n",
    "print(\"Share of observations with next-year observation (attrition diagnostic):\")\n",
    "display(df.groupby(\"split\")[\"has_next_year_obs\"].mean().rename(\"has_next_rate\").to_frame())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "76baf30e",
   "metadata": {},
   "source": [
    "### 5.5 Target prevalence and attrition diagnostics (by year and size)"
   ]
  },
  {
   "cell_type": "code",
   "id": "4fa023a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T12:58:06.567295Z",
     "start_time": "2026-01-15T12:58:05.090985Z"
    }
   },
   "source": [
    "# Target prevalence by label year\n",
    "target_cols = [\"target_next_v1\", \"target_next_v2\", \"target_next_v3\"]\n",
    "agg_dict = {\n",
    "    \"n_obs\": (\"firm_id\", \"size\"),\n",
    "    \"has_next_rate\": (\"has_next_year_obs\", \"mean\"),\n",
    "}\n",
    "for c in target_cols:\n",
    "    agg_dict[f\"{c}_rate\"] = (c, \"mean\")\n",
    "\n",
    "by_label_year = df.groupby([\"label_year\",\"split\"]).agg(**agg_dict).reset_index()\n",
    "\n",
    "display(by_label_year.tail(15))\n",
    "\n",
    "# By size decile (train pool), to assess composition effects\n",
    "agg_dict_size = {\"n_obs\": (\"firm_id\", \"size\")}\n",
    "for c in target_cols:\n",
    "    agg_dict_size[f\"{c}_rate\"] = (c, \"mean\")\n",
    "\n",
    "by_size = df.groupby([\"size_decile\",\"split\"]).agg(**agg_dict_size).reset_index()\n",
    "\n",
    "display(by_size.sort_values([\"split\",\"size_decile\"]).head(30))"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['has_next_year_obs', 'target_next_v1', 'target_next_v2', 'target_next_v3'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[77]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m target_cols:\n\u001B[32m      8\u001B[39m     agg_dict[\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_rate\u001B[39m\u001B[33m\"\u001B[39m] = (c, \u001B[33m\"\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m by_label_year = df.groupby([\u001B[33m\"\u001B[39m\u001B[33mlabel_year\u001B[39m\u001B[33m\"\u001B[39m,\u001B[33m\"\u001B[39m\u001B[33msplit\u001B[39m\u001B[33m\"\u001B[39m]).agg(**agg_dict).reset_index()\n\u001B[32m     12\u001B[39m display(by_label_year.tail(\u001B[32m15\u001B[39m))\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# By size decile (train pool), to assess composition effects\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/core/groupby/generic.py:1432\u001B[39m, in \u001B[36mDataFrameGroupBy.aggregate\u001B[39m\u001B[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[39m\n\u001B[32m   1429\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m] = engine_kwargs\n\u001B[32m   1431\u001B[39m op = GroupByApply(\u001B[38;5;28mself\u001B[39m, func, args=args, kwargs=kwargs)\n\u001B[32m-> \u001B[39m\u001B[32m1432\u001B[39m result = op.agg()\n\u001B[32m   1433\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dict_like(func) \u001B[38;5;129;01mand\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1434\u001B[39m     \u001B[38;5;66;03m# GH #52849\u001B[39;00m\n\u001B[32m   1435\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.as_index \u001B[38;5;129;01mand\u001B[39;00m is_list_like(func):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/core/apply.py:190\u001B[39m, in \u001B[36mApply.agg\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.apply_str()\n\u001B[32m    189\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_dict_like(func):\n\u001B[32m--> \u001B[39m\u001B[32m190\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.agg_dict_like()\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(func):\n\u001B[32m    192\u001B[39m     \u001B[38;5;66;03m# we require a list, but not a 'str'\u001B[39;00m\n\u001B[32m    193\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.agg_list_like()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/core/apply.py:423\u001B[39m, in \u001B[36mApply.agg_dict_like\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34magg_dict_like\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> DataFrame | Series:\n\u001B[32m    416\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    417\u001B[39m \u001B[33;03m    Compute aggregation in the case of a dict-like argument.\u001B[39;00m\n\u001B[32m    418\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    421\u001B[39m \u001B[33;03m    Result of aggregation.\u001B[39;00m\n\u001B[32m    422\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m423\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.agg_or_apply_dict_like(op_name=\u001B[33m\"\u001B[39m\u001B[33magg\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/core/apply.py:1603\u001B[39m, in \u001B[36mGroupByApply.agg_or_apply_dict_like\u001B[39m\u001B[34m(self, op_name)\u001B[39m\n\u001B[32m   1598\u001B[39m     kwargs.update({\u001B[33m\"\u001B[39m\u001B[33mengine\u001B[39m\u001B[33m\"\u001B[39m: engine, \u001B[33m\"\u001B[39m\u001B[33mengine_kwargs\u001B[39m\u001B[33m\"\u001B[39m: engine_kwargs})\n\u001B[32m   1600\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m com.temp_setattr(\n\u001B[32m   1601\u001B[39m     obj, \u001B[33m\"\u001B[39m\u001B[33mas_index\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, condition=\u001B[38;5;28mhasattr\u001B[39m(obj, \u001B[33m\"\u001B[39m\u001B[33mas_index\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1602\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1603\u001B[39m     result_index, result_data = \u001B[38;5;28mself\u001B[39m.compute_dict_like(\n\u001B[32m   1604\u001B[39m         op_name, selected_obj, selection, kwargs\n\u001B[32m   1605\u001B[39m     )\n\u001B[32m   1606\u001B[39m result = \u001B[38;5;28mself\u001B[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001B[32m   1607\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/core/apply.py:462\u001B[39m, in \u001B[36mApply.compute_dict_like\u001B[39m\u001B[34m(self, op_name, selected_obj, selection, kwargs)\u001B[39m\n\u001B[32m    460\u001B[39m is_groupby = \u001B[38;5;28misinstance\u001B[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001B[32m    461\u001B[39m func = cast(AggFuncTypeDict, \u001B[38;5;28mself\u001B[39m.func)\n\u001B[32m--> \u001B[39m\u001B[32m462\u001B[39m func = \u001B[38;5;28mself\u001B[39m.normalize_dictlike_arg(op_name, selected_obj, func)\n\u001B[32m    464\u001B[39m is_non_unique_col = (\n\u001B[32m    465\u001B[39m     selected_obj.ndim == \u001B[32m2\u001B[39m\n\u001B[32m    466\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m selected_obj.columns.nunique() < \u001B[38;5;28mlen\u001B[39m(selected_obj.columns)\n\u001B[32m    467\u001B[39m )\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m selected_obj.ndim == \u001B[32m1\u001B[39m:\n\u001B[32m    470\u001B[39m     \u001B[38;5;66;03m# key only used for output\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/py313/lib/python3.13/site-packages/pandas/core/apply.py:663\u001B[39m, in \u001B[36mApply.normalize_dictlike_arg\u001B[39m\u001B[34m(self, how, obj, func)\u001B[39m\n\u001B[32m    661\u001B[39m     cols = Index(\u001B[38;5;28mlist\u001B[39m(func.keys())).difference(obj.columns, sort=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    662\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cols) > \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m663\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mColumn(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(cols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m do not exist\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    665\u001B[39m aggregator_types = (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mdict\u001B[39m)\n\u001B[32m    667\u001B[39m \u001B[38;5;66;03m# if we have a dict of any non-scalars\u001B[39;00m\n\u001B[32m    668\u001B[39m \u001B[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001B[39;00m\n\u001B[32m    669\u001B[39m \u001B[38;5;66;03m# be list-likes\u001B[39;00m\n\u001B[32m    670\u001B[39m \u001B[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001B[39;00m\n",
      "\u001B[31mKeyError\u001B[39m: \"Column(s) ['has_next_year_obs', 'target_next_v1', 'target_next_v2', 'target_next_v3'] do not exist\""
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "id": "8843b675",
   "metadata": {},
   "source": [
    "### 5.6 Event indicators (evt_*) for decision support\n",
    "\n",
    "Events are discrete, interpretable signals designed for operational triage.  \n",
    "They are calibrated **using training data only** (when thresholds are estimated), and we explicitly **exclude** events mechanically tied to the distress-definition ratios (leverage/coverage) from the predictive feature set.\n",
    "\n",
    "Events implemented here (subject to data availability):\n",
    "- Dividend cut / suspension / initiation\n",
    "- Liquidity squeeze (current ratio < 1.0) and quick-ratio squeeze (< 0.8)\n",
    "- EBITDA drop (vs. t-1) and CFO drop (vs. t-1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "973f6172",
   "metadata": {},
   "source": [
    "# Ensure sorting already enforced\n",
    "assert df.index.is_monotonic_increasing\n",
    "\n",
    "# Lag helpers\n",
    "def lag(df_in: pd.DataFrame, col: str, n: int = 1) -> pd.Series:\n",
    "    \"\"\"Robust firm-level lag that enforces year adjacency (Issue 1).\"\"\"\n",
    "    val = df_in.groupby(\"firm_id\")[col].shift(n)\n",
    "    year_lag = df_in.groupby(\"firm_id\")[\"fyear\"].shift(n)\n",
    "    is_adjacent = (year_lag == (df_in[\"fyear\"] - n))\n",
    "    return val.where(is_adjacent.fillna(False), np.nan)\n",
    "\n",
    "# Identify dividend column (prefer dvc if present; else dv / dvt / dvp)\n",
    "dividend_candidates = [\"dvc\",\"dv\",\"dvt\",\"dvp\"]\n",
    "div_col = next((c for c in dividend_candidates if c in df.columns), None)\n",
    "\n",
    "if div_col is None:\n",
    "    print(\"Dividend column not found (looked for dvc/dv/dvt/dvp). Dividend events will be NaN.\")\n",
    "    df[\"evt_divcut\"] = np.nan\n",
    "    df[\"evt_divsusp\"] = np.nan\n",
    "    df[\"evt_divinit\"] = np.nan\n",
    "else:\n",
    "    # Use absolute value (guard against sign conventions)\n",
    "    df[\"dv_obs\"] = pd.to_numeric(df[div_col], errors=\"coerce\").abs()\n",
    "    df[\"dv_obs_l1\"] = lag(df, \"dv_obs\", 1)\n",
    "\n",
    "# Liquidity ratios\n",
    "if \"act\" in df.columns and \"lct\" in df.columns:\n",
    "    df[\"current_ratio\"] = safe_divide(df[\"act\"], df[\"lct\"], denom_floor=1e-6)\n",
    "else:\n",
    "    df[\"current_ratio\"] = np.nan\n",
    "\n",
    "if \"act\" in df.columns and \"lct\" in df.columns:\n",
    "    if \"invt\" in df.columns:\n",
    "        df[\"quick_ratio\"] = safe_divide(pd.to_numeric(df[\"act\"], errors=\"coerce\") - pd.to_numeric(df[\"invt\"], errors=\"coerce\"),\n",
    "                                        df[\"lct\"], denom_floor=1e-6)\n",
    "    elif \"che\" in df.columns and \"rect\" in df.columns:\n",
    "        df[\"quick_ratio\"] = safe_divide(pd.to_numeric(df[\"che\"], errors=\"coerce\") + pd.to_numeric(df[\"rect\"], errors=\"coerce\"),\n",
    "                                        df[\"lct\"], denom_floor=1e-6)\n",
    "    else:\n",
    "        df[\"quick_ratio\"] = df[\"current_ratio\"]\n",
    "else:\n",
    "    df[\"quick_ratio\"] = np.nan\n",
    "\n",
    "# EBITDA and CFO lags for deterioration events\n",
    "if \"ebitda_proxy\" in df.columns:\n",
    "    df[\"ebitda_l1\"] = lag(df, \"ebitda_proxy\", 1)\n",
    "if \"oancf\" in df.columns:\n",
    "    df[\"cfo_l1\"] = lag(df, \"oancf\", 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a512a90",
   "metadata": {},
   "source": [
    "#### 5.5.1 Dividend policy events (training-calibrated cut threshold)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f257c30f",
   "metadata": {},
   "source": [
    "event_params = {}\n",
    "\n",
    "if div_col is None:\n",
    "    pass\n",
    "else:\n",
    "    # YoY % change among observed payers with meaningful baseline\n",
    "    dv_l1 = pd.to_numeric(df[\"dv_obs_l1\"], errors=\"coerce\")\n",
    "    dv = pd.to_numeric(df[\"dv_obs\"], errors=\"coerce\")\n",
    "    df[\"div_pct_change\"] = np.where(dv_l1 > 1e-2, (dv - dv_l1) / dv_l1, np.nan)\n",
    "\n",
    "    payer_train = train_mask & (dv_l1 > 0) & pd.notna(df[\"div_pct_change\"])\n",
    "    if payer_train.sum() >= 50:\n",
    "        cut_thr = float(np.nanpercentile(df.loc[payer_train, \"div_pct_change\"], 10))\n",
    "    else:\n",
    "        cut_thr = -0.25\n",
    "\n",
    "    # Bound cut threshold to avoid pathological values\n",
    "    cut_thr = float(np.clip(cut_thr, -0.50, -0.10))\n",
    "    event_params[\"DIV_CUT_THR_P10_BOUNDED\"] = cut_thr\n",
    "\n",
    "    # Dividend cut: large negative YoY change among payers\n",
    "    df[\"evt_divcut\"] = (df[\"div_pct_change\"] <= cut_thr).astype(\"Int8\")\n",
    "    df.loc[df[\"div_pct_change\"].isna(), \"evt_divcut\"] = pd.NA\n",
    "\n",
    "    # Suspension: payer last year, ~zero dividend now\n",
    "    df[\"evt_divsusp\"] = ((dv_l1 > 0) & (dv.fillna(0) <= 1e-4)).astype(\"Int8\")\n",
    "    df.loc[dv_l1.isna() | dv.isna(), \"evt_divsusp\"] = pd.NA\n",
    "\n",
    "    # Initiation: ~zero last year, dividend now positive\n",
    "    df[\"evt_divinit\"] = ((dv_l1.fillna(0) <= 1e-4) & (dv > 1e-4)).astype(\"Int8\")\n",
    "    df.loc[dv_l1.isna() | dv.isna(), \"evt_divinit\"] = pd.NA\n",
    "\n",
    "    print(f\"Dividend cut threshold (train P10 bounded): {cut_thr:.3f}\")\n",
    "    display(df[[\"dv_obs\",\"dv_obs_l1\",\"div_pct_change\",\"evt_divcut\",\"evt_divsusp\",\"evt_divinit\"]].head(8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9ada601d",
   "metadata": {},
   "source": [
    "#### 5.5.2 Liquidity squeeze events"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3735439",
   "metadata": {},
   "source": [
    "cr = pd.to_numeric(df[\"current_ratio\"], errors=\"coerce\")\n",
    "df[\"evt_liq_squeeze\"] = (cr < 1.0).astype(\"Int8\")\n",
    "df.loc[cr.isna(), \"evt_liq_squeeze\"] = pd.NA\n",
    "\n",
    "qr = pd.to_numeric(df[\"quick_ratio\"], errors=\"coerce\")\n",
    "df[\"evt_quick_squeeze\"] = (qr < 0.8).astype(\"Int8\")\n",
    "df.loc[qr.isna(), \"evt_quick_squeeze\"] = pd.NA\n",
    "\n",
    "display(df[[\"current_ratio\",\"quick_ratio\",\"evt_liq_squeeze\",\"evt_quick_squeeze\"]].head(8))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3d21d0b2",
   "metadata": {},
   "source": [
    "#### 5.5.3 Operating deterioration events (vs. t-1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8da494b5",
   "metadata": {},
   "source": [
    "# EBITDA drop: requires lagged EBITDA observed and positive\n",
    "if \"ebitda_proxy\" in df.columns:\n",
    "    e = pd.to_numeric(df[\"ebitda_proxy\"], errors=\"coerce\")\n",
    "    e_l1 = pd.to_numeric(df[\"ebitda_l1\"], errors=\"coerce\")\n",
    "    ratio = e / e_l1\n",
    "    evt = ((e_l1 > 0) & ((ratio < 0.5) | (e <= 0))).astype(\"Int8\")\n",
    "    evt = evt.where(pd.notna(e_l1) & pd.notna(e), other=pd.NA).astype(\"Int8\")\n",
    "    df[\"evt_ebitdadrop\"] = evt\n",
    "else:\n",
    "    df[\"evt_ebitdadrop\"] = pd.NA\n",
    "\n",
    "# CFO drop: requires lagged CFO observed and positive\n",
    "if \"oancf\" in df.columns:\n",
    "    c = pd.to_numeric(df[\"oancf\"], errors=\"coerce\")\n",
    "    c_l1 = pd.to_numeric(df[\"cfo_l1\"], errors=\"coerce\")\n",
    "    ratio = c / c_l1\n",
    "    evt = ((c_l1 > 0) & ((ratio < 0.5) | (c <= 0))).astype(\"Int8\")\n",
    "    evt = evt.where(pd.notna(c_l1) & pd.notna(c), other=pd.NA).astype(\"Int8\")\n",
    "    df[\"evt_cfdrop\"] = evt\n",
    "else:\n",
    "    df[\"evt_cfdrop\"] = pd.NA\n",
    "\n",
    "display(df[[\"ebitda_proxy\",\"ebitda_l1\",\"evt_ebitdadrop\",\"oancf\",\"cfo_l1\",\"evt_cfdrop\"]].head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "185e58df",
   "metadata": {},
   "source": [
    "#### 5.5.4 Event dictionary (appendix-ready)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cfa35a4",
   "metadata": {},
   "source": [
    "event_dict_rows = [\n",
    "    {\"event\":\"evt_divcut\", \"definition\":\"Dividend YoY % change <= training P10 threshold (bounded [-0.50,-0.10])\", \"inputs\":div_col or \"N/A\", \"calibration\":\"train-only\"},\n",
    "    {\"event\":\"evt_divsusp\", \"definition\":\"Dividend >0 at t-1 and ~0 at t\", \"inputs\":div_col or \"N/A\", \"calibration\":\"none\"},\n",
    "    {\"event\":\"evt_divinit\", \"definition\":\"Dividend ~0 at t-1 and >0 at t\", \"inputs\":div_col or \"N/A\", \"calibration\":\"none\"},\n",
    "    {\"event\":\"evt_liq_squeeze\", \"definition\":\"Current ratio < 1.0\", \"inputs\":\"act,lct\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_quick_squeeze\", \"definition\":\"Quick ratio < 0.8\", \"inputs\":\"act,lct,invt (or che+rect)\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_ebitdadrop\", \"definition\":\"EBITDA <=0 OR EBITDA/EBITDA_{t-1}<0.5 (requires EBITDA_{t-1}>0)\", \"inputs\":\"oibdp\", \"calibration\":\"fixed threshold\"},\n",
    "    {\"event\":\"evt_cfdrop\", \"definition\":\"CFO <=0 OR CFO/CFO_{t-1}<0.5 (requires CFO_{t-1}>0)\", \"inputs\":\"oancf\", \"calibration\":\"fixed threshold\"},\n",
    "]\n",
    "event_dict = pd.DataFrame(event_dict_rows)\n",
    "event_dict[\"parameter\"] = event_dict[\"event\"].map(lambda e: json.dumps({k:v for k,v in event_params.items()}) if e==\"evt_divcut\" else \"\")\n",
    "display(event_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8efbebce",
   "metadata": {},
   "source": [
    "## 6. Preprocessing for Modeling (train-only fitting)\n",
    "\n",
    "Preprocessing design principles:\n",
    "- **Train-only fitting:** imputation (if needed), winsorization bounds, and scaling are all fit on *train* only.\n",
    "- **Binary events stay in levels** (0/1) to preserve interpretability and prevalence.\n",
    "- **Leakage audit:** variables that mechanically define the distress proxy are excluded from `MODEL_FEATS`.\n",
    "\n",
    "### 6.1 Feature set definition and leakage audit"
   ]
  },
  {
   "cell_type": "code",
   "id": "1b379b8c",
   "metadata": {},
   "source": [
    "# Features that participate in the distress proxy definition (must be excluded from predictors)\n",
    "# We key off PROXY_VERSION (not TARGET_NAME) so the same leakage rules apply to both objectives:\n",
    "#   - OBJECTIVE=\"state\"       -> TARGET_NAME = target_next_vX\n",
    "#   - OBJECTIVE=\"transition\"  -> TARGET_NAME = target_transition_vX\n",
    "\n",
    "try:\n",
    "    _pv = PROXY_VERSION\n",
    "except NameError:\n",
    "    # Backward compatibility if PROXY_VERSION is not defined in the targets cell\n",
    "    if TARGET_NAME.endswith(\"_v1\"):\n",
    "        _pv = \"v1\"\n",
    "    elif TARGET_NAME.endswith(\"_v2\"):\n",
    "        _pv = \"v2\"\n",
    "    elif TARGET_NAME.endswith(\"_v3\"):\n",
    "        _pv = \"v3\"\n",
    "    else:\n",
    "        _pv = \"v2\"\n",
    "\n",
    "if _pv == \"v1\":\n",
    "    # v1 uses niadj and oancf\n",
    "    DISTRESS_DEFINITION_VARS = {\"niadj\", \"oancf\", \"niadj_at\", \"loss_indicator\", \"ocf_to_debt\", \"fcf_to_debt\"}\n",
    "    continuous_feats_raw = [c for c in FEATURES_V1]\n",
    "    event_feats = []\n",
    "elif _pv == \"v2\":\n",
    "    # v2 uses seq\n",
    "    DISTRESS_DEFINITION_VARS = {\"seq\"}\n",
    "    continuous_feats_raw = [c for c in FEATURES_V2]\n",
    "    event_feats = []\n",
    "elif _pv == \"v3\":\n",
    "    # v3 uses ffo (oancf, xint, txp), debt (dlc, dltt), and equity (seq, mibt)\n",
    "    DISTRESS_DEFINITION_VARS = {\n",
    "        \"sp_ffo_to_debt\", \"sp_debt_to_capital\", \"sp_debt_to_ebitda\",\n",
    "        \"oancf\", \"xint\", \"txp\", \"dlc\", \"dltt\", \"seq\", \"mibt\", \"oibdp\",\n",
    "        \"ocf_to_debt\", \"fcf_to_debt\", \"debt_to_ebitda\", \"interest_coverage\"\n",
    "    }\n",
    "    # loss_indicator is binary, treat as event feature to avoid z-scoring\n",
    "    continuous_feats_raw = [c for c in FEATURES_V3 if c != \"loss_indicator\"]\n",
    "    event_feats = [\"loss_indicator\"]\n",
    "else:\n",
    "    DISTRESS_DEFINITION_VARS = set()\n",
    "    continuous_feats_raw = [c for c in FEATURES_V2]\n",
    "    event_feats = []\n",
    "continuous_feats_raw = [c for c in continuous_feats_raw if c in df.columns]\n",
    "event_feats = [c for c in event_feats if c in df.columns]\n",
    "\n",
    "# Final model feature list (events in levels; continuous will be z-scored with z_ prefix)\n",
    "MODEL_FEATS = [f\"z_{c}\" for c in continuous_feats_raw] + event_feats\n",
    "\n",
    "# Leakage audit: ensure no distress-definition variables are included (raw or scaled variants)\n",
    "leakage_hits = []\n",
    "for v in DISTRESS_DEFINITION_VARS:\n",
    "    if v in continuous_feats_raw or v in event_feats or f\"z_{v}\" in MODEL_FEATS:\n",
    "        leakage_hits.append(v)\n",
    "\n",
    "if leakage_hits:\n",
    "    raise ValueError(f\"Leakage audit failed: distress-definition variables present in feature set: {leakage_hits}\")\n",
    "\n",
    "print(\"Continuous (to be scaled):\", continuous_feats_raw)\n",
    "print(\"Events (kept in levels):\", event_feats)\n",
    "print(\"MODEL_FEATS (post-scaling names):\", MODEL_FEATS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "944e6d68",
   "metadata": {},
   "source": [
    "### 6.2 Modeling sample and target availability"
   ]
  },
  {
   "cell_type": "code",
   "id": "54b0ebd7",
   "metadata": {},
   "source": [
    "# Modeling requires a defined next-year label\n",
    "model_mask = df[TARGET_NAME].notna()\n",
    "df_model = df.loc[model_mask].copy()\n",
    "\n",
    "print(\"Modeling sample size:\", df_model.shape[0])\n",
    "display(df_model[\"split\"].value_counts().to_frame(\"n_obs\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad654f30",
   "metadata": {},
   "source": [
    "### 6.3 Replace infinities and set up train-only median imputation for remaining NaNs"
   ]
  },
  {
   "cell_type": "code",
   "id": "34293218",
   "metadata": {},
   "source": [
    "# Replace inf with NaN for preprocessing\n",
    "for c in continuous_feats_raw:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Train-only medians for remaining NaNs (after earlier imputation steps)\n",
    "train_medians = df_model.loc[df_model[\"split\"]==\"train\", continuous_feats_raw].median()\n",
    "\n",
    "for c in continuous_feats_raw:\n",
    "    df_model[c] = df_model[c].fillna(train_medians[c])\n",
    "\n",
    "# Event features: coerce to Int8 with missing -> 0 (conservative) but preserve missingness flags separately if desired\n",
    "for c in event_feats:\n",
    "    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\").fillna(0).astype(\"Int8\")\n",
    "\n",
    "assert df_model[continuous_feats_raw].isna().sum().sum() == 0, \"NaNs remain in continuous features after train-median fill.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea8146d5",
   "metadata": {},
   "source": [
    "### 6.4 Winsorize continuous features (train quantile bounds)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ac086d4",
   "metadata": {},
   "source": [
    "winsor_bounds = {}\n",
    "for c in continuous_feats_raw:\n",
    "    lo, hi = winsorize_train_bounds(df_model.loc[df_model[\"split\"]==\"train\", c], CONFIG[\"WINSOR_LO_Q\"], CONFIG[\"WINSOR_HI_Q\"])\n",
    "    winsor_bounds[c] = (lo, hi)\n",
    "    df_model[c] = apply_bounds(df_model[c], lo, hi)\n",
    "\n",
    "winsor_tbl = pd.DataFrame(\n",
    "    [{\"feature\": c, \"lo\": winsor_bounds[c][0], \"hi\": winsor_bounds[c][1]} for c in continuous_feats_raw]\n",
    ")\n",
    "display(winsor_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d779925e",
   "metadata": {},
   "source": [
    "### 6.5 Standardize continuous features (train-fit scaler; z_ prefix)"
   ]
  },
  {
   "cell_type": "code",
   "id": "64b21d21",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize continuous features (fit on TRAIN only)\n",
    "scaler = StandardScaler()\n",
    "df_model[continuous_feats_raw] = df_model[continuous_feats_raw].apply(lambda s: pd.to_numeric(s, errors=\"coerce\"))\n",
    "\n",
    "train_cont = df_model.loc[df_model[\"split\"] == \"train\", continuous_feats_raw].astype(float)\n",
    "scaler.fit(train_cont)\n",
    "\n",
    "Z_all = scaler.transform(df_model[continuous_feats_raw].astype(float))\n",
    "for j, c in enumerate(continuous_feats_raw):\n",
    "    df_model[f\"z_{c}\"] = Z_all[:, j].astype(float)\n",
    "\n",
    "# Final modeling matrix (events forced to clean 0/1 ints)\n",
    "z_cols = [f\"z_{c}\" for c in continuous_feats_raw]\n",
    "X = df_model[z_cols + event_feats].copy()\n",
    "\n",
    "# Guardrail check: verify excluded variables are not present in final feature matrix\n",
    "EXCLUDED_VARS = [\n",
    "    \"aco_act\", \"aqc_at\", \"caps_at\", \"capx_at\", \"dp_at\",\n",
    "    \"invch_act\", \"lco_lct\", \"mibt_at\", \"recch_act\",\n",
    "    \"txditc_at\", \"txp_lct\", \"xint_lct\"\n",
    "]\n",
    "EXCLUDED_Z_VARS = [f\"z_{v}\" for v in EXCLUDED_VARS]\n",
    "offending_cols = [c for c in X.columns if c in EXCLUDED_VARS or c in EXCLUDED_Z_VARS]\n",
    "if offending_cols:\n",
    "    raise ValueError(f\"Guardrail check failed: Excluded variables found in final feature matrix X: {offending_cols}\")\n",
    "\n",
    "for c in event_feats:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "    X[c] = X[c].fillna(0).astype(\"int8\")\n",
    "    assert set(X[c].unique()).issubset({0, 1}), f\"{c} not binary after coercion: {sorted(X[c].unique())}\"\n",
    "\n",
    "y = df_model[TARGET_NAME].astype(int)\n",
    "\n",
    "# Split views\n",
    "splits = {}\n",
    "for sp in [\"train\", \"val\", \"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    splits[sp] = {\"X\": X.loc[mask, :], \"y\": y.loc[mask], \"df\": df_model.loc[mask, :]}\n",
    "\n",
    "print({sp: (v[\"X\"].shape[0], v[\"X\"].shape[1]) for sp, v in splits.items()})\n",
    "\n",
    "# Numeric-safe finiteness check\n",
    "assert np.isfinite(X.astype(\"float64\").to_numpy()).all(), \"Non-finite values in modeling matrix.\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6734f55",
   "metadata": {},
   "source": [
    "## 7. Model Selection & Training\n",
    "\n",
    "### 7A. Logit model (primary baseline: calibrated PD with interpretable coefficients)\n",
    "\n",
    "#### 7A.1 Hyperparameter tuning on out-of-time validation year"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2ef67f2",
   "metadata": {},
   "source": [
    "train_X, train_y = splits[\"train\"][\"X\"], splits[\"train\"][\"y\"]\n",
    "val_X, val_y = splits[\"val\"][\"X\"], splits[\"val\"][\"y\"]\n",
    "\n",
    "results = []\n",
    "for C in CONFIG[\"LOGIT_C_GRID\"]:\n",
    "    mdl = LogisticRegression(C=C, solver=\"lbfgs\", max_iter=2000, random_state=SEED)\n",
    "    mdl.fit(train_X, train_y)\n",
    "    val_proba = mdl.predict_proba(val_X)[:, 1]\n",
    "    results.append({\n",
    "        \"C\": C,\n",
    "        \"val_roc_auc\": roc_auc_score(val_y, val_proba),\n",
    "        \"val_pr_auc\": average_precision_score(val_y, val_proba),\n",
    "        \"val_brier\": brier_score_loss(val_y, val_proba),\n",
    "    })\n",
    "\n",
    "tune_tbl = pd.DataFrame(results).sort_values(\"val_roc_auc\", ascending=False)\n",
    "display(tune_tbl)\n",
    "\n",
    "best_C = float(tune_tbl.iloc[0][\"C\"])\n",
    "print(\"Selected C:\", best_C)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6bd079298ae30c36",
   "metadata": {},
   "source": [
    "#### 7A.2 Fit Logit models and generate PDs"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce3526c900d40cfd",
   "metadata": {},
   "source": [
    "trainval_mask = df_model[\"split\"].isin([\"train\",\"val\"])\n",
    "X_trainval = X.loc[trainval_mask, :]\n",
    "y_trainval = y.loc[trainval_mask]\n",
    "\n",
    "# To ensure 'val' metrics are honest out-of-sample estimates, we use the model \n",
    "# trained on 'train' only for the validation split. \n",
    "# For the final 'test' performance, we use the model trained on 'train+val'.\n",
    "\n",
    "# Model trained on 'train' ONLY (for honest 'val' evaluation)\n",
    "logit_train_only = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=3000, random_state=SEED)\n",
    "logit_train_only.fit(train_X, train_y)\n",
    "\n",
    "# Model trained on 'train+val' (for final 'test' evaluation)\n",
    "logit_trainval = LogisticRegression(C=best_C, solver=\"lbfgs\", max_iter=3000, random_state=SEED)\n",
    "logit_trainval.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Assign predictions\n",
    "df_model[\"pd_logit\"] = np.nan\n",
    "# val gets predictions from train-only model (honest out-of-sample)\n",
    "df_model.loc[df_model[\"split\"]==\"val\", \"pd_logit\"] = logit_train_only.predict_proba(val_X)[:, 1]\n",
    "# test gets predictions from train+val model\n",
    "df_model.loc[df_model[\"split\"]==\"test\", \"pd_logit\"] = logit_trainval.predict_proba(splits[\"test\"][\"X\"])[:, 1]\n",
    "# train gets predictions from train+val model (in-sample)\n",
    "df_model.loc[df_model[\"split\"]==\"train\", \"pd_logit\"] = logit_trainval.predict_proba(train_X)[:, 1]\n",
    "\n",
    "# For legacy compatibility in reporting\n",
    "df_model[\"pd_logit_val\"] = np.where(df_model[\"split\"]==\"val\", df_model[\"pd_logit\"], np.nan)\n",
    "df_model[\"pd_logit_test\"] = np.where(df_model[\"split\"]==\"test\", df_model[\"pd_logit\"], np.nan)\n",
    "\n",
    "# Keep logit_clf as the final model for downstream use\n",
    "logit_clf = logit_trainval\n",
    "\n",
    "print(\"Example PDs (Logit):\")\n",
    "display(df_model[[\"firm_id\",\"fyear\",\"label_year\",\"split\",TARGET_NAME,\"pd_logit\"]].head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a94a27e",
   "metadata": {},
   "source": [
    "#### 7A.3 Inference audit (statsmodels Logit; clustered standard errors)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c743275",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from statsmodels.stats.sandwich_covariance import cov_cluster, cov_cluster_2groups\n",
    "# Statsmodels requires numpy arrays; keep column names for tables.\n",
    "X_sm = sm.add_constant(X_trainval, has_constant=\"add\")\n",
    "y_sm = y_trainval.astype(float)\n",
    "\n",
    "logit_sm = sm.Logit(y_sm, X_sm)\n",
    "res_sm = logit_sm.fit(disp=False, maxiter=200)\n",
    "\n",
    "# --- Firm cluster (numeric codes to avoid dtype issues) ---\n",
    "firm_raw = df_model.loc[trainval_mask, \"firm_id\"]\n",
    "firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\n",
    "\n",
    "cov_firm = cov_cluster(res_sm, firm_codes)\n",
    "se_firm = np.sqrt(np.diag(cov_firm))\n",
    "\n",
    "# --- Two-way cluster (firm + year), with feasibility + shape guards ---\n",
    "year_raw = df_model.loc[trainval_mask, \"label_year\"]\n",
    "firm_raw = df_model.loc[trainval_mask, \"firm_id\"]\n",
    "\n",
    "firm_codes = pd.factorize(firm_raw, sort=True)[0].astype(np.int64)\n",
    "year_codes = pd.factorize(year_raw, sort=True)[0].astype(np.int64)\n",
    "\n",
    "if (np.unique(firm_codes).size < 2) or (np.unique(year_codes).size < 2):\n",
    "    # Not enough clusters in one dimension -> two-way clustering not identified\n",
    "    se_2 = se_firm.copy()\n",
    "else:\n",
    "    cov_2 = cov_cluster_2groups(res_sm, firm_codes, year_codes)\n",
    "    cov_2 = np.asarray(cov_2)\n",
    "\n",
    "    k = len(res_sm.params)\n",
    "    if cov_2.ndim == 2 and cov_2.shape == (k, k):\n",
    "        se_2 = np.sqrt(np.diag(cov_2))\n",
    "    elif cov_2.ndim == 1 and cov_2.size == k:\n",
    "        # Some statsmodels versions may return only the diagonal variances\n",
    "        se_2 = np.sqrt(cov_2)\n",
    "    else:\n",
    "        # Unexpected shape -> fall back (safer than crashing)\n",
    "        se_2 = se_firm.copy()\n",
    "\n",
    "coef = res_sm.params\n",
    "p_firm = 2 * (1 - stats.norm.cdf(np.abs(coef / se_firm)))\n",
    "p_2 = 2 * (1 - stats.norm.cdf(np.abs(coef / se_2)))\n",
    "\n",
    "infer_tbl = pd.DataFrame({\n",
    "    \"coef_logodds\": coef,\n",
    "    \"se_firm\": se_firm,\n",
    "    \"p_firm\": p_firm,\n",
    "    \"se_firm_year\": se_2,\n",
    "    \"p_firm_year\": p_2,\n",
    "    \"odds_ratio\": np.exp(coef),\n",
    "})\n",
    "infer_tbl.index.name = \"feature\"\n",
    "display(infer_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a69777d6",
   "metadata": {},
   "source": [
    "#### 7A.4 Economic magnitude: MEM marginal effects and IQR-scaled effects"
   ]
  },
  {
   "cell_type": "code",
   "id": "f27addce",
   "metadata": {},
   "source": [
    "# MEM marginal effects using statsmodels (on train+val)\n",
    "try:\n",
    "    me = res_sm.get_margeff(at=\"mean\")\n",
    "    me_tbl = me.summary_frame()\n",
    "    # Align to inference table index (margeff typically excludes const)\n",
    "    me_tbl = me_tbl.reindex(infer_tbl.index)\n",
    "    display(me_tbl)\n",
    "except Exception as e:\n",
    "    print(\"Marginal effects computation failed:\", e)\n",
    "    me_tbl = None\n",
    "\n",
    "# IQR-scaled effects for continuous features (using TRAIN distribution, mapped into z-space)\n",
    "train_df = df_model.loc[df_model[\"split\"]==\"train\", :].copy()\n",
    "\n",
    "iqr_rows = []\n",
    "for j, raw_c in enumerate(continuous_feats_raw):\n",
    "    q25 = float(train_df[raw_c].quantile(0.25))\n",
    "    q75 = float(train_df[raw_c].quantile(0.75))\n",
    "    iqr = q75 - q25\n",
    "    sd = float(scaler.scale_[j]) if scaler.scale_[j] > 0 else np.nan\n",
    "    delta_z = iqr / sd if sd and not np.isnan(sd) else np.nan\n",
    "    beta = float(infer_tbl.loc[f\"z_{raw_c}\", \"coef_logodds\"]) if f\"z_{raw_c}\" in infer_tbl.index else np.nan\n",
    "    logodds_delta = beta * delta_z if not np.isnan(beta) and not np.isnan(delta_z) else np.nan\n",
    "    iqr_rows.append({\n",
    "        \"raw_feature\": raw_c,\n",
    "        \"IQR_raw\": iqr,\n",
    "        \"delta_z_equiv\": delta_z,\n",
    "        \"logodds_change_IQR\": logodds_delta,\n",
    "        \"odds_ratio_IQR\": float(np.exp(logodds_delta)) if not np.isnan(logodds_delta) else np.nan,\n",
    "    })\n",
    "\n",
    "iqr_tbl = pd.DataFrame(iqr_rows)\n",
    "display(iqr_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2e05569f33d2eab7",
   "metadata": {},
   "source": [
    "#### 7A.5 Average Partial Effects (APEs) in probability units with cluster-robust uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c05ca6e8e5396cbd",
   "metadata": {},
   "source": [
    "# APEs (Average Partial Effects) for logit model, using delta-method SEs with cluster-robust covariances\n",
    "# Notes:\n",
    "# - For logit, dP/dx_j = p*(1-p)*beta_j. The APE is the sample average of this derivative.\n",
    "# - We compute APEs on the TRAIN+VAL estimation sample used in statsmodels (X_sm, res_sm).\n",
    "# - SEs use the same cluster-robust covariance matrices already computed above (cov_firm and cov_2).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "def _coerce_cov(V, names):\n",
    "    \"\"\"Return numeric (k x k) covariance aligned to names. Fallback logic handles common statsmodels outputs.\"\"\"\n",
    "    k = len(names)\n",
    "\n",
    "    if isinstance(V, pd.DataFrame):\n",
    "        V = V.reindex(index=names, columns=names).to_numpy(dtype=float)\n",
    "        return V\n",
    "\n",
    "    V = np.asarray(V)\n",
    "    V = np.squeeze(V)\n",
    "\n",
    "    # Handle 3D objects (e.g., (3,k,k) or (k,k,3)): take first covariance slice\n",
    "    if V.ndim == 3:\n",
    "        if V.shape[1:] == (k, k):\n",
    "            V = V[0]\n",
    "        elif V.shape[:2] == (k, k):\n",
    "            V = V[:, :, 0]\n",
    "        else:\n",
    "            V = V.reshape(-1, k, k)[0]\n",
    "\n",
    "    # Handle diagonal-only variances\n",
    "    if V.ndim == 1:\n",
    "        if V.size != k:\n",
    "            raise ValueError(f\"Unexpected 1D covariance length: {V.size} (expected {k})\")\n",
    "        V = np.diag(V.astype(float))\n",
    "\n",
    "    if V.ndim != 2 or V.shape != (k, k):\n",
    "        raise ValueError(f\"Unexpected covariance shape: {V.shape} (expected {(k, k)})\")\n",
    "\n",
    "    V = V.astype(float)\n",
    "    V[~np.isfinite(V)] = 0.0\n",
    "    return V\n",
    "\n",
    "# ---- Align design matrix to params order ----\n",
    "X_df = X_sm if isinstance(X_sm, pd.DataFrame) else pd.DataFrame(X_sm)\n",
    "b_ser = res_sm.params\n",
    "\n",
    "names = list(b_ser.index)\n",
    "X_df = X_df.loc[:, names]                 # enforce same column order\n",
    "X_audit_np = X_df.to_numpy(dtype=float)\n",
    "\n",
    "b = b_ser.to_numpy(dtype=float)\n",
    "k = len(names)\n",
    "\n",
    "# Predicted probabilities on estimation sample\n",
    "eta = X_audit_np @ b\n",
    "p = 1.0 / (1.0 + np.exp(-eta))\n",
    "w = p * (1.0 - p)\n",
    "mw = float(np.mean(w))\n",
    "\n",
    "# APE_j = beta_j * mean(w)\n",
    "ape = b * mw\n",
    "if \"const\" in names:\n",
    "    ape[names.index(\"const\")] = np.nan\n",
    "\n",
    "# Delta-method gradient\n",
    "t = (w * (1.0 - 2.0 * p))[:, None] * X_audit_np\n",
    "dmw_db = np.mean(t, axis=0)\n",
    "\n",
    "G = np.full((k, k), np.nan, dtype=float)\n",
    "for j in range(k):\n",
    "    if names[j] == \"const\":\n",
    "        continue\n",
    "    g = dmw_db * b[j]\n",
    "    g[j] += mw\n",
    "    G[j, :] = g\n",
    "\n",
    "# Covariances (coerce 2-way; fallback to firm)\n",
    "V_firm = _coerce_cov(cov_firm, names)\n",
    "if \"cov_2\" in globals():\n",
    "    try:\n",
    "        V_2 = _coerce_cov(cov_2, names)\n",
    "    except Exception:\n",
    "        V_2 = V_firm\n",
    "else:\n",
    "    V_2 = V_firm\n",
    "\n",
    "def _se_from_V(V):\n",
    "    se = np.full(k, np.nan, dtype=float)\n",
    "    for j in range(k):\n",
    "        if not np.all(np.isfinite(G[j, :])):\n",
    "            continue\n",
    "        g = G[j, :].astype(float)\n",
    "        v = (g @ V @ g).item()  # scalar quadratic form\n",
    "        se[j] = np.sqrt(v) if v >= 0 else np.nan\n",
    "    return se\n",
    "\n",
    "se_ape_firm = _se_from_V(V_firm)\n",
    "se_ape_2 = _se_from_V(V_2)\n",
    "\n",
    "# p-values (normal approximation)\n",
    "z_firm = ape / se_ape_firm\n",
    "p_ape_firm = 2 * (1 - stats.norm.cdf(np.abs(z_firm)))\n",
    "\n",
    "z_2 = ape / se_ape_2\n",
    "p_ape_2 = 2 * (1 - stats.norm.cdf(np.abs(z_2)))\n",
    "\n",
    "ape_tbl = pd.DataFrame({\n",
    "    \"APE\": ape,\n",
    "    \"se_APE_firm\": se_ape_firm,\n",
    "    \"p_APE_firm\": p_ape_firm,\n",
    "    \"se_APE_firm_year\": se_ape_2,\n",
    "    \"p_APE_firm_year\": p_ape_2,\n",
    "}, index=pd.Index(names, name=\"feature\"))\n",
    "\n",
    "display(ape_tbl)\n",
    "\n",
    "infer_tbl_with_ape = infer_tbl.join(ape_tbl, how=\"left\")\n",
    "display(infer_tbl_with_ape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0b34ac3",
   "metadata": {},
   "source": [
    "### 7B. Tree-based model (XGBoost; nonlinear )\n",
    "\n",
    "Tree models capture interactions and nonlinearities that logit cannot, but they require stronger regularization and calibration discipline.\n",
    "\n",
    "Implementation details:\n",
    "- Early stopping on **PR-AUC** using validation split.\n",
    "- Conservative depth and regularization parameters.\n",
    "- Cost-sensitive weighting to reflect class imbalance and FN/FP asymmetry.\n",
    "- **Isotonic calibration** fit on validation predictions (train-only model remains unchanged).\n",
    "\n",
    "#### 7B.1 Train XGBoost with early stopping (validation PR-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8810a478",
   "metadata": {},
   "source": [
    "# Build DMatrix objects\n",
    "X_tr = splits[\"train\"][\"X\"]\n",
    "y_tr = splits[\"train\"][\"y\"].astype(int)\n",
    "X_va = splits[\"val\"][\"X\"]\n",
    "y_va = splits[\"val\"][\"y\"].astype(int)\n",
    "X_te = splits[\"test\"][\"X\"]\n",
    "y_te = splits[\"test\"][\"y\"].astype(int)\n",
    "\n",
    "n_pos = int(y_tr.sum())\n",
    "n_neg = int((y_tr==0).sum())\n",
    "imbalance = (n_neg / max(n_pos, 1))\n",
    "\n",
    "w_pos = CONFIG[\"COST_FN\"] * imbalance\n",
    "w_neg = CONFIG[\"COST_FP\"]\n",
    "\n",
    "w_tr = np.where(y_tr.values==1, w_pos, w_neg).astype(float)\n",
    "w_va = np.where(y_va.values==1, w_pos, w_neg).astype(float)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr, feature_names=X_tr.columns.tolist())\n",
    "dval   = xgb.DMatrix(X_va, label=y_va, weight=w_va, feature_names=X_tr.columns.tolist())\n",
    "dall   = xgb.DMatrix(X, label=y.astype(int), feature_names=X_tr.columns.tolist())\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "xgb_model = xgb.train(\n",
    "    params=CONFIG[\"XGB_PARAMS\"],\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=CONFIG[\"XGB_NUM_BOOST_ROUND\"],\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=CONFIG[\"XGB_EARLY_STOPPING\"],\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "print(\"Best iteration:\", xgb_model.best_iteration)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6a23d75",
   "metadata": {},
   "source": [
    "#### 7B.2 Isotonic calibration on validation set (probability calibration)"
   ]
  },
  {
   "cell_type": "code",
   "id": "86dbd5a4",
   "metadata": {},
   "source": [
    "# Raw probabilities (uncalibrated)\n",
    "p_val_raw = xgb_model.predict(dval)\n",
    "p_all_raw = xgb_model.predict(dall)\n",
    "\n",
    "# Fit isotonic on validation only\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso.fit(p_val_raw, y_va.values.astype(int))\n",
    "\n",
    "df_model[\"pd_tree\"] = iso.transform(p_all_raw)\n",
    "\n",
    "print(\"Calibration fitted on validation only.\")\n",
    "display(df_model[[\"split\",\"pd_tree\"]].groupby(\"split\").mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1fdd237e",
   "metadata": {},
   "source": [
    "#### 7B.3 Feature importance and SHAP (optional explainability)"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5a56f06",
   "metadata": {},
   "source": [
    "# Gain-based feature importance\n",
    "importance = xgb_model.get_score(importance_type=\"gain\")\n",
    "imp_tbl = (pd.DataFrame({\"feature\": list(importance.keys()), \"gain\": list(importance.values())})\n",
    "             .sort_values(\"gain\", ascending=False))\n",
    "display(imp_tbl.head(20))\n",
    "\n",
    "# Optional: SHAP summary for a subsample (can be expensive on large panels)\n",
    "try:\n",
    "    import shap\n",
    "    shap.initjs()\n",
    "    sample_n = min(5000, X_tr.shape[0])\n",
    "    X_sample = X_tr.sample(sample_n, random_state=SEED)\n",
    "    explainer = shap.TreeExplainer(xgb_model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    plt.figure()\n",
    "    shap.summary_plot(shap_values, X_sample, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"shap_summary_tree.png\", dpi=160)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped:\", e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "320efce1a9900b66",
   "metadata": {},
   "source": [
    "#### 7A.5 Walk-forward validation (expanding window)"
   ]
  },
  {
   "cell_type": "code",
   "id": "42f609b7767eedc2",
   "metadata": {},
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Walk-forward (expanding window) validation — Logit and XGBoost (leakage-safe)\n",
    "# =============================================================================\n",
    "# This implementation refits preprocessing (median fill, winsor bounds, scaler) within each fold.\n",
    "# That is required for honest temporal validation.\n",
    "\n",
    "trainpool_df = df_model.loc[df_model[\"split\"].isin([\"train\", \"val\"]), :].copy()\n",
    "years = sorted(trainpool_df[\"label_year\"].dropna().unique().tolist())\n",
    "years = [int(y) for y in years]\n",
    "\n",
    "\n",
    "# --- safe metrics helpers ---\n",
    "def _safe_auc(y, p):\n",
    "    y = np.asarray(y, int)\n",
    "    p = np.asarray(p, float)\n",
    "    if len(np.unique(y)) < 2:\n",
    "        return np.nan\n",
    "    return roc_auc_score(y, p)\n",
    "\n",
    "\n",
    "def _safe_pr(y, p):\n",
    "    y = np.asarray(y, int)\n",
    "    p = np.asarray(p, float)\n",
    "    if len(np.unique(y)) < 2:\n",
    "        return np.nan\n",
    "    return average_precision_score(y, p)\n",
    "\n",
    "\n",
    "N_SPLITS = 4\n",
    "if len(years) < (N_SPLITS + 2):\n",
    "    print(\"Not enough years for walk-forward validation; skipping.\")\n",
    "    wf_tbl = pd.DataFrame()\n",
    "else:\n",
    "    split_idx = np.linspace(2, len(years) - 1, N_SPLITS, dtype=int)\n",
    "\n",
    "\n",
    "    def prep_fold(df_tr, df_va):\n",
    "        # continuous: median fill (train), winsor clip (train), scaler (train)\n",
    "        cont = [c for c in continuous_feats_raw if c in df_tr.columns]\n",
    "        Xtr = df_tr[cont].apply(pd.to_numeric, errors=\"coerce\")\n",
    "        Xva = df_va[cont].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "        med = Xtr.median()\n",
    "        Xtr = Xtr.fillna(med)\n",
    "        Xva = Xva.fillna(med)\n",
    "\n",
    "        bounds = {c: winsorize_train_bounds(Xtr[c], CONFIG[\"WINSOR_LO_Q\"], CONFIG[\"WINSOR_HI_Q\"]) for c in cont}\n",
    "        for c, (lo, hi) in bounds.items():\n",
    "            Xtr[c] = apply_bounds(Xtr[c], lo, hi)\n",
    "            Xva[c] = apply_bounds(Xva[c], lo, hi)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        Ztr = pd.DataFrame(scaler.fit_transform(Xtr), columns=[f\"z_{c}\" for c in cont], index=df_tr.index)\n",
    "        Zva = pd.DataFrame(scaler.transform(Xva), columns=[f\"z_{c}\" for c in cont], index=df_va.index)\n",
    "\n",
    "        # events: keep as-is; fill missing with 0 (absence of event)\n",
    "        ev = [c for c in event_feats if c in df_tr.columns]\n",
    "        if ev:\n",
    "            Etr = df_tr[ev].fillna(0.0)\n",
    "            Eva = df_va[ev].fillna(0.0)\n",
    "            Ztr = pd.concat([Ztr, Etr], axis=1)\n",
    "            Zva = pd.concat([Zva, Eva], axis=1)\n",
    "\n",
    "        return Ztr, Zva\n",
    "\n",
    "\n",
    "    rows = []\n",
    "    for k in split_idx:\n",
    "        train_years = years[:k]\n",
    "        val_year = years[k]\n",
    "\n",
    "        df_tr = trainpool_df[trainpool_df[\"label_year\"].isin(train_years)].copy()\n",
    "        df_va = trainpool_df[trainpool_df[\"label_year\"].isin([val_year])].copy()\n",
    "\n",
    "        # drop missing labels for the fold\n",
    "        df_tr = df_tr[df_tr[TARGET_NAME].notna()].copy()\n",
    "        df_va = df_va[df_va[TARGET_NAME].notna()].copy()\n",
    "\n",
    "        X_tr, X_va = prep_fold(df_tr, df_va)\n",
    "        y_tr = df_tr[TARGET_NAME].astype(int).values\n",
    "        y_va = df_va[TARGET_NAME].astype(int).values\n",
    "\n",
    "        # ---- Logit ----\n",
    "        C_use = float(globals().get(\"best_C\", 1.0))\n",
    "        log_mdl = LogisticRegression(\n",
    "            penalty=\"l2\", C=C_use, solver=\"liblinear\",\n",
    "            class_weight={0: CONFIG[\"COST_FP\"], 1: CONFIG[\"COST_FN\"]},\n",
    "            random_state=SEED, max_iter=2000\n",
    "        )\n",
    "        log_mdl.fit(X_tr, y_tr)\n",
    "        p_va_log = log_mdl.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": \"logit\",\n",
    "            \"train_years_min\": min(train_years),\n",
    "            \"train_years_max\": max(train_years),\n",
    "            \"val_year\": val_year,\n",
    "            \"n_train\": int(len(y_tr)),\n",
    "            \"n_val\": int(len(y_va)),\n",
    "            \"roc_auc\": _safe_auc(y_va, p_va_log),\n",
    "            \"pr_auc\": _safe_pr(y_va, p_va_log),\n",
    "            \"brier\": float(brier_score_loss(y_va, p_va_log)),\n",
    "        })\n",
    "\n",
    "        # ---- XGBoost (same training block as main model; per-fold fit) ----\n",
    "        # Ensure y are pandas Series (so .values works exactly like your main cell)\n",
    "        y_tr = df_tr[TARGET_NAME].astype(int)\n",
    "        y_va = df_va[TARGET_NAME].astype(int)\n",
    "\n",
    "        # If a fold has only one class, XGBoost AUC/PR are undefined and training can be unstable.\n",
    "        if (y_tr.nunique() < 2) or (y_va.nunique() < 2):\n",
    "            rows.append({\n",
    "                \"model\": \"tree\",\n",
    "                \"train_years_min\": min(train_years),\n",
    "                \"train_years_max\": max(train_years),\n",
    "                \"val_year\": val_year,\n",
    "                \"n_train\": int(len(y_tr)),\n",
    "                \"n_val\": int(len(y_va)),\n",
    "                \"roc_auc\": np.nan,\n",
    "                \"pr_auc\": np.nan,\n",
    "                \"brier\": np.nan,\n",
    "                \"best_iteration\": np.nan,\n",
    "                \"note\": \"Skipped: single-class fold\"\n",
    "            })\n",
    "        else:\n",
    "            # --- exact same weight logic as your main model cell ---\n",
    "            n_pos = int(y_tr.sum())\n",
    "            n_neg = int((y_tr == 0).sum())\n",
    "            imbalance = (n_neg / max(n_pos, 1))\n",
    "\n",
    "            w_pos = CONFIG[\"COST_FN\"] * imbalance\n",
    "            w_neg = CONFIG[\"COST_FP\"]\n",
    "\n",
    "            w_tr = np.where(y_tr.values == 1, w_pos, w_neg).astype(float)\n",
    "            w_va = np.where(y_va.values == 1, w_pos, w_neg).astype(float)\n",
    "\n",
    "            # --- exact same DMatrix pattern as your main model cell ---\n",
    "            dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr, feature_names=X_tr.columns.tolist())\n",
    "            dval = xgb.DMatrix(X_va, label=y_va, weight=w_va, feature_names=X_tr.columns.tolist())\n",
    "\n",
    "            evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "            xgb_model = xgb.train(\n",
    "                params=CONFIG[\"XGB_PARAMS\"],\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round=CONFIG[\"XGB_NUM_BOOST_ROUND\"],\n",
    "                evals=evals,\n",
    "                early_stopping_rounds=CONFIG[\"XGB_EARLY_STOPPING\"],\n",
    "                verbose_eval=False,\n",
    "            )\n",
    "\n",
    "            # Raw probabilities (uncalibrated) — same as main cell\n",
    "            p_val_raw = xgb_model.predict(dval)\n",
    "\n",
    "            rows.append({\n",
    "                \"model\": \"tree\",\n",
    "                \"train_years_min\": min(train_years),\n",
    "                \"train_years_max\": max(train_years),\n",
    "                \"val_year\": val_year,\n",
    "                \"n_train\": int(len(y_tr)),\n",
    "                \"n_val\": int(len(y_va)),\n",
    "                \"roc_auc\": _safe_auc(y_va.values, p_val_raw),\n",
    "                \"pr_auc\": _safe_pr(y_va.values, p_val_raw),\n",
    "                \"brier\": float(brier_score_loss(y_va.values.astype(int), p_val_raw)),\n",
    "                \"best_iteration\": int(getattr(xgb_model, \"best_iteration\", np.nan)),\n",
    "            })\n",
    "\n",
    "    wf_tbl = pd.DataFrame(rows)\n",
    "    display(wf_tbl)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ffaf2ac",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation & Diagnostic Monitoring\n",
    "\n",
    "All evaluation in this section treats the **test split as untouchable**: no tuning based on test results.\n",
    "\n",
    "**Clean Evaluation Protocol Note:**\n",
    "- For **Logit**: The validation (`val`) performance reported below is an honest out-of-sample estimate because it uses a model trained on `train` only. The test performance uses a model trained on `train+val`.\n",
    "- For **Tree (XGBoost)**: The validation (`val`) performance is **in-sample** relative to early stopping and isotonic calibration, both of which use the validation set. Therefore, `val` performance for trees will appear optimistic.\n",
    "- **Unbiased Performance**: The **test split** results are the only strictly unbiased final performance metrics.\n",
    "\n",
    "We report:\n",
    "- ROC-AUC, PR-AUC, Brier score,\n",
    "- calibration curve and calibration slope (reliability),\n",
    "- persistence benchmark,\n",
    "- collinearity and drift diagnostics.\n",
    "\n",
    "### 8.1 Out-of-sample metrics (val and test) + persistence benchmark"
   ]
  },
  {
   "cell_type": "code",
   "id": "29873ad3",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "def eval_metrics_safe(y_true: pd.Series, p: np.ndarray) -> dict:\n",
    "    y = y_true.astype(int).values\n",
    "    out = {\n",
    "        \"roc_auc\": np.nan,\n",
    "        \"pr_auc\": np.nan,\n",
    "        \"brier\": brier_score_loss(y, p),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"event_rate\": float(np.mean(y)),\n",
    "        \"n\": int(len(y)),\n",
    "    }\n",
    "    # Guard against single-class slices (can occur under transition objective + small test sets)\n",
    "    if np.unique(y).size < 2:\n",
    "        # ROC-AUC undefined; PR-AUC equals event rate for a constant predictor\n",
    "        out[\"pr_auc\"] = float(out[\"event_rate\"])\n",
    "        return out\n",
    "    out[\"roc_auc\"] = float(roc_auc_score(y, p))\n",
    "    out[\"pr_auc\"] = float(average_precision_score(y, p))\n",
    "    return out\n",
    "\n",
    "rows = []\n",
    "for sp in [\"val\",\"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    y_sp = df_model.loc[mask, TARGET_NAME]\n",
    "\n",
    "    rows.append({\"split\": sp, \"model\":\"logit\", **eval_metrics_safe(y_sp, df_model.loc[mask, \"pd_logit\"].values)})\n",
    "    rows.append({\"split\": sp, \"model\":\"tree_calibrated\", **eval_metrics_safe(y_sp, df_model.loc[mask, \"pd_tree\"].values)})\n",
    "\n",
    "    obj = str(globals().get(\"OBJECTIVE\", \"state\")).lower()\n",
    "    if obj.startswith(\"trans\"):\n",
    "        # Under early-warning (transition) objective, PROXY_NAME==0 by construction. Use a simple \"always-0\" baseline.\n",
    "        base = np.zeros(mask.sum(), dtype=float)\n",
    "        rows.append({\"split\": sp, \"model\":\"always_0\", **eval_metrics_safe(y_sp, base)})\n",
    "    else:\n",
    "        # Surveillance objective baseline: predict next-year distress = current-year state (persistence)\n",
    "        pers = pd.to_numeric(df_model.loc[mask, PROXY_NAME], errors=\"coerce\").fillna(0).astype(int).values\n",
    "        rows.append({\"split\": sp, \"model\":\"persistence_state_t\", **eval_metrics_safe(y_sp, pers)})\n",
    "\n",
    "metrics_tbl = pd.DataFrame(rows).sort_values([\"split\",\"model\"])\n",
    "display(metrics_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "51c21d935f978c85",
   "metadata": {},
   "source": [
    "### 8.1b Early-warning vs Surveillance decomposition (state-conditional evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff41db2c85a96e38",
   "metadata": {},
   "source": [
    "# Objective-aware evaluation breakdown.\n",
    "# - If OBJECTIVE == \"transition\": df_model already represents the *risk set* (distress_t==0), so we report overall metrics.\n",
    "# - If OBJECTIVE == \"state\": we additionally break out performance on distress_t==0 (early-warning slice) vs distress_t==1 (surveillance slice).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "def safe_eval_metrics(y_true: pd.Series, p: np.ndarray) -> dict:\n",
    "    y = y_true.astype(int).values\n",
    "    out = {\n",
    "        \"roc_auc\": np.nan,\n",
    "        \"pr_auc\": np.nan,\n",
    "        \"brier\": brier_score_loss(y, p),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"event_rate\": float(np.mean(y)),\n",
    "        \"n\": int(len(y)),\n",
    "    }\n",
    "    if np.unique(y).size < 2:\n",
    "        out[\"pr_auc\"] = float(out[\"event_rate\"])\n",
    "        return out\n",
    "    out[\"roc_auc\"] = float(roc_auc_score(y, p))\n",
    "    out[\"pr_auc\"] = float(average_precision_score(y, p))\n",
    "    return out\n",
    "\n",
    "def eval_models(df_seg: pd.DataFrame, split_name: str, segment_name: str) -> list:\n",
    "    rows = []\n",
    "    if df_seg.empty:\n",
    "        return rows\n",
    "    y = df_seg[TARGET_NAME]\n",
    "\n",
    "    for col, mdl in [(\"pd_logit\",\"logit\"),\n",
    "                     (\"pd_tree\",\"tree_calibrated\")]:\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"segment\": segment_name,\n",
    "            \"model\": mdl,\n",
    "            **safe_eval_metrics(y, df_seg[col].values),\n",
    "        })\n",
    "\n",
    "    # Baseline(s)\n",
    "    obj = str(globals().get(\"OBJECTIVE\", \"state\")).lower()\n",
    "    if obj.startswith(\"trans\"):\n",
    "        base = np.zeros(df_seg.shape[0], dtype=float)\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"segment\": segment_name,\n",
    "            \"model\": \"always_0\",\n",
    "            **safe_eval_metrics(y, base),\n",
    "        })\n",
    "    else:\n",
    "        state = pd.to_numeric(df_seg[PROXY_NAME], errors=\"coerce\").fillna(0).astype(int).values\n",
    "        rows.append({\n",
    "            \"split\": split_name,\n",
    "            \"segment\": segment_name,\n",
    "            \"model\": \"state_only\",\n",
    "            **safe_eval_metrics(y, state),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "obj = str(globals().get(\"OBJECTIVE\", \"state\")).lower()\n",
    "\n",
    "seg_rows = []\n",
    "for sp in [\"val\", \"test\"]:\n",
    "    df_sp = df_model.loc[df_model[\"split\"]==sp, :].copy()\n",
    "\n",
    "    if obj.startswith(\"trans\"):\n",
    "        seg_rows += eval_models(df_sp, sp, f\"transition risk set ({PROXY_NAME}=0 by design)\")\n",
    "    else:\n",
    "        # Early-warning vs surveillance slices (conditional on current state)\n",
    "        dcur = pd.to_numeric(df_sp[PROXY_NAME], errors=\"coerce\")\n",
    "        df_sp = df_sp.loc[dcur.notna(), :].copy()\n",
    "        df_sp[\"distress_t_int\"] = dcur.loc[dcur.notna()].astype(int)\n",
    "\n",
    "        seg_rows += eval_models(df_sp.loc[df_sp[\"distress_t_int\"]==0, :], sp, f\"early_warning ({PROXY_NAME}=0)\")\n",
    "        seg_rows += eval_models(df_sp.loc[df_sp[\"distress_t_int\"]==1, :], sp, f\"surveillance ({PROXY_NAME}=1)\")\n",
    "\n",
    "seg_metrics_tbl = pd.DataFrame(seg_rows)\n",
    "if not seg_metrics_tbl.empty:\n",
    "    seg_metrics_tbl = seg_metrics_tbl.sort_values([\"split\",\"segment\",\"model\"])\n",
    "    display(seg_metrics_tbl)\n",
    "else:\n",
    "    print(\"No segment metrics computed (empty segments).\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "14804efc",
   "metadata": {},
   "source": [
    "### 8.2 Calibration diagnostics (curve + calibration-in-the-large + slope)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac2c963a",
   "metadata": {},
   "source": [
    "def calibration_slope_intercept(y_true: np.ndarray, p: np.ndarray) -> tuple[float,float]:\n",
    "    z = logit(p)\n",
    "    Xc = sm.add_constant(z, has_constant=\"add\")\n",
    "    mdl = sm.GLM(y_true, Xc, family=sm.families.Binomial())\n",
    "    res = mdl.fit()\n",
    "    intercept, slope = res.params[0], res.params[1]\n",
    "    return float(intercept), float(slope)\n",
    "\n",
    "def plot_calibration(y_true: np.ndarray, p: np.ndarray, title: str, fname: str):\n",
    "    frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=10, strategy=\"quantile\")\n",
    "    plt.figure()\n",
    "    plt.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "    plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "    plt.xlabel(\"Mean predicted probability\")\n",
    "    plt.ylabel(\"Fraction of positives\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / fname, dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "for sp in [\"val\",\"test\"]:\n",
    "    mask = df_model[\"split\"] == sp\n",
    "    y_sp = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "    for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "        p = df_model.loc[mask, pcol].values\n",
    "        icpt, slope = calibration_slope_intercept(y_sp, p)\n",
    "        print(f\"{sp} | {model_name}: calibration intercept={icpt:.3f}, slope={slope:.3f}\")\n",
    "        plot_calibration(y_sp, p, f\"Calibration curve — {model_name} ({sp})\", f\"cal_curve_{model_name}_{sp}.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dae2a433",
   "metadata": {},
   "source": [
    "### 8.3 Temporal stability (walk-forward fold metrics)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0c531ed",
   "metadata": {},
   "source": [
    "if 'wf_tbl' in globals() and len(wf_tbl) > 0:\n",
    "    display(wf_tbl)\n",
    "    plt.figure()\n",
    "    plt.plot(wf_tbl[\"val_year\"], wf_tbl[\"roc_auc\"], marker=\"o\", label=\"ROC-AUC\")\n",
    "    plt.plot(wf_tbl[\"val_year\"], wf_tbl[\"pr_auc\"], marker=\"o\", label=\"PR-AUC\")\n",
    "    plt.title(\"Walk-forward validation metrics \")\n",
    "    plt.xlabel(\"Validation label_year\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"walkforward_metrics_logit.png\", dpi=160)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e114cc8",
   "metadata": {},
   "source": [
    "### 8.4 Collinearity checks (VIF + high-correlation pairs)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a73fa727",
   "metadata": {},
   "source": [
    "# VIF on continuous z-features (train only)\n",
    "X_vif = splits[\"train\"][\"X\"][[f\"z_{c}\" for c in continuous_feats_raw]].copy()\n",
    "X_vif = sm.add_constant(X_vif, has_constant=\"add\")\n",
    "\n",
    "vif_rows = []\n",
    "for i, col in enumerate(X_vif.columns):\n",
    "    if col == \"const\":\n",
    "        continue\n",
    "    vif_rows.append({\"feature\": col, \"VIF\": float(variance_inflation_factor(X_vif.values, i))})\n",
    "\n",
    "vif_tbl = pd.DataFrame(vif_rows).sort_values(\"VIF\", ascending=False)\n",
    "display(vif_tbl)\n",
    "\n",
    "# Correlation screen (continuous only)\n",
    "corr = splits[\"train\"][\"X\"][[f\"z_{c}\" for c in continuous_feats_raw]].corr()\n",
    "high_pairs = []\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):\n",
    "        v = corr.iloc[i,j]\n",
    "        if abs(v) >= 0.85:\n",
    "            high_pairs.append((corr.columns[i], corr.columns[j], float(v)))\n",
    "high_pairs_tbl = pd.DataFrame(high_pairs, columns=[\"feat1\",\"feat2\",\"corr\"]).sort_values(\"corr\", key=np.abs, ascending=False)\n",
    "display(high_pairs_tbl)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5a8305ac",
   "metadata": {},
   "source": [
    "### 8.5 Drift diagnostics (standardized mean difference: train vs test)"
   ]
  },
  {
   "cell_type": "code",
   "id": "82250df7",
   "metadata": {},
   "source": [
    "feat_cols = [f\"z_{c}\" for c in continuous_feats_raw] + event_feats\n",
    "drift_rows = []\n",
    "for c in feat_cols:\n",
    "    smd = compute_smd(df_model.loc[df_model[\"split\"]==\"train\", c], df_model.loc[df_model[\"split\"]==\"test\", c])\n",
    "    drift_rows.append({\"feature\": c, \"SMD_train_vs_test\": smd})\n",
    "drift_tbl = pd.DataFrame(drift_rows).sort_values(\"SMD_train_vs_test\", key=lambda s: s.abs(), ascending=False)\n",
    "display(drift_tbl.head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "03071f10",
   "metadata": {},
   "source": [
    "### 8.6 Probability distributions by class (test split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644a37d748cd1e5",
   "metadata": {},
   "source": [
    "## 9.a Statistical uncertainty and model comparison on the test set (Cluster bootstrap CIs + firm-clustered pairwise tests)\n",
    "\n",
    "This section adds (i) cluster bootstrap by firm_id confidence intervals for key metrics and (ii) paired cluster bootstrap tests for ROC-AUC differences, with Holm and Bonferroni adjustments for multiple comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6516269832d9cc8e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss\n",
    "\n",
    "# ============================================================\n",
    "# Firm-clustered uncertainty quantification (panel-robust)\n",
    "# ============================================================\n",
    "# Rationale:\n",
    "# - Firm-year observations are not i.i.d.; errors are correlated within firm over time.\n",
    "# - Row-wise (i.i.d.) bootstrap and DeLong tests are therefore overconfident in panels.\n",
    "# - We use a *cluster bootstrap by firm_id*: resample firms with replacement and keep\n",
    "#   each sampled firm's full time-series block.\n",
    "#\n",
    "# Outputs:\n",
    "# 1) Model-wise cluster-bootstrap percentile CIs for ROC-AUC, PR-AUC, and Brier score.\n",
    "# 2) Pairwise *paired* cluster-bootstrap tests for ROC-AUC differences (with Holm/Bonferroni).\n",
    "\n",
    "\n",
    "N_BOOT = 1000  # increase (e.g., 2000) for tighter CIs at higher compute cost\n",
    "ALPHA = 0.05\n",
    "SEED_BOOT = 42\n",
    "\n",
    "def _cluster_groups(df: pd.DataFrame, cluster_col: str):\n",
    "    cl = df[cluster_col].astype(str).values\n",
    "    uniq, inv = np.unique(cl, return_inverse=True)\n",
    "    groups = [np.where(inv == k)[0] for k in range(len(uniq))]\n",
    "    return groups\n",
    "\n",
    "def _metric_safe(y: np.ndarray, p: np.ndarray, metric: str) -> float:\n",
    "    y = np.asarray(y).astype(int)\n",
    "    p = np.asarray(p).astype(float)\n",
    "    if metric == \"roc_auc\":\n",
    "        if np.unique(y).size < 2:\n",
    "            return np.nan\n",
    "        return float(roc_auc_score(y, p))\n",
    "    if metric == \"pr_auc\":\n",
    "        # Average precision requires positives to be meaningful; return NaN if no positives.\n",
    "        if y.sum() == 0 or y.sum() == len(y):\n",
    "            return np.nan\n",
    "        return float(average_precision_score(y, p))\n",
    "    if metric == \"brier\":\n",
    "        return float(brier_score_loss(y, p))\n",
    "    raise ValueError(f\"Unknown metric: {metric}\")\n",
    "\n",
    "def cluster_bootstrap_ci(\n",
    "    df: pd.DataFrame,\n",
    "    y_col: str,\n",
    "    p_col: str,\n",
    "    metric: str,\n",
    "    cluster_col: str = \"firm_id\",\n",
    "    n_boot: int = 1000,\n",
    "    alpha: float = 0.05,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    y = df[y_col].astype(int).values\n",
    "    p = df[p_col].astype(float).values\n",
    "\n",
    "    point = _metric_safe(y, p, metric)\n",
    "    groups = _cluster_groups(df, cluster_col)\n",
    "    G = len(groups)\n",
    "    if G == 0:\n",
    "        return point, np.nan, np.nan, 0\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vals = []\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        # sample clusters with replacement (same number of clusters)\n",
    "        sampled = rng.integers(0, G, size=G)\n",
    "        idx = np.concatenate([groups[g] for g in sampled])\n",
    "        v = _metric_safe(y[idx], p[idx], metric)\n",
    "        if v == v:  # not NaN\n",
    "            vals.append(v)\n",
    "\n",
    "    if len(vals) == 0:\n",
    "        return point, np.nan, np.nan, 0\n",
    "\n",
    "    lo = float(np.quantile(vals, alpha/2))\n",
    "    hi = float(np.quantile(vals, 1 - alpha/2))\n",
    "    return point, lo, hi, len(vals)\n",
    "\n",
    "def cluster_bootstrap_diff_test(\n",
    "    df: pd.DataFrame,\n",
    "    y_col: str,\n",
    "    p1_col: str,\n",
    "    p2_col: str,\n",
    "    metric: str = \"roc_auc\",\n",
    "    cluster_col: str = \"firm_id\",\n",
    "    n_boot: int = 1000,\n",
    "    alpha: float = 0.05,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    y = df[y_col].astype(int).values\n",
    "    p1 = df[p1_col].astype(float).values\n",
    "    p2 = df[p2_col].astype(float).values\n",
    "\n",
    "    point = _metric_safe(y, p1, metric) - _metric_safe(y, p2, metric)\n",
    "\n",
    "    groups = _cluster_groups(df, cluster_col)\n",
    "    G = len(groups)\n",
    "    if G == 0:\n",
    "        return point, np.nan, np.nan, np.nan, 0\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    diffs = []\n",
    "\n",
    "    for _ in range(n_boot):\n",
    "        sampled = rng.integers(0, G, size=G)\n",
    "        idx = np.concatenate([groups[g] for g in sampled])\n",
    "        m1 = _metric_safe(y[idx], p1[idx], metric)\n",
    "        m2 = _metric_safe(y[idx], p2[idx], metric)\n",
    "        if (m1 == m1) and (m2 == m2):\n",
    "            diffs.append(m1 - m2)\n",
    "\n",
    "    if len(diffs) == 0:\n",
    "        return point, np.nan, np.nan, np.nan, 0\n",
    "\n",
    "    diffs = np.asarray(diffs, dtype=float)\n",
    "    lo = float(np.quantile(diffs, alpha/2))\n",
    "    hi = float(np.quantile(diffs, 1 - alpha/2))\n",
    "\n",
    "    # Two-sided p-value from the bootstrap sign distribution (paired)\n",
    "    p_le0 = float(np.mean(diffs <= 0))\n",
    "    p_ge0 = float(np.mean(diffs >= 0))\n",
    "    pval = 2 * min(p_le0, p_ge0)\n",
    "    pval = float(min(max(pval, 0.0), 1.0))\n",
    "\n",
    "    return point, lo, hi, pval, len(diffs)\n",
    "\n",
    "# -------------------------\n",
    "# Multiple-testing adjustment helpers\n",
    "# -------------------------\n",
    "def p_adjust_bonferroni(pvals: np.ndarray) -> np.ndarray:\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    return np.minimum(p * len(p), 1.0)\n",
    "\n",
    "def p_adjust_holm(pvals: np.ndarray) -> np.ndarray:\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    m = len(p)\n",
    "    order = np.argsort(p)\n",
    "    adj = np.empty(m, dtype=float)\n",
    "    for i, idx in enumerate(order):\n",
    "        adj[idx] = (m - i) * p[idx]\n",
    "    # enforce monotonicity in sorted order\n",
    "    adj_sorted = np.maximum.accumulate(adj[order])\n",
    "    adj[order] = np.minimum(adj_sorted, 1.0)\n",
    "    return adj\n",
    "\n",
    "# -------------------------\n",
    "# Run on test set (df_model + TARGET_NAME)\n",
    "# -------------------------\n",
    "mask_te = df_model[\"split\"] == \"test\"\n",
    "df_te = df_model.loc[mask_te, :].copy()\n",
    "\n",
    "# Collect probability columns available (extend easily)\n",
    "candidate_cols = [\n",
    "    (\"logit\", \"pd_logit\"),\n",
    "    (\"tree_calibrated\", \"pd_tree\"),\n",
    "]\n",
    "\n",
    "models = {name: col for name, col in candidate_cols if col in df_te.columns}\n",
    "\n",
    "if len(models) == 0:\n",
    "    print(\"No model probability columns found in df_model (expected pd_logit / pd_tree).\")\n",
    "else:\n",
    "    # --- Cluster bootstrap CIs for each model (and baseline if desired)\n",
    "    rows = []\n",
    "    for name, col in models.items():\n",
    "        for metric in [\"roc_auc\", \"pr_auc\", \"brier\"]:\n",
    "            pt, lo, hi, n_eff = cluster_bootstrap_ci(\n",
    "                df_te, TARGET_NAME, col, metric=metric, cluster_col=\"firm_id\", n_boot=N_BOOT, alpha=ALPHA, seed=SEED_BOOT\n",
    "            )\n",
    "            rows.append({\n",
    "                \"model\": name,\n",
    "                \"metric\": metric,\n",
    "                \"point\": pt,\n",
    "                \"ci_lo\": lo,\n",
    "                \"ci_hi\": hi,\n",
    "                \"boot_repl_used\": n_eff,\n",
    "            })\n",
    "\n",
    "    ci_tbl = pd.DataFrame(rows).sort_values([\"metric\", \"model\"])\n",
    "    display(ci_tbl)\n",
    "\n",
    "    # --- Pairwise paired cluster-bootstrap tests (ROC-AUC diff)\n",
    "    if len(models) < 2:\n",
    "        print(\"Skipping pairwise model comparisons: need at least two model probability columns.\")\n",
    "    else:\n",
    "        comp_rows = []\n",
    "        for (n1, c1), (n2, c2) in combinations(models.items(), 2):\n",
    "            diff_pt, diff_lo, diff_hi, pval, n_eff = cluster_bootstrap_diff_test(\n",
    "                df_te, TARGET_NAME, c1, c2, metric=\"roc_auc\", cluster_col=\"firm_id\", n_boot=N_BOOT, alpha=ALPHA, seed=123\n",
    "            )\n",
    "            comp_rows.append({\n",
    "                \"model_1\": n1,\n",
    "                \"model_2\": n2,\n",
    "                \"roc_auc_diff_(1-2)\": diff_pt,\n",
    "                \"diff_ci_lo\": diff_lo,\n",
    "                \"diff_ci_hi\": diff_hi,\n",
    "                \"p_value\": pval,\n",
    "                \"boot_repl_used\": n_eff,\n",
    "            })\n",
    "\n",
    "        comp_tbl = pd.DataFrame(comp_rows)\n",
    "        if not comp_tbl.empty:\n",
    "            comp_tbl[\"p_bonferroni\"] = p_adjust_bonferroni(comp_tbl[\"p_value\"].values)\n",
    "            comp_tbl[\"p_holm\"] = p_adjust_holm(comp_tbl[\"p_value\"].values)\n",
    "            display(comp_tbl.sort_values(\"p_value\"))\n",
    "        else:\n",
    "            print(\"No pairwise comparisons computed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce4a5617",
   "metadata": {},
   "source": [
    "mask = df_model[\"split\"]==\"test\"\n",
    "y_true = df_model.loc[mask, TARGET_NAME].astype(int)\n",
    "\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol]\n",
    "    plt.figure()\n",
    "    plt.hist(p[y_true==0], bins=50, alpha=0.6, label=\"y=0\")\n",
    "    plt.hist(p[y_true==1], bins=50, alpha=0.6, label=\"y=1\")\n",
    "    plt.title(f\"Test PD histogram by class — {model_name}\")\n",
    "    plt.xlabel(\"Predicted PD\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"pd_hist_{model_name}_test.png\", dpi=160)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50013862",
   "metadata": {},
   "source": [
    "## 9b. Operational Risk Management Layer (Events + PDs)\n",
    "This section uses a **two-layer** design:\n",
    "\n",
    "- **Model layer (prediction):** calibrated probability of next-year distress (**PD**) from accounting ratios and structural predictors.\n",
    "- **Indicator layer (events):** discrete `evt_*` early-warning indicators **not used as predictors**. They serve governance, monitoring, and decision support.\n",
    "\n",
    "This structure matches four operational functions commonly discussed in risk-management systems:\n",
    "\n",
    "1. **Risk awareness:** documented prior knowledge of which indicators flag trouble (event dictionary + empirical lift).\n",
    "2. **Monitoring and warning:** continuous tracking of event activation/persistence and PD levels over the panel.\n",
    "3. **Communication:** translating signals into decision-maker-friendly views (risk tiers/deciles, transitions, reason codes).\n",
    "4. **Response capability:** predefined action rules (screen / monitor / no action) based on PDs and events under explicit costs and capacity constraints.\n",
    "\n",
    "### 9.1 Risk awareness — event dictionary and conditional risk (lift)"
   ]
  },
  {
   "cell_type": "code",
   "id": "94c3906b",
   "metadata": {},
   "source": [
    "EVT_COLS = event_dict[\"event\"].tolist()\n",
    "print(\"Decision-support events:\", EVT_COLS)\n",
    "\n",
    "# Optional: enrich the event dictionary with a simple mechanism taxonomy (appendix-ready)\n",
    "event_dict_enriched = event_dict.copy()\n",
    "mech_map = {\n",
    "    \"evt_divcut\": \"Payout policy\",\n",
    "    \"evt_divsusp\": \"Payout policy\",\n",
    "    \"evt_divinit\": \"Payout policy\",\n",
    "    \"evt_liq_squeeze\": \"Liquidity\",\n",
    "    \"evt_quick_squeeze\": \"Liquidity\",\n",
    "    \"evt_ebitdadrop\": \"Operating deterioration\",\n",
    "    \"evt_cfdrop\": \"Operating deterioration\",\n",
    "}\n",
    "event_dict_enriched[\"mechanism\"] = event_dict_enriched[\"event\"].map(mech_map).fillna(\"Other/unspecified\")\n",
    "display(event_dict_enriched)\n",
    "\n",
    "def event_lift_table(df_in: pd.DataFrame, events: list[str], y_col: str) -> pd.DataFrame:\n",
    "    # Event lift with explicit missingness handling.\n",
    "    # - prevalence_obs: among observations where the event is observed (not NA)\n",
    "    # - missing_rate: definitional missingness (insufficient inputs)\n",
    "    # - cond_distress_rate: P(y=1 | evt=1, evt observed)\n",
    "\n",
    "    base = df_in[y_col].astype(float).mean()\n",
    "    rows = []\n",
    "    for e in events:\n",
    "        if e not in df_in.columns:\n",
    "            continue\n",
    "\n",
    "        s = pd.to_numeric(df_in[e], errors=\"coerce\")  # may contain NA by construction\n",
    "        miss = float(s.isna().mean())\n",
    "        obs = s.notna()\n",
    "        if obs.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        s_obs = s[obs].astype(int)\n",
    "        n_event = int((s_obs == 1).sum())\n",
    "        if n_event == 0:\n",
    "            continue\n",
    "\n",
    "        rate = df_in.loc[obs & (s == 1), y_col].astype(float).mean()\n",
    "        prev = float((s_obs == 1).mean())\n",
    "\n",
    "        rows.append({\n",
    "            \"event\": e,\n",
    "            \"mechanism\": mech_map.get(e, \"Other/unspecified\"),\n",
    "            \"n_obs_event\": int(obs.sum()),\n",
    "            \"n_event\": n_event,\n",
    "            \"missing_rate\": miss,\n",
    "            \"prevalence_obs\": prev,\n",
    "            \"cond_distress_rate\": float(rate),\n",
    "            \"base_rate\": float(base),\n",
    "            \"lift_vs_base\": float(rate/base) if base > 0 else np.nan,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    if not out.empty:\n",
    "        out = out.sort_values([\"lift_vs_base\", \"n_event\"], ascending=[False, False])\n",
    "    return out\n",
    "\n",
    "for sp in [\"train\", \"test\"]:\n",
    "    df_sp = df_model.loc[df_model[\"split\"] == sp, :].copy()\n",
    "    print(f\"\\nEvent lift (labels: {TARGET_NAME}) — {sp}\")\n",
    "    display(event_lift_table(df_sp, EVT_COLS, TARGET_NAME).head(25))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35162ffd",
   "metadata": {},
   "source": [
    "### 9.2 Monitoring and warning — event dynamics, persistence, and PD×event risk grids\n",
    "\n",
    "Monitoring should reflect (i) **activation** (0→1), (ii) **persistence** (1→1), and (iii) how event regimes interact with PDs.\n",
    "We treat events as *operational indicators* (not predictors) and monitor them jointly with calibrated PDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "aaa8fd1b",
   "metadata": {},
   "source": [
    "# --- 9.2A Event activation and persistence (adjacency-safe) ---\n",
    "def transition_stats(df_in: pd.DataFrame, event: str) -> dict:\n",
    "    # Robust transition stats that enforce year adjacency and handle NaNs.\n",
    "    s = pd.to_numeric(df_in[event], errors=\"coerce\")\n",
    "    s_l1 = lag(df_in, event, 1)\n",
    "\n",
    "    valid = s.notna() & s_l1.notna()\n",
    "    if valid.sum() == 0:\n",
    "        return {\"event\": event, \"activation_01_rate\": np.nan, \"persistence_11_rate\": np.nan, \"n_transitions\": 0}\n",
    "\n",
    "    s0 = s_l1[valid].astype(int)\n",
    "    s1 = s[valid].astype(int)\n",
    "\n",
    "    act_01 = ((s0 == 0) & (s1 == 1)).mean()\n",
    "    pers_11 = ((s0 == 1) & (s1 == 1)).mean()\n",
    "    return {\n",
    "        \"event\": event,\n",
    "        \"activation_01_rate\": float(act_01),\n",
    "        \"persistence_11_rate\": float(pers_11),\n",
    "        \"n_transitions\": int(valid.sum()),\n",
    "    }\n",
    "\n",
    "rows = [transition_stats(df_model, e) for e in EVT_COLS]\n",
    "trans_tbl = pd.DataFrame(rows)\n",
    "if not trans_tbl.empty:\n",
    "    trans_tbl = trans_tbl.sort_values(\"activation_01_rate\", ascending=False)\n",
    "display(trans_tbl)\n",
    "\n",
    "# --- 9.2B Monitoring summary by fiscal year (panel-level tracking) ---\n",
    "def monitoring_by_year(df_in: pd.DataFrame, p_col: str, y_col: str, evt_cols: list[str]) -> pd.DataFrame:\n",
    "    d = df_in[[\"fyear\", \"split\", p_col, y_col] + evt_cols].copy()\n",
    "\n",
    "    # Event aggregation: triggered count; missingness summarized separately.\n",
    "    evt_mat = d[evt_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    d[\"evt_missing_rate_mean\"] = evt_mat.isna().mean(axis=1)\n",
    "    d[\"evt_count\"] = (evt_mat.fillna(0) == 1).sum(axis=1)\n",
    "    d[\"evt_any\"] = (d[\"evt_count\"] > 0).astype(int)\n",
    "\n",
    "    out = (d.groupby([\"split\", \"fyear\"])\n",
    "             .agg(\n",
    "                 n=(\"fyear\",\"size\"),\n",
    "                 mean_pd=(p_col,\"mean\"),\n",
    "                 realized_rate=(y_col,\"mean\"),\n",
    "                 evt_any_rate=(\"evt_any\",\"mean\"),\n",
    "                 mean_evt_count=(\"evt_count\",\"mean\"),\n",
    "                 mean_evt_missing=(\"evt_missing_rate_mean\",\"mean\"),\n",
    "             )\n",
    "             .reset_index()\n",
    "             .sort_values([\"split\",\"fyear\"]))\n",
    "    return out\n",
    "\n",
    "print(\"\\nMonitoring by year — calibrated tree PD (pd_tree)\")\n",
    "display(monitoring_by_year(df_model, \"pd_tree\", TARGET_NAME, EVT_COLS).head(40))\n",
    "\n",
    "# --- 9.2C PD × Event risk grid (operational triangulation) ---\n",
    "def pd_event_grid(df_in: pd.DataFrame, p_col: str, y_col: str, evt_cols: list[str], n_bins: int = 10) -> pd.DataFrame:\n",
    "    d = df_in[[p_col, y_col] + evt_cols].dropna(subset=[p_col, y_col]).copy()\n",
    "    evt_mat = d[evt_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    d[\"evt_count\"] = (evt_mat.fillna(0) == 1).sum(axis=1)\n",
    "\n",
    "    d[\"evt_bucket\"] = pd.cut(d[\"evt_count\"], bins=[-0.1, 0.5, 1.5, 10**6], labels=[\"0\", \"1\", \"2+\"])\n",
    "    d[\"pd_decile\"] = pd.qcut(d[p_col], q=n_bins, labels=False, duplicates=\"drop\") + 1\n",
    "\n",
    "    g = (d.groupby([\"pd_decile\",\"evt_bucket\"])\n",
    "           .agg(\n",
    "               n=(\"pd_decile\",\"size\"),\n",
    "               mean_pd=(p_col,\"mean\"),\n",
    "               realized_rate=(y_col,\"mean\"),\n",
    "           )\n",
    "           .reset_index())\n",
    "    return g.sort_values([\"pd_decile\",\"evt_bucket\"])\n",
    "\n",
    "print(\"\\nTest split PD × Events grid — calibrated tree\")\n",
    "display(pd_event_grid(df_model.loc[df_model[\"split\"]==\"test\", :], \"pd_tree\", TARGET_NAME, EVT_COLS, n_bins=10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89c18d2c",
   "metadata": {},
   "source": [
    "### 9.3 Communication — risk tiers, transitions, and reason codes\n",
    "\n",
    "Communication should translate model outputs and indicator triggers into decision-maker-friendly artifacts:\n",
    "\n",
    "- **Risk tiers/deciles:** expected vs realized risk by PD bucket.\n",
    "- **Transitions:** PD movements and event activations/persistence.\n",
    "- **Reason codes:** simple, interpretable attributions for material PD jumps (based on newly triggered events).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "48e1cb6a",
   "metadata": {},
   "source": [
    "def decile_table(df_in: pd.DataFrame, p_col: str, y_col: str) -> pd.DataFrame:\n",
    "    d = df_in[[p_col, y_col]].dropna().copy()\n",
    "    d[\"decile\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\"drop\") + 1\n",
    "    out = d.groupby(\"decile\").agg(\n",
    "        n=(\"decile\",\"size\"),\n",
    "        mean_pd=(p_col,\"mean\"),\n",
    "        realized_rate=(y_col,\"mean\"),\n",
    "    ).reset_index()\n",
    "    out[\"calibration_gap\"] = out[\"realized_rate\"] - out[\"mean_pd\"]\n",
    "    return out\n",
    "\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    print(f\"\\nTest deciles — {model_name}\")\n",
    "    dt = decile_table(df_model.loc[df_model[\"split\"]==\"test\", :], pcol, TARGET_NAME)\n",
    "    display(dt)\n",
    "    # --- 9.3A Reason codes for large PD jumps (event-based) ---\n",
    "# When PD decile increases materially year-over-year, summarize which events newly activated.\n",
    "\n",
    "def reason_codes_for_pd_jumps(df_in: pd.DataFrame, p_col: str, evt_cols: list[str], min_decile_jump: int = 3, split: str = \"test\") -> pd.DataFrame:\n",
    "    d = df_in.loc[df_in[\"split\"] == split, [\"firm_id\",\"fyear\", p_col] + evt_cols].copy()\n",
    "    d = d.sort_values([\"firm_id\",\"fyear\"])\n",
    "\n",
    "    # PD deciles within the split (communication tiering)\n",
    "    d[\"pd_decile\"] = pd.qcut(d[p_col], 10, labels=False, duplicates=\"drop\") + 1\n",
    "    d[\"pd_decile_l1\"] = lag(d, \"pd_decile\", 1)\n",
    "    d[\"decile_jump\"] = d[\"pd_decile\"] - d[\"pd_decile_l1\"]\n",
    "\n",
    "    jump_mask = d[\"decile_jump\"].notna() & (d[\"decile_jump\"] >= min_decile_jump)\n",
    "    if int(jump_mask.sum()) == 0:\n",
    "        return pd.DataFrame(columns=[\"event\",\"n_new_activation_in_jumps\",\"share_of_jumps\"])\n",
    "\n",
    "    n_jumps = int(jump_mask.sum())\n",
    "    rows = []\n",
    "    for e in evt_cols:\n",
    "        s = pd.to_numeric(d[e], errors=\"coerce\")\n",
    "        s_l1 = lag(d, e, 1)\n",
    "        valid = jump_mask & s.notna() & s_l1.notna()\n",
    "        if int(valid.sum()) == 0:\n",
    "            continue\n",
    "        new_act = int(((s_l1[valid].astype(int) == 0) & (s[valid].astype(int) == 1)).sum())\n",
    "        if new_act > 0:\n",
    "            rows.append({\n",
    "                \"event\": e,\n",
    "                \"n_new_activation_in_jumps\": new_act,\n",
    "                \"share_of_jumps\": float(new_act / n_jumps),\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"n_new_activation_in_jumps\", ascending=False)\n",
    "    return out\n",
    "\n",
    "print(\"\\nReason codes — events newly activating during large PD jumps (test split)\")\n",
    "display(reason_codes_for_pd_jumps(df_model, \"pd_tree\", EVT_COLS, min_decile_jump=3, split=\"test\").head(20))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2fc0a52a",
   "metadata": {},
   "source": [
    "### 9.4 Response capability — predefined action rules under costs and capacity\n",
    "\n",
    "We translate PDs and `evt_*` indicators into an operational policy with three actions:\n",
    "\n",
    "- **Screen / Review** (capacity-limited): highest-risk firms warrant immediate attention.\n",
    "- **Monitor more closely**: elevated risk, but not high enough for immediate screening.\n",
    "- **No action**: routine monitoring only.\n",
    "\n",
    "We compare:\n",
    "- **PD-only policy** (threshold on PD),\n",
    "- **Hybrid policy** (PD + event burden) that can prioritize “indicator-led” cases without retraining the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "66ca9b6f",
   "metadata": {},
   "source": [
    "COST_FN = float(CONFIG[\"COST_FN\"])\n",
    "COST_FP = float(CONFIG[\"COST_FP\"])\n",
    "CAPACITY_PCT = float(CONFIG[\"CAPACITY_PCT\"])\n",
    "MONITOR_PCT = float(CONFIG.get(\"MONITOR_PCT\", min(0.20, 2*CAPACITY_PCT)))  # fallback: monitor top 20% or 2x capacity\n",
    "\n",
    "def expected_cost(y_true: np.ndarray, y_hat: np.ndarray) -> float:\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    return COST_FN*fn + COST_FP*fp\n",
    "\n",
    "def apply_pd_only_policy(p: np.ndarray, thr_screen: float, thr_monitor: float) -> dict:\n",
    "    screen = (p >= thr_screen).astype(int)\n",
    "    monitor = ((p >= thr_monitor) & (p < thr_screen)).astype(int)\n",
    "    return {\"screen\": screen, \"monitor\": monitor}\n",
    "\n",
    "def apply_hybrid_policy(p: np.ndarray, evt_count: np.ndarray, alpha: float = 0.05, beta: float = 0.10) -> dict:\n",
    "    \"\"\"Hybrid prioritization score:\n",
    "      score = p + alpha*1{evt_any} + beta*1{evt_count>=2}\n",
    "    Screening/monitoring are then capacity-based on the score.\"\"\"\n",
    "    evt_any = (evt_count > 0).astype(int)\n",
    "    score = p + alpha*evt_any + beta*(evt_count >= 2).astype(int)\n",
    "    thr_score_screen = float(np.quantile(score, 1-CAPACITY_PCT))\n",
    "    thr_score_monitor = float(np.quantile(score, 1-MONITOR_PCT))\n",
    "    screen = (score >= thr_score_screen).astype(int)\n",
    "    monitor = ((score >= thr_score_monitor) & (score < thr_score_screen)).astype(int)\n",
    "    return {\"screen\": screen, \"monitor\": monitor, \"score\": score, \"thr_score_screen\": thr_score_screen, \"thr_score_monitor\": thr_score_monitor}\n",
    "\n",
    "def build_evt_count(df_in: pd.DataFrame, evt_cols: list[str]) -> np.ndarray:\n",
    "    evt_mat = df_in[evt_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return (evt_mat.fillna(0) == 1).sum(axis=1).values\n",
    "\n",
    "# --- Threshold selection (validation only) for PD-only policy ---\n",
    "grid = np.linspace(0.01, 0.99, 99)\n",
    "mask_val = df_model[\"split\"] == \"val\"\n",
    "y_val = df_model.loc[mask_val, TARGET_NAME].astype(int).values\n",
    "\n",
    "thr_tbls = {}\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p_val = df_model.loc[mask_val, pcol].values\n",
    "\n",
    "    # Cost-opt threshold\n",
    "    costs = []\n",
    "    for thr in grid:\n",
    "        costs.append(expected_cost(y_val, (p_val >= thr).astype(int)))\n",
    "    thr_cost_opt = float(grid[int(np.argmin(costs))])\n",
    "\n",
    "    # Capacity and monitoring thresholds (operational)\n",
    "    thr_capacity = float(np.quantile(p_val, 1-CAPACITY_PCT))\n",
    "    thr_monitor = float(np.quantile(p_val, 1-MONITOR_PCT))\n",
    "\n",
    "    thr_tbls[model_name] = {\"thr_cost_opt\": thr_cost_opt, \"thr_capacity\": thr_capacity, \"thr_monitor\": thr_monitor}\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(grid, costs)\n",
    "    plt.title(f\"Validation expected cost vs PD threshold — {model_name}\")\n",
    "    plt.xlabel(\"PD threshold\")\n",
    "    plt.ylabel(\"Expected misclassification cost\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / f\"cost_curve_{model_name}_val.png\", dpi=160)\n",
    "    plt.show()\n",
    "\n",
    "display(pd.DataFrame(thr_tbls).T)\n",
    "\n",
    "# --- Policy comparison on TEST: PD-only vs Hybrid (PD + events) ---\n",
    "mask_test = df_model[\"split\"] == \"test\"\n",
    "y_test = df_model.loc[mask_test, TARGET_NAME].astype(int).values\n",
    "evt_count_test = build_evt_count(df_model.loc[mask_test, :], EVT_COLS)\n",
    "\n",
    "rows = []\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p_test = df_model.loc[mask_test, pcol].values\n",
    "\n",
    "    thr_screen = thr_tbls[model_name][\"thr_capacity\"]\n",
    "    thr_monitor = thr_tbls[model_name][\"thr_monitor\"]\n",
    "\n",
    "    # PD-only (screen decision)\n",
    "    polA = apply_pd_only_policy(p_test, thr_screen, thr_monitor)\n",
    "    costA = expected_cost(y_test, polA[\"screen\"])\n",
    "    capA = float(polA[\"screen\"].mean())\n",
    "    tprA = float(((polA[\"screen\"]==1) & (y_test==1)).sum() / max(1, (y_test==1).sum()))\n",
    "    ppvA = float(((polA[\"screen\"]==1) & (y_test==1)).sum() / max(1, (polA[\"screen\"]==1).sum()))\n",
    "\n",
    "    # Hybrid (screen decision derived from capacity on composite score)\n",
    "    polB = apply_hybrid_policy(p_test, evt_count_test, alpha=0.05, beta=0.10)\n",
    "    costB = expected_cost(y_test, polB[\"screen\"])\n",
    "    capB = float(polB[\"screen\"].mean())\n",
    "    tprB = float(((polB[\"screen\"]==1) & (y_test==1)).sum() / max(1, (y_test==1).sum()))\n",
    "    ppvB = float(((polB[\"screen\"]==1) & (y_test==1)).sum() / max(1, (polB[\"screen\"]==1).sum()))\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"policy\": \"PD-only\",\n",
    "        \"screen_rate\": capA,\n",
    "        \"monitor_rate\": float(polA[\"monitor\"].mean()),\n",
    "        \"tpr_screen\": tprA,\n",
    "        \"ppv_screen\": ppvA,\n",
    "        \"expected_cost\": costA,\n",
    "        \"thr_screen_pd\": thr_screen,\n",
    "        \"thr_monitor_pd\": thr_monitor,\n",
    "    })\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"policy\": \"Hybrid (PD + events)\",\n",
    "        \"screen_rate\": capB,\n",
    "        \"monitor_rate\": float(polB[\"monitor\"].mean()),\n",
    "        \"tpr_screen\": tprB,\n",
    "        \"ppv_screen\": ppvB,\n",
    "        \"expected_cost\": costB,\n",
    "        \"thr_screen_score\": polB[\"thr_score_screen\"],\n",
    "        \"thr_monitor_score\": polB[\"thr_score_monitor\"],\n",
    "        \"alpha_evt_any\": 0.05,\n",
    "        \"beta_evt_2plus\": 0.10,\n",
    "    })\n",
    "\n",
    "policy_cmp = pd.DataFrame(rows).sort_values([\"model\",\"policy\"])\n",
    "print(\"\\nPolicy comparison on TEST (screen decision):\")\n",
    "display(policy_cmp)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e71b677",
   "metadata": {},
   "source": [
    "### 9.4.1 Decision curve analysis (net benefit)\n",
    "\n",
    "Decision curves provide an alternative view of “response capability”: the net benefit of acting at different PD thresholds (treat-all vs treat-none baselines)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fce9eda2",
   "metadata": {},
   "source": [
    "def net_benefit(y_true: np.ndarray, p: np.ndarray, pt: float) -> float:\n",
    "    y_hat = (p >= pt).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    n = len(y_true)\n",
    "    w = pt/(1-pt)\n",
    "    return (tp/n) - (fp/n)*w\n",
    "\n",
    "mask = df_model[\"split\"]==\"test\"\n",
    "y_test_np = df_model.loc[mask, TARGET_NAME].astype(int).values\n",
    "\n",
    "pts = np.linspace(0.01, 0.50, 50)\n",
    "plt.figure()\n",
    "for model_name, pcol in [(\"logit\",\"pd_logit\"), (\"tree_calibrated\",\"pd_tree\")]:\n",
    "    p = df_model.loc[mask, pcol].values\n",
    "    nb = [net_benefit(y_test_np, p, pt) for pt in pts]\n",
    "    plt.plot(pts, nb, label=model_name)\n",
    "\n",
    "# Treat-all and treat-none baselines\n",
    "event_rate = y_test_np.mean()\n",
    "nb_all = [event_rate - (1-event_rate)*(pt/(1-pt)) for pt in pts]\n",
    "nb_none = [0 for _ in pts]\n",
    "plt.plot(pts, nb_all, linestyle=\"--\", label=\"treat-all\")\n",
    "plt.plot(pts, nb_none, linestyle=\"--\", label=\"treat-none\")\n",
    "\n",
    "plt.title(\"Decision curves (test split): net benefit vs threshold probability\")\n",
    "plt.xlabel(\"Threshold probability (pt)\")\n",
    "plt.ylabel(\"Net benefit\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(CONFIG[\"FIG_DIR\"]) / \"decision_curves_test.png\", dpi=160)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "11412605",
   "metadata": {},
   "source": [
    "### 9.5 Scenario analysis (liquidity insurance vs liquidity fragility)\n",
    "\n",
    "Scenario analysis is a **communication and response** instrument: a structured way to translate plausible managerial / creditor actions and stress environments into PD sensitivity and triage policies—not as causal inference.\n",
    "\n",
    "Below are scenario-analysis use cases that are materially more defensible (and operationally useful) than \"raise current ratio to 1.2\" or \"CFO +10% of assets,\" while still fitting the two-layer architecture (PD model + non-predictor event layer):\n",
    "\n",
    "**2) Liquidity insurance vs liquidity fragility scenarios (cash, working capital, and credit lines)**\n",
    "\n",
    "**Why it is a better use case:**\n",
    "- Instead of targeting an arbitrary current ratio, use liquidity scenarios that map to liquidity insurance mechanisms documented in the literature: cash buffers and bank lines of credit.\n",
    "- Corporate cash holdings are a fundamental margin of safety with systematic determinants and implications.\n",
    "- Lines of credit are a core liquidity management instrument; their availability is state-contingent and interacts with profitability/cash flow.\n",
    "\n",
    "**What to implement (scenario templates):**\n",
    "- **Cash buffer stress:** \"cash burn\" scenario: `che ← che − Δ` (bounded at 0), optionally `oancf ← oancf − Δ` if you want a consistent flow hit.\n",
    "- **Working-capital release** (high realism, accounting-consistent): Reduce receivables and inventory (`rect`, `invt`) by a fraction; increase cash by the same amount. This is typically more plausible than \"CFO +10% of assets\" because it corresponds to collections and inventory liquidation.\n",
    "- **Liquidity squeeze + maturity wall:** shift a portion of `dltt` into `dlc` (or increase `dlc` share) to mimic refinancing risk; recompute short-term debt share and liquidity ratios.\n",
    "\n",
    "**Decision-support outputs:**\n",
    "- PD sensitivity to liquidity burn speed (months of runway proxy; even with annual data, you can approximate).\n",
    "- A liquidity \"traffic light\" that combines PD tier + liquidity events (`evt_liq_squeeze` / `evt_quick_squeeze`) for escalation."
   ]
  },
  {
   "cell_type": "code",
   "id": "350a73f0",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 9.5 Scenario analysis (liquidity insurance vs. fragility)\n",
    "# =============================================================================\n",
    "# Key design choice:\n",
    "# - Do NOT re-run dataset-wide cleaning here (medians, winsor bounds, scaler are already fit upstream).\n",
    "# - For scenarios, start from the already-clean base feature vector (df_model[continuous_feats_raw]) and\n",
    "#   ONLY overwrite features that are mechanically affected by the raw accounting perturbation.\n",
    "# - Then apply the *same* fitted (train) transforms: median fill -> winsor clip -> scaler transform.\n",
    "\n",
    "import traceback, sys, time\n",
    "print(\"[9.5] start\")\n",
    "t0 = time.time()\n",
    "def _checkpoint(msg): print(f\"[9.5] {msg} (t={time.time()-t0:.2f}s)\")\n",
    "\n",
    "def _safe_div(n, d):\n",
    "    try:\n",
    "        n_f = float(n); d_f = float(d)\n",
    "        if pd.isna(n_f) or pd.isna(d_f) or d_f == 0:\n",
    "            return np.nan\n",
    "        return n_f / d_f\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def _build_continuous_features_from_raw(row_raw: pd.Series) -> dict:\n",
    "    \"\"\"Compute only the continuous model features needed, from raw accounting items.\"\"\"\n",
    "    at    = row_raw.get(\"at\", np.nan)\n",
    "    che   = row_raw.get(\"che\", np.nan)\n",
    "    act   = row_raw.get(\"act\", np.nan)\n",
    "    lct   = row_raw.get(\"lct\", np.nan)\n",
    "    rect  = row_raw.get(\"rect\", np.nan)\n",
    "    invt  = row_raw.get(\"invt\", np.nan)\n",
    "    lt    = row_raw.get(\"lt\", np.nan)\n",
    "    dlc   = row_raw.get(\"dlc\", np.nan)\n",
    "    dltt  = row_raw.get(\"dltt\", np.nan)\n",
    "    oibdp = row_raw.get(\"oibdp\", np.nan)\n",
    "    dp    = row_raw.get(\"dp\", np.nan)\n",
    "    xint  = row_raw.get(\"xint\", np.nan)\n",
    "    ceq   = row_raw.get(\"ceq\", np.nan)\n",
    "    capx  = row_raw.get(\"capx\", np.nan)\n",
    "    ppent = row_raw.get(\"ppent\", np.nan)\n",
    "    intan = row_raw.get(\"intan\", np.nan)\n",
    "    oancf = row_raw.get(\"oancf\", np.nan)\n",
    "    re    = row_raw.get(\"re\", np.nan)\n",
    "    niadj = row_raw.get(\"niadj\", np.nan)\n",
    "    prstkc = row_raw.get(\"prstkc\", np.nan)\n",
    "\n",
    "    d_vals = [v for v in [dlc, dltt] if pd.notna(v)]\n",
    "    total_debt = float(np.sum(d_vals)) if len(d_vals) > 0 else np.nan\n",
    "\n",
    "    feat = {}\n",
    "    feat[\"ln_at\"] = np.log(at) if pd.notna(at) and at > 0 else np.nan\n",
    "    feat[\"cash_at\"] = _safe_div(che, at)\n",
    "\n",
    "    feat[\"current_ratio\"] = _safe_div(act, lct)\n",
    "    if pd.notna(act) and pd.notna(invt) and pd.notna(lct) and lct != 0:\n",
    "        feat[\"quick_ratio\"] = _safe_div(act - invt, lct)\n",
    "    elif pd.notna(che) and pd.notna(rect) and pd.notna(lct) and lct != 0:\n",
    "        feat[\"quick_ratio\"] = _safe_div(che + rect, lct)\n",
    "    else:\n",
    "        feat[\"quick_ratio\"] = feat[\"current_ratio\"]\n",
    "\n",
    "    feat[\"nwc_at\"] = _safe_div((act - lct), at)\n",
    "\n",
    "    feat[\"rect_act\"] = _safe_div(rect, act)\n",
    "    feat[\"invt_act\"] = _safe_div(invt, act)\n",
    "\n",
    "    feat[\"lt_at\"] = _safe_div(lt, at)\n",
    "    feat[\"dlc_at\"] = _safe_div(dlc, at)\n",
    "    feat[\"dltt_at\"] = _safe_div(dltt, at)\n",
    "    feat[\"debt_at\"] = _safe_div(total_debt, at)\n",
    "    feat[\"st_debt_share\"] = _safe_div(dlc, total_debt)\n",
    "\n",
    "    feat[\"ebitda_at\"] = _safe_div(oibdp, at)\n",
    "    feat[\"xint_at\"] = _safe_div(xint, at)\n",
    "    feat[\"interest_coverage\"] = _safe_div(oibdp, xint)\n",
    "    feat[\"debt_to_ebitda\"] = _safe_div(total_debt, oibdp)\n",
    "    feat[\"ebit_to_capital\"] = _safe_div((oibdp - dp), (total_debt + ceq))\n",
    "\n",
    "    feat[\"ppent_at\"] = _safe_div(ppent, at)\n",
    "    feat[\"intan_at\"] = _safe_div(intan, at)\n",
    "    feat[\"ocf_to_debt\"] = _safe_div(oancf, total_debt)\n",
    "    feat[\"fcf_to_debt\"] = _safe_div((oancf - capx), total_debt)\n",
    "    feat[\"re_at\"] = _safe_div(re, at)\n",
    "\n",
    "    feat[\"ceq_at\"] = _safe_div(ceq, at)\n",
    "    feat[\"niadj_at\"] = _safe_div(niadj, at)\n",
    "    feat[\"prstkc_at\"] = _safe_div(prstkc, at)\n",
    "    return feat\n",
    "\n",
    "def build_model_features_from_raw_scenario(row_raw: pd.Series, base_feature_row: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build the model feature vector for a scenario without redoing dataset-wide cleaning.\n",
    "    - Start from already-clean feature values (base_feature_row[continuous_feats_raw]).\n",
    "    - Overwrite features mechanically implied by the scenario raw row.\n",
    "    - Apply the fitted preprocessing (train medians, winsor bounds, scaler).\n",
    "    \"\"\"\n",
    "    out_cont = pd.Series({c: float(base_feature_row[c]) for c in continuous_feats_raw})\n",
    "\n",
    "    feat_updates = _build_continuous_features_from_raw(row_raw)\n",
    "    for k, v in feat_updates.items():\n",
    "        if k in out_cont.index:\n",
    "            out_cont[k] = v\n",
    "\n",
    "    out = pd.DataFrame([out_cont.to_dict()])\n",
    "\n",
    "    for c in continuous_feats_raw:\n",
    "        v = out[c].replace([np.inf, -np.inf], np.nan)\n",
    "        v = v.fillna(train_medians[c])\n",
    "        lo, hi = winsor_bounds[c]\n",
    "        v = apply_bounds(v, lo, hi)\n",
    "        out[c] = v\n",
    "\n",
    "    Z = scaler.transform(out[continuous_feats_raw].astype(float))\n",
    "    for j, c in enumerate(continuous_feats_raw):\n",
    "        out[f\"z_{c}\"] = Z[:, j]\n",
    "\n",
    "    # keep events from base (decision-support layer not redefined here)\n",
    "    for e in event_feats:\n",
    "        out[e] = int(base_feature_row[e]) if e in base_feature_row.index else 0\n",
    "\n",
    "    return out[[f\"z_{c}\" for c in continuous_feats_raw] + event_feats]\n",
    "\n",
    "def predict_pd_from_features(X_row: pd.DataFrame) -> dict:\n",
    "    try:\n",
    "        pd_logit = float(logit_clf.predict_proba(X_row)[:, 1][0])\n",
    "        drow = xgb.DMatrix(X_row, feature_names=X_row.columns.tolist())\n",
    "        pd_tree_raw = float(xgb_model.predict(drow)[0])\n",
    "        pd_tree = float(iso.transform([pd_tree_raw])[0])\n",
    "        return {\"pd_logit\": pd_logit, \"pd_tree\": pd_tree}\n",
    "    except Exception as e:\n",
    "        print(\"[9.5] Exception in predict_pd_from_features:\", repr(e))\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def compute_liquidity_from_raw_row(row_data: pd.Series) -> dict:\n",
    "    act  = row_data.get(\"act\", np.nan)\n",
    "    lct  = row_data.get(\"lct\", np.nan)\n",
    "    invt = row_data.get(\"invt\", np.nan)\n",
    "    che  = row_data.get(\"che\", np.nan)\n",
    "    rect = row_data.get(\"rect\", np.nan)\n",
    "\n",
    "    cr = _safe_div(act, lct)\n",
    "    if pd.notna(act) and pd.notna(invt) and pd.notna(lct) and lct != 0:\n",
    "        qr = _safe_div(act - invt, lct)\n",
    "    elif pd.notna(che) and pd.notna(rect) and pd.notna(lct) and lct != 0:\n",
    "        qr = _safe_div(che + rect, lct)\n",
    "    else:\n",
    "        qr = cr\n",
    "\n",
    "    return {\n",
    "        \"current_ratio\": cr,\n",
    "        \"quick_ratio\": qr,\n",
    "        \"evt_liq_squeeze\": 1.0 if (pd.notna(cr) and cr < 1.0) else 0.0,\n",
    "        \"evt_quick_squeeze\": 1.0 if (pd.notna(qr) and qr < 0.8) else 0.0,\n",
    "    }\n",
    "\n",
    "def get_traffic_light(pd_logit: float, evt_liq: float, evt_quick: float) -> str:\n",
    "    if pd_logit < 0.2:\n",
    "        pd_tier = \"Low\"\n",
    "    elif pd_logit < 0.5:\n",
    "        pd_tier = \"Medium\"\n",
    "    else:\n",
    "        pd_tier = \"High\"\n",
    "\n",
    "    has_liq = (evt_liq > 0.5) or (evt_quick > 0.5)\n",
    "    if pd_tier == \"Low\" and not has_liq:\n",
    "        return \"Green\"\n",
    "    if pd_tier == \"High\" and has_liq:\n",
    "        return \"Red\"\n",
    "    return \"Yellow\"\n",
    "\n",
    "def sensitivity_audit(base_X: pd.DataFrame, scen_X: pd.DataFrame, threshold: float = 1e-4, top_k: int = 15) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for feat in continuous_feats_raw:\n",
    "        zb = float(base_X[f\"z_{feat}\"].iloc[0])\n",
    "        zs = float(scen_X[f\"z_{feat}\"].iloc[0])\n",
    "        delta = zs - zb\n",
    "        rows.append({\"feature\": feat, \"z_base\": zb, \"z_scenario\": zs, \"z_delta\": delta})\n",
    "\n",
    "    df_audit = pd.DataFrame(rows, columns=[\"feature\", \"z_base\", \"z_scenario\", \"z_delta\"])\n",
    "    df_audit[\"abs_z_delta\"] = df_audit[\"z_delta\"].abs()\n",
    "    df_audit = df_audit.sort_values(\"abs_z_delta\", ascending=False)\n",
    "\n",
    "    df_sig = df_audit.loc[df_audit[\"abs_z_delta\"] > threshold].copy() if threshold > 0 else df_audit.copy()\n",
    "    df_top = df_audit.head(int(top_k)).copy()\n",
    "\n",
    "    df_top.attrs[\"material_count\"] = int(len(df_sig))\n",
    "    df_top.attrs[\"material_table\"] = df_sig\n",
    "    return df_top\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Select a sensitivity-safe representative observation\n",
    "# -----------------------------------------------------------------------------\n",
    "_checkpoint(\"select representative observation\")\n",
    "test_df = df_model.loc[df_model[\"split\"] == \"test\", :].copy()\n",
    "\n",
    "# Keep rect/invt in key_items even though WC release is deleted: quick ratio uses invt.\n",
    "key_items = [\"at\",\"che\",\"act\",\"lct\",\"rect\",\"invt\",\"dlc\",\"dltt\",\"oibdp\",\"xint\",\"oancf\",\"capx\",\"ceq\"]\n",
    "\n",
    "cand_mask = (test_df[\"pd_logit\"].between(0.15, 0.85)) & (test_df[\"pd_tree\"].between(0.15, 0.85))\n",
    "\n",
    "candidate_indices = []\n",
    "for idx in test_df.loc[cand_mask].index:\n",
    "    row_chk = df.loc[idx, :]\n",
    "    if not all(pd.notna(row_chk.get(k, np.nan)) for k in key_items):\n",
    "        continue\n",
    "    cr = _safe_div(row_chk.get(\"act\", np.nan), row_chk.get(\"lct\", np.nan))\n",
    "    if pd.notna(cr) and (0.2 <= cr <= 5.0):\n",
    "        candidate_indices.append(idx)\n",
    "\n",
    "if len(candidate_indices) == 0:\n",
    "    print(\"Warning: No observation meets strict criteria. Relaxing PD bounds to [0.10, 0.90].\")\n",
    "    cand_mask = (test_df[\"pd_logit\"].between(0.10, 0.90)) & (test_df[\"pd_tree\"].between(0.10, 0.90))\n",
    "    for idx in test_df.loc[cand_mask].index:\n",
    "        row_chk = df.loc[idx, :]\n",
    "        if not all(pd.notna(row_chk.get(k, np.nan)) for k in key_items):\n",
    "            continue\n",
    "        cr = _safe_div(row_chk.get(\"act\", np.nan), row_chk.get(\"lct\", np.nan))\n",
    "        if pd.notna(cr) and (0.2 <= cr <= 5.0):\n",
    "            candidate_indices.append(idx)\n",
    "\n",
    "if len(candidate_indices) == 0:\n",
    "    print(\"Warning: Fallback to highest-PD test observation with required raw items.\")\n",
    "    for idx in test_df.sort_values(\"pd_logit\", ascending=False).index:\n",
    "        row_chk = df.loc[idx, :]\n",
    "        if all(pd.notna(row_chk.get(k, np.nan)) for k in key_items):\n",
    "            candidate_indices = [idx]\n",
    "            break\n",
    "\n",
    "if len(candidate_indices) == 0:\n",
    "    raise ValueError(\"No suitable representative observation found. Inspect data quality and keys.\")\n",
    "\n",
    "rep_idx = test_df.loc[candidate_indices, \"pd_logit\"].idxmax()\n",
    "\n",
    "row0_raw  = df.loc[rep_idx, :].copy()\n",
    "row0_feat = df_model.loc[rep_idx, :].copy()\n",
    "\n",
    "# base feature row already contains z_ columns from upstream pipeline\n",
    "base_X = row0_feat[[f\"z_{c}\" for c in continuous_feats_raw] + event_feats].to_frame().T\n",
    "base_pd = {\"pd_logit\": float(row0_feat[\"pd_logit\"]), \"pd_tree\": float(row0_feat[\"pd_tree\"])}\n",
    "base_liq = compute_liquidity_from_raw_row(row0_raw)\n",
    "\n",
    "print(\"Representative observation (sensitivity-safe selection):\")\n",
    "display(df_model.loc[rep_idx, [\"firm_id\",\"fyear\",\"label_year\",\"pd_logit\",\"pd_tree\",\"target_next_v1\",\"target_next_v2\",\"target_next_v3\"]])\n",
    "print(\"Base PDs:\", base_pd)\n",
    "print(f\"Base liquidity: CR={base_liq['current_ratio']:.3f}, QR={base_liq['quick_ratio']:.3f}, \"\n",
    "      f\"evt_liq={base_liq['evt_liq_squeeze']:.0f}, evt_quick={base_liq['evt_quick_squeeze']:.0f}\")\n",
    "\n",
    "print(\"\\n=== Raw Accounting Sanity Check (Base) ===\")\n",
    "display(pd.DataFrame([{\"scenario\":\"base\", **{k: base_liq[k] for k in [\"current_ratio\",\"quick_ratio\",\"evt_liq_squeeze\",\"evt_quick_squeeze\"]}}]))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Run scenarios (ONLY cash burn + maturity wall)\n",
    "# -----------------------------------------------------------------------------\n",
    "_checkpoint(\"run scenarios\")\n",
    "scenario_rows = []\n",
    "\n",
    "def _append_result(name: str, row_s_raw: pd.Series):\n",
    "    Xs = build_model_features_from_raw_scenario(row_s_raw, row0_feat)\n",
    "    pds = predict_pd_from_features(Xs)\n",
    "    liq = compute_liquidity_from_raw_row(row_s_raw)\n",
    "    scenario_rows.append({\n",
    "        \"scenario\": name,\n",
    "        **pds,\n",
    "        \"current_ratio\": liq[\"current_ratio\"],\n",
    "        \"quick_ratio\": liq[\"quick_ratio\"],\n",
    "        \"evt_liq_squeeze\": liq[\"evt_liq_squeeze\"],\n",
    "        \"evt_quick_squeeze\": liq[\"evt_quick_squeeze\"],\n",
    "        \"traffic_light\": get_traffic_light(pds[\"pd_logit\"], liq[\"evt_liq_squeeze\"], liq[\"evt_quick_squeeze\"]),\n",
    "    })\n",
    "    return Xs\n",
    "\n",
    "# Base\n",
    "_ = _append_result(\"base\", row0_raw)\n",
    "\n",
    "# (A) Cash burn: burn fraction of ACT, reduce che/act/at; reduce ceq partially for rough coherence\n",
    "act_base = float(row0_raw.get(\"act\", 0.0) if pd.notna(row0_raw.get(\"act\", np.nan)) else 0.0)\n",
    "burn_rates = [0.10, 0.20, 0.30]\n",
    "\n",
    "for burn in burn_rates:\n",
    "    row_s = row0_raw.copy()\n",
    "    delta = burn * act_base\n",
    "\n",
    "    che0 = float(row_s.get(\"che\", 0.0) if pd.notna(row_s.get(\"che\", np.nan)) else 0.0)\n",
    "    act0 = float(row_s.get(\"act\", 0.0) if pd.notna(row_s.get(\"act\", np.nan)) else 0.0)\n",
    "    at0  = float(row_s.get(\"at\", 0.0)  if pd.notna(row_s.get(\"at\", np.nan))  else 0.0)\n",
    "    ceq0 = row_s.get(\"ceq\", np.nan)\n",
    "\n",
    "    row_s[\"che\"] = max(0.0, che0 - delta)\n",
    "    row_s[\"act\"] = max(0.0, act0 - delta)\n",
    "    row_s[\"at\"]  = max(1e-6, at0 - delta)  # keep positive for ln_at\n",
    "    if pd.notna(ceq0):\n",
    "        row_s[\"ceq\"] = max(0.0, float(ceq0) - 0.5 * delta)\n",
    "\n",
    "    Xs = _append_result(f\"cash_burn_{int(burn*100)}pct\", row_s)\n",
    "\n",
    "    audit_top = sensitivity_audit(base_X, Xs, threshold=1e-4, top_k=15)\n",
    "    mat_n = audit_top.attrs.get(\"material_count\", 0)\n",
    "\n",
    "    print(f\"\\n=== Sensitivity Audit: cash_burn_{int(burn*100)}pct ===\")\n",
    "    print(f\"Features changed (|Δz|>1e-4): {mat_n}\")\n",
    "    display(audit_top)\n",
    "\n",
    "# (C) Maturity wall: reclassify dltt->dlc and increase lct accordingly (dlc is part of lct)\n",
    "dlc0 = float(row0_raw.get(\"dlc\", 0.0) if pd.notna(row0_raw.get(\"dlc\", np.nan)) else 0.0)\n",
    "dltt0 = float(row0_raw.get(\"dltt\", 0.0) if pd.notna(row0_raw.get(\"dltt\", np.nan)) else 0.0)\n",
    "lct0 = float(row0_raw.get(\"lct\", 0.0) if pd.notna(row0_raw.get(\"lct\", np.nan)) else 0.0)\n",
    "total_debt0 = dlc0 + dltt0\n",
    "\n",
    "shift_rates = [0.10, 0.20]\n",
    "for sh in shift_rates:\n",
    "    row_s = row0_raw.copy()\n",
    "    shift_amt = sh * total_debt0\n",
    "\n",
    "    row_s[\"dltt\"] = max(0.0, dltt0 - shift_amt)\n",
    "    row_s[\"dlc\"]  = dlc0 + shift_amt\n",
    "    row_s[\"lct\"]  = lct0 + shift_amt\n",
    "\n",
    "    Xs = _append_result(f\"maturity_wall_{int(sh*100)}pct\", row_s)\n",
    "\n",
    "    audit_top = sensitivity_audit(base_X, Xs, threshold=1e-4, top_k=15)\n",
    "    mat_n = audit_top.attrs.get(\"material_count\", 0)\n",
    "\n",
    "    print(f\"\\n=== Sensitivity Audit: maturity_wall_{int(sh*100)}pct ===\")\n",
    "    print(f\"Features changed (|Δz|>1e-4): {mat_n}\")\n",
    "    display(audit_top)\n",
    "\n",
    "scenario_tbl = pd.DataFrame(scenario_rows)\n",
    "\n",
    "print(\"\\n=== Scenario Analysis Results ===\")\n",
    "cols = [\"scenario\",\"pd_logit\",\"pd_tree\",\"current_ratio\",\"quick_ratio\",\"evt_liq_squeeze\",\"evt_quick_squeeze\",\"traffic_light\"]\n",
    "display(scenario_tbl[cols])\n",
    "\n",
    "print(\"\\n=== Liquidity Traffic Light Summary ===\")\n",
    "traffic_summary = scenario_tbl[[\"scenario\",\"pd_logit\",\"evt_liq_squeeze\",\"evt_quick_squeeze\",\"traffic_light\"]].copy()\n",
    "traffic_summary[\"pd_tier\"] = traffic_summary[\"pd_logit\"].apply(lambda x: \"Low\" if x < 0.2 else (\"Medium\" if x < 0.5 else \"High\"))\n",
    "display(traffic_summary)\n",
    "\n",
    "print(\"[9.5] finished OK\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "757172aa",
   "metadata": {},
   "source": [
    "## 10. Results Summary & Interpretation Guardrails\n",
    "\n",
    "### 10.1 Interpretation guardrails (publication-ready language)\n",
    "\n",
    "- The label is a **constructed proxy** for balance-sheet/coverage stress; it is not a legal default outcome.\n",
    "- Coefficients and SHAP values are **associational and predictive**, not causal effects.\n",
    "- Even with leakage controls, residual mechanical endogeneity may remain because accounting choices jointly affect both predictors and the proxy label.\n",
    "- Attrition (missing next-year observations) can create sample-selection distortions; diagnostics are reported via `has_next_year_obs`.\n",
    "\n",
    "### 10.2 Replication artifacts\n",
    "\n",
    "The following tables/exports are written to `outputs/` for downstream paper workflow:\n",
    "- `config_summary.json`\n",
    "- `distress_rule.json`\n",
    "- `event_dictionary.csv`\n",
    "- `logit_inference_table.csv`\n",
    "- `metrics_table.csv`\n",
    "- `predictions.csv`\n",
    "\n",
    "### 10.3 Export tables, thresholds, and predictions"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9838ad0",
   "metadata": {},
   "source": [
    "out_dir = Path(CONFIG[\"OUTPUT_DIR\"])\n",
    "\n",
    "# Config + distress rule\n",
    "(out_dir / \"config_summary.json\").write_text(json.dumps(CONFIG, indent=2))\n",
    "(out_dir / \"distress_rule.json\").write_text(json.dumps(DISTRESS_RULE, indent=2))\n",
    "\n",
    "# Event dictionary\n",
    "event_dict.to_csv(out_dir / \"event_dictionary.csv\", index=False)\n",
    "\n",
    "# Logit inference table\n",
    "infer_tbl.reset_index().to_csv(out_dir / \"logit_inference_table.csv\", index=False)\n",
    "\n",
    "# Metrics table\n",
    "metrics_tbl.to_csv(out_dir / \"metrics_table.csv\", index=False)\n",
    "\n",
    "# Predictions export (replication-friendly)\n",
    "export_cols = [\"firm_id\",\"gvkey\",\"fyear\",\"label_year\",\"split\",\"target_next_v1\",\"target_next_v2\",\"target_next_v3\",\"pd_logit\",\"pd_tree\"]\n",
    "export_cols = [c for c in export_cols if c in df_model.columns]\n",
    "export_cols += [c for c in event_feats if c in df_model.columns]\n",
    "pred_export = df_model[export_cols].copy()\n",
    "pred_export.to_csv(out_dir / \"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Wrote artifacts to:\", out_dir.resolve())\n",
    "print_df(pred_export, n=10, name=\"predictions.csv preview\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50eece1d",
   "metadata": {},
   "source": [
    "### 10.4 Deployment and maintenance (future work)\n",
    "\n",
    "This notebook produces a research-grade replication pipeline. For production use (not required for journal replication), a minimal MLOps extension would include:\n",
    "- scheduled re-scoring and monitoring for drift in feature distributions and target prevalence,\n",
    "- retraining triggers and versioned model registry,\n",
    "- data validation contracts (schema + unit tests) for the upstream Compustat extraction process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
